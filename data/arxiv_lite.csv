title,summary,comment,authors,category,split
Gamma-Ray Bursts as the Death Throes of Massive Binary Stars,"It is proposed that gamma-ray bursts are created in the mergers of double neutron star binaries and black hole neutron star binaries at cosmological distances. Bursts with complex profiles and relatively long durations are the result of magnetic flares generated by the Parker instability in a post-merger differentially-rotating disk. Some bursts may also be produced through neutrino-antineutrino annihilation into electrons and positrons. In both cases, an optically thick fireball of size $\sles\ 100$ km is initially created, which expands ultrarelativistically to large radii before radiating. Several previous objections to the cosmological merger model are eliminated. It is predicted that $\gamma$-ray bursts will be accompanied by a burst of gravitational radiation from the spiraling-in binary which could be detected by LIGO.",14 pages,"Ramesh Narayan, Bohdan Paczyński, Tsvi Piran",physics,test
Gravitational Lensing and the Variability of G,"The four observables associated with gravitational lensing of distant quasars by intervening galaxies: image splittings, relative amplifications, time delays, and optical depths, provide separate measures of the strength of the gravitational constant $G$ at cosmological distances. These allow one, in principle, to factor out unknown lensing parameters to directly to probe the variation of $G$ over cosmological time. We estimate constraints on $\dot{G}$ which may be derivable by this method both now and in the future. The limits one may obtain can compete or exceed other direct limits on $\dot{G}$ today, but unfortunately extracting this information, is not independent of the effort to fix other cosmological parameters such as $H_0$ and $\Omega_0$ from lensing observations.",13 pages plus figures (not included),"Lawrence Krauss, Martin White",physics,val
The Ptolemaic Gamma-Ray Burst Universe,"The BATSE experiment on GRO has demonstrated the isotropic arrival directions and flat $\log N$ {\it vs.} $\log S$ of cosmic gamma-ray bursts. These data are best explained if the burst sources are distributed throughout an extended spherical Galactic halo, as previously suggested by Jennings. The halo's radius is at least 40 Kpc, and probably is more than 100 Kpc. I consider possible origins of this halo, including primordial formation and neutron stars recoiling from their birthplaces in the Galactic disc. A simple geometrical model leads to a predicted relation between the dipole and quadrupole anisotropy. I suggest that neutron stars born with low recoil become millisecond pulsars, while those born with high recoil become the sources of gamma-ray bursts; these populations are nearly disjoint. Quiescent counterparts of gamma-ray bursts are predicted to be undetectably faint.",10 pages (Replaced to provide omitted line.),J. I. Katz,physics,train
Expanding Photospheres of Type II Supernovae and the Extragalactic Distance Scale,"We use the Expanding Photosphere Method to determine distances to 10 type II supernovae. The effects of asymmetries, extinction, and flux dilution are explored. Using empirical evidence and time-independent, spherical models which treat H and He in non-LTE, we show that blackbody corrections caused by flux dilution are small for type II supernovae in the infrared, and in the optical when their color temperatures are less than 6000~K. The extinction to a type II-P supernova can be estimated from its light curve: the uncertainty introduced into a distance measurement due to extinction is usually less than 10\%. Correcting for extinction and flux dilution we derive distances to 10 supernovae: SN 1968L, SN 1969L, SN 1970G, SN 1973R, SN 1979C, SN 1980K, SN 1987A, SN 1988A, SN 1990E, and SN 1990ae. The distance measurements span a wide range, 50 kpc to 120 Mpc, which is unique among the methods for establishing the extragalactic distance scale. The distances measured to SN 1970G in M101 and SN 1987A in the LMC are in good agreement with distances determined from Cepheid variable stars. Our distance to the Virgo Cluster, 22 +- 3 Mpc, is larger than recent distances estimates made using surface brightness fluctuations, planetary nebula luminosity functions, and the Tully-Fisher method. Using the distances determined from these type II supernovae we derive a value of $H_0 = 60 \pm 10$ km sec$^{-1}$Mpc$^{-1}$. This value is subject to errors caused by local deviations in the Hubble flow, but will soon be improved by applying the Expanding Photosphere Method to several distant type II supernovae.",21 pages,"B P Schmidt, R P Kirshner, R G Eastman",physics,train
Radiation Transfer in Gamma-Ray Bursts,"We have calculated gamma-ray radiative transport in regions of high energy density, such as gamma-ray burst source regions, using a discrete ordinate, discrete energy group method. The calculations include two-photon pair production and annihilation, as well as three-photon pair annihilation. The radiation field itself acts as an absorbing medium, and the optical depth depends on its intensity, so the problem is intrinsically nonlinear. Spherical divergence produces effective collimation of the flux. At high optical depth the high energy ($E > 1$ MeV) portion of the emergent spectrum assumes a nearly universal form. An approximate limit is derived for the high energy flux from a gamma-ray burst source region of given size, and the implications of this limit for the distance to the March 5, 1979 event are briefly discussed. We discuss more generally the problem of very luminous bursts, and implications of Galactic halo distances for flare models.",24 pages,"B. J. Carrigan, J. I. Katz",physics,test
Nova Dust Nucleation: Kinetics and Photodissociation,"Dust is observed to form in nova ejecta. The grain temperature is determined by the diluted nova radiation field rather than the gas kinetic temperature, making classical nucleation theory inapplicable. We used kinetic equations to calculate the growth of carbon nuclei in these ejecta. For expected values of the parameters too many clusters grew, despite the small sticking probability of atoms to small clusters, and the clusters only reached radii of about 100\AA\ when the carbon vapor was depleted. We then included the effects of cluster photodissociation by ultraviolet radiation from the nova. This suppresses nucleation, but too well, and no grains form at all. Finally we suggest that a few growing carbon nuclei may be protected from photodissociation by a sacrificial surface layer of hydrogen.",29 pages,"D. J. Johnson, M. W. Friedlander, J. I. Katz",physics,train
Nonstationary Gravitational Lenses and the Fermat Principle,"We apply Perlick's (1990a) rigorous formulation of the Fermat principle in arbitrary spacetimes to prove the correctness of the description of gravitational lensing by gravitational waves, given in the literature using the scalar and vector formalisms. We obtain an expression for the time delay due to such nonstationary lenses; the advantage over previous papers is that Perlick's formulation of the Fermat principle is very rigorous and more suitable for practical calculations in some cases. It is also shown that ordinary moving gravitational lenses must be considered as a stationary case.",12 pages,Valerio Faraoni,physics,train
Giant Molecular Cloud Formation through the Parker Instability in a Skewed Magnetic Field,"The effect of the magnetic skew on the Parker instability is investigated by means of the linear stability analysis for a gravitationally stratified gas layer permeated by a horizontal magnetic field. When the magnetic field is skewed (i.e., the field line direction is a function of the height), the wavelength of the most unstable mode is $ \lambda \; \sim \; 10 H $ where $ H $ is the pressure scale height. The growth rate of the short wavelength modes is greatly reduced when the gradient in the magnetic field direction exceeds 0.5 radian per scale height. Our results indicate that the Parker instability in a skewed magnetic field preferentially forms large scale structures like giant molecular clouds.",12 pages,"T. Hanawa, R. Matsumoto, K. Shibata",physics,train
Particle Acceleration in (by) Accretion Discs,"I present a model for acceleration of protons by the second-order Fermi process acting on randomly scrambled magnetic flux arches above an accretion disc. The accelerated protons collide with thermal protons in the disc, producing degraded energetic protons, charged and neutral pions, and neutrons. The pions produce gamma-rays by spontaneous decay of $\pi^0$ and by bremsstrahlung and Compton processes following the decay of $\pi^\pm$ to $e^\pm$.",3 pages,J. I. Katz,physics,train
The Spatial Distribution of Nearby Galaxy Clusters in the Northern and Southern Galactic Hemispheres,"We compare the spatial distributions of galaxy clusters in the northern and southern galactic hemispheres, and the Abell and ACO clusters distributions. We perform a statistical (correlation and cluster) analysis of a sample of Abell and ACO galaxy clusters in the southern galactic hemisphere. We compare these results with a symmetric sample at northern galactic latitude taken from Postman et al. (1992). For the northern sample, we substantially confirm the results of Postman et al. We find that the two-point spatial correlation function of northern and southern clusters is comparable, with mean correlation length 19.6 Mpc and slope -1.8 positive up to about 45 Mpc. Percolation properties are remarkably similar in the northern and southern cluster samples. We give also a catalog of superclusters. In the south galactic hemisphere the main feature is a very rich, extended supercluster in the Horologium region at a redshift 0.06, near to a large void.",20 pages,"A. Cappi, S. Maurogordato",physics,train
Non-Minimal Quintessence With Nearly Flat Potential,"We consider Brans-Dicke type nonminimally coupled scalar field as a candidate for dark energy. In the conformally transformed Einstein's frame, our model is similar to {\it coupled quintessence} model. In such models, we consider potentials for the scalar field which satisfy the slow-roll conditions: $[(1/V)(dV/d\phi)]^2 << 1$ and $(1/V)(d^2V/d\phi^2) << 1$. For such potentials, we show that the equation of state for the scalar field can be described by a universal behaviour, provided the scalar field rolls only in the flat part of the potentials where the slow-roll conditions are satisfied. Our work generalizes the previous work by Scherrer and Sen \cite{scherrer} for minimally coupled scalar field case. We have also studied the observational constraints on the model parameters considering the Supernova and BAO observational data.",,"Anjan A Sen, Gaveshna Gupta, Sudipta Das",physics,val
Robust determination of the major merger fraction at z = 0.6 in Groth Strip,"(Abridged) We measure the fraction of galaxies undergoing disk-disk major mergers (f_m) at intermediate redshifts (0.35 <= z < 0.85) by studying the asymmetry index A of galaxy images. Results are provided for B- and Ks-band absolute magnitude selected samples from the Groth strip in the GOYA photometric survey. Three sources of systematic error are carefully addressed: (i) we avoid morphological K-corrections, (ii) we measure asymmetries in artificially redshifted to z_d = 0.75 galaxies to lead with loss of morphological information with redshift, and (iii) we take into account the observational errors in z and A, that tend to overestimate the merger fraction, by maximum likelihood techniques. We find: (i) our data allow for a robust merger fraction to be provided for a single redshift bin centered at z=0.6. (ii) Merger fractions have low values: f_m = 0.045 for M_B <= -20 galaxies, and f_m = 0.031 for M_Ks <= -23.5 galaxies. And, (iii) failure to address the effects of the observational errors leads to overestimating f_m by factors of 10%-60%. Combining our results with those on literature, and parameterizing the merger fraction evolution as f_m(z) = f_m(0)(1+z)^m, we obtain that m = 2.9 +- 0.8, and f_m(0) = 0.012 +- 0.004$. Assuming a Ks-band mass-to-light ratio not varying with luminosity, we infer that the merger rate of galaxies with stellar mass M >= 3.5x10^10 M_Sun is R_m = 1.6x10^-4 Mpc^-3 Gyr^-1. When we compare with previous studies at similar redshifts, we find that the merger rate decreases when mass increases.","Accepted for publication in ApJ. 11 pages, 7 figures, 3 tables.
  Formatted with emulateapj","C. López-Sanjuan, M. Balcells, C. E. García-Dabó, M. Prieto, D. Cristóbal-Hornillos, M. C. Eliche-Moral, D. Abreu, P. Erwin, R. Guzmán",physics,test
"Neutrino Masses, Dark Energy and the Gravitational Lensing of Pregalactic HI",We study the constraints which the next generation of radio telescopes could place on the mass and number of neutrino species by studying the gravitational lensing of high redshift 21 cm emission in combination with wide-angle surveys of galaxy lensing. We use simple characterizations of reionization history and of proposed telescope designs to forecast the constraints and detectability threshold for neutrinos. It is found that the degeneracy between neutrino parameters and dark energy parameters is significantly reduced by incorporating 21 cm lensing. The combination of galaxy and 21 cm lensing could constrain the sum of the neutrino masses to within ~ 0.04 eV and the number of species to within ~ 0.1. This is an improvement of a factor of 2.6 in mass and 1.3 in number over a galaxy lensing survey alone. This includes marginalizing over an 11 parameter cosmological model with a two parameter model for the dark energy equation of state. If the dark energy equation of state is held fixed at w = p/\rho=-1 the constraints improve to ~0.03 eV and 0.04. These forecasted errors depend critically on the fraction of sky that can be surveyed in redshifted 21 cm emission (25% is assumed here) and the redshift of reionization ($z=7$ is assumed here). It is also found that neutrinos with masses too small to be detected in the data could none the less cause a significant bias in the measured dark energy equation of state.,"7 pages, 6 figures, submitted to MNRAS",R. Benton Metcalf,physics,val
Impact of Instrumental Systematic Contamination on the Lensing Mass Reconstruction using the CMB Polarization,"In this paper, we study the effects of instrumental systematics on the reconstruction of the deflection angle power spectrum from weak lensing of Cosmic Microwave Background (CMB) temperature and polarization observations. We consider seven types of effects which are related to known instrumental systematics: calibration, rotation, pointing, spin-flip, monopole leakage, dipole leakage and quadrupole leakage. These effects can be characterized by 11 distortion fields. Each of these systematic effects can mimic the effective projected matter power spectrum and hence contaminate the lensing reconstruction. To demonstrate the effect of these instrumental systematics, we consider two types of experiments, one with a detector noise level for polarization of 9.6 uK-arcmin and FWHM of 8.0', typical of upcoming ground and balloon-based CMB experiments, and a CMBPol-like instrument with a detector noise level for polarization of 2.0 uK-arcmin and FWHM of 4.0', typical of future space-based CMB experiments. For each systematics, we consider various choices of coherence scale. Among all the 11 systematic parameters, rotation and monopole leakage place the most stringent requirements, while quadrupole leakage, pointing error, and calibration are among the least demanding. The requirements from lensing extraction are about 1-2 orders of magnitude less stringent than the requirements to measure the primordial B-modes with inflationary energy scale of 1.0*10^{16} GeV. On the other hand the requirements for lensing reconstruction are comparable or even more stringent for some systematic parameters than the requirements to detect primordial B-modes with inflationary scale E_i = 3.0*10^{16} GeV.","22 pages, 7 figures","Meng Su, Amit P. S. Yadav, Matias Zaldarriaga",physics,val
Tracing the Reionization-Epoch Intergalactic Medium with Metal Absorption Lines,"IGM metal absorption lines observed in z>6 spectra offer the opportunity to probe early feedback processes, the nature of enriching sources, and the topology of reionization. We run high-resolution cosmological simulations including galactic outflows to study the observability and physical properties of 5 ions (C II, C IV, O I, Si II, Si IV) in absorption between z=8->5. We apply three cases for ionization conditions: Fully neutral, fully reionized, and a patchy model based on the flux from the nearest galaxy. We find that our simulations broadly fit available z~5-6 IGM metal-line data, although all observations cannot be accommodated with a single ionization condition. Variations in O I absorbers among sight lines seen by Becker et al. (2006) suggest significant neutral IGM patches down to z~6. Strong C IV absorbers at z~6 may be the result of ionization by their parent galaxy. Our outflows have typical speeds of ~200 km/s and mass loading factors of ~6. Such high mass loading is critical for enriching the IGM to the observed levels while curtailing star formation to match the observed z~6 rest-frame UV luminosity function. The volume filling factor of metals increases during this epoch, but only reaches ~1% for Z>10^(-3) Zsolar by z=5. C IV is an ideal tracer of IGM metals at z~5-6, with dropping global ionization fractions to either higher or lower redshifts. This results in a strongly increasing global Omega(C IV) from z=8->5, in contrast to its relative constancy from z=5->2. Our simulations do not support widespread early IGM enrichment from e.g. Pop III stars. High-z absorbers arise from metals on their first outward journey from galaxies, at distances less than 50 kpc. The galaxies responsible for early IGM enrichment have typical M*=10^(7.0-8.5) Msolar.","Accepted to MNRAS, 34 pages, 24 figures, 1 table (Sections 5.5,
  6.3.1, & 6.3.2 added as well as 5 figures and 1 table)","Benjamin D. Oppenheimer, Romeel Davé, Kristian Finlator",physics,train
Lensing effects in inhomogeneous cosmological models,"Concepts developed in the gravitational lensing techniques such as shear, convergence, tangential and radial arcs maybe used to see how tenable inhomogeneous models proposed to explain the acceleration of the universe models are. We study the widely discussed LTB cosmological models. It turns out that for the observer sitting at origin of a global LTB solution the shear vanishes as in the FRW models, while the value of convergence is different which may lead to observable cosmological effects. We also consider Swiss-cheese models proposed recently based on LTB with an observer sitting in the FRW part. It turns out that they have different behavior as far as the formation of radial and tangential arcs are concerned.","8 pages, 8 figures","Sima Ghassemi, Salomeh Khoeini Moghaddam, Reza Mansouri",physics,val
Classical Cosmological Tests for Galaxies of the Hubble Ultra Deep Field,"Images of the Hubble Ultra Deep Field are analyzed to obtain a catalog of galaxies for which the angular sizes, surface brightness, photometric redshifts, and absolute magnitudes are found. The catalog contains a total of about 4000 galaxies identified at a high signal-to-noise ratio, which allows the cosmological relations angular size{redshift and surface brightness-redshift to be analyzed. The parameters of the evolution of linear sizes and surface brightness of distant galaxies in the redshift interval 0.5-6.5 are estimated in terms of a grid of cosmological models with different density parameters. The distribution of photometric redshifts of galaxies is analyzed and possible superlarge inhomogeneities in the radial distribution of galaxies are found with scale lengths as large as 2000 Mpc.","23 pages, 9 figures, 1 table","Nikita V. Nabokov, Yuriy V. Baryshev",physics,train
Gravitational waves in the Hyperspace?,"In the framework of the debate on high-frequency gravitational waves (GWs), after a review of GWs in standard General Relativity, which is due for completness, the possibility of merging such a traditional analysis with the Hyperspace formalism that has been recently introduced in some papers in the literature, with the goal of a better understanding of manifolds dimensionality also in a cosmological framework, is discussed. Using the concept of refractive index in the Hyperspace, spherical solutions are given and the propagation of GWs in a region of the Hyperspace with an unitary refractive index is also discussed. Propagation phenomena associated to the higher dimensionality are proposed, possibly including non-linear effects. Further and accurate studies in this direction are needed.","Accepted for publication by Modern Physics Letters A. In the new
  version the references have been updated","Christian Corda, Giorgio Fontana, Gloria Garcia Cuadrado",physics,train
HD and H2 formation in low-metallicity dusty gas clouds at high redshift,"Context: The HD and H2 molecules play important roles in the cooling of primordial and very metal-poor gas at high redshift. Aims: Grain surface and gas phase formation of HD and H2 is investigated to assess the importance of trace amounts of dust, 10^{-5}-10^{-3} Zo, in the production of HD and H2. Methods: We consider carbonaceous and silicate grains and include both physisorption and chemisorption, tunneling, and realistic grain surface barriers. We find, for a collapsing gas cloud environment with coupled chemical and thermal balance, that dust abundances as small as 10^{-5} solar lead to a strong boost in the H2 formation rate due to surface reactions. As a result of this enhancement in H2, HD is formed more efficiently in the gas phase through the D+ + H2 reaction. Direct formation of HD on dust grains cannot compete well with this gas phase process for dust temperatures below 150 K. We also derive up-to-date analytic fitting formulae for the grain surface formation of H2 and HD, including the different binding energies of H and D. Results: Grain surface reactions are crucial to the availability of H2 and HD in very metal-poor environments. Above metallicities of 10^{-5} solar, the grain surface route dominates the formation of H2, which in turn, drives the formation of HD in the gas phase. At dust temperatures above 150 K, laboratory experiments and theoretical modelling suggest that H2 formation on grains is suppressed while HD formation on grains is not.","typos corrected, accepted for publication in Astronomy and
  Astrophysics","S. Cazaux, M. Spaans",physics,train
Black hole spin and radio loudness in a LCDM universe,"We use a combination of a cosmological N-body simulation of the concordance Lambda cold dark matter (LCDM) paradigm and a semi-analytic model of galaxy formation to investigate the spin development of central supermassive black holes (BHs) and its relation to the BH host galaxy properties. In order to compute BH spins, we use the alpha-model of Shakura & Sunyaev and consider the King et al. warped disc alignment criterion. The orientation of the accretion disc is inferred from the angular momentum of the source of accreted material, which bears a close relationship to the large-scale structure in the simulation. We find that the final BH spin depends almost exclusively on the accretion history and only weakly on the warped disc alignment. The main mechanisms of BH spin-up are found to be gas cooling processes and disc instabilities, a result that is only partially compatible with Monte-Carlo models where the main spin-up mechanisms are major mergers and disc instabilities; the latter results are reproduced when implementing randomly oriented accretion discs in our model. Regarding the BH population, we find that more massive BHs, which are hosted by massive ellipticals, have higher spin values than less-massive BHs, hosted by spiral galaxies. We analyse whether gas accretion rates and BH spins can be used as tracers of the radio loudness of active galactic nuclei (AGN). We find that the current observational indications of an increasing trend of radio-loud AGN fractions with stellar and BH mass can be easily obtained when placing lower limits on the BH spin, with a minimum influence from limits on the accretion rates; a model with random accretion disc orientations is unable to reproduce this trend. (ABRIDGED)","13 pages, 8 figures. Accepted for publication in MNRAS","Claudia del P. Lagos, Nelson D. Padilla, Sofia A. Cora",physics,train
HAT-P-11b: A Super-Neptune Planet Transiting a Bright K Star in the Kepler Field,"We report on the discovery of HAT-P-11b, the smallest radius transiting extrasolar planet (TEP) discovered from the ground, and the first hot Neptune discovered to date by transit searches. HAT-P-11b orbits the bright (V=9.587) and metal rich ([Fe=H] = +0.31 +/- 0.05) K4 dwarf star GSC 03561-02092 with P = 4.8878162 +/- 0.0000071 days and produces a transit signal with depth of 4.2 mmag. We present a global analysis of the available photometric and radial-velocity data that result in stellar and planetary parameters, with simultaneous treatment of systematic variations. The planet, like its near-twin GJ 436b, is somewhat larger than Neptune (17Mearth, 3.8Rearth) both in mass Mp = 0.081 +/- 0.009 MJ (25.8 +/- 2.9 Mearth) and radius Rp = 0.422 +/- 0.014 RJ (4.73 +/- 0.16 Rearth). HAT-P-11b orbits in an eccentric orbit with e = 0.198 +/- 0.046 and omega = 355.2 +/- 17.3, causing a reflex motion of its parent star with amplitude 11.6 +/- 1.2 m/s, a challenging detection due to the high level of chromospheric activity of the parent star. Our ephemeris for the transit events is Tc = 2454605.89132 +/- 0.00032 (BJD), with duration 0.0957 +/- 0.0012 d, and secondary eclipse epoch of 2454608.96 +/- 0.15 d (BJD). The basic stellar parameters of the host star are M* = 0.809+0.020-0.027 Msun, R* = 0.752 +/- 0.021 Rsun and Teff = 4780 +/- 50 K. Importantly, HAT-P-11 will lie on one of the detectors of the forthcoming Kepler mission. We discuss an interesting constraint on the eccentricity of the system by the transit light curve and stellar parameters. We also present a blend analysis, that for the first time treats the case of a blended transiting hot Jupiter mimicing a transiting hot Neptune, and proves that HAT-P-11b is not such a blend.","Accepted for publication in ApJ, 24 pages, 14 figures, 6 tables. All
  RV data presented in this version","G. Á. Bakos, G. Torres, A. Pál, J. Hartman, Géza Kovács, R. W. Noyes, D. W. Latham, D. D. Sasselov, B. Sipőcz, G. A. Esquerdo, D. A. Fischer, J. A. Johnson, G. W. Marcy, R. P. Butler, H. Isaacson, A. Howard, S. Vogt, Gábor Kovács, J. Fernandez, A. Moór, R. P. Stefanik, J. Lázár, I. Papp, P. Sári",physics,train
Physical collisions of moonlets and clumps with the Saturn's F-ring core,"Since 2004, observations of Saturn's F ring have revealed that the ring's core is surrounded by structures with radial scales of hundreds of kilometers, called ""spirals"" and ""jets"". Gravitational scattering by nearby moons was suggested as a potential production mechanism; however, it remained doubtful because a population of Prometheus-mass moons is needed and, obviously, such a population does not exist in the F ring region. We investigate here another mechanism: dissipative physical collisions of kilometer-size moonlets (or clumps) with the F-ring core. We show that it is a viable and efficient mechanism for producing spirals and jets, provided that massive moonlets are embedded in the F-ring core and that they are impacted by loose clumps orbiting in the F ring region, which could be consistent with recent data from ISS, VIMS and UVIS. We show also that coefficients of restitution as low as ~0.1 are needed to reproduce the radial extent of spirals and jets, suggesting that collisions are very dissipative in the F ring region. In conclusion, spirals and jets would be the direct manifestation the ongoing collisional activity of the F ring region.","Accepted for publication in ICARUS 17 pages, 6 figures, 1 table",Sebastien Charnoz,physics,test
Discovering the Growth Histories of Exoplanets: The Saturn Analog HD 149026b,"The transiting ""hot Saturn"" HD 149026b, which has the highest mean density of any confirmed planet in the Neptune-Jupiter mass range, has challenged theories of planet formation since its discovery in 2005. Previous investigations could not explain the origin of the planet's 45-110 Earth-mass solid core without invoking catastrophes such as gas giant collisions or heavy planetesimal bombardment launched by neighboring planets. Here we show that HD 149026b's large core can be successfully explained by the standard core accretion theory of planet formation. The keys to our reconstruction of HD 149026b are (1) applying a model of the solar nebula to describe the protoplanet nursery; (2) placing the planet initially on a long-period orbit at Saturn's heliocentric distance of 9.5 AU; and (3) adjusting the solid mass in the HD 149026 disk to twice that of the solar nebula in accordance with the star's heavy element enrichment. We show that the planet's migration into its current orbit at 0.042 AU is consistent with our formation model. Our study of HD 149026b demonstrates that it is possible to discover the growth history of any planet with a well-defined core mass that orbits a solar-type star.","20 pages, including 3 figures. Accepted for publication in ApJ
  letters. Discussion updated to include new NICMOS transit photometry (Carter
  et al. 2009)","Sarah E. Dodson-Robinson, Peter Bodenheimer",physics,train
Transit observations at the observatory in Grossschwabhausen: XO-1b and TrES-1,"We report on observations of transit events of the transiting planets XO-1b and TrES-1 with the AIU Jena telescope in Grossschwabhausen. Based on our IR photometry (in March 2007) and available transit timings (SuperWASP, XO and TLC-project-data) we improved the orbital period of XO-1b (P = 3.941497$\pm$0.000006) and TrES-1 (P = 3.0300737$\pm$0.000006), respectively. The new ephemeris for the both systems are presented.","4 pages, 2 figures","M. Vanko, St. Raetz, M. Mugrauer, T. O. B. Schmidt, T. Roell, T. Eisenbeiss, M. Hohle, A. Seifahrt, A. Koeltzsch, Ch. Broeg, J. Koppenhoefer, R. Neuhaeuser",physics,val
Thermal Tides in Short Period Exoplanets,"Time-dependent insolation in a planetary atmosphere induces a mass quadrupole upon which the stellar tidal acceleration can exert a force. This ""thermal tide"" force can give rise to secular torques on the planet and orbit as well as radial forces causing eccentricity evolution. We apply this idea to the close-in gas giant exoplanets (""hot Jupiters""). The response of radiative atmospheres is computed in a hydrostatic model which treats the insolation as a time-dependent heat source, and solves for thermal radiation using flux-limited diffusion. Fully nonlinear numerical simulations are compared to solutions of the linearized equations, as well as analytic approximations, all of which are in good agreement. We find generically that thermal tide density perturbations {\it lead} the semi-diurnal forcing. As a result thermal tides can generate asynchronous spin and eccentricity. Our results are as follows: (1) Departure from synchronous spin is significant for hot Jupiters, and increases with orbital period. (2) Ongoing gravitational tidal dissipation in spin equilibrium leads to steady-state internal heating rates up to $\sim 10^{28} {\rm erg\ s^{-1}}$. If deposited sufficiently deep, these heating rates may explain the anomalously large radii of many hot Jupiters in terms of a ""tidal main sequence"" where cooling balances tidal heating. At fixed stellar type, planet mass and tidal $Q$, planetary radius increases strongly toward the star inside orbital periods $\la 2$ weeks. (3) There exists a narrow window in orbital period where small eccentricities, $e$, grow exponentially with a large rate. This window may explain the $\sim 1/4$ of hot Jupiters which should have been circularized by the gravitational tide long ago, but are observed to have significant nonzero $e$.(Abridged)",Submitted to ApJ,"Phil Arras, Aristotle Socrates",physics,val
A Metric and Optimisation Scheme for Microlens Planet Searches,"OGLE III and MOA II are discovering 600-1000 Galactic Bulge microlens events each year. This stretches the resources available for intensive follow-up monitoring of the lightcurves in search of anomalies caused by planets near the lens stars. We advocate optimizing microlens planet searches by using an automatic prioritization algorithm based on the planet detection zone area probed by each new data point. This optimization scheme takes account of the telescope and detector characteristics, observing overheads, sky conditions, and the time available for observing on each night. The predicted brightness and magnification of each microlens target is estimated by fitting to available data points. The optimisation scheme then yields a decision on which targets to observe and which to skip, and a recommended exposure time for each target, designed to maximize the planet detection capability of the observations. The optimal strategy maximizes detection of planet anomalies, and must be coupled with rapid data reduction to trigger continuous follow-up of anomalies that are thereby found. A web interface makes the scheme available for use by human or robotic observers at any telescope. We also outline a possible self-organising scheme that may be suitable for coordination of microlens observations by a heterogeneous telescope network.","17 pages, 15 figures, MNRAS in press (6 Jan 2009)","Keith Horne, Colin Snodgrass, Yianni Tsapras",physics,train
Abundances of the elements in the solar system,A review of the abundances and condensation temperatures of the elements and their nuclides in the solar nebula and in chondritic meteorites. Abundances of the elements in some neighboring stars are also discussed.,"42 pages, 11 tables, 8 figures, chapter, In Landolt- B\""ornstein, New
  Series, Vol. VI/4B, Chap. 4.4, J.E. Tr\""umper (ed.), Berlin, Heidelberg, New
  York: Springer-Verlag, p. 560-630","K. Lodders, H. Palme, H. -P. Gail",physics,train
The Earth as an extrasolar planet: The vegetation spectral signature today and during the last Quaternary climatic extrema,"The so-called Vegetation Red-Edge (VRE), a sharp increase in the reflectance around $700 nm$, is a characteristic of vegetation spectra, and can therefore be used as a biomarker if it can be detected in an unresolved extrasolar Earth-like planet integrated reflectance spectrum. Here we investigate the potential for detection of vegetation spectra during the last Quaternary climatic extrema, the Last Glacial Maximum (LGM) and the Holocene optimum, for which past climatic simulations have been made. By testing the VRE detectability during these extrema when Earth's climate and biomes maps were different from today, we are able to test the vegetation detectability on a terrestrial planet different from our modern Earth. Data from the Biome3.5 model have been associated to visible GOME spectra for each biome and cloud cover to derive Earth's integrated spectra for given Earth phases and observer positions. The VRE is then measured. Results show that the vegetation remains detectable during the last climatic extrema. Compared to current Earth, the Holocene optimum with a greener Sahara slightly increases the mean VRE on one hand, while on the other hand, the large ice cap over the northern Hemisphere during the LGM decreases vegetation detectability. We finally discuss the detectability of the VRE in the context of recently proposed space missions.","31-page manuscript, 12 figures, accepted for publication in Int. J.
  of Astrobiology","Luc Arnold, François-Marie Bréon, Simon Brewer",physics,val
On the various origins of close-in extrasolar planets,"The extrasolar planets (EPs) so far detected are very different to the planets in our own Solar System. Many of them have Jupiter-like masses and close-in orbits (the so-called hot planets, HPs), with orbital periods of only a few days. In this paper, we present a new statistical analysis of the observed EPs, focusing on the origin of the HPs. Among the several HP formation mechanisms proposed so far, the two main formation mechanisms are type II migration and scattering. In both cases, planets form beyond the so-called snow-line of the protoplanetary disk and then migrate inward due to angular momentum and energy exchange with either the protoplanetary disk or with companion planets. Although theoretical studies produce a range of observed features, no firm correspondence between the observed EPs and models has yet been established. In our analysis, by means of principal component analysis and hierarchical cluster analysis, we find convincing indications for the existence of two types of HPs, whose parameters reflect physical mechanisms of type II migration and scattering.","5 pages, 4 figures; Accepted on 2009 January 3 by MNRAS Letters","S. Marchi, S. Ortolani, M. Nagasawa, S. Ida",physics,train
"Intermittent turbulence, noisy fluctuations and wavy structures in the Venusian magnetosheath and wake","Recent research has shown that distinct physical regions in the Venusian induced magnetosphere are recognizable from the variations of strength of the magnetic field and its wave/fluctuation activity. In this paper the statistical properties of magnetic fluctuations are investigated in the Venusian magnetosheath and wake regions. The main goal is to identify the characteristic scaling features of fluctuations along Venus Express (VEX) trajectory and to understand the specific circumstances of the occurrence of different types of scalings. For the latter task we also use the results of measurements from the previous missions to Venus. Our main result is that the changing character of physical interactions between the solar wind and the planetary obstacle is leading to different types of spectral scaling in the near-Venusian space. Noisy fluctuations are observed in the magnetosheath, wavy structures near the terminator and in the nightside near-planet wake. Multi-scale turbulence is observed at the magnetosheath boundary layer and near the quasi-parallel bow shock. Magnetosheath boundary layer turbulence is associated with an average magnetic field which is nearly aligned with the Sun-Venus line. Noisy magnetic fluctuations are well described with the Gaussian statistics. Both magnetosheath boundary layer and near shock turbulence statistics exhibit non-Gaussian features and intermittency over small spatio-temporal scales. The occurrence of turbulence near magnetosheath boundaries can be responsible for the local heating of plasma observed by previous missions.",,"Z. Vörös, T. L. Zhang, M. P. Leubner, M. Volwerk, M. Delva, W. Baumjohann",physics,train
New knowledge of the Galactic magnetic fields,"The magnetic fields of our Milky Way galaxy are the main agent for cosmic rays to transport. In the last decade, much new knowledge has been gained from measurements of the Galactic magnetic fields. In the Galactic disk, from the RMs of a large number of newly discovered pulsars, the large-scale magnetic fields along the spiral arms have been delineated in a much larger region than ever before, with alternating directions in the arm and interarm regions. The toroidal fields in the Galactic halo were revealed to have opposite directions below and above the Galactic plane, which is an indication of an A0 mode dynamo operating in the halo. The strength of large-scale fields obtained from pulsar RM data has been found to increase exponentially towards the Galactic center. Compared to the steep Kolmogorov spectrum of magnetic energy at small scales, the large-scale magnetic fields show a shallow broken spatial magnetic energy spectrum.","8 pages, 4 figures. Invited Talk at XIV International Symposium on
  Very High Energy Cosmic Ray Interactions, WeiHai, China 15-22 Aug 2006",J. L. Han,physics,train
Interstellar medium in the M 43 nebula,We present a list of interstellar absorption lines in the direction of HD 37061 in the M 43 nebula. Some of the absorption lines arise from atomic excited levels that are uncommon in interstellar clouds. The excited levels of Fe II are populated by fluorescence. We found a large number of H2 molecular absorption lines arising from vibrationally excited levels. The ortho/para H2 ratio is equal to 2.7. The H2 rotational temperature of vibrational levels 1 - 5 exceeds 2000 K.,,Piotr Gnacinski,physics,train
"PIERNIK mhd code - a multi-fluid, non-ideal extension of the relaxing-TVD scheme (IV)","We present a new multi-fluid, grid MHD code PIERNIK, which is based on the Relaxing TVD scheme (Jin & Xin, 1995). The original scheme (see Trac & Pen (2003) and Pen et al. (2003)) has been extended by an addition of dynamically independent, but interacting fluids: dust and a diffusive cosmic ray gas, described within the fluid approximation, with an option to add other fluids in an easy way. The code has been equipped with shearing-box boundary conditions, and a selfgravity module, Ohmic resistivity module, as well as other facilities which are useful in astrophysical fluid-dynamical simulations. The code is parallelized by means of the MPI library. In this paper we present an extension of PIERNIK, which is designed for simulations of diffusive propagation of the Cosmic-Ray (CR) component in the magnetized ISM.","4 pages, 1 figure, proceedings of The Role of Disk-Halo Interaction
  in Galaxy Evolution: Outflow vs Infall, 2008, Espinho","Michał Hanasz, Kacper Kowalik, Dominik Wóltański, Rafał Pawłaszek",physics,train
Mid-infrared imaging of 25 local AGN with VLT-VISIR,"Aims. High angular resolution N-band imaging is used to discern the torus of active galactic nuclei (AGN) from its environment in order to allow a comparison of its mid-infrared properties to the expectations of the unified scenario for AGN. Methods. We present VLT-VISIR images of 25 low-redshift AGN of different Seyfert types, as well as N-band SEDs of 20 of them. In addition, we compare our results for 19 of them to Spitzer IRS spectra. Results. We find that at a resolution of ~ 0.35"", all the nuclei of our observed sources are point-like, except for 2 objects whose extension is likely of instrumental origin. For 3 objects, however, we observed additional extended circumnuclear emission, even though our observational strategy was not designed to detect it. Comparison of the VISIR photometry and Spitzer spectrophotometry indicates that the latter is affected by extended emission in at least 7 out of 19 objects and the level of contamination is (0.20 ~ 0.85) * F_IRS. In particular, the 10 um silicate emission feature seen in the Spitzer spectra of 6 type I AGN, possibly 1 type II AGN and 2 LINERs, also probably originates not solely in the torus but also in extended regions. Conclusions. Our results generally agree with the expectations from the unified scenario, while the relative weakness of the silicate feature supports clumpy torus models. Our VISIR data indicate that, for low-redshift AGN, a large fraction of Spitzer IRS spectra are contaminated by extended emission close to the AGN.","Accepted for publication in Astronomy & Astrophysics; 11 pages, 11
  figures","Hannes Horst, Wolfgang J. Duschl, Poshak Gandhi, Alain Smette",physics,train
A Limit on the Polarized Anomalous Microwave Emission of Lynds 1622,"The dark cloud Lynds 1622 is one of a few specific sites in the Galaxy where, relative to observed free-free and vibrational dust emission, there is a clear excess of microwave emission. In order to constrain models for this microwave emission, and to better establish the contribution which it might make to ongoing and near-future microwave background polarization experiments, we have used the Green Bank Telescope to search for linear polarization at 9.65 Ghz towards Lynds 1622. We place a 95.4% upper limit of 88 micro-Kelvin (123 micro-Kelvin at 99.7 confidence) on the total linear polarization of this source averaged over a 1'.3 FWHM beam. Relative to the observed level of anomalous emission in Stokes I these limits correspond to fractional linear polarizations of 2.7% and 3.5%.",replaced with version accepted by ApJ,"B. S. Mason, T. Robishaw, C. Heiles, D. Finkbeiner, C. Dickinson",physics,train
Alignment of Dust by Radiative Torque: Recent Developments,"Alignment of dust by radiative torques (RATs) has proven to be the most promising mechanism to explain alignment in various astrophysical environments, from comet atmospheres to accretion disks, molecular clouds, and diffuse interstellar gas. We discuss some of the major advances, which include, first of all, formulating of the analytical model of RATs. This model was shown to reproduce well the torques acting on actual irregular dust grains and allowed studies of the parameter space for which the alignment happens with long axes perpendicular and parallel to the magnetic field. Such a study resulted in an important conclusion that, without any paramagnetic relaxation, the RAT alignment always happens for interstellar grains with long axes perpendicular to the magnetic field. We show that the gaseous bombardment in some cases increases the degree of alignment by knocking out grains from the positions of imperfect alignment when the grains rotate slowly to more stable positions of perfect alignment where grains rotate fast. In terms of pinwheel torques, important revisions have been made in the Lazarian and Draine model of grain flipping and thermal trapping. Those, however, do not change the major conclusion that very small grains (i.e. grain size smaller than ~0.03 micron) should be marginally aligned. Recent work made the RAT alignment a predictive theory which is ready for quantitative modeling of astrophysical polarization. We predict that the microwave emission from the Zodiacal dust presents an important contaminant, which should be included into foreground polarization templates.","18 pages, 9 figures, review for Astropol2008 meeting, complementary
  to the extended Lazarian (2007) review","A. Lazarian, Thiem Hoang",physics,train
Secular evolution and the assembly of bulges,"Bulges are of different types, morphologies and kinematics, from pseudo-bulges, close to disk properties (Sersic index, rotation fraction, flatenning), to classical de Vaucouleurs bulges, close to elliptical galaxies. Secular evolution and bar development can give rise to pseudo-bulges. To ensure prolonged secular evolution, gas flows are required along the galaxy life-time. There is growing evidence for cold gas accretion around spiral galaxies. This can explain the bar cycle of destruction and reformation, together with pseudo-bulge formation. However, bulges can also be formed through major mergers, minor mergers, and massive clumps early in the galaxy evolution. Bulge formation is so efficient that it is difficult to explain the presence of bulgeless galaxies today.","8 pages, 5 figures, invited review in ""Galaxy Evolution: Emerging
  Insights and Future Challenges"", S. Jogee, L. Hao, G. Blanc, I. Marinova, eds",F. Combes,physics,train
Radiation pressure and absorption in AGN: results from a complete unbiased sample from Swift,"Outward radiation pressure can exceed the inward gravitational pull on gas clouds in the neighbourhood of a luminous Active Galactic Nucleus (AGN). This creates a forbidden region for long-lived dusty clouds in the observed columnn density - Eddington fraction plane. (The Eddington fraction lambda_Edd is the ratio of the bolometric luminosity of an AGN to the Eddington limit for its black hole mass.) The Swift/BAT catalogue is the most complete hard X-ray selected sample of AGN and has 97 low redshift AGN with measured column densities N_H and inferred black hole masses. Eddington fractions for the sources have been obtained using recent bolometric corrections and the sources have been plotted on the N_H - lambda_Edd plane. Only one source lies in the forbidden region and it has a large value of N_H due to an ionized warm absorber, for which radiation pressure is reduced. The effective Eddington limit for the source population indicates that the high column density clouds in the more luminous objects lie within the inner few pc, where the central black hole provides at least half the mass. Our result shows that radiation pressure does affect the presence of gas clouds in the inner galaxy bulge. We discuss briefly how the N_H - lambda_Edd plane may evolve to higher redshift, when feedback due to radiation pressure may have been strong.","4 pages, 2 figures, MNRAS in press","A. C. Fabian, R. V. Vasudevan, R. F. Mushotzky, L. M. Winter C. S. Reynolds",physics,val
Locality of MHD Turbulence in Isothermal Disks,"We numerically evolve turbulence driven by the magnetorotational instability (MRI) in a 3D, unstratified shearing box and study its structure using two-point correlation functions. We confirm Fromang and Papaloizou's result that shearing box models with zero net magnetic flux are not converged; the dimensionless shear stress $\alpha$ is proportional to the grid scale. We find that the two-point correlation of the magnetic field shows that it is composed of narrow filaments that are swept back by differential rotation into a trailing spiral. The correlation lengths along each of the correlation function principal axes decrease monotonically with the grid scale. For mean azimuthal field models, which we argue are more relevant to astrophysical disks than the zero net field models, we find that: $\alpha$ increases weakly with increasing resolution at fixed box size; $\alpha$ increases slightly as the box size is increased; $\alpha$ increases linearly with net field strength, confirming earlier results; the two-point correlation function of the magnetic field is resolved and converged, and is composed of narrow filaments swept back by the shear; the major axis of the two-point increases slightly as the box size is increased; these results are code independent, based on a comparison of ATHENA and ZEUS runs. The velocity, density, and magnetic fields decorrelate over scales larger than $\sim H$, as do the dynamical terms in the magnetic energy evolution equations. We conclude that MHD turbulence in disks is localized, subject to the limitations imposed by the absence of vertical stratification, the use of an isothermal equation of state, finite box size, finite run time, and finite resolution","25 pages, 8 figures, accepted by ApJ","Xiaoyue Guan, Charles F. Gammie, Jacob B. Simon, Bryan M. Johnson",physics,val
Imaging the Circumnuclear Region of NGC 1365 with Chandra,"We present the first Chandra/ACIS imaging study of the circumnuclear region of the nearby Seyfert galaxy NGC 1365. The X-ray emission is resolved into point-like sources and complex, extended emission. The X-ray morphology of the extended emission shows a biconical soft X-ray emission region extending ~5 kpc in projection from the nucleus, coincident with the high excitation outflow cones seen in optical emission lines particularly to the northwest. Harder X-ray emission is detected from a kpc-diameter circumnuclear ring, coincident with the star-forming ring prominent in the Spitzer mid-infrared images; this X-ray emission is partially obscured by the central dust lane of NGC 1365. Spectral fitting of spatially separated components indicates a thermal plasma origin for the soft extended X-ray emission (kT=0.57 keV). Only a small amount of this emission can be due to photoionization by the nuclear source. Detailed comparison with [OIII]5007 observations shows the hot interstellar medium (ISM) is spatially anticorrelated with the [OIII] emitting clouds and has thermal pressures comparable to those of the [OIII] medium, suggesting that the hot ISM acts as a confining medium for the cooler photoionized clouds. The abundance ratios of the hot ISM are fully consistent with the theoretical values for enrichment from Type II supernovae, suggesting that the hot ISM is a wind from the starburst circumnuclear ring. X-ray emission from a ~450 pc long nuclear radio jet is also detected to the southeast.","Accepted for publication in The Astrophysical Journal (April 2009).
  50 pages, 13 figures, 6 tables","Junfeng Wang, G. Fabbiano, M. Elvis, G. Risaliti, J. M. Mazzarella, J. H. Howell, S. Lord",physics,train
Spectral States of XTE J1701-462: Link between Z and Atoll Sources,"We have analyzed 866 RXTE observations of the 2006-2007 outburst of the accreting neutron star XTE J1701-462, during which the source evolves from super-Eddington luminosities to quiescence. The X-ray color evolution first resembles the Cyg X-2 subgroup of Z sources, with frequent excursions on the horizontal and normal branches (HB/NB). The source then decays and evolves to the Sco X-1 subgroup, with increasing focus on the flaring branch (FB) and the lower vertex of the ""Z"". Finally, the FB subsides, and the source transforms into an atoll source, with the lower vertex evolving to the atoll soft state. Spectral analyses suggest that the atoll stage is characterized by a constant inner disk radius, while the Z stages exhibit a luminosity-dependent expansion of the inner disk, which we interpret as effects related to the local Eddington limit. Contrary to the view that the mass accretion rate ($\dot{m}$) changes along the Z, we find that changes in $\dot{m}$ are instead responsible for the secular evolution of the Z and the subclasses. Motion along the Z branches appears to be caused by three different mechanisms that may operate at roughly constant $\dot{m}$. For the Sco X-1-like Z stage, we find that the FB is an instability track that proceeds off the lower vertex when the inner disk radius shrinks from the value set by the X-ray luminosity toward the value measured for the atoll soft state. Excursions up the NB occur when the apparent size of the boundary layer increases while the disk exhibits little change. The HB is associated with Comptonization of the disk emission. The Z branches for the Cyg X-2-like stage are more complicated, and their origin is unclear. Finally, our spectral results lead us to hypothesize that the lower and upper Z vertices correspond to a standard thin disk and a slim disk, respectively.","22 pages, 21 figures, submitted to ApJ","Dacheng Lin, Ronald A. Remillard, Jeroen Homan",physics,train
Gamma-ray Bursts: Light on the distant Universe,"Observations of a long-lasting Gamma-ray burst, one that has the brightest optical counterpart yet discovered, challenge theoretical understanding of these bursts but may enhance their usefulness as cosmic probes.","News and Views article for Nature (Sept. 11, 2008)",Jonathan Grindlay,physics,train
GRB physics with Fermi,"Radiation from GRBs in the prompt phase, flares and an afterglow is thought to be produced by accelerated electrons in magnetic fields. Such emission may be produced at collisionless shocks of baryonic outflows or at reconnection sites (at least for the prompt and flares) of the magnetically dominated (Poynting flux driven) outflows, where no shocks presumably form at all. An astonishing recent discovery is that during reconnection strong small-scale magnetic fields are produced via the Weibel instability, very much like they are produced at relativistic shocks. The relevant physics has been successfully and extensively studied with the PIC simulations in 2D and, to some extent, in 3D for the past few years. We discuss how these simulations predict the existence of MeV-range synchrotron/jitter emission in some GRBs, which can be observed with Fermi. Recent results on modeling of the spectral variability and spectral correlations of the GRB prompt emission in the Weibel-jitter paradigm applicable to both baryonic and magnetic-dominated outflows is reviewed with the emphasis on observational predictions.",6 pages; submitted to proc. of Huntsville 2008 symposium on GRBs,Mikhail V. Medvedev,physics,test
Dark Matter Annihilation Induced Gamma Ray Emission from Galaxy Cluster 1E0657-56,"Based on minimal supersymmetric standard model, neutralino dark matter annihilation induced gamma ray emission from galaxy cluster 1E0657-56 is calculated. The merge of bullet-like subcluster with the main cluster is also investigated.",,"C. Zhang, G. -C. Liu",physics,val
Different satellites - different GRB redshift distributions?,"The measured redshifts of gamma-ray bursts (GRBs), which were first detected by the Swift satellite, seem to be bigger on average than the redshifts of GRBs detected by other satellites. We analyzed the redshift distribution of GRBs triggered and observed by different satellites (Swift[1], HETE2[2], BeppoSax, Ulyssses). After considering the possible biases significant difference was found at the p = 95.70% level in the redshift distributions of GRBs measured by HETE and the Swift.","2008 NANJING GAMMA-RAY BURST CONFERENCE. AIP Conference Proceedings,
  Volume 1065, pp. 119-122 (2008)","Z. Bagoly, L. G. Balazs, I. Horvath, J. Kelemen, A. Meszaros, P. Veres, G. Tusnady",physics,val
The First X-Ray Proper-Motion Measurements of the Forward Shock in the Northeastern Limb of SN 1006,"We report on the first X-ray proper-motion measurements of the nonthermally-dominated forward shock in the northeastern limb of SN 1006, based on two Chandra observations taken in 2000 and 2008. We find that the proper motion of the forward shock is about 0.48 arcsec/yr and does not vary around the rim within the ~10% measurement uncertainties. The proper motion measured is consistent with that determined by the previous radio observations. The mean expansion index of the forward shock is calculated to be ~0.54 which matches the value expected based on an evolutionary model of a Type Ia supernova with either a power-law or an exponential ejecta density profile. Assuming pressure equilibrium around the periphery from the thermally-dominated northwestern rim to the nonthermally-dominated northeastern rim, we estimate the ambient density to the northeast of SN 1006 to be about 0.085/cm^3.",Accepted for publication in The Astrophysical Journal Letters,"Satoru Katsuda, Robert Petre, Knox S. Long, Stephen P. Reynolds, P. Frank Winkler, Koji Mori, Hiroshi Tsunemi",physics,test
Blazar nuclei in radio-loud narrow-line Seyfert 1?,"It has been suggested that some radio-loud narrow-line Seyfert 1 contain relativistic jets, on the basis of their flat-spectrum radio nuclei and studies on variability. We present preliminary results of an ongoing investigation of the X-ray and multiwavelength properties of 5 radio-loud NLS1 based on archival data from Swift and XMM-Newton. Some sources present interesting characteristics, very uncharacteristic for a radio-quiet narrow-line Seyfert 1, such as very hard X-ray spectra, and correlated optical and ultraviolet variability. However, none of the studied sources show conclusive evidence for relativistic jets. gamma-ray observations with Fermi are strongly recommended to definitely decide on the presence or not of relativistic jets.","9 pages, 4 figures. Talk presented at the 37th COSPAR Assembly
  (Montreal, Canada, July 13-20, 2008), Session E17. Accepted for publication
  on Advances in Space Research","L. Foschini, L. Maraschi, F. Tavecchio, G. Ghisellini, M. Gliozzi, R. M. Sambruna",physics,val
Ultra High Energy Cosmic Ray Protons: Signatures and Observations,"The status of the Greisen-Zatsepin-Kuzmin (GZK) cutoff and pair-production dip in Ultra High Energy Cosmic Rays (UHECR) is discussed.They are the features in the spectrum of protons propagating through CMB radiation in extragalactic space, and discovery of these features implies that primary particles are mostly extragalactic protons. The spectra measured by AGASA, Yakutsk, HiRes and Auger detectors are in good agreement with the pair-production dip, and HiRes data have strong evidences for the GZK cutoff. The Auger spectrum,as presented at the 30th ICRC 2007, agrees with the GZK cutoff, too. The AGASA data agree well with the beginning of the GZK cutoff at E \leq 80 EeV, but show the excess of events at higher energies, the origin of which is not understood. The difference in the absolute fluxes measured by different detectors disappears after energy shift within the systematic errors of each experiment.","Plenary talk at NOW 2008 Wirkshop, 6 pages, 5 figures",V. Berezinsky,physics,train
Evidence for an anticorrelation between the duration of the shallow decay phase of GRB X-ray afterglows and redshift,"One of the most intriguing features discovered by Swift is a plateau phase in the X-ray flux decay of about 70% of the afterglows of gamma-ray bursts (GRBs). The physical origin of this feature is still being debated. We constrain the proposed interpretations, based on the intrinsic temporal properties of the plateau phase. We selected and analyzed all the Swift/XRT GRB afterglows at known redshift observed between March 2005 and June 2008 featuring a shallow decay phase in their X-ray lightcurves. For our sample of 21 GRBs we find an anticorrelation of the logarithm of the duration of the shallow phase with re dshift, with a Spearman rank-order correlation coefficient of r=-0.4 and a null hypothesis probability of 5%. When we correct the durations for cosmological dilation, the anticorrelation strenghtens, with r=-0.6 and a null hypothesis probability of 0.4%. Considering only those GRBs in our sample that have a well-measured burst peak energy (8 out of 21), we find an anticorrelation between the energy of the burst and the shallow phase duration, with r=-0.80 and a null hypothesis probability of 1.8%. If the burst energy anticorrelation with the shallow phase duration is real, then the dependence of the shallow phase on redshift could be the result of a selection effect, since on average high-redshift bursts with lower energies and longer plateaus would be missed. A burst energy anticorrelation with the shallow phase duration would be expected if the end of the plateau arises from a collimated outflow. Alternative scenarios are briefly discussed involving a possible cosmological evolution of the mechanism responsible for the X-ray shallow decay.","4 pages, 2 figures, 1 table, accepted as a Letter to A&A","G. Stratta, D. Guetta, V. D'Elia, M. Perri, S. Covino, L. Stella",physics,train
The new intermediate long bursting source XTE J1701-407,"XTE J1701-407 is a newly discovered X-ray transient source. In this work we investigate its flux variability and study the intermediate long and short bursts discovered by Swift on July 17, and 27, 2008, respectively. So far, only one intermediate long burst, with a duration of ~18 minutes and ten days later a short burst, have been recorded from XTE J1701-407. We analyzed the public available data from Swift and RXTE, and compared the observed properties of the intermediate long burst with theoretical ignition condition and light curves to investigate the possible nuclear burning processes. The intermediate long burst may have exhibited a photospheric radius expansion, allowing us to derive the source distance at 6.2 kpc assuming the empirically derived Eddington luminosity for pure helium. The intermediate long burst decay was best fit by using two exponential functions with e-folding times of \tau_1=40(3) s and \tau_2=221(9) s. The bursts occurred at a persistent luminosity of L_{per}=8.3x10E36 erg/s. For the intermediate long burst the mass accretion rate per unit area onto the NS was \dot{m}=4x10E3 g/cm2/s, and the total energy released was E_{burst}=3.5x10E40 erg. This corresponds to an ignition column depth of y_{ign}=1.8x10E9 g/cm2, for a pure helium burning. We find that the energetics of this burst can be modeled in different ways, as (i) pure helium ignition, as the result of either pure helium accretion or depletion of hydrogen by steady burning during accumulation, or (ii) as ignition of a thick layer of hydrogen-rich material in a source with low metallicity. However, comparison of the burst duration with model light curves suggests that hydrogen burning plays a role during the burst, and therefore this source is a low accretion rate burster with a low metallicity in the accreted material.","11 pages, 8 figures, 4 tables, accepted for publication in A&A","M. Falanga, A. Cumming, E. Bozzo, J. Chenevez",physics,train
Deep-Sea Acoustic Neutrino Detection and the AMADEUS System as a Multi-Purpose Acoustic Array,The use of conventional neutrino telescope methods and technology for detecting neutrinos with energies above 1 EeV from astrophysical sources would be prohibitively expensive and may turn out to be technically not feasible. Acoustic detection is a promising alternative for future deep-sea neutrino telescopes operating in this energy regime. It utilises the effect that the energy deposit of the particle cascade evolving from a neutrino interaction in water generates a coherently emitted sound wave with frequency components in the range between about 1 and 50 kHz. The AMADEUS (Antares Modules for Acoustic DEtection Under the Sea) project is integrated into the ANTARES neutrino telescope and aims at the investigation of techniques for acoustic particle detection in sea water. The acoustic sensors of AMADEUS are using piezo elements and are recording a broad-band signal with frequencies ranging up to 125 kHz. After an introduction to acoustic neutrino detection it will be shown how an acoustic array similar to AMADEUS can be used for positioning as well as acoustic particle detection. Experience from AMADEUS and possibilities for a future large scale neutrino telescope in the Mediterranean Sea will be discussed.,"Proceedings of the VLVnT08 workshop
  (http://marwww.in2p3.fr/VLVnT08/), April 2008",Robert Lahmann,physics,test
Status and First Results of the Acoustic Detection Test System AMADEUS,"The AMADEUS system is integrated in the ANTARES neutrino telescope in the Mediterranean Sea and aims for the investigation of acoustic particle detection techniques in the deep sea. Installed at a depth of more than 2000m, the acoustic sensors of AMADEUS are using piezo-ceramic elements for the broad-band recording of acoustic signals with frequencies ranging up to 125kHz. AMADEUS consists of six clusters, each one comprising six acoustic sensors that are arranged at distances of roughly 1m from each other. Three acoustic clusters are installed along a vertical mechanical structure (a so-called Line) of ANTARES with spacings of about 15m and 110m, respectively. The remaining 3 clusters are installed with vertical spacings of 15m on a further Line of the ANTARES detector. The horizontal distance between the two lines is 240m. Each acoustic cluster allows for the suppression of random noise by requiring local coincidences and the reconstruction of the arrival direction of acoustic waves. Source positions can then be reconstructed using the precise time correlations between the clusters provided by the ANTARES clock system. AMADEUS thus allows for extensive acoustic background studies including signal correlations on several length scales as well as source localisation. The system is therefore excellently suited for feasibility studies for a potential future large scale acoustic neutrino telescope in sea water. Since the start of data taking on December 5th, 2007 a wealth of data has been recorded. The AMADEUS system will be described and some first results will be presented.","Proceedings of the ARENA 2008 workshop
  (http://www.roma1.infn.it/arena2008/), June 2008. 8 pages, 10 figures",Robert Lahmann,physics,val
Modeling and Reproducibility of Suzaku HXD PIN/GSO Background,"Suzaku Hard X-ray Detector (HXD) achieved the lowest background level than any other previously or currently operational missions sensitive in the energy range of 10--600 keV, by utilizing PIN photodiodes and GSO scintillators mounted in the BGO active shields to reject particle background and Compton-scattered events as much as possible. Because it does not have imaging capability nor rocking mode for the background monitor, the sensitivity is limited by the reproducibility of the non X-ray background (NXB) model. We modeled the HXD NXB, which varies with time as well as other satellites with a low-earth orbit, by utilizing several parameters, including particle monitor counts and satellite orbital/attitude information. The model background is supplied as an event file in which the background events are generated by random numbers, and can be analyzed in the same way as the real data. The reproducibility of the NXB model depends on the event selection criteria (such as cut-off rigidity and energy band) and the integration time, and the 1sigma systematic error is estimated to be less than 3% (PIN 15--40 keV) and 1% (GSO 50--100 keV) for more than 10 ksec exposure.","29 pages, 45 figures, will appear on the PASJ 61, Suzaku 3rd issue","Yasushi Fukazawa, Tsunefumi Mizuno, Shin Watanabe, Motohide Kokubun, Hiromitsu Takahashi, Naomi Kawano, Sho Nishino, Mahito Sasada, Hirohisa Shirai, Takuya Takahashi, Tomonori Yamasaki, Tomonori Yasuda, Aya Bamba, Masanori Ohno, Tadayuki Takahashi, Masayoshi Ushio, Teruaki Enoto, Takao Kitaguchi, Kazuo Makishima, Kazuhiro Nakazawa, Yuichi Uehara, Shin'ya Yamada, Takayuki Yuasa, Naoki Isobe, Madoka Kawaharada, Takaaki Tanaka, Makoto Tashiro, Yukikatsu Terada, Kazutaka Yamaoka",physics,test
The ARCADE 2 Instrument,"The second generation Absolute Radiometer for Cosmology, Astrophysics, and Diffuse Emission (ARCADE 2) instrument is a balloon-borne experiment to measure the radiometric temperature of the cosmic microwave background and Galactic and extra-Galactic emission at six frequencies from 3 to 90 GHz. ARCADE 2 utilizes a double-nulled design where emission from the sky is compared to that from an external cryogenic full-aperture blackbody calibrator by cryogenic switching radiometers containing internal blackbody reference loads. In order to further minimize sources of systematic error, ARCADE 2 features a cold fully open aperture with all radiometrically active components maintained at near 2.7 K without windows or other warm objects, achieved through a novel thermal design. We discuss the design and performance of the ARCADE 2 instrument in its 2005 and 2006 flights.","12 pages, 14 figues, 3 tables, 2 figures added, Accepted to ApJ","J. Singal, D. J. Fixsen, A. Kogut, S. Levin, M. Limon, P. Lubin, P. Mirel, M. Seiffert, T. Villela, E. Wollack, C. A. Wuensche",physics,train
The Cosmic Origins Spectrograph and the Future of Ultraviolet Astronomy,"I describe the capabilities of the Cosmic Origins Spectrograph, scheduled for May 2009 installation on the Hubble Space Telescope. With a factor-of-ten increase in far-UV throughput for moderate resolution spectroscopy, COS will enable a range of scientific programs that study hot stars, AGN, and gas in the interstellar medium, intergalactic medium, and galactic halos. We also plan a large-scale HST Spectroscopic Legacy Project for QSO absorption lines, galactic halos, and AGN outflows. Studies of next-generation telescopes for UV/O astronomy are now underway, including small, medium, and large missions to fill the imminent ten-year gap between the end of Hubble and a plausible launch of the next large mission. Selecting a strategy for achieving these goals will involve hard choices and tradeoffs in aperture, wavelength, and capability.","To appear in Future Directions in Ultraviolet Astronomy (AIP Conf
  Proc)",J. Michael Shull,physics,train
Findings of the Joint Dark Energy Mission Figure of Merit Science Working Group,"These are the findings of the Joint Dark Energy Mission (JDEM) Figure of Merit (FoM) Science Working Group (SWG), the FoMSWG. JDEM is a space mission planned by NASA and the DOE for launch in the 2016 time frame. The primary mission is to explore the nature of dark energy. In planning such a mission, it is necessary to have some idea of knowledge of dark energy in 2016, and a way to quantify the performance of the mission. In this paper we discuss these issues.",,"Andreas Albrecht, Luca Amendola, Gary Bernstein, Douglas Clowe, Daniel Eisenstein, Luigi Guzzo, Christopher Hirata, Dragan Huterer, Robert Kirshner, Edward Kolb, Robert Nichol",physics,train
High performance computing for classic gravitational N-body systems,"The role of gravity is crucial in astrophysics. It determines the evolution of any system, over an enormous range of time and space scales. Astronomical stellar systems as composed by N interacting bodies represent examples of self-gravitating systems, usually treatable with the aid of newtonian gravity but for particular cases. In this note I will briefly discuss some of the open problems in the dynamical study of classic self-gravitating N-body systems, over the astronomical range of N. I will also point out how modern research in this field compulsorily requires a heavy use of large scale computations, due to the contemporary requirement of high precision and high computational speed.","Invited talk presented at the CSFI 2008 Conference (Rimini, Italy,
  may 27-may 31 2008); 4 pages including one table. Latex: requires
  \documentclass{cimento}. In press in the Conference Proceedings published as
  a copy of Il Nuovo Cimento journal",Roberto Capuzzo-Dolcetta,physics,train
Status of NEMO: results from the NEMO Phase-1 detector,"The NEMO Collaboration installed an underwater detector including most of the critical elements of a possible km$^3$ neutrino telescope: a four-floor tower (called Mini-Tower) and a Junction Box, including the data transmission, the power distribution, the timing calibration and the acoustic positioning systems. These technical solutions will be evaluated, among others proposed for the construction of the km$^3$ detector, within the KM3NeT Consortium. The main test of this test experiment was the validation of the proposed design solutions mentioned above. We present results of the analysis of data collected with the NEMO Mini-Tower. The position of PMTs is determined through the acoustic position system; signals detected with PMTs are used to reconstruct the tracks of atmospheric muons. The angular distribution of atmospheric muons was measured and results were compared with Monte Carlo simulations.",Proc. of CRIS 2008,Carla Distefano,physics,val
VLBI Polarisation with the Yebes (EVN) and Hobart (LBA) antennae,"Work has been on-going for the development of the required code for full polarisation processing of VLBI data using some new antennae mounts. The extensions of AIPS allows the support of two new mount types; the left-handed and right-handed Nasmyth antennae (Pico Veleta in the GMVA and Yebes-40m in the EVN) and the EW-mount (Hobart in the LBA). The data handling process is seamless, once the correct mount type has been selected. All subsequent calls to the parallactic angle subroutine PARANG will return the feed angles for Left or Right Nasmyth or EW-mount. These are required, respectively, for Pico Veleta, Yebes-40m (low frequency branch) and Hobart.","The 9th European VLBI Network Symposium, 2008",R. Dodson,physics,train
Integrated Laboratory Demonstrations of Multi-Object Adaptive Optics on a Simulated 10-Meter Telescope at Visible Wavelengths,"One important frontier for astronomical adaptive optics (AO) involves methods such as Multi-Object AO and Multi-Conjugate AO that have the potential to give a significantly larger field of view than conventional AO techniques. A second key emphasis over the next decade will be to push astronomical AO to visible wavelengths. We have conducted the first laboratory simulations of wide-field, laser guide star adaptive optics at visible wavelengths on a 10-meter-class telescope. These experiments, utilizing the UCO/Lick Observatory's Multi-Object / Laser Tomography Adaptive Optics (MOAO/LTAO) testbed, demonstrate new techniques in wavefront sensing and control that are crucial to future on-sky MOAO systems. We (1) test and confirm the feasibility of highly accurate atmospheric tomography with laser guide stars, (2) demonstrate key innovations allowing open-loop operation of Shack-Hartmann wavefront sensors (with errors of ~30 nm) as will be needed for MOAO, and (3) build a complete error budget model describing system performance. The AO system maintains a performance of 32.4% Strehl on-axis, with 24.5% and 22.6% at 10"" and 15"", respectively, at a science wavelength of 710 nm (R-band) over the equivalent of 0.8 seconds of simulation. The MOAO-corrected field of view is ~25 times larger in area than that limited by anisoplanatism at R-band. Our error budget is composed of terms verified through independent, empirical experiments. Error terms arising from calibration inaccuracies and optical drift are comparable in magnitude to traditional terms like fitting error and tomographic error. This makes a strong case for implementing additional calibration facilities in future AO systems, including accelerometers on powered optics, 3D turbulators, telescope and LGS simulators, and external calibration ports for deformable mirrors.","29 pages, 11 figures, submitted to PASP","S. Mark Ammons, Luke Johnson, Edward A. Laag, Renate Kupke, Donald T. Gavel, Brian J. Bauman, Claire E. Max",physics,val
Photospheric and Subphotospheric Dynamics of Emerging Magnetic Flux,"Magnetic fields emerging from the Sun's interior carry information about physical processes of magnetic field generation and transport in the convection zone. Soon after appearance on the solar surface the magnetic flux gets concentrated in sunspot regions and causes numerous active phenomena on the Sun. This paper discusses some properties of the emerging magnetic flux observed on the solar surface and in the interior. A statistical analysis of variations of the tilt angle of bipolar magnetic regions during the emergence shows that the systematic tilt with respect to the equator (the Joy's law) is most likely established below the surface. However, no evidence of the dependence of the tilt angle on the amount of emerging magnetic flux, predicted by the rising magnetic flux rope theories, is found. Analysis of surface plasma flows in a large emerging active region reveals strong localized upflows and downflows at the initial phase of emergence but finds no evidence for large-scale flows indicating future appearance a large-scale magnetic structure. Local helioseismology provides important tools for mapping perturbations of the wave speed and mass flows below the surface. Initial results from SOHO/MDI and GONG reveal strong diverging flows during the flux emergence, and also localized converging flows around stable sunspots. The wave speed images obtained during the process of formation of a large active region, NOAA 10488, indicate that the magnetic flux gets concentrated in strong field structures just below the surface. Further studies of magnetic flux emergence require systematic helioseismic observations from the ground and space, and realistic MHD simulations of the subsurface dynamics.","21 pages, 15 figures, to appear in Space Science Reviews",A. G. Kosovichev,physics,test
Observational Evidence for Coronal Twisted Flux Rope,"Multi-instrument data sets of NOAA AR10938 on Jan. 16, 2007, (e.g., {\emph{Hinode}}, {\it{STEREO}}, {\it{GOES}}, {\it{MLSO}} and {\it{ISOON}} H$\alpha$) are utilized to study the fine structure and evolution of a magnetic loop system exhibiting multiple crossing threads, whose arrangement and individual shapes are very suggestive of individual field lines in a flux rope. The footpoints of the magnetic threads are closely rooted into pores and plage areas. A C-class flare recorded by {\it{GOES}} at approximately 2:35 UT near one of the footpoints of the multi-thread system (along with a wisp of loop material shown by EUV data) led to the brightening of the magnetic structure revealing its fine structure with several threads that indicate a high degree of linking (suggesting a left-handed helical pattern as shown by the filament structure formed later-on). EUV observations by {\emph{Hinode}}/EIS of hot spectral lines at 2:46 UT show a complex structure of coronal loops. The same features were observed about 20 minutes later in X-ray images from {\emph{Hinode}}/XRT and about 30 minutes further in EUV images of {\it{STEREO}}/SECCHI/EUVI with much better resolution. H$\alpha$ and 304 {\AA} images revealed the presence of several filament fibrils in the same area. They evolved a few hours later into a denser structure seemingly showing helical structure, which persistently lasted for several days forming a segment of a larger scale filament. The present observations provide an important indication for a flux robe as a precursor of a solar filament.","13 pages, 4 figures",N. -E. Raouafi,physics,train
On active region loops: Hinode/EIS observations,"Coronal loops are fundamental building blocks of the solar active regions and the corona. Therefore, a clear understanding of the physics of coronal loops will help us understand the physics of active region heating in particular and coronal heating in general. This requires a precise measurement of physical quantities such as electron densities and filling factors, temperatures, and flows in coronal loops. In this paper we have carried out an investigation of a spatially well resolved coronal loop using the EIS onboard Hinode to measure the above mentioned physical quantities. Based on this study we find that a nano-flare model could explain most of the observed characteristics of this loop.","27 pages, 7 figures, Accepted in ApJ","D. Tripathi, H. E. Mason, B. N. Dwivedi, G. Del Zanna, P. R. Young",physics,train
Relativistic Lidov-Kozai resonance in binaries,"We consider the secular dynamics of a binary and a planet in terms of non-restricted, hierarchical three-body problem, including the general relativity corrections to the Newtonian gravity. We determine regions in the parameter space where the relativistic corrections may be important for the long-term dynamics. We try to constrain the inclinations of putative Jovian planets in recently announced binary systems of HD 4113 and HD 156846.","6 pages, 5 figures, proceedings of the conference ""Extrasolar planets
  in multi-body systems: theory and observations"" (August 2008, Torun, Poland)","Cezary Migaszewski, Krzysztof Gozdziewski",physics,val
Polarization of FIR emission from T Tauri Disks,"Recent observation of 850 micron sub-mm polarization from T Tauri disks opens up the possibility of studying magnetic field structure within protostellar disks. The degree of polarization is around 3 % and the direction of polarization is perpendicular to the disk. Since thermal emission from dust grains dominates the spectral energy distribution at the sub-mm/FIR regime, dust grains are thought to be the cause of the polarization. We discuss grain alignment by radiation and we explore the efficiency of dust alignment in T Tauri disks. Calculations show that dust grains located far away from the Central proto-star are more efficiently aligned. In the presence of a regular magnetic field, the aligned grains produce polarized emission in sub-mm/FIR wavelengths. The direction of polarization is perpendicular to the local magnetic field direction. When we use a recent T Tauri disk model and take a Mathis-Rumpl-Nordsieck-type distribution with maximum grain size of 500-1000 $\mu$m, the degree of polarization is around 2-3 % level at wavelengths larger than $\sim100\mu$m. Our study indicates that multifrequency infrared polarimetric studies of protostellar disks can provide good insights into the details of their magnetic structure. We also provide predictions for polarized emission for disks viewed at different wavelengths and viewing angles.","8 pages, 8 figures; submitted to RevMexAA (conference series)","Jungyeon Cho, A. Lazarian",physics,train
Modeling the RV and BVS of active stars,"We present a method of modeling the radial velocity (RV) measurements which can be useful in searching for planets hosted by chromospherically active stars. We assume that the observed RV signal is induced by the reflex motion of a star as well as by distortions of spectral line profiles, measured by the Bisector Velocity Span (BVS). The RVs are fitted with a common planetary model including RV correction term depending linearly on the BVS, which accounts for the stellar activity. The coefficient of correlation is an additional free parameter of the RV model. That approach differs from correcting the RVs before or after fitting the ""pure"" planetary model. We test the method on simulated data derived for single-planet systems. The results are compared with the outcomes of algorithms found in the literature.","6 pages, 2 figures, proceedings of the conference ""Extrasolar planets
  in multi-body systems: theory and observations"" (August 2008, Torun, Poland)","Cezary Migaszewski, Grzegorz Nowak",physics,train
NLTE models of line-driven stellar winds III. Influence of X-ray radiation on wind structure of O stars,"We study the influence of X-rays on the wind structure of selected O stars. For this purpose we use our non-local thermodynamic equilibrium (NLTE) wind code with inclusion of additional artificial source of X-rays, assumed to originate in the wind shocks. We show that the influence of shock X-ray emission on wind mass-loss rate is relatively small. Wind terminal velocity may be slightly influenced by the presence of strong X-ray sources, especially for stars cooler than Teff < 35 000 K. We discuss the origin of the Lx/L \sim 10^-7 relation. For stars with thick wind this relation can be explained assuming that the cooling time depends on wind density. Stars with optically thin winds exhibiting the ""weak wind problem"" display enhanced X-ray emission which may be connected with large shock cooling length. We propose that this effect can explain the ""weak wind problem"". Inclusion of X-rays leads to a better agreement of the model ionization structure with observations. However, we do not found any significant influence of X-rays on Pv ionization fraction implying that the presence of X-rays cannot explain the Pv problem. We study the implications of modified ionization equilibrium due to shock emission on the line transfer in the X-ray region. We conclude that the X-ray line profiles of helium-like ions may be affected by the line absorption within the cool wind.","16 pages, accepted for publication in MNRAS","Jiri Krticka, Jiri Kubat",physics,val
Advances in theory and simulations of large-scale dynamos,"Recent analytical and computational advances in the theory of large-scale dynamos are reviewed. The importance of the magnetic helicity constraint is apparent even without invoking mean-field theory. The tau approximation yields expressions that show how the magnetic helicity gets incorporated into mean-field theory. The test-field method allows an accurate numerical determination of turbulent transport coefficients in linear and nonlinear regimes. Finally, some critical views on the solar dynamo are being offered and targets for future research are highlighted.","19 pages, 2 figures, to appear in Space Sci. Rev",Axel Brandenburg,physics,train
Magnetism of Herbig Ae/Be stars,"Observations of magnetic fields of stars at the pre-main sequence phase can provide important new insights into the complex physics of the late stages of star formation. This is especially true at intermediate stellar masses, where magnetic fields are strong and globally organised, and therefore most amenable to direct study. Recent circularly-polarised spectroscopic observations of pre-main sequence Herbig Ae/Be stars have revealed the presence of organised magnetic fields in the photospheres of a small fraction of these objects. To date, 9 magnetic HAeBe stars have been detected, and those detections confirmed by repeated observations. The morphology and variability of their Stokes V signatures indicates that their magnetic fields have important dipole components of kG strength, and that the dipole is stable on timescales ofat least years. These magnetic stars exhibit a large range of stellar mass, from about 2-13 solar masses, and diverse rotational properties, with vsini from a few km/s to 200 km/s. Most magnetic HAeBe stars show approximately solar abundances; they clearly do not generally exhibit the strong and systematic peculiarities of the magnetic main sequence A and B type stars (the Ap/Bp stars). The observed fractional bulk incidence of magnetic HAeBe stars is about 7%, a value compatible with the incidence of magnetic intermediate-mass stars on the main sequence. This low incidence is at odds with formation scenarios generally involving magnetically-mediated accretion. The similarily between the magnetic properties of the pre-main sequence and main sequence intermediate-mass stars appears compatible with the hypothesis of a fossil origin of magnetism in these objects.","13 pages, 7 figs, proceedings of ""Astronomical Polarimetry 2008: From
  small to large telescopes"" (invited presentation)","G. A. Wade, E. Alecian, J. Grunhut, C. Catala, S. Bagnulo, C. P. Folsom, J. D. Landstreet",physics,test
Chirality of Intermediate Filaments and Magnetic Helicity of Active Regions,"Filaments which form either between or around active regions (ARs) are called intermediate filaments. In spite of various theoretical studies, the origin of the chirality of filaments is still uncovered. We investigated how intermediate filaments are related to their associated ARs, especially from the point of view of magnetic helicity and the orientation of polarity inversion lines (PILs). The chirality of filaments has been determined based on the orientations of barbs observed in BBSO full-disk Halpha images taken during the rising phase of solar cycle 23. The sign of magnetic helicity of ARs has been determined using S/inverse-S shaped sigmoids from Yohkoh SXT images. As a result, we have found a good correlation between the chirality of filaments and the magnetic helicity sign of ARs. Among 45 filaments, 42 filaments have shown the same sign as helicity sign of nearby ARs. It has been also confirmed that the role of both the orientation and the relative direction of PILs to ARs in determining the chirality of filaments is not significant, against a theoretical prediction. These results suggest that the chirality of intermediate filaments may originate from magnetic helicity of their associated ARs.","13 pages, 7 figures, Accepted for ApJ","Eun-Kyung Lim, Jongchul Chae",physics,train
Universal quantum critical dynamics of two-dimensional antiferromagnets,"The universal dynamic and static properties of two dimensional antiferromagnets in the vicinity of a zero-temperature phase transition from long-range magnetic order to a quantum disordered phase are studied. Random antiferromagnets with both N\'{e}el and spin-glass long-range magnetic order are considered. Explicit quantum-critical dynamic scaling functions are computed in a 1/N expansion to two-loops for certain non-random, frustrated square lattice antiferromagnets. Implications for neutron scattering experiments on the doped cuprates are noted.",11 pages,"Subir Sachdev, Jinwu Ye",physics,train
Spin Singlet Quantum Hall Effect and Nonabelian Landau-Ginzburg Theory,"We show that the Halperin-Haldane SQHE wave function can be written in the form of a product of a wave function for charged semions in a magnetic field and a wave function for the Chiral Spin Liquid of neutral spin-$\12$ semions. We introduce field-theoretic model in which the electron operators are factorized in terms of charged spinless semions (holons) and neutral spin-$\12$ semions (spinons). Broken time reversal symmetry and short ranged spin correlations lead to $SU(2)_{k=1}$ Chern-Simons term in Landau-Ginzburg action for SQHE phase. We construct appropriate coherent states for SQHE phase and show the existence of $SU(2)$ valued gauge potential. This potential appears as a result of ``spin rigidity"" of the ground state against any displacements of nodes of wave function from positions of the particles and reflects the nontrivial monodromy in the presence of these displacements. We argue that topological structure of $SU(2)_{k=1}$ Chern-Simons theory unambiguously dictates {\it semion} statistics of spinons.",,Alexander Balatsky,physics,train
A novel class of singlet superconductors,"A new class of singlet superconductors with a gap function $\Delta(\bk, \omega_n)$ which is {\it odd} in both momentum and Matsubara frequency is considered. Some of the physical properties of this superconductivity are discussed and it is argued that: i) the electron-phonon interaction can produce this kind of pairing, ii) in many cases there is no gap in the quasiparticle spectrum, iii) these superconductors will exhibit a Meissner effect.",10 pages,"Alexander Balatsky, Elihu Abrahams",physics,train
Physics beyond quasi-particles: Spectrum and completeness of the 3 state superintegrable chiral Potts model,We find the rules which count the energy levels of the 3 state superintegrable chiral Potts model and demonstrate that these rules are complete. We then derive the complete spectrum of excitations in the thermodynamic limit in the massive phase and demonstrate the existence of excitations which do not have a quasi-particle form. The physics of these excitations is compared with the BCS superconductivity spectrum and the counting rules are compared with the closely related $S=1$ XXZ spin chain.,39 pages,"Srinandan Dasmahapatra, Rinat Kedem, Barry M. McCoy",physics,val
Investigations of Pairing in Anyon Systems,"We investigate pairing instabilities in the Fermi-liquid-like state of a single species of anyons. We describe the anyons as Fermions interacting with a Chern-Simons gauge field and consider the weak coupling limit where their statistics approaches that of Fermions. We show that, within the conventional BCS approach, due to induced repulsive Coulomb and current-current interactions, the attractive Aharonov-Bohm interaction is not sufficient to generate a gap in the Fermion spectrum.","(11 pages, 2 Figures not included)","M. I. Dobroliubov, I. I. Kogan, G. W. Semenoff",physics,train
Chirality Ordering of Chiral Spin Liquids,"We study the effect of introducing a weak antiferromagnetic interplanar exchange coupling in the two dimensional frustrated Heisenberg model. We show that a ferromagnetic(FM) ordering of chirality - {\it i.e.}, same chirality on adjacent planes - is energetically favoured, thus leading to bulk violation of the discrete symmetries parity($P$) and time reversal($T$).",11 pages,"D. M. Gaitonde, Dileep P. Jatkar, Sumathi Rao",physics,val
Theory of Directed Polymers,"We develop a theory of polymers in a nematic solvent by exploiting an analogy with two-dimensional quantum bosons at zero temperature. We argue that the theory should also describe polymers in an {\sl isotropic} solvent. The dense phase is analyzed in a Bogoliubov-like approximation, which assumes a broken symmetry in the phase of the boson order parameter. We find a stiffening of the longitudinal fluctuations of the nematic field, calculate the density-density correlation function, and extend the analysis to the case of ferro- and electrorheological fluids. The boson formalism is used to derive a simple hydrodynamic theory which is indistinguishable from the corresponding theory of polymer nematics in an isotropic solvent at long wavelengths. We also use hydrodynamics to discuss the physical meaning of the boson order parameter. A renormalization group treatment in the dilute limit shows that logarithmic corrections to polymer wandering, predicted by de Gennes, are unaffected by interpolymer interactions. A continuously variable Flory exponent appears for polymers embedded in a {\sl two}-dimensional nematic solvent. We include free polymer ends and hairpin configurations in the theory and show that hairpins are described by an Ising-like symmetry-breaking term in the boson field theory.","29 pages (small) - requires harvmac.tex (16 figures, not included)","R. D. Kamien, P. Le Doussal, D. R. Nelson",physics,train
Image of the Energy Gap Anisotropy in the Vibrational Spectum of a High Temperature Superconductor,We present a new method of determining the anisotropy of the gap function in layered high-Tc superconductors. Careful inelastic neutron scattering measurements at low temperature of the phonon dispersion curves in the (100) direction in La_(1.85)Sr_(.15)CuO_4 would determine whether the gap is predominately s-wave or d-wave. We also propose an experiment to determine the gap at each point on a quasi-two-dimensional Fermi surface.,12 pages + 2 figures (included),Michael E. Flatte,physics,train
"Order Parameters, Broken Symmetry, and Topology","We introduce the theoretical framework we use to study the bewildering variety of phases in condensed--matter physics. We emphasize the importance of the breaking of symmetries, and develop the idea of an order parameter through several examples. We discuss elementary excitations and the topological theory of defects.","Lectures Given at the Santa Fe Complexity Institute Summer School,
  1991. Jeffrey Goldstone's name corrected",James P. Sethna,physics,train
Meissner Effect and Constraints,"We notice some beautiful geometrical defects found in liquid crystals, and explain them by imposing a constraint. We study the way constraints can occur, and introduce the concept of massive fields. We develop the theory of magnetic field expulsion in superconductors as an example. We notice strong analogies with the formation of grain boundaries in crystals, and realize that we do not understand crystals very deeply","Lectures Given at the Santa Fe Complexity Institute Summer School,
  1991. Figures added","James P. Sethna, Ming Huang",physics,val
A Field Theory for Finite Dimensional Site Disordered Spin Systems,"We present a new field theoretic approach for finite dimensional site disordered spin systems by introducing the notion of grand canonical disorder, where the number of spins in the system is random but quenched. We analyze this field theory using the variational replica formalism. For a variety of interactions we find a spin glass phase (with continuous replica symmetry breaking) and explicitly discuss a three dimensional system where this occurs. This approximation also suggests that any ferromagnetic transition occur within the spin glass phase.","Replaced with published version. 4 pages, 1 Postscript figure, uses
  revtex. Also available at
  http://chimera.roma1.infn.it/index_papers_complex.html","David S. Dean, David Lancaster",physics,test
"Hierarchical Diffusion, Aging and Multifractality","We study toy aging processes in hierarchically decomposed phase spaces where the equilibrium probability distributions are multifractal. We found that the an auto-correlation function, survival-return probability, shows crossover behavior from a power law $t^{-x}$ in the quasi-equilibrium regime ($t\ll\tw$) to another power law $t^{-\lambda}$ ($\lambda \geq x$) in the off-equilibrium regime ($t\gg\tw$) obeying a simple $t/\tw$ scaling law. The exponents $x$ and $\lambda$ are related with the so called mass exponents which characterize the multifractality.","28 pages, LaTex, 6 PostScript figures. To appear in Journal of
  Physics A",Hajime Yoshino,physics,train
Retrieval Phase Diagrams of Non-monotonic Hopfield Networks,We investigate the retrieval phase diagrams of an asynchronous fully-connected attractor network with non-monotonic transfer function by means of a mean-field approximation. We find for the noiseless zero-temperature case that this non-monotonic Hopfield network can store more patterns than a network with monotonic transfer function investigated by Amit et al. Properties of retrieval phase diagrams of non-monotonic networks agree with the results obtained by Nishimori and Opris who treated synchronous networks. We also investigate the optimal storage capacity of the non-monotonic Hopfield model with state-dependent synaptic couplings introduced by Zertuche et el. We show that the non-monotonic Hopfield model with state-dependent synapses stores more patterns than the conventional Hopfield model. Our formulation can be easily extended to a general transfer function.,Latex 13 pages using IOP style file,Jun-ichi Inoue,physics,val
A Single Slice 2d Anderson Model at Weak Disorder,"We introduce a matrix-operator formulation of the Anderson model in d=2. In a single slice, we can then derive an analogy between our model and a standard random matrices problem. This enables us to construct and control the Green function in one slice, which is an important prerequisite to a full multi-scale study of the problem using the Renormalisation Group approach.","paper withdrawn, reader can refer to cond-mat/9702111 for a stronger
  result with a much understandable derivation along with various bug fixing",Gilles Poirot,physics,val
Site Disordered Spin Systems in the Gaussian Variational Approximation,"We define a replica field theory describing finite dimensional site disordered spin systems by introducing the notion of grand canonical disorder, where the number of spins in the system is random but quenched. A general analysis of this field theory is made using the Gaussian variational or Hartree Fock method, and illustrated with several specific examples. Irrespective of the form of interaction between the spins this approximation predicts a spin glass phase. We discuss the replica symmetric phase at length, explicitly identifying the correlator that diverges at the spin glass transition. We also discuss the form of continuous replica symmetry breaking found just below the transition. Finally we show how an analysis of ferromagnetic ordering indicates a breakdown of the approximation.","Replaced with version to be published. 33 pages, 3 postscript
  figures, using harvmac. Also available at
  http://chimera.roma1.infn.it/index_papers_complex.html","David Dean, David Lancaster",physics,val
Statistical mechanics of the random K-SAT model,"The Random K-Satisfiability Problem, consisting in verifying the existence of an assignment of N Boolean variables that satisfy a set of M=alpha N random logical clauses containing K variables each, is studied using the replica symmetric framework of diluted disordered systems. We present an exact iterative scheme for the replica symmetric functional order parameter together for the different cases of interest K=2, K>= 3 and K>>1. The calculation of the number of solutions, which allowed us [Phys. Rev. Lett. 76, 3881 (1996)] to predict a first order jump at the threshold where the Boolean expressions become unsatisfiable with probability one, is thoroughly displayed. In the case K=2, the (rigorously known) critical value (alpha=1) of the number of clauses per Boolean variable is recovered while for K>=3 we show that the system exhibits a replica symmetry breaking transition. The annealed approximation is proven to be exact for large K.","34 pages + 1 table + 8 fig., submitted to Phys. Rev. E, new section
  added and references updated","R. Monasson, R. Zecchina",physics,train
Hopfield models as generalized random mean field models,"We give a comprehensive self-contained review on the rigorous analysis of the thermodynamics of a class of random spin systems of mean field type whose most prominent example is the Hopfield model. We focus on the low temperature phase and the analysis of the Gibbs measures with large deviation techniques. There is a very detailed and complete picture in the regime of ``small $\a$''; a particularly satisfactory result concerns a non-trivial regime of parameters in which we prove 1) the convergence of the local ``mean fields'' to gaussian random variables with constant variance and random mean; the random means are from site to site independent gaussians themselves; 2) ``propagation of chaos'', i.e. factorization of the extremal infinite volume Gibbs measures, and 3) the correctness of the ``replica symmetric solution'' of Amit, Gutfreund and Sompolinsky [AGS]. This last result was first proven by M. Talagrand [T4], using different techniques.","92pp, Plain TeX, updated and corrected, final version to be published
  in ``Mathematical Aspects of Spin Glasses and Neural Networks'', Series:
  Progress in Probability, Birkhaeuser, Boston","Anton Bovier, Veronique Gayrard",physics,train
Multifractality and percolation in the coupling space of perceptrons,The coupling space of perceptrons with continuous as well as with binary weights gets partitioned into a disordered multifractal by a set of $p=\gamma N$ random input patterns. The multifractal spectrum $f(\alpha)$ can be calculated analytically using the replica formalism. The storage capacity and the generalization behaviour of the perceptron are shown to be related to properties of $f(\alpha)$ which are correctly described within the replica symmetric ansatz. Replica symmetry breaking is interpreted geometrically as a transition from percolating to non-percolating cells. The existence of empty cells gives rise to singularities in the multifractal spectrum. The analytical results for binary couplings are corroborated by numerical studies.,"13 pages, revtex, 4 eps figures, version accepted for publication in
  Phys. Rev. E","M. Weigt, A. Engel",physics,train
Ground state properties of solid-on-solid models with disordered substrates,"We study the glassy super-rough phase of a class of solid-on-solid models with a disordered substrate in the limit of vanishing temperature by means of exact ground states, which we determine with a newly developed minimum cost flow algorithm. Results for the height-height correlation function are compared with analytical and numerical predictions. The domain wall energy of a boundary induced step grows logarithmically with system size, indicating the marginal stability of the ground state, and the fractal dimension of the step is estimated. The sensibility of the ground state with respect to infinitesimal variations of the quenched disorder is analyzed.","4 pages RevTeX, 3 eps-figures included","H. Rieger, U. Blasum",physics,train
An Experimentally Realizable Weiss Model for Disorder-Free Glassiness,We summarize recent work on a frustrated periodic long-range Josephson array in a parameter regime where its dynamical behavior is identical to that of the $p=4$ disordered spherical model. We also discuss the physical requirements imposed by the theory on the experimental realization of this superconducting network.,"6 pages, LaTeX, 2 Postscript figures","P. Chandra, M. V. Feigelman, M. E. Gershenson, L. B. Ioffe",physics,train
Quantum transport in semiconductor-superconductor microjunctions,"Recent experiments on conduction between a semiconductor and a superconductor have revealed a variety of new mesoscopic phenomena. Here is a review of the present status of this rapidly developing field. A scattering theory is described which leads to a conductance formula analogous to Landauer's formula in normal-state conduction. The theory is used to identify features in the conductance which can serve as ""signatures"" of phase-coherent Andreev reflection, i.e. for which the phase coherence of the electrons and the Andreev-reflected holes is essential. The applications of the theory include a quantum point contact, quantum dot, weak localization, universal conductance fluctuations, shot noise, and reflectionless tunneling. This review is based on lectures at the Les Houches summer school, Session LXI, 1994.","38 pages, 17 figures (included in version 2)",C. W. J. Beenakker,physics,train
Mode-Locking in Quantum-Hall-Effect Point Contacts,"We study the effect of an ac drive on the current-voltage (I-V) characteristics of a tunnel junction between two fractional Quantum Hall fluids at filling $\nu ^{-1}$ an odd integer. Within the chiral Luttinger liquid model of edge states, the point contact dynamics is described by a driven damped quantum mechanical pendulum. In a semi-classical limit which ignores electron tunnelling, this model exhibits mode-locking, which corresponds to current plateaus in the I-V curve at integer multiples of $I= e\omega /2\pi$, with $\omega$ the ac drive angular frequency. By analyzing the full quantum model at non-zero $\nu$ using perturbative and exact methods, we study the effect of quantum fluctuation on the mode-locked plateaus. For $\nu=1$ quantum fluctuations smear completely the plateaus, leaving no trace of the ac drive. For $\nu \ge 1/2$ smeared plateaus remain in the I-V curve, but are not centered at the currents $I=n e \omega /2\pi$. For $\nu < 1/2$ rounded plateaus centered around the quantized current values are found. The possibility of using mode locking in FQHE point contacts as a current-to-frequency standard is discussed.","12 pages, 8 figures, minor changes","Hsiu-Hau Lin, Matthew P. A. Fisher",physics,test
Spectral Fluctuations in Disordered Metals,"This is a review of the properties of spectral fluctations in disordered metals, their relation with Random Matrix Theory and semiclassical picture. We also review the physics of persistent currents in mesoscopic isolated rings, the parametric correlations and curvature distributions.","45 LateX pages, 15 postscript figures, Minor typos have been
  corrected and references updated",Gilles Montambaux,physics,test
Ultrasmall double junction in terms of orthogonal polynomials,The ``orthodox theory'' of a single electron double junction is dealt with. It is shown that the stationary solution of the underlying master equation allows the construction of any time-dependent solution in terms of orthogonal polynomials. The approach pays off if the stationary solution becomes simple. Two special cases are considered. We use the time-dependent solution to calculate the current noise in these cases.,"6 pages, 4 Postscript figures, uses epsf.sty and multicol.sty,
  amended computation in the high-temperature domain","Heinz-Olaf Müller, Andreas Hädicke, Ulrik Hanke, K. A. Chao",physics,train
Inelastic Electron Lifetime in Disordered Mesoscopic Systems,"The inelastic quasiparticle lifetime due to the electron-electron interaction (out-scattering time in the kinetic equation formalism) is calculated for finite metallic diffusive systems (quantum dots) in the whole range of parameters. Both cases of ``continuous'' (the inelastic level broadening much exceeds the mean level spacing) and ``discrete'' spectrum are analyzed. In particular, crossover between one- and zero-dimensional regimes is studied in detail. In the case of continuous spectrum the out-scattering time is shown to be the same as the inelastic time entering expressions for universal conductance fluctuations and persistent currents. It is also found to be shorter than the phase-breaking time in two- and one-dimensional systems, while in zero-dimensional systems these two times coincide. In the case of discrete spectrum for small enough systems a universal behavior of the scattering time is obtained. For temperatures below the mean level spacing the out-scattering rate is shown to be vanishingly small.","24 pages + 4 figures, Revtex. Final version, some revisions are made,
  references to recent work added",Yaroslav M. Blanter,physics,test
Surface acoustic wave attenuation by a two-dimensional electron gas in a strong magnetic field,"The propagation of a surface acoustic wave (SAW) on GaAs/AlGaAs heterostructures is studied in the case where the two-dimensional electron gas (2DEG) is subject to a strong magnetic field and a smooth random potential with correlation length Lambda and amplitude Delta. The electron wave functions are described in a quasiclassical picture using results of percolation theory for two-dimensional systems. In accordance with the experimental situation, Lambda is assumed to be much smaller than the sound wavelength 2*pi/q. This restricts the absorption of surface phonons at a filling factor \bar{\nu} approx 1/2 to electrons occupying extended trajectories of fractal structure. Both piezoelectric and deformation potential interactions of surface acoustic phonons with electrons are considered and the corresponding interaction vertices are derived. These vertices are found to differ from those valid for three-dimensional bulk phonon systems with respect to the phonon wave vector dependence. We derive the appropriate dielectric function varepsilon(omega,q) to describe the effect of screening on the electron-phonon coupling. In the low temperature, high frequency regime T << Delta (omega_q*Lambda /v_D)^{alpha/2/nu}, where omega_q is the SAW frequency and v_D is the electron drift velocity, both the attenuation coefficient Gamma and varepsilon(omega,q) are independent of temperature. The classical percolation indices give alpha/2/nu=3/7. The width of the region where a strong absorption of the SAW occurs is found to be given by the scaling law |Delta \bar{\nu}| approx (omega_q*Lambda/v_D)^{alpha/2/nu}. The dependence of the electron-phonon coupling and the screening due to the 2DEG on the filling factor leads to a double-peak structure for Gamma(\bar{\nu}).","17 pages, 3 Postscript figures, minor changes made","Andreas Knaebchen, Yehoshua Levinson, Ora Entin-Wohlman",physics,val
Correlated ground states with (spontaneously) broken time-reversal symmetry,"We propose a self-consistent scheme for the determination of the ground-state (GS) properties of interacting electrons in a magnetic field, and of systems whose GS's time-reversal-symmetry (TRS) is spontaneously broken. It is based on a newly-developed many-body perturbation theory that is valid, irrespective of the strength of correlation, provided the GS number densities $n_{\uparrow}({\bf r})$, $n_{\downarrow}({\bf r})$, and the {\sl total} paramagnetic particle flux density are pure-state non-interacting $v$-representable. Our approach can in particular be applied to (modulated) two-dimensional electron systems in the fractional quantum-Hall regime.","4 pages, 2 figures; fig. 2 corrected & 2 references added",Behnam Farid,physics,train
Statistics of skyrmions and the 5/2 puzzle,"1) For the hard core interaction there is some freedom left in the choice of the exact multiskyrmionic wave function's topology. The statistics of textured quasiholes, analyzed by calculation of the Berry phase, depends on this choice of topology. 2) We find a class of textured two-hole eigenstates of the Coulomb interaction. There is no definite quantum statistics but there is a definite rule of how to construct Coulomb eigenstates out of the hard core wave functions. 3) A wave function for the 5/2 state is constructed according to this rule.","13 pages, Latex; Extended version to appear in Phys.Rev.B; wave
  function for a droplet of 5/2 state is proposed; some new rigorous results
  about spin",Jacek Dziarmaga,physics,train
Transport through a single-band wire connected to measuring leads,"Transport through a one-dimensional wire of interacting electrons connected to semi infinite leads is investigated using a bosonization approach. The dynamic nonlocal conductivity is rigorously expressed in terms of the transmission. For abrupt variations of the interaction parameters at the junctions, an incident electron is transmitted as a sequence of partial charges: the central wire acts as a Fabry-P\'erot resonator. The dc conductance is shown to be given by the total transmission which turns out to be perfect. When the wire has a tendency towards superconducting order, partial Andreev reflection of an incident electron occurs. Finally, we study the role of a weak barrier at one contact or inside the wire by a renormalization group method at finite temperature. We compute the conductance in the presence of localized or extended disorder, and compare our results to recent experiments on quantum wires.","14 pages, 3 Figures, crckapb style. The paper has not been changed,
  but replaced to solve technical problems","Inès Safi, H. J. Schulz",physics,val
Spin-Excitation-Instability-Induced Quantum Phase Transitions in Double-Layer Quantum Hall Systems,"We study intersubband spin density collective modes in double-layer quantum Hall systems at $\nu=2$ within the time-dependent Hartree-Fock approximation. We find that these intersubband spin density excitations may soften under experimentally accessible conditions, signaling a phase transition to a new quantum Hall state with interlayer inplane antiferromagnetic spin correlations. We show that this novel canted antiferromagnetic phase is energetically stable and that the phase transition is continuous.",Revised final version to appear in Phys. Rev. Lett,"Lian Zheng, R. J. Radtke, S. Das Sarma",physics,val
Electronic Structure of Single- and Multiple-shell Carbon Fullerenes,"We study the electronic states of giant single-shell and the recently discovered nested multi-shell carbon fullerenes within the tight-binding approximation. We use two different approaches, one based on iterations and the other on symmetry, to obtain the $\pi$-state energy spectra of large fullerene cages: $C_{240}$, $C_{540}$, $C_{960}$, $C_{1500}$, $C_{2160}$ and $C_{2940}$. Our iteration technique reduces the dimensionality of the problem by more than one order of magnitude (factors of $\sim 12$ and $20$), while the symmetry-based approach reduces it by a factor of $10$. We also find formulae for the highest occupied and lowest unoccupied molecular orbital (HOMO and LUMO) energies of $C_{60{\cdot}n^{2}}$ fullerenes as a function of $n$, demonstrating a tendency towards metallic regime for increasing $n$. For multi-shell fullerenes, we analytically obtain the eigenvalues of the intershell interaction.","5 pages, RevTex, 2 figures upon request (to be published in Physical
  Review B, Feb. 1994)","Yeong-Lieh Lin, Franco Nori",physics,train
Recursion and Path-Integral Approaches to the Analytic Study of the Electronic Properties of $C_{60}$,"The recursion and path-integral methods are applied to analytically study the electronic structure of a neutral $C_{60}$ molecule. We employ a tight-binding Hamiltonian which considers both the $s$ and $p$ valence electrons of carbon. From the recursion method, we obtain closed-form {\it analytic} expressions for the $\pi$ and $\sigma$ eigenvalues and eigenfunctions, including the highest occupied molecular orbital (HOMO) and the lowest unoccupied molecular orbital (LUMO) states, and the Green's functions. We also present the local densities of states around several ring clusters, which can be probed experimentally by using, for instance, a scanning tunneling microscope. {}From a path-integral method, identical results for the energy spectrum are also derived. In addition, the local density of states on one carbon atom is obtained; from this we can derive the degree of degeneracy of the energy levels.","19 pages, RevTex, 6 figures upon request","Yeong-Lieh Lin, Franco Nori",physics,train
"Phonon Transmission Rate, Fluctuations, and Localization in Random Semiconductor Superlattices: Green's Function Approach","We analytically study phonon transmission and localization in random superlattices by using a Green's function approach. We derive expressions for the average transmission rate and localization length, or Lyapunov exponent, in terms of the superlattice structure factor. This is done by considering the backscattering of phonons, due to the complex mass density fluctuations, which incorporates all of the forward scattering processes. These analytical results are applied to two types of random superlattices and compared with numerical simulations based on the transfer matrix method. Our analytical results show excellent agreement with the numerical data. A universal relation for the transmission fluctuations versus the average transmission is derived explicitly, and independently confirmed by numerical simulations. The transient of the distribution of transmission to the log-normal distribution for the localized phonons is also studied.","36 pages, Latex","Norihiko Nishiguchi, Shin-ichiro Tamura, Franco Nori",physics,train
Phonon Universal Transmission Fluctuations and Localization in Semiconductor Superlattices with a Controlled Degree of Order,"We study both analytically and numerically phonon transmission fluctuations and localization in partially ordered superlattices with correlations among neighboring layers. In order to generate a sequence of layers with a varying degree of order we employ a model proposed by Hendricks and Teller as well as partially ordered versions of deterministic aperiodic superlattices. By changing a parameter measuring the correlation among adjacent layers, the Hendricks- Teller superlattice exhibits a transition from periodic ordering, with alterna- ting layers, to the phase separated opposite limit; including many intermediate arrangements and the completely random case. In the partially ordered versions of deterministic superlattices, there is short-range order (among any $N$ conse- cutive layers) and long range disorder, as in the N-state Markov chains. The average and fluctuations in the transmission, the backscattering rate, and the localization length in these multilayered systems are calculated based on the superlattice structure factors we derive analytically. The standard deviation of the transmission versus the average transmission lies on a {\it universal\/} curve irrespective of the specific type of disorder of the SL. We illustrate these general results by applying them to several GaAs-AlAs superlattices for the proposed experimental observation of phonon universal transmission fluctuations.","16-pages, Revtex","Norihiko Nishiguchi, Shin-ichiro Tamura, Franco Nori",physics,train
The effect of monomer evaporation on a simple model of submonolayer growth,"We present a model for thin film growth by particle deposition that takes into account the possible evaporation of the particles deposited on the surface. Our model focuses on the formation of two-dimensional structures. We find that the presence of evaporation can dramatically affect the growth kinetics of the film, and can give rise to regimes characterized by different ``growth'' exponents and island size distributions. Our results are obtained by extensive computer simulations as well as through a simple scaling approach and the analysis of rate equations describing the system. We carefully discuss the relationship of our model with previous studies by Venables and Stoyanov of the same physical situation, and we show that our analysis is more general.","41 pages including figures, Revtex, to be published in Physical
  Review B","Pablo Jensen, Hernán Larralde, Alberto Pimpinelli",physics,val
"Statistical Mechanics of Cracks: Thermodynamic Limit, Fluctuations, Breakdown, and Asymptotics of Elastic Theory","We study a class of models for brittle fracture: elastic theory models which allow for cracks but not for plastic flow. We show that these models exhibit, at all finite temperatures, a transition to fracture under applied load similar to that at a first order liquid-gas transition. We study this transition at low temperature for small tension. We discuss the appropriate thermodynamic limit of these theories: a large class of boundary conditions is identified for which the energy release for a crack becomes independent of the macroscopic shape of the material. Using the complex variable method in a two-dimensional elastic theory, we prove that the energy release in an isotropically stretched material due to the creation of an arbitrary curvy cut is the same to cubic order as the energy release for the straight cut with the same end points. We find the normal modes and the energy spectrum for crack shape fluctuations and for crack surface phonons, under a uniform isotropic tension. For small uniform isotropic tension in two dimensions we calculate the essential singularity associated with fracturing the material in a saddle point approximation including quadratic fluctuations. This singularity determines the lifetime of the material (half-life for fracture), and also determines the asymptotic divergence of the high-order corrections to the zero temperature elastic coefficients. We calculate the asymptotic ratio of the high-order elastic coefficients of the inverse bulk modulus and argue that the result is unchanged by nonlinearities --- the ratio of the high-order nonlinear terms are determined solely by the linear theory.","25 pages, LaTeX, 9 Postscript figures","Alex Buchel, James P. Sethna",physics,test
The structure and phase stability of CO adsorbates on Rh(110),"The structure of CO adsorbates on the Rh(110) surface is studied at full coverage using first-principles techniques. The relative energies of different adsorbate geometries are determined by means of accurate structure optimizations. In agreement with experiments, we find that a p2mg(2x1) 2CO structure is the most stable. The CO molecules sit on the short-bridge site (carbon below) with the molecular axis slightly tilted off the surface normal, along the (001) direction. Configurations corresponding to different distributions of tilt angles are mapped onto an anisotropic 2D Ising model whose parameters are extracted from our ab-initio calculations. We find that an order-disorder phase-transition occurs at a temperature T_c=350 K.","4 pages, latex file, 2 figures included","Dario Alfe', Stefano Baroni",physics,val
Theoretical Analysis of STM Experiments at Rutile TiO_2 Surfaces,"A first-principles atomic orbital-based electronic structure method is used to investigate the low index surfaces of rutile Titanium Dioxide. The method is relatively cheap in computational terms, making it attractive for the study of oxide surfaces, many of which undergo large reconstructions, and may be governed by the presence of Oxygen vacancy defects. Calculated surface charge densities are presented for low-index surfaces of TiO$_2$, and the relation of these results to experimental STM images is discussed. Atomic resolution images at these surfaces tend to be produced at positive bias, probing states which largely consist of unoccupied Ti 3$d$ bands, with a small contribution from O 2$p$. These experiments are particularly interesting since the O atoms tend to sit up to 1 angstrom above the Ti atoms, so providing a play-off between electronic and geometric structure in image formation.","9 pages, Revtex, 3 postscript figures, accepted by Surf. Science","O. Gulseren, R. James, D. W. Bullett",physics,train
Improved Magnetic Information Storage using Return-Point Memory,"The traditional magnetic storage mechanisms (both analog and digital) apply an external field signal H(t) to a hysteretic magnetic material, and read the remanent magnetization M(t), which is (roughly) proportional to H(t). We propose a new analog method of recovering the signal from the magnetic material, making use of the shape of the hysteresis loop M(H). The field H, ``stored'' in a region with N domains or particles, can be recovered with fluctuations of order 1/N using the new method - much superior to the 1/sqrt{N} fluctuations in traditional analog storage.","9 pages, 15 figures","Olga Perkovic, James P. Sethna",physics,train
Zn-related deep centers in wurtzite GaN,"Zn in GaN forms an efficient radiative center and acts as a deep acceptor which can make the crystal insulating. Four different Zn-related centers have been by now identified, leading to light emission in the range between 1.8 eV and 2.9 eV. We present a first-principles investigation total energy and electronic structure calculations for Ga-substitutional and hetero-antisite N-substitutional Zn in wurtzite GaN, using ultrasoft pseudopotentials and a conjugate-gradient total energy minimization method. Our results permit the identification of the blue-light emission center as the substitutional acceptor, while contrary to a common belief the Zn_N heteroantisite has a very high formation energy and donor behavior, which seems to exclude it as the origin of the other centers.","4 pages, to appear in ""The Physics of Semiconductors""","Fabio Bernardini, Vincenzo Fiorentini, R. M. Nieminen",physics,train
Thermodynamically consistent equilibrium properties of normal-liquid Helium-3,"The high-precision data for the specific heat C_{V}(T,V) of normal-liquid Helium-3 obtained by Greywall, taken together with the molar volume V(T_0,P) at one temperature T_0, are shown to contain the complete thermodynamic information about this phase in zero magnetic field. This enables us to calculate the T and P dependence of all equilibrium properties of normal-liquid Helium-3 in a thermodynamically consistent way for a wide range of parameters. The results for the entropy S(T,P), specific heat at constant pressure C_P(T,P), molar volume V(T,P), compressibility kappa(T,P), and thermal expansion coefficient alpha(T,P) are collected in the form of figures and tables. This provides the first complete set of thermodynamically consistent values of the equilibrium quantities of normal-liquid Helium-3. We find, for example, that alpha(T,P) has a surprisingly intricate pressure dependence at low temperatures, and that the curves alpha(T,P) vs T do not cross at one single temperature for all pressures, in contrast to the curves presented in the comprehensive survey of helium by Wilks. Corrected in cond-mat/9906222v3: The sign of the coefficient d_0 was misprinted in Table I of cond-mat/9906222v1 and v2. It now correctly reads d_0=-7.1613436. All results in the paper were obtained with the correct value of d_0. (We would like to thank for E. Collin, H. Godfrin, and Y. Bunkov for finding this misprint.)","19 pages, 19 figures, 9 tables; published version; note added in
  proof; v3: misprint corrected","M. Kollar, D. Vollhardt",physics,test
"Comment on ""Phonon Spectrum and Dynamical Stability of a Dilute Quantum Degenerate Bose-Fermi Mixture",We show that the conclusions of a recent PRL by Pu et al is incorrect.,latex,S. -K. Yip,physics,train
Pair dynamics in the formation of molecules in a Bose-Einstein condensate,"We revisit the mean-field treatment of photoassociation and Feshbach resonances in a Bose-Einstein condensate previously used by various authors. Generalizing the Cherny and Shanenko approach (Phys. Rev. E 62, 1646-59 (2000) ) where the finite size of the potentials is explicitly introduced, we develop a two-channel model for a mixed atomic-molecular condensate. Besides the individual dynamics of the condensed and non-condensed atoms, the model also takes into account their pair dynamics by means of pair wave functions. We show that the resulting set of coupled equations can be reduced to the usual coupled Gross-Pitaevskii equations when the time scale of the pair dynamics is short compared to that of the individual dynamics. Such time scales are discussed in the case of typical photoassociation experiments with cw lasers. We show that the individual dynamics plays a minor role, demonstrating the validity of the rates predicted by the usual models describing photoassociation in a nondegenerate gas.","15 pages, 4 figures: updated with respect to the published version","Pascal Naidon, Francoise Masnou-Seeuws",physics,train
Thermal conductivity of doped $\rm\bf La_2CuO_4$ as an example for heat transport by optical phonons in complex materials,"We investigate the phonon thermal conductivity $\kappa_{\mathrm{ph}}$ of doped $\rm La_2CuO_4$ based on out-of-plane thermal conductivity measurements. When room temperature is approached the temperature dependence of $\kappa_{\mathrm{ph}}$ strongly deviates from the $T^{-1}$-decrease which is usually expected for heat transport by acoustic phonons. Instead, $\kappa_{\mathrm{ph}}$ decreases much weaker or even increases with rising temperature. Simple arguments suggest that such unusual temperature dependencies of $\kappa_{\mathrm{ph}}$ are caused by heat transport via dispersive optical phonons.",,"C. Hess, B. Büchner",physics,val
Non-Gaussian Velocity Distributions in Optical Lattices,"We present a detailed experimental study of the velocity distribution of atoms cooled in an optical lattice. Our results are supported by full-quantum numerical simulations. Even though the Sisyphus effect, the responsible cooling mechanism, has been used extensively in many cold atom experiments, no detailed study of the velocity distribution has been reported previously. For the experimental as well as for the numerical investigation, it turns out that a Gaussian function is not the one that best reproduce the data for all parameters. We also fit the data to alternative functions, such as Lorentzians, Tsallis functions and double Gaussians. In particular, a double Gaussian provides a more precise fitting to our results.",Final published version with 12 pages and 12 figures,"Johan Jersblad, Harald Ellmann, Kristian Stöchkel, Anders Kastberg, Laurent Sanchez-Palencia, Robin Kaiser",physics,val
Heating and atom loss during upward ramps of Feshbach resonance levels in Bose-Einstein condensates,"The production of pairs of fast atoms leads to a pronounced loss of atoms during upward ramps of Feshbach resonance levels in dilute Bose-Einstein condensates. We provide comparative studies on the formation of these bursts of atoms containing the physical predictions of several theoretical approaches at different levels of approximation. We show that despite their very different description of the microscopic binary physics during the passage of a Feshbach resonance, all approaches lead to virtually the same prediction on the total loss of condensate atoms, provided that the ramp of the magnetic field strength is purely linear. We give the reasons for this remarkable insensitivity of the remnant condensate fraction to the microscopic physical processes and compare the theoretical predictions with recent Feshbach resonance crossing experiments on 23Na and 85Rb.","12 pages, 7 eps figures; final version","Thorsten Koehler, Krzysztof Goral, Thomas Gasenzer",physics,train
Energy Spectrum Evolution of a Diffuse Field in Elastic Body Caused by Weak Nonlinearity,We study the evolution of diffuse elastodynamic spectral energy density under the influence of weak nonlinearity. It is shown that the rate of change of this quantity is given by a convolution of the linear energy at two frequencies. Quantitative estimates are given for sample aluminum and fused silica blocks of experimental interest.,"9 pages, 3 figures; revised for better presentation","Alexei Akolzin, Richard L. Weaver",physics,val
Atomic Bose-Fermi mixtures in an optical lattice,"A mixture of ultracold bosons and fermions placed in an optical lattice constitutes a novel kind of quantum gas, and leads to phenomena, which so far have been discussed neither in atomic physics, nor in condensed matter physics. We discuss the phase diagram at low temperatures, and in the limit of strong atom-atom interactions, and predict the existence of quantum phases that involve pairing of fermions with one or more bosons, or, respectively, bosonic holes. The resulting composite fermions may form, depending on the system parameters, a normal Fermi liquid, a density wave, a superfluid liquid, or an insulator with fermionic domains. We discuss the feasibility for observing such phases in current experiments.","4 pages, 1 eps figure, misprints corrected","M. Lewenstein, L. Santos, M. A. Baranov, H. Fehrmann",physics,train
Finite-size effects of a left-handed material slab on the image quality,"The characteristics of an imaging system formed by a left-handed material (LHM) slab of finite length are studied, and the influence of the finite length of the slab on the image quality is analyzed. Unusual phenomena such as surface bright spots and negative energy stream at the image side are observed and explained as the cavity effects of surface plasmons excited by the evanescent components of the incident field. For a thin LHM slab, the cavity effects are found rather sensitive to the length of the slab, and the bright spots on the bottom surface of the slab may stretch to the image plane and degrade the image quality.","changes in the content and the title, and also the figures","Long Chen, Sailing He, Linfang Shen",physics,train
Magnetic bipolar transistor,"A magnetic bipolar transistor is a bipolar junction transistor with one or more magnetic regions, and/or with an externally injected nonequilibrium (source) spin. It is shown that electrical spin injection through the transistor is possible in the forward active regime. It is predicted that the current amplification of the transistor can be tuned by spin.","4 pages, 2 figures","Jaroslav Fabian, Igor Zutic, S. Das Sarma",physics,train
Impurity Scattering in a Bose-Einstein Condensate at finite temperature,"We consider the effects of finite temperature on the scattering of impurity atoms in a BoseEinstein condensate, showing that the scattering rate is enhanced by the thermal atoms. Collisions can increase or decrease the impurity energy. Below the Landau velocity only the first process occurs, i.e., the collisions cool the condensate. Above the critical velocity the dissipative collisions prevail over the cooling ones for sufficiently low temperatures. These considerations are applied to a recent experiment.",4 figures.,Alberto Montina,physics,val
Macroscopic Quantum Coherence in a repulsive Bose-Einstein condensate,"We consider a Bose-Einstein bicondensate (BEC) of $^{87}Rb$, trapped in two different internal levels, in a situation where the density undergoes a symmetry breaking in momentum space. This occurs for a suitable number of condensed atoms within a double well dispersion curve, obtained by Raman coupling two internal states with two tilted and detuned light fields. Evidence of bistability results from the Gross-Pitaevskii equation. By second quantization, we evaluate the tunneling rate between the two asymmetric states; the effects of losses on coherence are also considered.","4 pages, 4 figures","A. Montina, F. T. Arecchi",physics,test
Bose-Einstein condensation into non-equilibrium states studied by condensate focusing,"We report the formation of Bose-Einstein condensates into non-equilibrium states. Our condensates are much longer than equilibrium condensates with the same number of atoms, show strong phase fluctuations, and have a dynamical evolution similar to that of quadrupole shape oscillations of regular condensates. The condensates emerge in elongated traps as the result of local thermalization when the nucleation time is short compared to the axial oscillation time. We introduce condensate focusing as a powerful method to extract the phase-coherence length of Bose-Einstein condensates.","4 pages, 2 figures","I. Shvarchuck, Ch. Buggle, D. S. Petrov, K. Dieckmann, M. Zielonkovski, M. Kemmann, T. Tiecke, W. von Klitzing, G. V. Shlyapnikov, J. T. M. Walraven",physics,train
Bose-Einstein condensation in a magnetic double-well potential,"We present the first experimental realisation of Bose-Einstein condensation in a purely magnetic double-well potential. This has been realised by combining a static Ioffe-Pritchard trap with a time orbiting potential (TOP). The double trap can be rapidly switched to a single harmonic trap of identical oscillation frequencies thus accelerating the two condensates towards each other. Furthermore, we show that time averaged potentials can be used as a means to control the radial confinement of the atoms. Manipulation of the radial confinement allows vortices and radial quadrupole oscillations to be excited.","5 pages, 5 figures. Submitted to Journal of Optics B, see
  http://stacks.iop.org/JOptB/5/S119","T. G. Tiecke, M. Kemmann, Ch. Buggle, I. Shvarchuck, W. von Klitzing, J. T. M. Walraven",physics,train
Shape oscillations in non-degenerate Bose gases - transition from the collisionless to the hydrodynamic regime,"We investigate collective oscillations of non-degenerate clouds of Rb-87 atoms as a function of density in an elongated magnetic trap. For the low-lying M=0 monopole-quadrupole shape oscillation we measure the oscillation frequencies and damping rates. At the highest densities the mean-free-path is smaller than the axial dimension of the sample, which corresponds to collisionally hydrodynamic conditions. This allows us to cover the cross-over from the collisionless to the hydrodynamic regime. The experimental results show good agreement with theory. We also analyze the influence of trap anharmonicities on the oscillations in relation to observed temperature dependencies of the dipole and quadrupole oscillation frequencies. We present convenient expressions to quantify these effects.","10 pages, 5 figures","Ch. Buggle, P. Pedri, W. von Klitzing, J. T. M. Walraven",physics,train
Time-Averaged Adiabatic Potentials: Versatile traps and waveguides for ultracold quantum gases,"We demonstrate a novel class of trapping potentials, time-averaged adiabatic potentials (TAAP) which allows the generation of a large variety of traps and waveguides for ultracold atoms. Multiple traps can be coupled through controllable tunneling barriers or merged altogether. We present analytical expressions for pancake-, cigar-, and ring- shaped traps. The ring-geometry is of particular interest for guided matter-wave interferometry as it provides a perfectly smooth waveguide of controllable diameter, and thus a tunable sensitivity of the interferometer.","5 pages, 3 figures","Igor Lesanovsky, Wolf von Klitzing",physics,test
Many-body approach to low-lying collective excitations in a BEC approaching collapse,"An approximate many-body theory incorporating two-body correlations has been employed to calculate low-lying collective multipole frequencies in a Bose-Einstein condensate containing $A$ bosons, for different values of the interaction parameter $\lambda=\frac{Aa_{s}}{a_{ho}}$. Significant difference from the variational estimate of the Gross-Pitaevskii equation has been found near the collapse region. This is attributed to two-body correlations and finite range attraction of the realistic interatomic interaction. A large deviation from the hydrodynamic model is also seen for the second monopole breathing mode and the quadrupole mode for large positive $\lambda$.","8 pages, 2 figures","Anindya Biswas, Tapan Kumar Das",physics,val
Antiferromagnetic Order of Repulsively Interacting Fermions on Optical lattices,"The N\'eel state in fermionic mixtures of two pseudospin species in an optical lattice is analyzed at low temperatures. Experimentally it remains a challenge to demonstrate antiferromagnetic correlations in ultracold fermionic quantum gases. We find that, while in balanced systems the N\'eel order parameter can point in any spatial direction, in imbalanced mixtures antiferromagnetism is strictly perpendicular to the quantization axis (i.e., the z-axis). Since, experimentally, one always has to assume some minimal imbalance this should have important consequences for ongoing experiments.","4 pages, 3 figures","Tobias Gottwald, Peter van Dongen",physics,train
Evaporative depolarization and spin transport in a unitary trapped Fermi gas,"We consider a partially spin-polarized atomic Fermi gas in a high-aspect-ratio trap, with a flux of predominantly spin-up atoms exiting the center of the trap. We argue that such a scenario can be produced by evaporative cooling, and we find that it can result in a substantially non-equilibrium polarization pattern for typical experimental parameters. We offer this as a possible explanation for the quantitative discrepancies in recent experiments on spin-imbalanced unitary Fermi gases.","6 pages, 3 figures; published version","Meera M. Parish, David A. Huse",physics,train
Repulsive Fermi gas in a harmonic trap: Ferromagnetism and spin textures,"We study ferromagnetism in a repulsively interacting two-component Fermi gas in a harmonic trap. Within a local density approximation, the two components phase-separate beyond a critical interaction strength, with one species having a higher density at the trap center. We discuss several easily observable experimental signatures of this transition. The mean field release energy, its separate kinetic and interaction contributions, as well as the potential energy, all depend on the interaction strength and contain a sharp signature of this transition. In addition, the conversion rate of atoms to molecules, arising from three-body collisions, peaks at an interaction strength just beyond the ferromagnetic transition point. We then go beyond the local density approximation, and derive an energy functional which includes a term that depends on the local magnetization gradient and acts as a `surface tension'. Using this energy functional, we numerically study the energetics of some candidate spin textures which may be stabilized in a harmonic trapping potential at zero net magnetization. We find that a hedgehog state has a lower energy than an `in-out' domain wall state in an isotropic trap. Upon inclusion of trap anisotropy we find that the hedgehog magnetization profile gets distorted due to the surface tension term, this distortion being more apparent for small atom numbers. We estimate that the magnetic dipole interaction does not play a significant role in this system. We consider possible implications for experiments on trapped Li-6 and K-40 gases.","10 pgs, 5 figs: Added discussion of suppression of atom loss rate
  with onset of ferromagnetism; Added fig showing separate
  kinetic/potential/interaction energy signatures of ferromagnetism","L. J. LeBlanc, J. H. Thywissen, A. A. Burkov, A. Paramekanti",physics,train
Structure Function of Polymer Nematic Liquid Crystals: A Monte Carlo Simulation,"We present a Monte Carlo simulation of a polymer nematic for varying volume fractions, concentrating on the structure function of the sample. We achieve nematic ordering with stiff polymers made of spherical monomers that would otherwise not form a nematic state. Our results are in good qualitative agreement with theoretical and experimental predictions, most notably the bowtie pattern in the static structure function.","10 pages, plain TeX, macros included, 3 figures available from
  archive. Published version","Randall D. Kamien, Gary S. Grest",physics,train
Noisy kink in microtubules,We study the power spectrum of a class of noise effects generated by means of a digital-like disorder in the traveling variable of the conjectured Ginzburg-Landau-Montroll kink excitations moving along the walls of the microtubules. We have found a 1/f^{\alpha} noise with \alpha \in (1.82-2.04) on all the time scales we have considered,"8 pp latex (with 2 eps figs), based on a contribution presented by HC
  Rosu at the Workshop on Biophysics of Microtubules in Houston (April
  12-14/96)","H. C. Rosu, J. A. Tuszyński, A. González",physics,train
Renormalization of Fluctuating Tilted-Hexatic Membranes,"We consider the tilted-hexatic Hamiltonian on the fluctuating membranes. A renormalization-group analysis leads us to find two critical regions; one corresponds to the strong coupling regime of the gradient cross coupling, the other to the weak coupling regime. In the strong coupling regime, we find the locked tilted-hexatic to liquid phase transition when disclinations and vortices unbind simultaneously. On the other hand, in the weak coupling regime we find four phases; the unlocked tilted-hexatic phase, the hexatic phase, the tilted phase, and liquid phase. Disclinations and vortices unbind independently. The crinkled-to-crumpled transition of the fluctuating tilted-hexatic membranes is also described. The crinkled phase in the strong coupling regime is stiffer than that in the weak coupling regime.","REVTEX, 4 pages with 2 figures. To appear in Physical Review E Rapid
  Communication in July issue",Jeong-Man Park,physics,test
Nonequilibrium Fluctuations in Sedimenting Suspensions: A Dynamical Renormalization Group Theory,"A nonlinear two-fluid stochastic hydrodynamical description of velocity and concentration fluctuations in sedimenting suspensions is constructed, and analyzed using self-consistent (SC) and renormalization group (RG) methods. The advection of particles by velocity fluctuations is shown to be ``relevant'' in all dimensions $d < 6$ . Both RG and SC analyses predict a strong reduction in the dependence of velocity fluctuations on system-size $L$ relative to the $L^{1/2}$ obtained in the linearized theory of Caflisch and Luke [Phys. Fluids {\bf 28}, 785 (1985)]. This is an important step towards resolving a ten-year old puzzle in the field.","Four pages, revtex, two .eps files, uses epsf.sty","Alex Levine, Sriram Ramaswamy, Robijn Bruinsma",physics,val
Instability and front propagation in laser-tweezed lipid bilayer tubules,"We study the mechanism of the `pearling' instability seen recently in experiments on lipid tubules under a local applied laser intensity. We argue that the correct boundary conditions are fixed chemical potentials, or surface tensions \Sigma, at the laser spot and the reservoir in contact with the tubule. We support this with a microscopic picture which includes the intensity profile of the laser beam, and show how this leads to a steady-state flow of lipid along the surface and gradients in the local lipid concentration and surface tension (or chemical potential). This leads to a natural explanation for front propagation and makes several predictions based on the tubule length. While most of the qualitative conclusions of previous studies remain the same, the `ramped' control parameter (surface tension) implies several new qualitative results. We also explore some of the consequences of front propagation into a noisy (due to pre-existing thermal fluctuations) unstable medium.","12 page latex + figures using epsf.sty to be published in Journal de
  Physique II, January 1997","Peter D. Olmsted, F. C. MacKintosh",physics,train
The Role of Bilayer Tilt Difference in Equilibrium Membrane Shapes,"Lipid bilayer membranes below their main transition have two tilt order parameters, corresponding to the two monolayers. These two tilts may be strongly coupled to membrane shape but only weakly coupled to each other. We discuss some implications of this observation for rippled and saddle phases, bilayer tubules, and bicontinuous phases. Tilt difference introduces a length scale into the elastic theory of tilted fluid membranes. It can drive an instability of the flat phase; it also provides a simple mechanism for the spontaneous breaking of inversion symmetry seen in some recent experiments.","Latex file; .ps available at
  http://dept.physics.upenn.edu/~nelson/saddle.ps","Udo Seifert, Julian Shillcock, Philip Nelson",physics,val
Coupled Fluctuations near Critical Wetting,Recent work on the complete wetting transition has emphasized the role played by the coupling of fluctuations of the order parameter at the wall and at the depinning fluid interface. Extending this approach to the wetting transition itself we predict a novel crossover effect associated with the decoupling of fluctuations as the temperature is lowered towards the transition temperature T_W. Using this we are able to reanalyse recent Monte-Carlo simulation studies and extract a value \omega(T_W)=0.8 at T_W=0.9T_C in very good agreement with long standing theoretical predictions.,"4 pages, LaTex, 1 postscript figure","A. O. Parry, C. J. Boulter, P. S. Swain",physics,val
Fluid adsorption at a non-planar wall: roughness induced first-order wetting,"We study the problem of fluid adsorption at a non-planar wall with a view to understanding the influence of surface roughness on the wetting transition. Starting from an appropriate Landau-type free energy functional we develop a linear response theory relating the free energy of the non-planar system to the correlation functions in its planar counterpart. We generalize the well known graphical construction method used to study the planar surface phase diagram and derive analytical expressions for the shift in the phase boundary for first and second-order wetting transitions. Of particular interest is the influence of surface roughness on a second order wetting transition which is driven first order, even for small deviations from the plane.","5 pages, RevTex, 2 postscript figures included. To appear in J.Phys.:
  Condens. Matter","A. O. Parry, P. S. Swain, J. A. Fox",physics,test
Straightening of Thermal Fluctuations in Semi-Flexible Polymers by Applied Tension,"We investigate the propagation of a suddenly applied tension along a thermally excited semi-flexible polymer using analytical approximations, scaling arguments and numerical simulation. This problem is inherently non-linear. We find sub-diffusive propagation with a dynamical exponent of 1/4. By generalizing the internal elasticity, we show that tense strings exhibit qualitatively different tension profiles and propagation with an exponent of 1/2.","Latex file; with three postscript figures; .ps available at
  http://dept.physics.upenn.edu/~nelson/pull.ps","Udo Seifert, Wolfgang Wintz, Philip Nelson",physics,val
Dynamics of the swelling or collapse of a homopolymer,"We study the dynamics of a polymer when it is quenched from a $\theta$ solvent into a good or bad solvent by means of a Langevin equation. The variation of the radius of gyration is studied as a function of time. For the first stage of collapse or swelling, the characteristic time-scale is found to be independent of the number of monomers. Other scaling laws are derived for the diffusion regime at larger times. Although the present model is solved only for homopolymers and doesn't include hydrodynamic interactions, these results may be a first step towards the understanding of the early stages of protein folding.",,"E. Pitard, H. Orland",physics,train
Stable quasicrystalline ground states,"We give a strong evidence that noncrystalline materials such as quasicrystals or incommensurate solids are not exceptions but rather are generic in some regions of a phase space. We show this by constructing classical lattice-gas models with translation-invariant, finite-range interactions and with a unique quasiperiodic ground state which is stable against small perturbations of two-body potentials. More generally, we provide a criterion for stability of nonperiodic ground states.","14 pages, Latex, 10 figures available upon request, completely
  revised version",Jacek Miekisz,physics,val
Fractal Dimensions of Confined Clusters in Two-Dimensional Directed Percolation,"The fractal structure of directed percolation clusters, grown at the percolation threshold inside parabolic-like systems, is studied in two dimensions via Monte Carlo simulations. With a free surface at y=\pm Cx^k and a dynamical exponent z, the surface shape is a relevant perturbation when k<1/z and the fractal dimensions of the anisotropic clusters vary continuously with k. Analytic expressions for these variations are obtained using a blob picture approach.","6 pages, Plain TeX file, epsf, 3 postscript-figures","C. Kaiser, L. Turban",physics,val
Surface Magnetization of Aperiodic Ising Systems: a Comparative Study of the Bond and Site Problems,"We investigate the influence of aperiodic perturbations on the critical behaviour at a second order phase transition. The bond and site problems are compared for layered systems and aperiodic sequences generated through substitution. In the bond problem, the interactions between the layers are distributed according to an aperiodic sequence whereas in the site problem, the layers themselves follow the sequence. A relevance-irrelevance criterion introduced by Luck for the bond problem is extended to discuss the site problem. It involves a wandering exponent for pairs, which can be larger than the one considered before in the bond problem. The surface magnetization of the layered two-dimensional Ising model is obtained, in the extreme anisotropic limit, for the period-doubling and Thue-Morse sequences.","19 pages, Plain TeX, IOP macros + epsf, 6 postscript figures, minor
  corrections","L. Turban, P. E. Berche, B. Berche",physics,val
Surface Shape and Local Critical Behaviour in Two-Dimensional Directed Percolation,"Two-dimensional directed site percolation is studied in systems directed along the x-axis and limited by a free surface at y=\pm Cx^k. Scaling considerations show that the surface is a relevant perturbation to the local critical behaviour when k<1/z where z=\nu_\parallel/\nu is the dynamical exponent. The tip-to-bulk order parameter correlation function is calculated in the mean-field approximation. The tip percolation probability and the fractal dimensions of critical clusters are obtained through Monte-Carlo simulations. The tip order parameter has a nonuniversal, C-dependent, scaling dimension in the marginal case, k=1/z, and displays a stretched exponential behaviour when the perturbation is relevant. The k-dependence of the fractal dimensions in the relevant case is in agreement with the results of a blob picture approach.","13 pages, Plain TeX file, epsf, 6 postscript-figures, minor
  corrections","C. Kaiser, L. Turban",physics,train
Anisotropic Scaling in Layered Aperiodic Ising Systems,"The influence of a layered aperiodic modulation of the couplings on the critical behaviour of the two-dimensional Ising model is studied in the case of marginal perturbations. The aperiodicity is found to induce anisotropic scaling. The anisotropy exponent z, given by the sum of the surface magnetization scaling dimensions, depends continuously on the modulation amplitude. Thus these systems are scale invariant but not conformally invariant at the critical point.","7 pages, 2 eps-figures, Plain TeX and epsf, minor corrections","B. Berche, P. E. Berche, M. Henkel, F. Igloi, P. Lajko, S. Morgan, L. Turban",physics,train
Ferromagnetism in Hubbard Models,"We present the first rigorous examples of non-singular Hubbard models which exhibit ferromagnetism at zero temperature. The models are defined in arbitrary dimensions, and are characterized by finite-ranged hoppings, dispersive bands, and finite on-site Coulomb interaction U. The picture, which goes back to Heisenberg, that sufficiently large Coulomb interaction can revert Pauli paramagnetism into ferromagnetism has finally been confirmed in concrete examples.","LaTeX, 8 pages with two epsf figures. A short note is added in August
  1997",Hal Tasaki,physics,train
Long-range order versus random-singlet phases in quantum antiferromagnetic systems with quenched disorder,"The stability of antiferromagnetic long-range order against quenched disorder is considered. A simple model of an antiferromagnet with a spatially varying Neel temperature is shown to possess a nontrivial fixed point corresponding to long-range order that is stable unless either the order parameter or the spatial dimensionality exceeds a critical value. The instability of this fixed point corresponds to the system entering a random-singlet phase. The stabilization of long-range order is due to quantum fluctuations, whose role in determining the phase diagram is discussed.","5 pp., REVTeX, epsf, 3 eps figs, final version as published,
  including erratum","T. R. Kirkpatrick, D. Belitz",physics,val
Breakdown of Landau-Ginzburg-Wilson theory for certain quantum phase transitions,"The quantum ferromagnetic transition of itinerant electrons is considered. It is shown that the Landau-Ginzburg-Wilson theory described by Hertz and others breaks down due to a singular coupling between fluctuations of the conserved order parameter. This coupling induces an effective long-range interaction between the spins of the form 1/r^{2d-1}. It leads to unusual scaling behavior at the quantum critical point in $1<d\leq 3$ dimensions, which is determined exactly.","4 pp., REVTeX, no figs, final version as published","T. Vojta, D. Belitz, R. Narayanan, T. R. Kirkpatrick",physics,train
Quantum critical behavior of disordered itinerant ferromagnets,"The quantum ferromagnetic transition at zero temperature in disordered itinerant electron systems is considered. Nonmagnetic quenched disorder leads to diffusive electron dynamics that induces an effective long-range interaction between the spin or order parameter fluctuations of the form r^{2-2d}, with d the spatial dimension. This leads to unusual scaling behavior at the quantum critical point, which is determined exactly. In three-dimensional systems the quantum critical exponents are substantially different from their finite temperature counterparts, a difference that should be easily observable. Experiments to check these predictions are proposed.","14pp., REVTeX, 3 eps figs, final version as published","T. R. Kirkpatrick, D. Belitz",physics,train
Self--organized criticality due to a separation of energy scales,"Certain systems with slow driving and avalanche-like dissipation events are naturally close to a critical point when the ratio of two energy scales is large. The first energy scale is the threshold above which an avalanche is triggered, the second scale is the threshold above which a site is affected by an avalanche. I present results of computer simulations, and a mean-field theory.","This paper is very different from the old version which had an error
  in the simulation code. Please destroy the old version if you have it",Barbara Drossel,physics,train
The Mott-Hubbard Transition on the D=infinity Bethe Lattice,"In view of a recent controversy we investigated the Mott-Hubbard transition in D=infinity with a novel cluster approach. i) We show that any truncated Bethe lattice of order n can be mapped exactly to a finite Hubbard-like cluster. ii) We evaluate the self-energy numerically for n=0,1,2 and compare with a series of self-consistent equation-of-motion solutions. iii) We find the gap to open continously at the critical U_c~2.5t* (t = t* / sqrt{4d}). iv) A low-energy theory for the Mott-Hubbard transition is developed and relations between critical exponents are presented.",Replaced with the published version,"Claudius Gros, Wolfgang Wenzel, Roser Valenti, Georg Huelsenbeck, Joachim Stolze",physics,train
Questions and Issues Arising at SCES '94 Theory,"I summarize some of the key questions to have emerged during the 1994 conference on ``Strongly Correlated Electron Systems'', held in Amsterdam, August 1994. Issues addressed include: Hunds rule interactions and how they renormalize; the Luttinger sum rule and metamagnetism; heavy fermion insulators, the nature of the charge gap, spectral weight transfer in the optical conductivity; non-Fermi liquid behavior in transition and heavy fermion metals; order parameter symmetry and the unusual nature of quasiparticle excitations in heavy fermion superconductors.",summary--Amsterdam,P. Coleman,physics,val
The Hubbard Model: Introduction and Selected Rigorous Results,"The Hubbard model is a ""highly oversimplified model"" for electrons in a solid which interact with each other through extremely short ranged repulsive (Coulomb) interaction. The Hamiltonian of the Hubbard model consists of two pieces; H_hop which describes quantum mechanical hopping of electrons, and Hint which describes nonlinear repulsive interaction. Either H_hop or H_int alone is easy to analyze, and does not favor any specific order. But their sum H=H_hop+H_int is believed to exhibit various nontrivial phenomena including metal-insulator transition, antiferromagnetism, ferrimagnetism, ferromagnetism, Tomonaga-Luttinger liquid, and superconductivity. It is believed that we can find various interesting ""universality classes"" of strongly interacting electron systems by studying the idealized Hubbard model. In the present article we review some mathematically rigorous results on the Hubbard model which shed light on ""physics"" of this fascinating model. We mainly concentrate on magnetic properties of the model at its ground states. We discuss Lieb-Mattis theorem on the absence of ferromagnetism in one dimension, Koma-Tasaki bounds on decay of correlations at finite temperatures in two-dimensions, Yamanaka-Oshikawa-Affleck theorem on low-lying excitations in one-dimension, Lieb's important theorem for half-filled model on a bipartite lattice, Kubo-Kishi bounds on the charge and superconducting susceptibilities of half-filled models at finite temperatures, and three rigorous examples of saturated ferromagnetism due to Nagaoka, Mielke, and Tasaki. We have tried to make the article accessible to nonexperts by describing basic definitions and elementary materials in detail.","LaTeX2e, 34 pages, 11 epsf figures. Completely revised and extended
  in December 1997",Hal Tasaki,physics,train
Spin-gap phase in nearly-half-filled one-dimensional conductors coupled with phonons,"Asymptotic properties of nearly-half-filled one-dimensional conductors coupled with phonons are studied through a renormalization group method. Due to spin-charge coupling via electron-phonon interaction, the spin correlation varies with filling as well as the charge correlation. Depending on the relation between cut-off energy scales of the Umklapp process and of the electron-phonon interaction, various phases appear. We found a metallic phase with a spin gap and a dominant charge- density-wave correlation near half filling between a gapless density-wave phase (like in the doped repulsive Hubbard model) and a superconductor phase with a spin gap. The spin gap is produced by phonon-assisted backward scatterings which are interfered with the Umklapp process constructively or destructively depending on the character of electron-phonon coupling.","14 pages, revtex, replaced 5 ps figures, published in PRB","K. Yonemitsu, M. Imada",physics,train
Non Fermi-Liquid States and Pairing of a general Model of Copper-Oxide Metals,"A model of copper-oxygen bonding and anti-bonding bands with the most general two-body interactions allowable by symmetry is considered. The model has a continuous transition as a function of hole-density x and temperature T to a phase in which a current circulates in each unit cell. This phase preserves the translational symmetry of the lattice while breaking time-reversal invariance and the four-fold rotational symmetry. The product of time-reversal and four-fold rotation is preserved. The circulating current phase terminates at a critical point at $x=x_c, T=0$. In the quantum-critical region about this point the logarithm of the frequency of the current fluctuations scales with their momentum. The microscopic basis for the marginal Fermi-liquid phenemenology and the observed long wavelength transport anomalies near $x=x_c$ are derived from such fluctuations. The symmetry of the current fluctuations is such that the associated magnetic field fluctuations are absent at oxygen sites and have the correct form to explain the anomalous copper nuclear relaxation rate. Cross-overs to the Fermi-liquid phase on either side of $x_c$ and the role of disorder are briefly considered. The current fluctuations promote superconductive instability with a propensity towards ``D-wave"" symmetry or ``extended S-wave""symmetry depending on details of the band-structure.","85 pages RevTex,15 figures available from the author",C. M. Varma,physics,test
On two channel flavor anisotropic and one channel compactified Kondo models,"We reinvestigate the two channel flavor anisotropic model (2CFAK) and one channel compacitified Kondo model (1CCK). For these two models, all the possible fixed points and their symmetries are identified; the finite size spectra, the electron conductivity and pairing susceptibility are calculated. It is shown that the only non-fermi liquid (NFL) fixed point of the 2CFAK is the NFL of the two channel Kondo model (2CK) with the symmetry $O(3) \times O(5)$. Any flavor anisotropies between the two channels drive the system to the fermi-liquid (FL) fixed point with the symmetry $O(4) \times O(4)$ where one of the two channels suffers the phase shift \pi/2 and the other remains free. The NFL fixed point of the 1CCK has the symmetry $O(3) \times O(1)$ and has the same thermodynamics as the NFL fixed point of the 2CK. However, in contrast to the 2CK, its conductivity shows $T^{2}$ behavior and there is no pairing susceptibility divergence. Any anisotropies between the spin and isospin sectors drive the system to the FL fixed point with the symmetry O(4) where the electrons suffer the phase shift \pi/2. The connection and differences between the two models are explicitly demonstrated. The recent conjectures and claims on the NFL behaviors of the two models are commented.","20 pages, REVTEX, no figure",Jinwu Ye,physics,train
Solution of two channel spin-flavor Kondo model,"We investigate a model where an impurity couples to both the spin and the flavor currents of the two channel conduction electrons. This model can be used as a prototype model of a magnetic impurity tunneling between two sites in a metal and of some heavy fermion systems where the ground state of the impurity has a fourfold degeneracy. The system is shown to flow to a doubly degenerate non fermi-liquid(NFL) fixed point; the thermodynamic quantities show NFL behaviors, but the transport quantities show fermi liquid (FL) behaviors . A spin-flavor coupling double tensor term is shown to drive the system to one of the two singlet FL fixed points. The relation with SU(4) Coqblin-Schrieffer model is studied. The implications on the possible experiments are given.","11 pages, REVTEX, no figures. To appear in Phys. Rev. B (Rapid Comm.)
  July 1, 1997",Jinwu Ye,physics,train
Solution of effective Hamiltonian of impurity hopping between two sites in a metal,"We analyze in detail all the possible fixed points of the effective Hamiltonian of a non-magnetic impurity hopping between two sites in a metal obtained by Moustakas and Fisher(MF). We find a line of non-fermi liquid fixed points which continuously interpolates between the 2-channel Kondo fixed point(2CK) and the one channel, two impurity Kondo (2IK) fixed point. The additional non-fermi liquid fixed point found by MF has the same symmetry as the 2IK, The system is shown to flow to a line of fermi-liquid fixed points which continuously interpolates between the non-interacting fixed point and the 2 channel spin-flavor Kondo fixed point (2CSFK) discussed by the author previously. The effect of particle-hole symmetry breaking is discussed. The effective Hamiltonian in the external magnetic field is analysed. The scaling functions for the physical measurable quantities are derived in the different regimes; their predictions for the experiments are given. Finally the implications are given for a non-magnetic impurity hopping around three sites with triangular symmetry discussed by MF.","27 pages, REVTEX, 1 figure embedded in the text",Jinwu Ye,physics,val
Itinerant Antiferromagnetism in FeGe_2,"FeGe_2, and lightly doped compounds based on it, have a Fermi surface driven instability which drive them into an incommensurate spin density wave state. Studies of the temperature and magnetic field dependence of the resistivity have been used to determine the magnetic phase diagram of the pure material which displays an incommensurate phase at high temperatures and a commensurate structure below 263 K in zero field. Application of a magnetic field in the tetragonal basal plane decreases the range of temperatures over which the incommensurate phase is stable. We have used inelastic neutron scattering to measure the spin dynamics of FeGe_2. Despite the relatively isotropic transport the magnetic dynamics is quasi-one dimensional in nature. Measurements carried out on HET at ISIS have been used to map out the spin wave dispersion along the c-axis up the 400 meV, more than an order of magnitude higher than the zone boundary magnon for wavevectors in the basal plane.","6 pages, Latex2e uses epsfig and elsart, to appear in the Proceedings
  of the International Conference on the Physics of Transition Metals, Physica
  B","T. E. Mason, C. P. Adams, S. A. M. Mentink, E. Fawcett, A. Z. Menshikov, C. D. Frost, J. B. Forsyth, T. G. Perring, T. M. Holden",physics,val
Zero-bias anomalies of point contact resistance due to adiabatic electron renormalization of dynamical defects,"We study effect of the adiabatic electron renormalization on the parameters of the dynamical defects in the ballistic metallic point contact. The upper energy states of the ``dressed'' defect are shown to give a smaller contribution to a resistance of the contact than the lower energy ones. This holds both for the ""classical"" renormalization related to defect coupling with average local electron density and for the ""mesoscopic"" renormalization caused by the mesoscopic fluctuations of electronic density the dynamical defects are coupled with. In the case of mesoscopic renormalization one may treat the dynamical defect as coupled with Friedel oscillations originated by the other defects, both static and mobile. Such coupling lifts the energy degeneracy of the states of the dynamical defects giving different mesoscopic contribution to resistance, and provides a new model for the fluctuator as for the object originated by the electronic mesoscopic disorder rather than by the structural one. The correlation between the defect energy and the defect contribution to the resistance leads to zero-temperature and zero-bias anomalies of the point contact resistance. A comparison of these anomalies with those predicted by the Two Channel Kondo Model (TCKM) is made. It is shown, that although the proposed model is based on a completely different from TCKM physical background, it leads to a zero-bias anomalies of the point contact resistance, which are qualitatively similar to TCKM predictions.","6 pages, to be published in Phys. Rev. B","V. I. Kozub, A. M. Rudin",physics,test
Transport and Boundary Scattering in Confined Geometries: Analytical Results,We utilize a geometric argument to determine the effects of boundary scattering on the carrier mean-free path in samples of various cross sections. Analytic expressions for samples with rectangular and circular cross sections are obtained. We also outline a method for incorporating these results into calculations of the thermal conductivity.,"35 pages, Latex","R. Richardson, Franco Nori",physics,train
Quantum Interference on the Kagomé Lattice,"We study quantum interference effects due to electron motion on the Kagom\'e lattice in a perpendicular magnetic field. These effects arise from the interference between phase factors associated with different electron closed-paths. From these we compute, analytically and numerically, the superconducting-normal phase boundary for Kagom\'e superconducting wire networks and Josephson junction arrays. We use an analytical approach to analyze the relationship between the interference and the complex structure present in the phase boundary, including the origin of the overall and fine structure. Our results are obtained by exactly summing over one thousand billion billions ($\sim 10^{21}$) closed paths, each one weighted by its corresponding phase factor representing the net flux enclosed by each path. We expect our computed mean-field phase diagrams to compare well with several proposed experiments.","9 pages, Revtex, 3 figures upon request","Yeong-Lieh Lin, Franco Nori",physics,train
Theory of Scanning Tunneling Microscopy Probe of Impurity States in a D-Wave Superconductor,"Scanning tunneling microscopy can provide a probe for the detailed study of quasiparticle states in high-Tc superconductors. We propose that it can also be used to acquire specific information about impurity-induced quasiparticle states and the superconducting order-parameter structure. In particular, the local density of states is found to be sensitive to impurity-induced resonances and to the symmetry of the order parameter.",,"M. I. Salkola, A. V. Balatsky, D. J. Scalapino",physics,val
Effects of Interlayer Interaction on the Superconducting State in YBCO,"For a two layer system in a weak coupling BCS formalism any interlayer interaction, regardless of its sign, enhances the critical temperature. The sign has an effect upon the relative phase of the order parameter in each of the two planes but not upon its magnitude. When one of the planes has a dispersion consistent with CuO chains and no intrinsic pairing interaction there is both an enhancement of the critical temperature and an s+d mixing in both layers as the interlayer interaction is increased. The magnetic penetration depth, c-axis Josephson tunneling, density of states and Knight shift are calculated for several sets of model parameters.","Small changes in response to referee and other minor changes; 10
  pages + 5 figures in ReVTeX with epsf to embed figures.","C. O'Donovan, J. P. Carbotte",physics,train
"Superfluid Bosons and Flux Liquids: Disorder, Thermal Fluctuations, and Finite-Size Effects","The influence of different types of disorder (both uncorrelated and correlated) on the superfluid properties of a weakly interacting or dilute Bose gas, as well as on the corresponding quantities for flux line liquids in high-temperature superconductors at low magnetic fields are reviewed, investigated and compared. We exploit the formal analogy between superfluid bosons and the statistical mechanics of directed lines, and explore the influence of the different ""imaginary time"" boundary conditions appropriate for a flux line liquid. For superfluids, we discuss the density and momentum correlations, the condensate fraction, and the normal-fluid density as function of temperature for two- and three-dimensional systems subject to a space- and time-dependent random potential as well as conventional point-, line-, and plane-like defects. In the case of vortex liquids subject to point disorder, twin boundaries, screw dislocations, and various configurations of columnar damage tracks, we calculate the corresponding quantities, namely density and tilt correlations, the ``boson'' order parameter, and the tilt modulus. The finite-size corrections due to periodic vs. open ""imaginary time"" boundary conditions differ in interesting and important ways. Experimental implications for vortex lines are described briefly.","78 pages, RevTex, 4 figures included (sorry, there are no ps-files
  for the remaining 2 figures; if needed, please send mail to
  tauber@thphys.ox.ac.uk); brief erratum appended (2 pages)","Uwe C. Täuber, David R. Nelson",physics,val
Similarity renormalization of the electron--phonon coupling,"We study the problem of the phonon-induced electron-electron interaction in a solid. Starting with a Hamiltonian that contains an electron-phonon interaction, we perform a similarity renormalization transformation to calculate an effective Hamiltonian. Using this transformation singularities due to degeneracies are avoided explicitely. The effective interactions are calculated to second order in the electron-phonon coupling. It is shown that the effective interaction between two electrons forming a Cooper pair is attractive in the whole parameter space. For a simple Einstein model we calculate the renormalization of the electronic energies and the critical temperature of superconductivity.","17 pages, LaTeX2e, uses AMS-fonts, 5 ps-figures included. Replaced by
  a completely revised version that contains several new results on the
  renormalization of single particle energies, on the superconducting gap, and
  on the critical temperature",Andreas Mielke,physics,test
High-T_c Superconductivity and Shadow State Formation in YBa_{2}Cu_{3}O_{6+δ} and Bi_{2}Sr_{2}CaCu_{2}O_{8+δ},"The normal and superconducting state of YBa_{2}Cu_{3}O_{6+\delta} and Bi_{2}Sr_{2}CaCu_{2}O_{8+\delta} are investigated by using the mono- and bilayer Hubbard model within the fluctuation exchange approximation and a proper description of the Fermi surface topology. The inter- and intra-layer interactions, the renormalization of the bilayer splitting and the formation of shadow bands are investigated in detail. Although the shadow states are not visible in the monolayer, we find that the additional correlations in bilayers boost the shadow state intensity and will lead to their observability. In the superconducting state we find a $d_{x^2-y^2}$ symmetry of the order parameter and demonstrate the importance of inter-plane Copper pairing.","5 pages, Revtex, 5 postscript figures","S. Grabowski, J. Schmalian, K. H. Bennemann",physics,train
Simple Ginzburg-Landau Theory for Vortices in a Crystal Lattice,"We study the Ginzburg-Landau model with a nonlocal quartic term as a simple phenomenological model for superconductors in the presence of coupling between the vortex lattice and the underlying crystal lattice. In mean-field theory, our model is consistent with a general oblique vortex lattice ranging from a triangular lattice to a square lattice. This simple formulation enables us to study the effect of thermal fluctuations in the vortex liquid regime. We calculate the structure factor of the vortex liquid nonperturbatively and find Bragg-like peaks with four-fold symmetry appearing in the structure factor even though there is only a short-range crystalline order.","Revised version with new title and additional results for the vortex
  liquid regime, to be published in Phys. Rev. Lett. 5 pages RevTeX, 1 figure
  included","Joonhyun Yeo, M. A. Moore",physics,train
First-Order Melting of a Moving Vortex Lattice: Effects of Disorder,We study the melting of a moving vortex lattice through numerical simulations with the current driven 3D XY model with disorder. We find that there is a first-order phase transition even for large disorder when the corresponding equilibrium transition is continuous. The low temperature phase is an anisotropic moving glass.,"Important changes from original version. Finite size analysis of
  results has been added. Figure 2 has been changed. There is a new additional
  Figure. To be published in Physical Review Letters","Daniel Dominguez, Niels Gronbech-Jensen, A. R. Bishop",physics,train
Generalized London free energy for high-$T_c$ vortex lattices,"We generalize the London free energy to include four-fold anisotropies which could arise from d-wave pairing or other sources in a tetragonal material. We use this simple model to study vortex lattice structure and discuss neutron scattering, STM, Bitter decoration and $\mu$SR experiments.","REVTeX, 4 pages, 2 .ps figures included, submitted to PRL","Ian Affleck, Marcel Franz, M. H. Sharifzadeh Amin",physics,test
Non-Minimally Coupled Scalar Field and Ashtekar Variables,"The non-minimal coupling of a scalar field is considered in the framework of Ashtekar's new variables formulation of gravity. A first order action functional for this system is derived in which the field variables are a tetrad field, and an SL(2,C) connection, together with the scalar field. The tetrad field and the SL(2,C) connection are related to the Ashtekar variables for the vacuum case by a conformal transformation. A canonical analysis shows that for this coupling the equations of Ashtekar's formulation of canonical gravity are non-polynomial in the scalar field. (to be published in Phys. Rev. D)",6 pages,Riccardo Capovilla,physics,train
Remarks on Pure Spin Connection Formulations of Gravity,"In the derivation of a pure spin connection action functional for gravity two methods have been proposed. The first starts from a first order lagrangian formulation, the second from a hamiltonian formulation. In this note we show that they lead to identical results for the specific cases of pure gravity with or without a cosmological constant.",,"Riccardo Capovilla, Ted Jacobson",physics,train
Nonsymmetric Gravity Theories: Inconsistencies and a Cure,"Motivated by the apparent dependence of string $\sigma$--models on the sum of spacetime metric and antisymmetric tensor fields, we reconsider gravity theories constructed from a nonsymmetric metric. We first show that all such ""geometrical"" theories homogeneous in second derivatives violate standard physical requirements: ghost-freedom, absence of algebraic inconsistencies or continuity of degree-of-freedom content. This no-go result applies in particular to the old unified theory of Einstein and its recent avatars. However, we find that the addition of nonderivative, ``cosmological'' terms formally restores consistency by giving a mass to the antisymmetric tensor field, thereby transmuting it into a fifth-force-like massive vector but with novel possible matter couplings. The resulting macroscopic models also exhibit ``van der Waals''-type gravitational effects, and may provide useful phenomenological foils to general relativity.",34 pages,"T. Damour, S. Deser, J. McCarthy",physics,train
Degenerate Extensions of General Relativity,"General relativity has previously been extended to incorporate degenerate metrics using Ashtekar's hamiltonian formulation of the theory. In this letter, we show that a natural alternative choice for the form of the hamiltonian constraints leads to a theory which agrees with GR for non-degenerate metrics, but differs in the degenerate sector from Ashtekar's original degenerate extension. The Poisson bracket algebra of the alternative constraints closes in the non-degenerate sector, with structure functions that involve the {\it inverse} of the spatial triad. Thus, the algebra does {\it not} close in the degenerate sector. We find that it must be supplemented by an infinite number ofsecondary constraints, which are shown to be first class (although their explicit form is not worked out in detail). All of the constraints taken together are implied by, but do not imply, Ashtekar's original form of constraints. Thus, the alternative constraints give rise to a different degenerate extension of GR. In the corresponding quantum theory, the single loop and intersecting loop holonomy states found in the connection representation satisfy {\it all} of the constraints. These states are therefore exact (formal) solutions to this alternative degenerate extension of quantum gravity, even though they are {\it not} solutions to the usual vector constraint.",9 pages,"Ted Jacobson, Joseph D. Romano",physics,train
The Spin Holonomy Group In General Relativity,"It has recently been shown by Goldberg et al that the holonomy group of the chiral spin-connection is preserved under time evolution in vacuum general relativity. Here, the underlying reason for the time-independence of the holonomy group is traced to the self-duality of the curvature 2-form for an Einstein space. This observation reveals that the holonomy group is time-independent not only in vacuum, but also in the presence of a cosmological constant. It also shows that once matter is coupled to gravity, the ""conservation of holonomy"" is lost. When the fundamental group of space is non-trivial, the holonomy group need not be connected. For each homotopy class of loops, the holonomies comprise a coset of the full holonomy group modulo its connected component. These cosets are also time-independent. All possible holonomy groups that can arise are classified, and examples are given of connections with these holonomy groups. The classification of local and global solutions with given holonomy groups is discussed.",21 pages,"Ted Jacobson, Joseph D. Romano",physics,train
The No-Hair Theorem for the Abelian Higgs Model,"We consider the general procedure for proving no-hair theorems for static, spherically symmetric black holes. We apply this method to the abelian Higgs model and find a proof of the no-hair conjecture that circumvents the objections raised against the original proof due to Adler and Pearson.","9pp, harvmac",Amitabha Lahiri,physics,train
Gravitational Waves from an Axi-symmetric Source in the Nonsymmetric Grav. Theory,"We examine gravitational waves in an isolated axi--symmetric reflexion symmetric NGT system. The structure of the vacuum field equations is analyzed and the exact solutions for the field variables in the metric tensor are found in the form of expansions in powers of a radial coordinate. We find that in the NGT axially symmetric case the mass of the system remains constant only if the system is static (as it necessarily is in the case of spherical symmetry). If the system radiates, then the mass decreases monotonically and the energy flux associated with waves is positive.",26 pages,"J. W. Moffat, D. C. Tatarski",physics,train
The Dirac Equation Is Separable On The Dyon Black Hole Metric,"Using the tetrad formalism, we carry out the separation of variables for the massive complex Dirac equation in the gravitational and electromagnetic field of a four-parameter (mass, angular momentum, electric and magnetic charges) black hole.",13 pages,İbrahim Semiz,physics,train
Centrifugal force in Kerr geometry,"We have obtained the correct expression for the centrifugal force acting on a particle at the equatorial circumference of a rotating body in the locally non-rotating frame of the Kerr geometry. Using this expression for the equilibrium of an element on the surface of a slowly rotating Maclaurin spheroid, we obtain the expression for the ellipticity (as discussed earlier by Abramowicz and Miller) and determine the radius at which the ellipticity is maximum.","6 pages, LateX macros","Sai Iyer, A R Prasanna",physics,train
Nonlinear Noise in Cosmology,"This paper derives and analyzes exact, nonlocal Langevin equations appropriate in a cosmological setting to describe the interaction of some collective degree of freedom with a surrounding ``environment.'' Formally, these equations are much more general, involving as they do a more or less arbitrary ``system,'' characterized by some time-dependent potential, which is coupled via a nonlinear, time-dependent interaction to a ``bath'' of oscillators with time-dependent frequencies. The analysis reveals that, even in a Markov limit, which can often be justified, the time dependences and nonlinearities can induce new and potentially significant effects, such as systematic and stochastic mass renormalizations and state-dependent ``memory'' functions, aside from the standard ``friction'' of a heuristic Langevin description. One specific example is discussed in detail, namely the case of an inflaton field, characterized by a Landau-Ginsburg potential, that is coupled quadratically to a bath of scalar ``radiation.'' The principal conclusion derived from this example is that nonlinearities and time-dependent couplings do {\em not} preclude the possibility of deriving a fluctuation-dissipation theorem, and do {\em not} change the form of the late-time steady state solution for the system, but {\em can} significantly shorten the time scale for the approach towards the steady state.",26 pages,"Salman Habib, Henry E. Kandrup",physics,train
An optimal method of moments to measure the charge asymmetry at the $Z^0$,"Parity violation at LEP or SLC can be measured through the charge asymmetry. An optimal method of moments is developed here to measure this asymmetry, as well as similar asymmetries. This method is equivalent to the likelihood fit. It is simpler in use, as it gives analytical formulas for both the asymmetry and its statistical error. These formulas give the dependence of the accuracy on the experimental angular acceptance explicitly.","7 pages of uuencoded postscript, NIKHEF preprint NIKHEF-H/94-06",Nichol C. Brummer,physics,train
Observation of Anisotropic Event Shapes and Transverse Flow in Au+Au Collisions at AGS Energy,Event shapes for Au + Au collisions at 11.4 GeV/c per nucleon were studied over nearly the full solid angle with the E877 apparatus. The analysis was performed by Fourier expansion of azimuthal distributions of the transverse energy (E_T) measured in different pseudorapidity intervals. For semicentral collisions a pronounced event anisotropy is identified beyond that expected due to fluctuations in particle multiplicity. The signal decreases for peripheral and very central collisions. The amplitude of the flow signal reaches up to 7% of the mean E_T.,"16 pages (incl. figs.), SUNY-RHI-94-08",J. Barrette,physics,train
Measurement of alpha-s from energy-energy correlations at the Z0 resonance,"We have determined the strong coupling alpha-s from a comprehensive study of energy-energy correlations (EEC) and their asymmetry (AEEC) in hadronic decays of Z0 bosons collected by the SLD experiment at SLAC. The data were compared with all four available predictions of QCD calculated up to O(alpha-s**2) in perturbation theory, and also with a resummed calculation matched to all four of these calculations. We find large discrepancies between alpha-s values extracted from the different O(alpha-s**2) calculations. We also find a large renormalization scale ambiguity in alpha-s determined from the EEC using the O(alpha-s**2) calculations; this ambiguity is reduced in the case of the AEEC, and is very small when the matched calculations are used. Averaging over all calculations, and over the EEC and AEEC results, we obtain alpha-s(MZ)=0.124+0.003-0.004(exp.) +-0.009(theory).","37, SLAC-PUB-6451",K. Abe,physics,test
A Precise Measurement of the Weak Mixing Angle in Neutrino-Nucleon Scattering,"We report a precise measurement of the weak mixing angle from the ratio of neutral current to charged current inclusive cross-sections in deep-inelastic neutrino-nucleon scattering. The data were gathered at the CCFR neutrino detector in the Fermilab quadrupole-triplet neutrino beam, with neutrino energies up to 600 GeV. Using the on-shell definition, ${\rm sin ^2\theta_W} \equiv 1 - \frac{{\rm M_W} ^2}{{\rm M_Z} ^2}$, we obtain ${\rm sin ^2\theta_W} = 0.2218 \pm 0.0025 ({\rm stat.}) \pm 0.0036 ({\rm exp.\: syst.}) \pm 0.0040 ({\rm model})$.","10 pages, Nevis Preprint #1498 (Submitted to Phys. Rev. Lett.)",C. G. Arroyo,physics,test
Precise Determination of the Weak Mixing Angle from a measurement of ALR in e+e- -> Z0,"In the 1993 SLC/SLD run, the SLD recorded 50,000 $\z0$ events produced by the collision of longitudinally polarized electrons on unpolarized positrons at a center-of-mass energy of 91.26 GeV. The luminosity-weighted average polarization of the SLC electron beam was (63.0$\pm$1.1)\%. We measure the left-right cross-section asymmetry in $\z0$ boson production, $\alr$, to be 0.1628$\pm$0.0071(stat.)$\pm$0.0028(syst.) which determines the effective weak mixing angle to be $\swein=0.2292\pm0.0009({\rm stat.})\pm0.0004({\rm syst.}).$","10 pages (postscript), SLAC-PUB-6493. Presented at the XXIXth
  Rencontres de Moriond: Electroweak Interactions and Unified Theories,
  Meribel, France, March 12-19, 1994",SLD Collaboration,physics,val
LEP asymmetries and fits of the Standard Model,"The lepton and quark asymmetries measured at LEP are presented. The results of the Standard Model fits to the electoweak data presented at this conference are given. The top mass obtained from the fit to the LEP data is $172^{+13+18}_{-14-20}$ GeV; it is $177^{+11+18}_{-11-19}$ when also the collider, $\nu$ and $A_{LR}$ data are included.","ps file,8 pages, LAPP-EXP-94.07",B. Pietrzyk,physics,train
Average Multiplicities in Gluon and Quark Jets in Higher-Order Perturbative QCD,The ratio of average multiplicities in gluon and quark jets is shown to become noticeably smaller in higher-order QCD compared to its lowest order value what improves agreement with experiment. QCD anomalous dimension has been calculated. It has been used to get energy dependence of mean multiplicities.,"Submitted to Mod. Phys. Lett.A Latex document, 10 pages. Preprint
  number FIAN TD-3 March 1994","I. M. Dremin, V. A. Nechitailo",physics,val
A Neural Network for Locating the Primary Vertex in a Pixel Detector,"Using simulated collider data for $p+p\rightarrow 2{\rm Jets}\ $ interactions in a 2-barrel pixel detector, a neural network is trained to construct the coordinate of the primary vertex to a high degree of accuracy. Three other estimates of this coordinate are also considered and compared to that of the neural network. It is shown that the network can match the best of the traditional estimates.","10 pages in Latex, and now with 9 figures as uufiles, OKHEP-94-11","R. Kantowski, Caren Marzban",physics,val
Semileptonic Branching Fraction of Charged and Neutral B Mesons,"An examination of leptons in ${\Upsilon (4S)}$ events tagged by reconstructed $B$ decays yields semileptonic branching fractions of $b_-=(10.1 \pm 1.8\pm 1.4)\%$ for charged and $b_0=(10.9 \pm 0.7\pm 1.1)\%$ for neutral $B$ mesons. This is the first measurement for charged $B$. Assuming equality of the charged and neutral semileptonic widths, the ratio $b_-/b_0=0.93 \pm 0.18 \pm 0.12$ is equivalent to the ratio of lifetimes. A postscript version is available through World-Wide-Web in http://w4.lns.cornell.edu/public/CLNS/1994","9 pages (in REVTEX format) Preprint CLNS94-1286, CLEO 94-16",The CLEO collaboration,physics,train
Measurement of the B -> D^* l nu Branching Fractions and |Vcb|,"We study the exclusive semileptonic B meson decays B- -> D*0 l- nu and B0 -> D*+ l- nu using data collected with the CLEO II detector at CESR. We present measurements of the branching fractions B(B0 -> D*+ l-nu) = 0.5/f00* [4.49+/-0.32+/-0.39]% and B(B- -> D*0 l-nu) = 0.5/f+-*[5.13+/-0.54+/-0.64]%, where f00 and f+- are the neutral and charged B meson production fractions at the Upsilon(4s) resonance. Assuming isospion invariance and taking the charged to neutral B meson lifetimes measured at higher energy machines, we determine the ratio f+-/f00=1.04+/-0.14+/-0.13+-/-0.10; further assuming f+- + f00 = 1 we also determine the partial width G(B->D* l nu) = 29.9+/-1.9+/-2.7+/-2.0 ns-1 (independent of f+-/f00). From this partial width we calculate B -> D* l nu branching fractions that do not depend on f+-/f00, nor the individual B lifetimes, but only on the charged to neutral lifetime ratio. The product of the CKM matrix element |Vcb| times the normalization of the decay form factor at the point of zero recoil of the D* meson, F(y=1), is determined from a linear fit to the combined differential decay rate of the exclusive B->D* l nu decays: |Vcb|F(y) = 0.0351 +/- 0.0019 +/- 0.0018 +/- 0.0008. Using theoretical calculations of the form factor normalization we extract a value for |Vcb|. LATEX (REVTEX style) file with uuencoded figures attached (uses PSBOX). Available on WWW http://w4.lns.cornell.edu/public/CLNS/","42 pages,CLNS 94/1285, CLEO 94-27",The CLEO Collaboration,physics,train
How to Put a Heavier Higgs on the Lattice,"Lattice work, exploring the Higgs mass triviality bound, seems to indicate that a strongly interacting scalar sector in the minimal standard model cannot exist while low energy QCD phenomenology seems to indicate that it could. We attack this puzzle using the 1/N expansion and discover a simple criterion for selecting a lattice action that is more likely to produce a heavy Higgs particle. Our large $N$ calculation suggests that the Higgs mass bound might be around $850 GeV$, which is about 30% higher than previously obtained.",,"U. M. Heller, H. Neuberger, P. Vranas",physics,val
Spectral Density Study of the SU(3) Deconfining Phase Transition,"We present spectral density reweighting techniques adapted to the analysis of a time series of data with a continuous range of allowed values. In a first application we analyze action and Polyakov line data from a Monte Carlo simulation on $L_t L^3 (L_t=2,4)$ lattices for the SU(3) deconfining phase transition. We calculate partition function zeros, as well as maxima of the specific heat and of the order parameter susceptibility. Details and warnings are given concerning i) autocorrelations in computer time and ii) a reliable extraction of partition function zeros. The finite size scaling analysis of these data leads to precise results for the critical couplings $\beta_c$, for the critical exponent $\nu$ and for the latent heat $\triangle s$. In both cases ($L_t=2$ and 4), the first order nature of the transition is substantiated.",,"Nelsons A. Alves, Bernd Al. Berg, Sergiu Sanielevici",physics,train
Vectorized Cluster Search,"Contrary to conventional wisdom, the construction of clusters on a lattice can easily be vectorized, namely over each ``generation'' in a breadth first search. This applies directly to, e.g., the {\it single cluster} variant of the Swendsen-Wang algorithm. On a Cray Y-MP, total CPU time was reduced by a factor 3.5 -- 7 in actual applications.",,Hans Gerd Evertz,physics,train
Multi-Grid Monte Carlo III. Two-Dimensional O(4)-Symmetric Nonlinear $σ$-Model,"We study the dynamic critical behavior of the multi-grid Monte Carlo (MGMC) algorithm with piecewise-constant interpolation applied to the two-dimensional O(4)-symmetric nonlinear $\sigma$-model [= SU(2) principal chiral model], on lattices up to $256 \times 256$. We find a dynamic critical exponent $z_{int,{\cal M}^2} = 0.60 \pm 0.07$ for the W-cycle and $z_{int,{\cal M}^2} = 1.13 \pm 0.11$ for the V-cycle, compared to $z_{int,{\cal M}^2} = 2.0 \pm 0.15$ for the single-site heat-bath algorithm (subjective 68% confidence intervals). Thus, for this asymptotically free model, critical slowing-down is greatly reduced compared to local algorithms, but not completely eliminated. For a $256 \times 256$ lattice, W-cycle MGMC is about 35 times as efficient as a single-site heat-bath algorithm.",,"Robert G. Edwards, Sabino José Ferreira, Jonathan Goodman, Alan D. Sokal",physics,train
Monte Carlo Simulations of Higgs-Fermion Systems,"To gain understanding of the Higgs-fermion sector of the standard model, we study the one-component $Z_2$ symmetric and the four-component O(4) symmetric scalar models coupled to staggered fermions using the hybrid Monte Carlo algorithm. We map out the phase diagrams, and show that the $Z_2$ model has a tree level perturbative behaviour at all points in the broken phase. The O(4) model on the other hand is shown to have two characteristically different behaviours; one for large Yukawa couplings where the fermions get infinitely heavy and decouple in the continuum limit, and one for small Yukawa couplings where the fermions remain light. For very small Yukawa couplings the fermions show the expected tree level perturbative behaviour and for larger values the influence of the fermions becomes substantial. After estimating the finite size effects at small Yukawa couplings we make relatively accurate measurements of the scalar mass and wave function renormalization constants at the point $\kappa=0.0$ and $y=0.85-0.95$. Even though this is not the largest value possible for the Yukawa coupling we are able to show that the bound of the Higgs mass will move up significantly, from around $600 GeV$ to around $900 GeV$, by including fermions in the model. Likewise we show that a bound can be put on the fermion mass, around $200 GeV$. The largest value of the bare Yukawa coupling is obtained at rather large negative $\kappa$. Due to bad convergence rates in the inversion of the fermion matrix, which is needed in the updating procedure, this region has not been possible to investigate.",,Jonas Berlin,physics,test
A Study of Symmetry Restoration at Finite Temperature in the O(4) Model Using Anisotropic Lattices,"Results of investigations of the O(4) spin model at finite temperature using anisotropic lattices are presented. In both the large $N$ approximation and the numerical simulations using the Wolff cluster algorithm we find that the ratio of the symmetry restoration temperature $T_{\rm SR}$ to the Higgs mass $m_{\rm H}$ is independent of the anisotropy. We obtain a lower bound of $0.59 \pm 0.04$ for the ratio, $T_{\rm SR}/m_{\rm H}$, at $m_{\rm H}a \simeq 0.5$, which is lowered further by about 10% at $m_{\rm H}a \simeq 1.$",,"R. V. Gavai, U. M. Heller, F. Karsch, B. Plache, T. Neuhaus",physics,train
Dynamic Critical Behaviour of Wolff's Algorithm for $RP^N$ $σ$-Models,"We study the performance of a Wolff-type embedding algorithm for $RP^N$ $\sigma$-models. We find that the algorithm in which we update the embedded Ising model \`a la Swendsen-Wang has critical slowing-down as $z_\chi \approx 1$. If instead we update the Ising spins with a perfect algorithm which at every iteration produces a new independent configuration, we obtain $z_\chi \approx 0$. This shows that the Ising embedding encodes well the collective modes of the system, and that the behaviour of the first algorithm is connected to the poor performance of the Swendsen-Wang algorithm in dealing with a frustrated Ising model.",,"S. Caracciolo, R. G. Edwards, A. Pelissetto, A. D. Sokal",physics,train
How to Put a Heavier Higgs on the Lattice,"The cutoff dependence of the Scalar Sector of the Minimal Standard Model can result in an increase of the existing triviality bound estimates of the Higgs mass. We present a large $N$ calculation and some preliminary N=4 results that suggest that the increase can be as large as 30%, resulting to a bound of about 850 G eV.",,"U. M. Heller, M. Klomfass, H. Neuberger, P. Vranas",physics,val
QCD Hadron Spectroscopy with Staggered Dynamical Quarks at $β= 5.6$,"We present preliminary results from the 1991 HEMCGC simulations with staggered dynamical fermions on a $16^3 \times 32$ lattice at $\beta = 5.6$ with sea quark masses $am_q = 0.025$ and 0.01. The spectroscopy was done both for staggered valence quarks with mass equal to the sea quark masses and for Wilson valence quarks at six different values for $\kappa$, 0.1320, 0.1410, 0.1525, 0.1565, 0.1585, and 0.1600. In addition to the measurements performed in our earlier work, we also measured the $\Delta$ and other `extended' hadrons for staggered valence quarks and pseudo-scalar decay constants and vector meson matrix elements, the wave function at the origin, for Wilson valence quarks.",,"K. M. Bitar, R. Edwards, T. A. DeGrand, Steven Gottlieb, U. M. Heller, A. D. Kennedy, J. B. Kogut, A. Krasnitz, W. Liu, M. C. Ogilvie, R. L. Renken, D. K. Sinclair, R. L. Sugar, D. Toussaint, K. C. Wang",physics,train
Path Integrals and Voronin's Theorem on the Universality of the Riemann Zeta Function,We explore a new approach to the path integral for a latticized quantum theory. This talk is based on work with N. Khuri and H. Ren.,,Khalil M. Bitar,physics,train
Comments on the Electroweak Phase Transition,"We report on an investigation of various problems related to the theory of the electroweak phase transition. This includes a determination of the nature of the phase transition, a discussion of the possible role of higher order radiative corrections and the theory of the formation and evolution of the bubbles of the new phase. We find in particular that no dangerous linear terms appear in the effective potential. However, the strength of the first order phase transition is 2/3 times less than what follows from the one-loop approximation. This rules out baryogenesis in the minimal version of the electroweak theory.","14 pages, 2 figures (not included)","M. Dine, R. G. Leigh, P. Huet, A. D. Linde, D. A. Linde",physics,train
A Natural Framework for Solar and 17 keV Neutrinos,"Motivated by recent experimental claims for the existence of a 17 keV neutrino and by the solar neutrino problem, we construct a class of models which contain in their low-energy spectrum a single light sterile neutrino and one or more Nambu-Goldstone bosons. In these models the required pattern of breaking of lepton-number symmetry takes place near the electroweak scale and all mass heirarchies are technically natural. The models are compatible with all cosmological and astrophysical constraints, and can solve the solar neutrino problem via either the MSW effect or vacuum oscillations. The deficit in atmospheric muon neutrinos seen in the Kamiokande and IMB detectors can also be explained in these models.",23 pages,"C. P. Burgess, J. Cline, Markus Luty",physics,train
Towards the Theory of Cosmological Phase Transitions,"We discuss recent progress (and controversies) in the theory of finite temperature phase transitions. This includes the structure of the effective potential at a finite temperature, the infrared problem in quantum statistics of gauge fields, the theory of formation of critical and subcritical bubbles and the theory of bubble wall propagation.",50 pp,"M. Dine, R. Leigh, P. Huet, A. Linde, D. Linde",physics,train
The quest for low-energy supersymmetry and the role of high-energy $e^+e^-$ colliders,"The motivations for low-energy supersymmetry and the main features of the minimal supersymmetric extension of the Standard Model are reviewed. Possible non-minimal models and the issue of gauge coupling unification are also discussed. Theoretical results relevant for supersymmetric particle searches at present and future accelerators are presented, with emphasis on the role of a proposed $\epem$ collider with $\sqrt{s} = 500 \gev$. In particular, recent results on radiative corrections to supersymmetric Higgs boson masses and couplings are summarized, and their implications for experimental searches are discussed in some detail. (Plenary talk at the Workshop on Physics and Experiments with Linear Colliders, Saariselk\""a, Lapland, Finland, 9--14 September 1991)",44 pages,F. Zwirner,physics,train
Extended Color Models with a Heavy Top Quark,"We present a class of models in which the top quark, by mixing with new physics at a higher energy scale, is naturally heavier than the other standard model particles. We take this new physics to be extended color. Our models contain new particles with masses between 100 GeV and 1 TeV, some of which may be just within the reach of the next generation of experiments. In particular one of our models implies the existence of two right handed top quarks. These models demonstrate the existence of a standard model-like theory consistent with experiment, and leading to new physics below the TeV scale, in which the third generation is treated differently than the first two.",8 pages,Oscar F. Hernandez,physics,test
Solutions to the strong CP problem in a world with gravity,We examine the sensitivity of several solutions of the strong-CP problem to violations of global symmetries by Planck scale physics. We find that the Peccei-Quinn solution is extremely sensitive to U(1)_PQ violating operators of dimension less than 10. We construct models in which the PQ symmetry is protected by gauge symmetries to the requisite level.,10 pages,"R. Holman, S. D. H. Hsu, T. Kephart, E. Kolb, R. Watkins, L. Widrow",physics,val
Differential Renormalization of Massive Quantum Field Theories,"We extend the method of differential renormalization to massive quantum field theories treating in particular $\ph4$-theory and QED. As in the massless case, the method proves to be simple and powerful, and we are able to find, in particular, compact explicit coordinate space expressions for the finite parts of two notably complicated diagrams, namely, the 2-loop 2-point function in $\ph4$ and the 1-loop vertex in QED.","8 pages(LaTex, no figures)","Peter Haagensen, Jose I. Latorre",physics,val
Monopole annihilation at the electroweak scale---Not!,"We examine the issue of monopole annihilation at the electroweak scale induced by flux tube confinement, concentrating first on the simplest possibility---one which requires no new physics beyond the standard model. Monopoles existing at the time of the electroweak phase transition may trigger $W$ condensation which can confine magnetic flux into flux tubes. However we show on very general grounds, using several independent estimates, that such a mechanism is impotent. We then present several general dynamical arguments constraining the possibility of monopole annihilation through any confining phase near the electroweak scale.",15 pp,E. Gates L. Krauss J. Terning,physics,train
How Efficient Is The Langacker-Pi Mechanism of Monopole Annihilation?,"We investigate the dynamics of monopole annihilation by the Langacker-Pi mechanism. We find taht considerations of causality, flux-tube energetics and the friction from Aharonov-Bohm scatteering suggest that the monopole annihilation is most efficient if electromagnetism is spontaneously broken at the lowest temperature ($T_{em} \approx 10^6 GeV$) consistent with not having the monopoles dominate the energy density of the universe.",10 pages,"R. Holman, T. W. B. Kibble, Soo-Jong Rey",physics,val
Precision bounds on $m_H$ and $m_t,"We perform a fit to precise electroweak data to determine the Higgs and top masses. Penalty functions taking into account their production limits are included. We find ${\displaystyle m_H=65^{+245}_{-4}\ GeV}$ and ${\displaystyle m_t=122^{+25}_{-20}\ GeV}$. However whereas the top $\chi^2$ distribution behaves properly near the minimum, the Higgs $\chi^2$ distribution does not, indicating a statistical fluctuation or new physics. In fact no significative bound on the Higgs mass can be given at present. However, if the LEP accuracy is improved and the top is discovered in the preferred range of top masses, a meaningful bound on the Higgs mass could be obtained within the standard model framework.",11 pages,"F. del Aguila, M. Martinez, M. Quiros",physics,val
Exact Black String Solutions in Three Dimensions,"A family of exact conformal field theories is constructed which describe charged black strings in three dimensions. Unlike previous charged black hole or extended black hole solutions in string theory, the low energy spacetime metric has a regular inner horizon (in addition to the event horizon) and a timelike singularity. As the charge to mass ratio approaches unity, the event horizon remains but the singularity disappears.",17 pages,"James H. Horne, Gary T. Horowitz",physics,train
Hamiltonian construction of W-gravity actions,We show that all W-gravity actions can be easilly constructed and understood from the point of view of the Hamiltonian formalism for the constrained systems. This formalism also gives a method of constructing gauge invariant actions for arbitrary conformally extended algebras.,9 pages,A. Mikovic,physics,train
Supersymmetric Gelfand-Dickey Algebra,We study the classical version of supersymmetric $W$-algebras. Using the second Gelfand-Dickey Hamiltonian structure we work out in detail $W_2$ and $W_3$-algebras.,13 pages,"Katri Huitu, Dennis Nemeschansky",physics,val
Ground Ring Of Two Dimensional String Theory,"String theories with two dimensional space-time target spaces are characterized by the existence of a ``ground ring'' of operators of spin $(0,0)$. By understanding this ring, one can understand the symmetries of the theory and illuminate the relation of the critical string theory to matrix models. The symmetry groups that arise are, roughly, the area preserving diffeomorphisms of a two dimensional phase space that preserve the fermi surface (of the matrix model) and the volume preserving diffeomorphisms of a three dimensional cone. The three dimensions in question are the matrix eigenvalue, its canonical momentum, and the time of the matrix model.",,Edward Witten,physics,val
Fusion Residues,"We discuss when and how the Verlinde dimensions of a rational conformal field theory can be expressed as correlation functions in a topological LG theory. It is seen that a necessary condition is that the RCFT fusion rules must exhibit an extra symmetry. We consider two particular perturbations of the Grassmannian superpotentials. The topological LG residues in one perturbation, introduced by Gepner, are shown to be a twisted version of the $SU(N)_k$ Verlinde dimensions. The residues in the other perturbation are the twisted Verlinde dimensions of another RCFT; these topological LG correlation functions are conjectured to be the correlation functions of the corresponding Grassmannian topological sigma model with a coupling in the action to instanton number.",16 pages,Kenneth Intriligator,physics,train
Discrete and Continuum Approaches to Three-Dimensional Quantum Gravity,"It is shown that, in the three-dimensional lattice gravity defined by Ponzano and Regge, the space of physical states is isomorphic to the space of gauge-invariant functions on the moduli space of flat $SU(2)$ connections over a two-dimensional surface, which gives physical states in the $ISO(3)$ Chern-Simons gauge theory.",14 pages,"Hirosi Ooguri, Naoki Sasakura",physics,val
Infinite Quantum Group Symmetry of Fields in Massive 2D Quantum Field Theory,"Starting from a given S-matrix of an integrable quantum field theory in $1+1$ dimensions, and knowledge of its on-shell quantum group symmetries, we describe how to extend the symmetry to the space of fields. This is accomplished by introducing an adjoint action of the symmetry generators on fields, and specifying the form factors of descendents. The braiding relations of quantum field multiplets is shown to be given by the universal $\CR$-matrix. We develop in some detail the case of infinite dimensional Yangian symmetry. We show that the quantum double of the Yangian is a Hopf algebra deformation of a level zero Kac-Moody algebra that preserves its finite dimensional Lie subalgebra. The fields form infinite dimensional Verma-module representations; in particular the energy-momentum tensor and isotopic current are in the same multiplet.",29 pages,"A. LeCLair, F. Smirnov",physics,val
Novel Symmetries of Topological Conformal Field theories,"We show that various actions of topological conformal theories that were suggested recentely are particular cases of a general action. We prove the invariance of these models under transformations generated by nilpotent fermionic generators of arbitrary conformal dimension, $\Q$ and $\G$. The later are shown to be the $n^{th}$ covariant derivative with respect to ``flat abelian gauge field"" of the fermionic fields of those models. We derive the bosonic counterparts $\W$ and $\R$ which together with $\Q$ and $\G$ form a special $N=2$ super $W_\infty$ algebra. The algebraic structure is discussed and it is shown that it generalizes the so called ``topological algebra"".",26 pages,"J. Sonnenschein, S. Yankielowicz",physics,train
Solving 3+1 QCD on the Transverse Lattice Using 1+1 Conformal Field Theory,"A new transverse lattice model of $3+1$ Yang-Mills theory is constructed by introducing Wess-Zumino terms into the 2-D unitary non-linear sigma model action for link fields on a 2-D lattice. The Wess-Zumino terms permit one to solve the basic non-linear sigma model dynamics of each link, for discrete values of the bare QCD coupling constant, by applying the representation theory of non-Abelian current (Kac-Moody) algebras. This construction eliminates the need to approximate the non-linear sigma model dynamics of each link with a linear sigma model theory, as in previous transverse lattice formulations. The non-perturbative behavior of the non-linear sigma model is preserved by this construction. While the new model is in principle solvable by a combination of conformal field theory, discrete light-cone, and lattice gauge theory techniques, it is more realistically suited for study with a Tamm-Dancoff truncation of excited states. In this context, it may serve as a useful framework for the study of non-perturbative phenomena in QCD via analytic techniques.",25 pages,Paul A. Griffin,physics,train
String Winding in a Black Hole Geometry,"$U(1)$ zero modes in the $SL(2,R)_k/U(1)$ and $SU(2)_k/U(1)$ conformal coset theories, are investigated in conjunction with the string black hole solution. The angular variable in the Euclidean version, is found to have a double set of winding. Region III is shown to be $SU(2)_k/U(1)$ where the doubling accounts for the cut sructure of the parafermionic amplitudes and fits nicely across the horizon and singularity. The implications for string thermodynamics and identical particles correlations are discussed.",,Mordechai Spiegelglas,physics,train
Conformal invariance in two-dimensional percolation,"The immediate purpose of the paper was neither to review the basic definitions of percolation theory nor to rehearse the general physical notions of universality and renormalization (an important technique to be described in Part Two). It was rather to describe as concretely as possible, although in hypothetical form, the geometric aspects of universality, especially conformal invariance, in the context of percolation, and to present the numerical results that support the hypotheses. On the other hand, one ulterior purpose is to draw the attention of mathematicians to the mathematical problems posed by the physical notions. Some precise basic definitions are necessary simply to orient the reader. Moreover a brief description of scaling and universality on the one hand and of renormalization on the other is also essential in order to establish their physical importance and to clarify their mathematical content.",61 pages. Abstract added in migration,"Robert Langlands, Philippe Pouliot, Yvan Saint-Aubin",physics,train
Gauge Symmetry and Integrable Models,"We establish the isomorphism between a nonlinear $\sigma$-model and the abelian gauge theory on an arbitrary curved background, which allows us to derive integrable models and the corresponding Lax representations from gauge theoretical point of view. In our approach the spectral parameter is related to the global degree of freedom associated with the conformal or Galileo transformations of the spacetime. The B$\ddot{\rm a}$cklund transformations are derived from Chern-Simons theory where the spectral parameter is defined in terms of the extract compactified space dimension coordinate.",,"Hao-Shiung Lin, Oktay K. Pashaev, Shi-Shyr Roan",physics,train
Vortex Dynamics for the Ginzburg-Landau-Schrödinger Equation,"The initial value problem for the Ginzburg-Landau-Schr\""odinger equation is examined in the $\epsilon \rightarrow 0$ limit under two main assumptions on the initial data $\phi^\epsilon$. The first assumption is that $\phi^\epsilon$ exhibits $m$ distinct vortices of degree $\pm 1$; these are described as points of concentration of the Jacobian $[J\phi^\epsilon]$ of $\phi^\epsilon$. Second, we assume energy bounds consistent with vortices at the points of concentration. Under these assumptions, we identify ``vortex structures'' in the $\epsilon \rightarrow 0$ limit of $\phi^\epsilon$ and show that these structures persist in the solution $u^\epsilon(t)$ of $GLS_\epsilon$. We derive ordinary differential equations which govern the motion of the vortices in the $\epsilon \rightarrow 0$ limit. The limiting system of ordinary differential equations is a Hamitonian flow governed by the renormalized energy of Bethuel, Brezis and H\'elein. Our arguments rely on results about the structural stability of vortices which are proved in a separate paper.",,"James Ellis Colliander, Robert L. Jerrard",physics,train
On a $p$-Laplacian type of evolution system and applications to the Bean model in the type-II superconductivity theory,"We study the Cauchy problem for an $p$-Laplacian type of evolution system ${\mathbf H}_{t}+\g [ | \g {\mathbf H}|^{p-2} \g {\mathbf H}|]={\mathbf F}$. This system governs the evolution of a magnetic field ${\bf H}$, where the current displacement is neglected and the electrical resistivity is assumed to be some power of the current density. The existence, uniqueness and regularity of solutions to the system are established. Furthermore, it is shown that the limit solution as the power $p\rightarrow \infty$ solves the problem of Bean's model in the type-II superconductivity theory. The result provides us information about how the superconductor material under the external force to become the normal conductor and vice visa. It also provides an effective method to find numerical solutions to Bean's model.",,Hong-Ming Yin,physics,val
Symmetry of the Schrödinger equation with variable potential,"We study symmetry properties of the Schr\""odinger equation with the potential as a new dependent variable, i.e., the transformations which do not change the form of the class of equations. We also consider systems of the Schr\""odinger equations with certain conditions on the potential. In addition we investigate symmetry properties of the equation with convection term. The contact transformations of the Schr\""odinger equation with potential are obtained.",,"Wilhelm Fushchych, Zoya Symenoh, Ivan Tsyfra",physics,val
Stochastic cohomology of the frame bundle of the loop space,"We study the differential forms over the frame bundle of the based loop space. They are stochastics in the sense that we put over this frame bundle a probability measure. In order to understand the curvatures phenomena which appear when we look at the Lie bracket of two horizontal vector fields, we impose some regularity assumptions over the kernels of the differential forms. This allows us to define an exterior stochastic differential derivative over these forms.",,Rémi Léandre,physics,train
The integrability of Lie-invariant geometric objects generated by ideals in the Grassmann algebra,"We investigate closed ideals in the Grassmann algebra serving as bases of Lie-invariant geometric objects studied before by E. Cartan. Especially, the E. Cartan theory is enlarged for Lax integrable nonlinear dynamical systems to be treated in the frame work of the Wahlquist Estabrook prolongation structures on jet-manifolds and Cartan-Ehresmann connection theory on fibered spaces. General structure of integrable one-forms augmenting the two-forms associated with a closed ideal in the Grassmann algebra is studied in great detail. An effective Maurer-Cartan one-forms construction is suggested that is very useful for applications. As an example of application the developed Lie-invariant geometric object theory for the Burgers nonlinear dynamical system is considered having given rise to finding an explicit form of the associated Lax type representation.",,"Denis Blackmore, Yarema A. Prykarpatsky, Roman Samulyak",physics,train
Lie symmetries of Einstein's vacuum equations in N dimensions,"We investigate Lie symmetries of Einstein's vacuum equations in N dimensions, with a cosmological term. For this purpose, we first write down the second prolongation of the symmetry generating vector fields, and compute its action on Einstein's equations. Instead of setting to zero the coefficients of all independent partial derivatives (which involves a very complicated substitution of Einstein's equations), we set to zero the coefficients of derivatives that do not appear in Einstein's equations. This considerably constrains the coefficients of symmetry generating vector fields. Using the Lie algebra property of generators of symmetries and the fact that general coordinate transformations are symmetries of Einstein's equations, we are then able to obtain all the Lie symmetries. The method we have used can likely be applied to other types of equations.",,Louis Marchildon,physics,train
On the Moyal quantized BKP type hierarchies,Quantization of BKP type equations are done through the Moyal bracket and the formalism of pseudo-differential operators. It is shown that a variant of the dressing operator can also be constructed for such quantized systems.,,"Dolan Chapa Sen, A. Roy Chowdhury",physics,val
Finding Exact Values For Infinite Sums,This paper offers a solution method that allows one to find exact values for a large class of convergent series of rational terms. Sums of this form arise often in problems dealing with Quantum Field Theory.,,Costas Efthimiou,physics,train
Parameter estimation in nonlinear stochastic differential equations,"We discuss the problem of parameter estimation in nonlinear stochastic differential equations based on sampled time series. A central message from the theory of integrating stochastic differential equations is that there exists in general two time scales, i.e. that of integrating these equations and that of sampling. We argue that therefore maximum likelihood estimation is computational extremely expensive. We discuss the relation between maximum likelihood and quasi maximum likelihood estimation. In a simulation study, we compare the quasi maximum likelihood method with an approach for parameter estimation in nonlinear stochastic differential equations that disregards the existence of the two time scales.","in press: Chaos, Solitons & Fractals",J. Timmer,physics,train
The Minority Game with Variable Payoffs,"In the standard minority game, each agent in the minority group receives the same payoff regardless of the size of the minority group. Of great interest for real social and biological systems are cases in which the payoffs to members of the minority group depend on the size of the minority group. This latter includes the fixed sum game. We find, remarkably, that the phase structure and general scaling behavior of the standard minority game persists when the payoff function depends on the size of the minority group. there is still a phase transition at the same value of z, the ratio of the dimension of the strategy space to the number of agents playing the game. We explain the persistence of the phase structure and argue that it is due to the absence of temporal cooperation in the dynamics of the minority game. We also discuss the behavior of average agent wealth and the wealth distribution in these variable payoff games.","16 pages, 6 figures","Yi Li, Adrian VanDeemen, Robert Savit",physics,train
A family of multi-value cellular automaton model for traffic flow,"A family of multi-value cellular automaton (CA) associated with traffic flow is presented in this paper. The family is obtained by extending the rule-184 CA, which is an ultradiscrete analogue to the Burgers equation. CA models in the family show both metastable states and stop-and-go waves, which are often observed in real traffic flow. Metastable states in the models exist not only on a prominent part of a free phase but also in a congested phase.","LaTeX 12 pages and 13 Postscript figures, submitted to Phys. Rev. E","Katsuhiro Nishinari, Daisuke Takahashi",physics,test
The effect of synchronized area on SOC behavior in a kind of Neural Network Model,"Based on the LISSOM model and the OFC earthquake model, we introduce a self-organized feature map Neural Network model . It displays a ""Self Organized Criticality""(SOC) behavior. It can be seen that the feature area (synchronized area) produced by self-organized process brings about some definite effect on SOC behavior and the system evolves into a ""partly-synchronized"" state. For explaining this phenomena, a quasi-OFC earthquake model is simulated.","11 pages,15 EPS files,uses REVtex4","Xiao Wei Zhao, Tian Lun Chen",physics,train
Scaling in Athletic World Records,"World records in athletics provide a measure of physical as well as physiological human performance. Here we analyse running records and show that the mean speed as a function of race time can be described by two scaling laws that have a breakpoint at about 150-170 seconds (corresponding to the ~1,000 m race). We interpret this as being the transition time between anaerobic and aerobic energy expenditure by athletes.",published in the Brief Communication section of Nature,"Sandra Savaglio, Vincenzo Carbone",physics,val
Cluster Coagulation and Growth Limited by Surface Interactions with Polymers,"The physical and chemical properties of metal nanoparticles differ significantly from those of free metal atoms as well as from the properties of bulk metals, and therefore, they may be viewed as a transition regime between the two physical states. Within this nanosize regime, there is a wide fluctuation of properties, particularly chemical reactivity, as a function of the size, geometry, and electronic state of the metal nanoparticles. In recent years, great advancements have been made in the attempts to control and manipulate the growth of metal particles to pre-specified dimensions. One of the main synthetic methods utilized in this endeavor, is the capping of the growing clusters with a variety of molecules, e.g. polymers. In this paper we attempt to model such a process and show the relationship between the concentration of the polymer present in the system and the final metal particle size obtained. The theoretical behavior which we obtained is compared with experimental results for the cobalt-polystyrene system.",submitted for publication,"Horacio G. Rotstein, Amy Novick-Cohen, Rina Tannenbaum",physics,val
Remarks on scaling properties inherent to the systems with hierarchically organized supplying network,"We study the emergence of a power law distribution in the systems which can be characterized by a hierarchically organized supplying network. It is shown that conservation laws on the branches of the network can, at some approximation, impose power law properties on the systems. Some simple examples taken from economics, biophysics etc. are considered.",,"V. Gafiychuk, I. Lubashevsky, A. Stosyk",physics,train
Spatial competition and price formation,"We look at price formation in a retail setting, that is, companies set prices, and consumers either accept prices or go someplace else. In contrast to most other models in this context, we use a two-dimensional spatial structure for information transmission, that is, consumers can only learn from nearest neighbors. Many aspects of this can be understood in terms of generalized evolutionary dynamics. In consequence, we first look at spatial competition and cluster formation without price. This leads to establishement size distributions, which we compare to reality. After some theoretical considerations, which at least heuristically explain our simulation results, we finally return to price formation, where we demonstrate that our simple model with nearly no organized planning or rationality on the part of any of the agents indeed leads to an economically plausible price.",Minor changes,"Kai Nagel, Martin Shubik, Maya Paczuski, Per Bak",physics,val
Schemata Evolution and Building Blocks,"In the light of a recently derived evolution equation for genetic algorithms we consider the schema theorem and the building block hypothesis. We derive a schema theorem based on the concept of effective fitness showing that schemata of higher than average effective fitness receive an exponentially increasing number of trials over time. The equation makes manifest the content of the building block hypothesis showing how fit schemata are constructed from fit sub-schemata. However, we show that generically there is no preference for short, low-order schemata. In the case where schema reconstruction is favored over schema destruction large schemata tend to be favored. As a corollary of the evolution equation we prove Geiringer's theorem.",20 pages,"C. R. Stephens, H. Waelbroeck",physics,train
Schemata as Building Blocks: Does Size Matter?,"We analyze the schema theorem and the building block hypothesis using a recently derived, exact schemata evolution equation. We derive a new schema theorem based on the concept of effective fitness showing that schemata of higher than average effective fitness receive an exponentially increasing number of trials over time. The building block hypothesis is a natural consequence in that the equation shows how fit schemata are constructed from fit sub-schemata. However, we show that generically there is no preference for short, low-order schemata. In the case where schema reconstruction is favoured over schema destruction large schemata tend to be favoured. As a corollary of the evolution equation we prove Geiringer's theorem. We give supporting numerical evidence for our claims in both non-epsitatic and epistatic landscapes.","17 pages, 10 postscript figures","C. R. Stephens, H. Waelbroeck, R. Aguirre",physics,train
New mathematical models for particle flow dynamics,"A new class of integro-partial differential equation models is derived for the prediction of granular flow dynamics. These models are obtained using a novel limiting averaging method (inspired by techniques employed in the derivation of infinite-dimensional dynamical systems models) on the Newtonian equations of motion of a many-particle system incorporating widely used inelastic particle-particle force formulas. By using Taylor series expansions, these models can be approximated by a system of partial differential equations of the Navier-Stokes type. The exact or approximate governing equations obtained are far from simple, but they are less complicated than most of the continuum models now being used to predict particle flow behavior. Solutions of the new models for granular flows down inclined planes and in vibrating beds are compared with known experimental and analytical results and good agreement is obtained.",,"Denis Blackmore, Roman Samulyak, Anthony Rosato",physics,train
Viewing the efficiency of chaos control,This paper aims to cast some new light on controlling chaos using the OGY- and the Zero-Spectral-Radius methods. In deriving those methods we use a generalized procedure differing from the usual ones. This procedure allows us to conveniently treat maps to be controlled bringing the orbit to both various saddles and to sources with both real and complex eigenvalues. We demonstrate the procedure and the subsequent control on a variety of maps. We evaluate the control by examining the basins of attraction of the relevant controlled systems graphically and in some cases analytically.,,"Philippe Chanfreau, Hannu Lyyjynen",physics,val
Local estimates for entropy densities in coupled map lattices,"We present a method to derive an upper bound for the entropy density of coupled map lattices with local interactions from local observations. To do this, we use an embedding technique being a combination of time delay and spatial embedding. This embedding allows us to identify the local character of the equations of motion. Based on this method we present an approximate estimate of the entropy density by the correlation integral.","4 pages, 5 figures included","Eckehard Olbrich, Rainer Hegger, Holger Kantz",physics,train
Lyapunov Instability for a hard-disk fluid in equilibrium and nonequilibrium thermostated by deterministic scattering,We compute the full Lyapunov spectra for a hard-disk fluid under temperature gradient and shear. The system is thermalized by deterministic and time-reversible scattering at the boundary. This thermostating mechanism allows for energy fluctuations around a mean value which is reflected by only two vanishing Lyapunov exponents in equilibrium and nonequilibrium. The Lyapunov exponents are calculated with a recently developed formalism for systems with elastic hard collisions. In a nonequilibrium steady state the average phase space volume is contracted onto a fractal attractor leading to a negative sum of Lyapunov exponents. Since the system is driven inhomogeneously we do not expect the conjugate pairing rule to hold which is confirmed numerically.,13 pages (revtex) with 8 figures (encapsulated postscript),C. Wagner,physics,train
Frobenius-Perron Resonances for Maps with a Mixed Phase Space,"Resonances of the time evolution (Frobenius-Perron) operator P for phase space densities have recently been shown to play a key role for the interrelations of classical, semiclassical and quantum dynamics. Efficient methods to determine resonances are thus in demand, in particular for Hamiltonian systems displaying a mix of chaotic and regular behavior. We present a powerful method based on truncating P to a finite matrix which not only allows to identify resonances but also the associated phase space structures. It is demonstrated to work well for a prototypical dynamical system.","5 pages, 2 figures, 2nd version as published (minor changes)","Joachim Weber, Fritz Haake, Petr Seba",physics,val
The statistical properties of the city transport in Cuernavaca (Mexico) and Random matrix ensembles,We analyze statistical properties of the city bus transport in Cuernavaca (Mexico) and show that the bus arrivals display probability distributions conforming those given by the Unitary Ensemble of random matrices.,"4 pages, 3 figures","M. Krbalek, P. Seba",physics,train
Superconvergence of period doubling cascade in trapezoid maps,"In the symmetric and the asymmetric trapezoid maps, as a slope of the trapezoid is increased, the period doubling cascade occurs and the symbolic sequence of periodic points is the Metropolis-Stein-Stein sequence and the convergence of the onset point of the period 2^m solution to the accumulation point is exponentially fast. We reported these results previously. In this paper, we give the detailed description of the proof on the results. Further, we study the period doubling cascade starting from period p solution and show the superconvergence of the period doubling cascade.","34 pages, 7 figures, 6 sty files",T. Uezu,physics,train
Periodic orbit action correlations in the Baker map,"Periodic orbit action correlations are studied for the piecewise linear, area-preserving Baker map. Semiclassical periodic orbit formulae together with universal spectral statistics in the corresponding quantum Baker map suggest the existence of universal periodic orbit correlations. The calculation of periodic orbit sums for the Baker map can be performed with the help of a Perron-Frobenius type operator. This makes it possible to study periodic orbit correlations for orbits with period up to 500 iterations of the map. Periodic orbit correlations are found to agree quantitatively with the predictions from random matrix theory up to a critical length determined by the semiclassical error. Exponentially increasing terms dominate the correlations for longer orbits which are due to the violation of unitarity in the semiclassical approximation.","14 pages, 5 figures",Gregor Tanner,physics,val
Spectral statistics for unitary transfer matrices of binary graphs,"Quantum graphs have recently been introduced as model systems to study the spectral statistics of linear wave problems with chaotic classical limits. It is proposed here to generalise this approach by considering arbitrary, directed graphs with unitary transfer matrices. An exponentially increasing contribution to the form factor is identified when performing a diagonal summation over periodic orbit degeneracy classes. A special class of graphs, so-called binary graphs, is studied in more detail. For these, the conditions for periodic orbit pairs to be correlated (including correlations due to the unitarity of the transfer matrix) can be given explicitly. Using combinatorial techniques it is possible to perform the summation over correlated periodic orbit pair contributions to the form factor for some low--dimensional cases. Gradual convergence towards random matrix results is observed when increasing the number of vertices of the binary graphs.","18 pages, 8 figures",Gregor Tanner,physics,test
Mean- Field Approximation and a Small Parameter in Turbulence Theory,"Numerical and physical experiments on two-dimensional (2d) turbulence show that the differences of transverse components of velocity field are well described by a gaussian statistics and Kolmogorov scaling exponents. In this case the dissipation fluctuations are irrelevant in the limit of small viscosity. In general, one can assume existence of critical space-dimensionality $d=d_{c}$, at which the energy flux and all odd-order moments of velocity difference change sign and the dissipation fluctuations become dynamically unimportant. At $d<d_{c}$ the flow can be described by the ``mean-field theory'', leading to the observed gaussian statistics and Kolmogorov scaling of transverse velocity differences. It is shown that in the vicinity of $d=d_{c}$ the ratio of the relaxation and translation characteristic times decreases to zero, thus giving rise to a small parameter of the theory. The expressions for pressure and dissipation contributions to the exact equation for the generating function of transverse velocity differences are derived in the vicinity of $d=d_{c}$. The resulting equation describes experimental data on two-dimensional turbulence and demonstrate onset of intermittency as $d-d_{c}>0$ and $r/L\to 0$ in three-dimensional flows in close agreement with experimental data. In addition, some new exact relations between correlation functions of velocity differences are derived. It is also predicted that the single-point pdf of transverse velocity difference in developing as well as in the large-scale stabilized two-dimensional turbulence is a gaussian.","25 pages, 1 figure",Victor Yakhot,physics,val
Convergence to equilibrium in a class of interacting particle systems evolving in discrete time,"We conjecture that for a wide class of interacting particle systems evolving in discrete time, namely conservative cellular automata with piecewise linear flow diagram, relaxation to the limit set follows the same power law at critical points. We further describe the structure of the limit sets of such systems as unions of shifts of finite type. Relaxation to the equilibrium resembles ballistic annihilation, with ``defects'' propagating in opposite direction annihilating upon collision.","15 pages, 6 figures","Henryk Fuks, Nino Boccara",physics,train
Number conserving cellular automata: form decidability to dynamics,"We compare several definitions for number-conserving cellular automata that we prove to be equivalent. A necessary and sufficient condition for \cas to be number-conserving is proved. Using this condition, we give a linear-time algorithm to decide number-conservation. The dynamical behavior of number-conserving \cas is studied and a classification that focuses on chaoticity is given.","24 pages, 2 figures","B. Durand, E. Formenti, Z. Roka",physics,val
Exact limiting solutions for certain deterministic traffic rules,"We analyze the steady-state flow as a function of the initial density for a class of deterministic cellular automata rules (``traffic rules'') with periodic boundary conditions [H. Fuks and N. Boccara, Int. J. Mod. Phys. C 9, 1 (1998)]. We are able to predict from simple considerations the observed, unexpected cutoff of the average flow at unity. We also present an efficient algorithm for determining the exact final flow from a given finite initial state. We analyze the behavior of this algorithm in the infinite limit to obtain for R_m,k an exact polynomial equation maximally of 2(m+k)th degree in the flow and density.","25 pages, 8 figures","Janne V. Kujala, Tuomas J. Lukka",physics,train
Structure of Rule Table and Phase Diagram of One Dimensional Cellular Automata,"In addition to the $\lambda$ parameter, we have found another parameter which characterize the class III, class II and class IV patterns more quantitatively. It explains why the different classes of patterns coexist at the same $\lambda$. With this parameter, the phase diagram for an one dimensional cellular automata is obtained. Our result explains why the edge of chaos(class IV) is scattered rather wide range in $\lambda$ around 0.5, and presents an effective way to control the pattern classes. \noindent PACS: 89.75.-k Complex Systems","13 pages in latex, 3 Postscript figures","Sunao Sakai, Megumi Kanno",physics,val
A New Kind of Science?,"Book Review for: ""A New Kind of Science"", by Stephen Wolfram (Wolfram Media, Inc. Champaign IL 2002).",,Leo P. Kadanoff,physics,train
The Mermin fixed point,"The most efficient known method for solving certain computational problems is to construct an iterated map whose fixed points are by design the problem's solution. Although the origins of this idea go back at least to Newton, the clearest expression of its logical basis is an example due to Mermin. A contemporary application in image recovery demonstrates the power of the method.","Contribution to Mermin Festschrift; 8 pages, 5 figures",Veit Elser,physics,train
Kinetic boundary conditions in the lattice Boltzmann method,"Derivation of the lattice Boltzmann method from the continuous kinetic theory [X. He and L. S. Luo, {\it Phys. Rev. E} {\bf 55}, R6333 (1997); X. Shan and X. He, {\it Phys. Rev. Lett.} {\bf 80}, 65 (1998)] is extended in order to obtain boundary conditions for the method. For the model of a diffusively reflecting moving solid wall, the boundary condition for the discrete set of velocities is derived, and the error of the discretization is estimated. Numerical results are presented which demonstrate convergence to the hydrodynamic limit. In particular, the Knudsen layer in the Kramers' problem is reproduced correctly for small Knudsen numbers.","14 pages, 2 Figures, To appear in Phys. Rev. E","Santosh Ansumali, Iliya V. Karlin",physics,val
Headway distribution of the asymmetric simple exclusion model,We present an exact solution of headway distribution of the asymmetric simple exclusion model with open boundary conditions and compare it to the headway distributions of the highway traffic.,"10 pages, 1 figure",M. Krbalek,physics,val
Headway statistics of public transport in Mexican cities,We present a cellular automaton simulating the behavior of public bus transport in several Mexican cities. The headway statistics obtained from the model is compared to the measured time intervals between subsequent bus arrivals to a given bus stop and to a spacing distribution resulting from a random matrix theory.,"5 pages, 3 figures","M. Krbalek, P. Seba",physics,train
Microscopic/stochastic timesteppers and coarse control: a kinetic Monte Carlo example,"Coarse timesteppers provide a bridge between microscopic / stochastic system descriptions and macroscopic tasks such as coarse stability/bifurcation computations. Exploiting this computational enabling technology, we present a framework for designing observers and controllers based on microscopic simulations, that can be used for their coarse control. The proposed methodology provides a bridge between traditional numerical analysis and control theory on the one hand and microscopic simulation on the other.",,"C. I. Siettos, A. Armaou, A. G. Makeev, I. G. Kevrekidis",physics,train
Asymmetric Squares as Standing Waves in Rayleigh-Benard Convection,"Possibility of asymmetric square convection is investigated numerically using a few mode Lorenz-like model for thermal convection in Boussinesq fluids confined between two stress free and conducting flat boundaries. For relatively large value of Rayleigh number, the stationary rolls become unstable and asymmetric squares appear as standing waves at the onset of secondary instability. Asymmetric squares, two dimensional rolls and again asymmetric squares with their corners shifted by half a wavelength form a stable limit cycle.","8 pages, 7 figures","Alaka Das, Ujjal Ghosal, Krishna Kumar",physics,train
Application of the Entropy Production Principle to the Analysis of the Morphological Stability of a Growing Cylindrical Crystal,"Stability of cylindrical and spherical crystals growing from a supersaturated solution (in Mullins-Sekerka's approximation) is considered using the maximum entropy production principle. The concept of the binodal of the nonequilibrium (morphological) phase transition is introduced for interpretation of the obtained results. The limits of the metastable regions are determined. The morphological phase diagrams of stable-unstable growth in the plane (surface energy, supersaturation) are given.","Acrobat Exchange 3.0,14 pages with 4 figures","L. M. Martiouchev, V. D. Seleznev, I. E. Kuznetsova",physics,train
Multi-component optical solitary waves,"We discuss several novel types of multi-component (temporal and spatial) envelope solitary waves that appear in fiber and waveguide nonlinear optics. In particular, we describe multi-channel solitary waves in bit-parallel-wavelength fiber transmission systems for high performance computer networks, multi-colour parametric spatial solitary waves due to cascaded nonlinearities of quadratic materials, and quasiperiodic envelope solitons due to quasi-phase-matching in Fibonacci optical superlattices.","12 pages, 11 figures; To be published in: Proceedings of the Dynamics
  Days Asia-Pacific: First International Conference on Nonlinear Science
  (Hong-Kong, 13-16 July, 1999), Editor: Bambi Hu (Elsevier Publishers, 2000)","Yuri S. Kivshar, Andrey A. Sukhorukov, Elena A. Ostrovskaya, Tristram J. Alexander, Ole Bang, Solomon M. Saltiel, Carl Balslev Clausen, Peter L. Christiansen",physics,val
Period Stabilization in the Busse-Heikes Model of the Kuppers-Lortz Instability,The Busse-Heikes dynamical model is described in terms of relaxational and nonrelaxational dynamics. Within this dynamical picture a diverging alternating period is calculated in a reduced dynamics given by a time-dependent Hamiltonian with decreasing energy. A mean period is calculated which results from noise stabilization of a mean energy. The consideration of spatial-dependent amplitudes leads to vertex formation. The competition of front motion around the vertices and the Kuppers-Lortz instability in determining an alternating period is discussed.,"28 pages, 11 figures","R. Toral, M. San Miguel, R. Gallego",physics,train
Patterns and localized structures in bistable semiconductor resonators,We report experiments on spatial switching dynamics and steady state structures of passive nonlinear semiconductor resonators of large Fresnel number. Extended patterns and switching front dynamics are observed and investigated. Evidence of localization of structures is given.,5 pages with 9 figures,"V. B. Taranenko, I. Ganne, R. J. Kuszelewicz, C. O. Weiss",physics,train
Spatial solitons in a semiconductor microresonator,We show experimentally the existence of bright and dark spatial solitons in a passive quantum-well-semiconductor resonator of large Fresnel number. For the wavelength of observation the nonlinearity is mixed absorptive/defocusing. Bright solitons appear more stable than dark ones.,4 pages with 7 figures,"V. B. Taranenko, I. Ganne, R. J. Kuszelewicz, C. O. Weiss",physics,train
Raman solitons in transient SRS,We report the observation of Raman solitons on numerical simulations of transient stimulated Raman scattering (TSRS) with small group velocity dispersion. The theory proceeds with the inverse scattering transform (IST) for initial-boundary value problems and it is shown that the explicit theoretical solution obtained by IST for a semi-infinite medium fits strikingly well the numerical solution for a finite medium. We understand this from the rapid decrease of the medium dynamical variable (the potential of the scattering theory). The spectral transform reflection coefficient can be computed directly from the values of the input and output fields and this allows to see the generation of the Raman solitons from the numerical solution. We confirm the presence of these nonlinear modes in the medium dynamical variable by the use of a discrete spectral analysis.,"LaTex file, to appear in Inverse Problems","M. Boiti, J-G. Caputo, J. Leon, F. Pempinelli",physics,val
"Three-dimensional pattern formation, multiple homogeneous soft modes, and nonlinear dielectric electroconvection","Patterns forming spontaneously in extended, three-dimensional, dissipative systems are likely to excite several homogeneous soft modes ($\approx$ hydrodynamic modes) of the underlying physical system, much more than quasi one- and two-dimensional patterns are. The reason is the lack of damping boundaries. This paper compares two analytic techniques to derive the patten dynamics from hydrodynamics, which are usually equivalent but lead to different results when applied to multiple homogeneous soft modes. Dielectric electroconvection in nematic liquid crystals is introduced as a model for three-dimensional pattern formation. The 3D pattern dynamics including soft modes are derived. For slabs of large but finite thickness the description is reduced further to a two-dimensional one. It is argued that the range of validity of 2D descriptions is limited to a very small region above threshold. The transition from 2D to 3D pattern dynamics is discussed. Experimentally testable predictions for the stable range of ideal patterns and the electric Nusselt numbers are made. For most results analytic approximations in terms of material parameters are given.","29 pages, 2 figures",Axel G. Rossberg,physics,train
Asymptotic Dynamics of Ripples,"A new nonlinear equation governing asymptotic dynamics of ripples is derived by using a short wave perturbative expansion on a generalized version of the Green-Naghdi system. It admits peakon solutions with amplitude, velocity and width in interrelation and static compacton solutions with amplitude and width in interrelation. Short wave pattern formation is shown to result from a balance between linear dispersion and nonlinearity.","LaTex file, no figures",M. A. Manna,physics,val
Discreteness effects on soliton dynamics: a simple experiment,We present a simple laboratory experiment to illustrate some aspects of the soliton theory in discrete lattices with a system that models the dynamics of dislocations in a crystal or the properties of adsorbed atomic layers. The apparatus not only shows the role of the Peierls-Nabarro potential but also illustrates the hierarchy of depinning transitions and the importance of the collective motion in mass transport.,"9 pages, 4 Figures, to Appear in American Journal of Physics","Claude Laroche, Thierry Dauxois, Michel Peyrard",physics,train
r-Matrix for the restricted KdV Flows with the Neumann constraints,"Under the Neumann constraints, each equation of the KdV hierarchy is decomposed into two finite dimensional systems, including the well-known Neumann model. Like in the case of the Bargmann constraint, the explicit Lax representations are deduced from the adjoint representation of the auxiliary spectral problem. It is shown that the Lax operator satisfies the r-matrix relation in the Dirac bracket. Thus, the integrabilities of these resulting systems with the Neumann constraints are obtained.",,Ruguang Zhou,physics,train
Bilinearization of coupled nonlinear Schrödinger type equations: integrabilty and solitons,"Considering the coupled envelope equations in nonlinear couplers, the question of integrability is attempted. It is explicitly shown that Hirota's bilinear method is one of the simple and alternative techniques to Painlev\'e analysis to obtain the integrability conditions of the coupled nonlinear Schr\""odinger (CNLS) type equations. We also show that the coupled Hirota equation introduced by Tasgal and Potasek is the next hierarchy of the inverse scattering solvable CNLS equation. The results are in agreement with the known results.",,Kuppusamy Porsezian,physics,train
Neumann and Bargmann systems associated with an extension of the coupled KdV hierarchy,An eigenvalue problem with a reference function and the corresponding hierarchy of nonlinear evolution equations are proposed. The bi-Hamiltonian structure of the hierarchy is established by using the trace identity. The isospectral problem is nonlinearized as to be finite-dimensional completely integrable systems in Liouville sense under Neumann and Bargmann constraints.,,Zhimin Jiang,physics,train
Quest for universal integrable models,"In this paper we discuss a universal integrable model, given by a sum of two Wess-Zumino-Witten-Novikov (WZWN) actions, corresponding to two different orbits of the coadjoint action of a loop group on its dual, and the Polyakov-Weigmann cocycle describing their interactions. This is an effective action for free fermions on a torus with nontrivial boundary conditions. It is universal in the sense that all other known integrable models can be derived as reductions of this model. Hence our motivation is to present an unified description of different integrable models. We present a proof of this universal action from the action of the trivial dynamical system on the cotangent bundles of the loop group. We also present some examples of reductions.",,"Partha Guha, Mikhail Olshanetsky",physics,train
Fermionic representation for basic hypergeometric functions related to Schur polynomials,"We present the fermionic representation for the q-deformed hypergeometric functions related to Schur polynomials considered by S.Milne \cite{Milne}. For $q=1$ these functions are also known as hypergeometric functions of matrix argument which are related to zonal spherical polynomials for $GL(N,C)/U(N)$ symmetric space. We show that these multivariable hypergeometric functions are tau-functions of the KP hierarchy. At the same time they are the ratios of Toda lattice tau-functions considered by Takasaki in \cite{Tinit}, \cite{T} evaluated at certain values of higher Toda lattice times. The variables of the hypergeometric functions are related to the higher times of those hierarchies via Miwa change of variables. The discrete Toda lattice variable shifts parameters of hypergeometric functions. Hypergeometric functions of type ${}_pF_s$ can be also viewed as group 2-cocycle for the $\Psi$DO on the circle of the order $p-s \leq 1$ (the group times are higher times of TL hierarchy and the arguments of hypergeometric function). We get the determinant representation and the integral representation of special type of KP tau-functions, these results generalize some of Milne's results in \cite{Milne}. We write down a system of linear differential and difference equations for these tau-functions (string equations). We present also fermionic representation for special type of Gelfand-Graev hypergeometric functions.",,"A. Yu. Orlov, D. M. Scherbin",physics,train
Q-deformed solitons and quantum solitons of the Maxwell-Bloch lattice,"We report for the first time exact solutions of a completely integrable nonlinear lattice system for which the dynamical variables satisfy a q-deformed Lie algebra - the Lie-Poisson algebra su_q(2). The system considered is a q-deformed lattice for which in continuum limit the equations of motion become the envelope Maxwell-Bloch (or SIT) equations describing the resonant interaction of light with a nonlinear dielectric. Thus the N-soliton solutions we here report are the natural q-deformations, necessary for a lattice, of the well-known multi-soliton and breather solutions of self-induced transparency (SIT). The method we use to find these solutions is a generalization of the Darboux-Backlund dressing method. The extension of these results to quantum solitons is sketched.",12 pages,"Andrei Rybin, Jussi Timonen, Gennadii Varzugin, Robin K. Bullough",physics,train
A new method to introduce additional separated variables for high-order binary constrained flows,Degrees of freedom for high-order binary constrained flows of soliton equations admitting $2\times 2$ Lax matrices are $2N+k_0$. It is known that $N+k_0$ pairs of canonical separated variables for their separation of variables can be introduced directly via their Lax matrices. In present paper we propose a new method to introduce the additional $N$ pairs of canonical separated variables and $N$ additional separated equations. The Jacobi inversion problems for high-order binary constrained flows and for soliton equations are also established. This new method can be applied to all high-order binary constrained flows admitting $2\times 2$ Lax matrices.,"34 pages, AmsTex, to be published in J. Phys. A",Yunbo Zeng,physics,test
(2+0)-Dimensional Integrable Equations and Exact Solutions,We propose a nonlinear $\sigma$-model in a curved space as a general integrable elliptic model. We construct its exact solutions and obtain energy estimates near the critical point. We consider the Pohlmeyer transformation in Euclidean space and investigate the gauge equivalence conditions for a broad class of elliptic equations. We develop the inverse scattering transform method for the $\sinh$-Gordon equation and evaluate its exact and asymptotic solutions.,24 pages,"E. Sh. Gutshabash, V. D. Lipovskii, S. S. Nikulichev",physics,train
n-Dimensional Bateman Equation and Painleve Analysis of Wave Equations,"In the Painleve analysis of nonintegrable partial differential equations one obtains differential constraints describing the movable singularity manifold. We show, for a class of n-dimensional wave equations, that these constraints have a general structure which is related to the $n$-dimensional Bateman equation. In particular, we derive the exact expressions of the singularity manifold constraints for the n-dimensional sine-Gordon -, Liouville -, Mikhailov -, and double sine-Gordon equation, as well as two 2-dimensional polynomial field theory equations, and prove that their singularity manifold conditions are satisfied by the n-dimensional Bateman equation. Finally we give some examples.",21 pages,"Norbert Euler, Ove Lindblom",physics,train
The Supercomplexifications And Odd Bihamiltonians Structures,The general method of the cojmplex supersymmetrization (supercomplexifications) of the soliton equations with the odd (bi) hamiltoninan structure is established. New version of the supercomplexified Kadomtsev-Petvishvili hierarchy is given. The second odd Hamiltonina operator of the SUSY KdV equation generates the odd N=2 SUSY Virasoro like algebra.,"Proceeding of the International Seminar ""Supersymmetry and Quantum
  Symmetries (July 1999 Dubna Rosia)",Ziemowit Popowicz,physics,train
Dilepton production from p-p to Ca-Ca at the Bevalac,"The DLS collaboration has recently completed a high statistics study of dilepton production at the Bevalac. In particular, we have measured dielectrons (e+e-) from p-p and p-d collisions to understand the basic dilepton production mechanisms in the energy range from 1.05 - 4.9 GeV. These data can be used to determine the basic processes which contribute to nucleon-nucleon dilepton production such as hadronic bremsstrahlung, vector meson processes, and hadronic Dalitz decay. The data show that a simple elastic bremsstrahlung calculation is insufficient to explain the data. Theoretical models are compared with the data. A new high statistics study of Ca-Ca at 1.05 A GeV has been made to study the collectivity of A-A collisions.","6 pages, Preprints available from HSMatis@lbl.gov. Will be published
  in Nuclear Physics A - The Proceedings on the 1994 Nucleus Nucleus Collisions
  Conference, Taorimina","H. S. Matis, S. Beedoe, M. Bougteb, J. Carroll, W. Christie, W. Gong, T. Hallman, L. Heilbronn, H. Huang, P. N. Kirk, G. Krebs, G. Igo, A. Letessier-Selvon L. Madansky, F. Manso, J. Miller, C. Naudet, R. J. Porter, M. Prunet, G. Roche, L. S. Schroeder, P. Seidl, Z. F. Wang, R. Welsh, W. K. Wilson, A. Yegneswaran",physics,test
Measurement of Pion Enhancement at Low Transverse Momentum and of the Delta-Resonance Abundance in Si-Nucleus Collisions at AGS Energy,We present measurements of the pion transverse momentum (p_t) spectra in central Si-nucleus collisions in the rapidity range 2.0<y<5.0 for p_t down to and including p_t=0. The data exhibit an enhanced pion yield at low p_t compared to what is expected for a purely thermal spectral shape. This enhancement is used to determine the Delta-resonance abundance at freeze-out. The results are consistent with a direct measurement of the Delta-resonance yield by reconstruction of proton-pion pairs and imply a temperature of the system at freeze-out close to 140 MeV.,12 pages + 4 figures (uuencoded at end-of-file),J. Barrette,physics,train
"Charged Particle Pseudorapidity Distributions in Au+Al, Cu, Au, and U Collisions at 10.8 A$\cdot$GeV/c","We present the results of an analysis of charged particle pseudorapidity distributions in the central region in collisions of a Au projectile with Al, Cu, Au, and U targets at an incident energy of 10.8~GeV/c per nucleon. The pseudorapidity distributions are presented as a function of transverse energy produced in the target or central pseudorapidity regions. The correlation between charged multiplicity and transverse energy measured in the central region, as well as the target and projectile regions is also presented. We give results for transverse energy per charged particle as a function of pseudorapidity and centrality.","31 pages + 12 figures (compressed and uuencoded by uufiles), LATEX,
  Submitted to PRC","E877 Collaboration, J. ~Barrette et. al",physics,train
Radial Flow in Au+Au Collisions at E=0.25-1.15 A GeV,A systematic study of energy spectra for light particles emitted at midrapidity from Au+Au collisions at E=0.25-1.15 A GeV reveals a significant non-thermal component consistent with a collective radial flow. This component is evaluated as a function of bombarding energy and event centrality. Comparisons to Quantum Molecular Dynamics (QMD) and Boltzmann-Uehling-Uhlenbeck (BUU) models are made for different equations of state.,10 pages of text and 4 figures (all ps files in a uuencoded package).,"M. A. Lisa, S. Albergo, F. Bieser, F. P. Brady, Z. Caccia, D. A. Cebra, A. D. Chacon, J. L. Chance, Y. Choi, S. Costa, J. B. Elliott, M. L. Gilkes, J. A. Hauger, A. S. Hirsch, E. L. Hjort, A. Insolia, M. Justice, D. Keane, J. Kintner, H. S. Matis, M. McMahan, C. McParland, D. L. Olson, M. D. Partlan, N. T. Porile, R. Potenza, G. Rai, J. Rasmussen, H. G. Ritter, J. Romanski, J. L. Romero, G. V. Russo, R. Scharenberg, A. Scott, Y. Shao, B. K. Srivastava, T. J. M. Symons, M. Tincknell, C. Tuve, S. Wang, P. Warren, G. D. Westfall, H. H. Wieman, K. Wolf",physics,train
"Onset of Collectivity in Neutron Deficient $^{196,198}$Po","We have studied via in-beam $\gamma$-ray spectroscopy $^{196}$Po and $^{198}$Po, which are the first neutron-deficient Po isotopes to exhibit a collective low-lying structure. The ratios of yrast state energies and the E2 branching ratios of transitions from non-yrast to yrast states are indicative of a low-lying vibrational structure. The onset of collective motion in these isotopes can be attributed to the opening of the neutron i$_{13/2}$ orbital at N$\approx$112 and the resulting large overlap between the two valence protons in the h$_{9/2}$ orbital and the valence neutrons in the i$_{13/2}$ orbital.","(accepted by Phys. Rev. C, in press) 18 pages, revtex 3.0, Five figs.
  available upon request","L. A. Bernstein, J. A. Cizewski, H. -Q. Jin, W. Younes, R. G. Henry, L. P. Farris, A. Charos, M. P. Carpenter, R. V. F. Janssens, T. L. Khoo, T. Lauritsen, I. G. Bearden, D. Ye, J. A. Becker, E. A. Henry, M. J. Brinkman, J. R. Hughes, A. Kuhnert, T. F. Wang, M. A. Stoyer, R. M. Diamond, F. S. Stephens, M. A. Deleplanque, A. O. Macchiavelli, I. Y. Lee, B. Cederwall, J. R. B. Oliveira, J. Burde, P. Fallon, C. Duyar, J. E. Draper, E. Rubel, D. T. Vo",physics,train
Signatures of Statistical Decay,"The partition of decay energy between the kinetic energy of reaction products and their Q-value of formation is obtained in a statistical derivation appropriate to highly excited nuclei, and is shown to be in a constant ratio. We measure the kinetic energy fraction, $R = \Sigma E_{kin}/(\Sigma E_{kin} + \Sigma Q_0)$, over a wide range of excitation energy for well-defined systems formed in the Cl + C reaction at 35A MeV. Relationships between excitation energy, charged-particle multiplicity, and intermediate-mass-fragment multiplicity, observed in this work and in recent experiments by a number of other groups, follow from the derivation of the average kinetic energies and Q-values.","8 pages, 5 figures, latex","D. Horn, G. C. Ball, D. R. Bowman, A. Galindo-Uribarri, E. Hagberg, R. Laforest, J. Pouliot, R. B. Walker",physics,train
Inclusive Electron Scattering from Nuclei at $x \simeq 1$,"The inclusive A(e,e') cross section for $x \simeq 1$ was measured on $^2$H, C, Fe, and Au for momentum transfers $Q^2$ from 1-7 (GeV/c)$^2$. The scaling behavior of the data was examined in the region of transition from y-scaling to x-scaling. Throughout this transitional region, the data exhibit $\xi$-scaling, reminiscent of the Bloom-Gilman duality seen in free nucleon scattering.","4 pages, RevTeX; 4 figures (postscript in .tar.Z file)","J. Arrington, P. Anthony, R. G. Arnold, E. J. Beise, J. E. Belz, P. E. Bosted, H. -J. Bulten, M. S. Chapman, K. P. Coulter, F. Dietrich, R. Ent, M. Epstein, B. W. Filippone, H. Gao, R. A. Gearhart, D. F. Geesaman, J. -O. Hansen, R. J. Holt, H. E. Jackson, C. E. Jones, C. E. Keppel, E. R. Kinney, S. Kuhn, K. Lee, W. Lorenzon, A. Lung, N. C. R. Makins, D. J. Margaziotis, R. D. McKeown, R. G. Milner, B. Mueller, J. Napolitano, J. Nelson, T. G. O'Neill, V. Papavassiliou, G. G. Petratos, D. H. Potterveld, S. E. Rock, M. Spengos, Z. M. Szalata, L. H. Tao, K. vanBibber, J. F. J. van den Brand, J. L. White, D. Winter, B. Zeidman",physics,val
Spectroscopy of $^{194}$Po,"Prompt, in-beam $\gamma$ rays following the reaction $^{170}$Yb + 142 MeV $^{28}$Si were measured at the ATLAS facility using 10 Compton-suppressed Ge detectors and the Fragment Mass Analyzer. Transitions in $^{194}$Po were identified and placed using $\gamma$-ray singles and coincidence data gated on the mass of the evaporation residues. A level spectrum up to J$\approx$10$\hbar$ was established. The structure of $^{194}$Po is more collective than that observed in the heavier polonium isotopes and indicates that the structure has started to evolve towards the more collective nature expected for deformed nuclei.","8 pages, revtex 3.0, 4 figs. available upon request","W. Younes, J. A. Cizewski, H. -Q. Jin, L. A. Bernstein, D. P. McNabb, C. N. Davids, R. V. F. Janssens, T. L. Khoo, C. J. Lister, D. J. Blumenthal, M. P. Carpenter, D. Henderson, R. G. Henry, T. Lauritsen, D. T. Nisius, H. T. Penttilä, M. W. Drigert",physics,train
Spin-rotor Interpretation of Identical Bands and Quantized Alignment in Superdeformed A $\approx$ 190 Nuclei,"The ``identical'' bands in superdeformed mercury, thallium, and lead nuclei are interpreted as examples of orbital angular momentum rotors with the weak spin-orbit coupling of pseudo-$SU(3)$ symmetries and supersymmetries.","15 pages, revtex 3.0, 7 figures available upon request from
  elaine@runpmx.rutgers.edu","J. A. Cizewski, R. Bijker",physics,val
On the transverse momentum distribution of strange hadrons produced in relativistic heavy ion collisions,"Particles with strange quark content produced in the system 1.93 AGeV $^{58}$Ni on $^{58}$Ni have been investigated at GSI Darmstadt with the FOPI detector system. The correlation of these produced particles was analyzed with respect to the reaction plane. Lambda baryons exhibit a very pronounced sideward flow pattern which is qualitatively similar to the proton flow. However, the kaon ($K^+$,$K^0_S$) flow patterns are significantly different from that of the protons, and their form may be useful to restrict theoretical models on the form of the kaon potential in the nuclear medium.","3 pages TeX using pljour2 (Springer Verlag), or compressed and
  uuencoded postscript","J. L. Ritman, N. Herrmann, D. Best, the FOPI collaboration",physics,val
An Interactive NeXTstep Interface to a Fortran Code for Solving Coupled Differential Equations,"This paper describes a user-friendly frontend to a Fortran program that integrates coupled nonlinear ordinary differential equations. The user interface is built using the NeXTstep Interface Builder, together with a public-domain graphical palette for displaying intermediate and final results. In running the code for a given set of equation parameters the user sees a plot of the solutions at each stage of the iterative process. In the case of a successful sequence of iterations, the initially discontinuous curves smooth out as the scale parameters of the solutions are adjusted to achieve a solution to the nonlinear equations. If the iterative process goes astray, as it often does for a poor choice of starting scale parameters, the user has the opportunity to stop and start over with a better choice, guided by the result of the previous run. The ease of interaction with the equations also allows the user to develop an intuition regarding their solutions and to explore the parameter space for the equations much more quickly.","15 pages text (revtex3), 8 figs (added as uuencoded PostScript file),
  LA-UR 92-2541, August 1992, revised January 1993. To be pub., Comp. in Phys.,
  July '93",Richard R. Silbar,physics,train
"Quark Delocalization, Color Screening, and Nuclear Intermediate Range Attraction","We consider the effect of including quark delocalization and color screening, in the nonrelativistic quark cluster model, on baryon-baryon potentials and phase shifts. We find that the inclusion of these additional effects allows a good qualitative description of both.","10 pages, LaTeX, 4 figures in PostScript after text, LA-UR-91-2152","Fan Wang, Guang-han Wu, Li-jian Teng, T. Goldman",physics,val
Quadrupole Contribution to Two Neutron Removal in Heavy Ion Collisions,"In this report, electric quadrupole corrections to the two neutron removal cross section measured in heavy ion collisions are estimated for $^{197}$Au and $^{59}$Co targets. The quadrupole process is assumed to proceed primarily through excitation of the giant isovector quadrupole resonance, which then decays by neutron emission. For $^{59}$Co, the contribution from E2 radiation is found to be small, while for $^{197}$Au we find the quadrupole contribution resolves the discrepancy between experiment and the simple predictions of the Weissacker-Williams virtual photon method.","8 pages,LA-UR 92-2680",C. J. Benesh,physics,train
Resonances in $Λd$ Scattering and the $Σ$-hypertriton,"Using separable $NN$ and $\Lambda N$-$\Sigma N$ potentials in the Faddeev equations, we have demonstrated that the predicted enhancement in the $\Lambda d$ cross section near the $\Sigma d$ threshold is associated with resonance poles in the scattering amplitude. The positions of these poles, on the second Riemann sheet of the complex energy plane, are determined by examining the eigenvalues of the kernel of the Faddeev equations. This suggests that for a certain class of $\Lambda N$-$\Sigma N$ potentials we can form a $\Sigma$-hypertriton with a width of about 8 MeV.",34 pages,"I. R. Afnan, B. F. Gibson",physics,train
Anatomy of the Soft-Photon Approximation in Hadron-Hadron Bremsstrahlung,"A modified Low procedure for constructing soft-photon amplitudes has been used to derive two general soft-photon amplitudes, a two-s-two-t special amplitude $M^{TsTts}_{\mu}$ and a two-u-two-t special amplitude $M^{TuTts}_{\mu}$, where s, t and u are the Mandelstam variables. $M^{TsTts}_{\mu}$ depends only on the elastic T-matrix evaluated at four sets of (s,t) fixed by the requirement that the amplitude be free of derivatives ($\partial$T/$\partial$s and /or $\partial$T/$\partial t$). Likewise $M^{TuTts}_{\mu}$ depends only on the elastic T-matrix evaluated at four sets of (u,t). In deriving these amplitudes, we impose the condition that $M^{TsTts}_{\mu}$ and $M^{TuTts}_{\mu}$ reduce to $\bar{M}^{TsTts}_{\mu}$ and $\bar{M}^{TuTts}_{\mu}$, respectively, their tree level approximations. The amplitude $\bar{M}^{TsTts}_{\mu}$ represents photon emission from a sum of one-particle t-channel exchange diagrams and one-particle s-channel exchange diagrams, while the amplitude $\bar{M}^{TuTts} _{\mu}$ represents photon emission from a sum of one-particle t-channel exchange diagrams and one-particle u-channel exchange diagrams. The precise expressions for $\bar{M}^{TsTts}_{\mu}$ and $\bar{M}^{TuTts}_{\mu}$ are determined by using the radiation decomposition identities of Brodsky and Brown. We point out that it is theoretically impossible to describe all bremsstrahlung processes by using only a single class of soft-photon amplitudes. At least two different classes are required: the amplitudes which depend on s and t or the amplitudes which depend on u and t. When resonance effects are important, the amplitude $M^{TsTts}_{\mu}$, not $M^{Low(st)}_{\mu}$, should be used. For processes with strong u-channel exchange effects, the amplitude $M^{TuTts}_{\mu}$ should be the first choice.",49 pages report # LA-UR-92-2702,"M. K. Liou, Dahang Lin, B. F. Gibson",physics,train
Saturation in the Nuclear Matter Problem,"Once density-dependent meson masses are introduced into the nuclear many-body problem, conventional mechanisms for saturation no longer operate. We suggest that a loop correction, essentially the introduction of the axial vector coupling $g_A(\rho,k)$ as function of density $\rho$ and momentum $k$, can bring about saturation, and present schematic calculations to illustrate this. We find that a very small density-dependence in $g_A$ gives rise to a very large saturating effect on nuclear matter. In fact, this new saturation mechanism turns out to be more powerful than any of the conventional mechanisms.","16 pages text (latex), 2 figures (not included, available upon
  request) September 1992","G. E. Brown, R. Machleidt",physics,train
Relativistic Corrections to the Triton Binding Energy,"The influence of relativity on the triton binding energy is investigated. The relativistic three-dimensional version of the Bethe-Salpeter equation proposed by Blankenbecler and Sugar (BbS) is used. Relativistic (non-separable) one-boson-exchange potentials (constructed in the BbS framework) are employed for the two-nucleon interaction. In a 34-channel Faddeev calculation, it is found that relativistic effects increase the triton binding energy by about 0.2 MeV. Including charge-dependence (besides relativity), the final triton binding energy predictions are 8.33 and 8.16 MeV for the Bonn A and B potential, respectively.","25 pages of text (latex), 1 figure (not included, available upon
  request)","F. Sammarruca, D. P. Xu, R. Machleidt",physics,val
Riemann's theorem for quantum tilted rotors,"The angular momentum, angular velocity, Kelvin circulation, and vortex velocity vectors of a quantum Riemann rotor are proven to be either (1) aligned with a principal axis or (2) lie in a principal plane of the inertia ellipsoid. In the second case, the ratios of the components of the Kelvin circulation to the corresponding components of the angular momentum, and the ratios of the components of the angular velocity to those of the vortex velocity are analytic functions of the axes lengths.","8 pages, Phys. Rev. C","G. Rosensteel, A. L. Goodman",physics,train
Effects of Octupole Vibrations on Quasiparticle Modes of Excitation in Superdeformed $^{193}$Hg,"A particle-vibration coupling calculation based on the RPA and the cranked shell model has been carried out for superdeformed rotational bands in $^{193}$Hg. The result suggests that properties of single-particle motions in superdeformed nuclei may be significantly affected by coupling effects with low-frequency octupole vibrational modes, especially by the lowest $K=2$ octupole mode.",8 pages,"Takashi Nakatsukasa, Shoujirou Mizutori, Kenichi Matsuyanagi",physics,val
Monte Carlo methods for the nuclear shell model,We present novel Monte Carlo methods for treating the interacting shell model that allow exact calculations much larger than those heretofore possible. The two-body interaction is linearized by an auxiliary field; Monte Carlo evaluation of the resulting functional integral gives ground-state or thermal expectation values of few-body operators. The ``sign problem'' generic to quantum Monte Carlo calculations is absent in a number of cases. We discuss the favorable scaling of these methods with nucleon numb er and basis size and their suitability to parallel computation.,"13 pages, MAP-148","C. W. Johnson, S. E. Koonin, G. H. Lang, W. E. Ormand",physics,train
Future Colliders,"The high energy physics advantages, disadvantages and luminosity requirements of hadrons, of leptons and photon-photon colliders are considered. Technical arguments for increased energy in each type of machine are presented. Their relative size, and the implications of size on cost are discussed.","LaTeX, 10 pages, 10figures","R. B. Palmer, J. C. Gallardo",physics,train
High Luminosity Muon Collider Design,"Muon Colliders have unique technical and physics advantages and disadvantages when compared with both hadrons and electron machines. They should be regarded as complementary. Parameters are given of a 4 TeV high luminosity muon-muon collider, and of a 0.5 TeV demonstration machine. We discuss the various systems in such muon collider.",LaTeX 5 pages 4 figures,"R. B. Palmer, J. C. Gallardo",physics,train
On Stern-Gerlach forces allowed by special relativity and the special case of the classical spinning particle of Derbenev-Kondratenko,This work is devoted to an examination of Stern-Gerlach forces consistent with special relativity and is motivated by recent interest in the relativistic Stern-Gerlach force acting on polarized protons in high-energy particle accelerators. The equations for the orbital and spin motion of a classical charged particle with arbitrary intrinsic magnetic dipole moment in an external electromagnetic field are considered and by imposing the constraints of special relativity and restricting to first order in spin (= first order $\hbar$) a well-defined class of spin-orbit systems is obtained. All these systems can be treated on an equal footing including such prominent cases as those considered by Frenkel and by Good. The Frenkel case is considered in great detail because I show that this system is identical with the one introduced by Derbenev and Kondratenko for studying spin motion in accelerators. In particular I prove that the spin-orbit system of Derbenev and Kondratenko is (nonmanifestly) Poincar\'e covariant and identify the transformation properties of this system under the Poincar\'e group. The Derbenev-Kondratenko Hamiltonian was originally proposed as a way to combine relativistic spin precession and the Lorentz force. The aforementioned findings now demonstrate that the Derbenev-Kondratenko Hamiltonian also provides a legitimate framework for handling the relativistic Stern-Gerlach force. Numerical examples based on the Frenkel and Good cases for the HERA proton ring and electromagnetic traps are provided.,"88 pages, Latex",K. Heinemann,physics,train
Comparisons Between Modeling and Measured Performance of the BNL Linac,"Quite good agreement has been achieved between computer modeling and actual performance of the Brookhaven 200 MeV Linac. We will present comparisons between calculated and measured performance for the beam transport through the RFQ, the 6 meter transport from RFQ to the linac and meching and transport through the linac.",3 pages,"D. Raparia, J. G. Alessi, A. Kponou",physics,train
New Expression for the Transverse Deflection of Relativistic Particle in High-Frequency Fields and Correlation with Panofsky- Wenzel Theorem,"It is shown that change in transverse momentum of a relativistic particle, crossing an accelerating cavity parallel to its axis, may be presented as an integral over trajectory, the integrand of which is proportional to the component of magnetic field parallel to this axis. The changes in two transversal components of momentum are equal in value but opposite in sign. The obtained result is compared with Panofsky-Wenzel theorem","5 pages, latex, no figures, 9kb, in initial version the Title and
  abstract were omitted by mistake in the body of paper",V. N. Melekhin,physics,train
Generator-Invertor-Dumper System of Electron (Positron) Bunches Moving in Cold plasma for Development of Strong Accelerating Electric Field,"It is shown that high accelerating gradient can be obtained in a specially constructed system of electron (positron) bunches, moving in cold plasma,with definite density. These combined bunch systems do not generate the wake fields behind them and can pass through the plasma column in a periodic sequence. The consideration is carried out numericaly and analyticaly in one dimensional approach, (which can be applied to finite system when its transverse dimensions are larger than plasma wave length, divided by $2\pi$). The possibilities of the experimental tests by measuring the predicted energy gain are discussed on the examples of Argonne Wakefield Accelerator and induction linac with typical parameters.","21 pages, latex, 12 figures appended as uuencoded file","A. Amatuni, S. G. Arutunian, M. R. Mailian",physics,val
One Dimensional Nonlinear Wake-fields Excited in a Cold Plasma by Charged Bunches,One dimensional nonlinear plasma wake-fields excited by a single bunch and by series of bunches are considered. Essential differences are brought to light between negatively charged bunch case and positively one. The bunches with nonuniform distributions of density are investigated. The obtained results show dependence of excited potential electric fields on bunches parameters and allows to choose these parameters optimal.,"13 pages, latex, 6 figures",A. G. Khachatryan,physics,train
High Energy Colliders,"We consider the high energy advantages, disadvantages and luminosity requirements of hadrons, leptons and photon-photon colliders. Technical problems in obtaining increased energy in each type of machine are presented. The machines relative size are also discussed.","LaTeX, 27 pages, 8 figures (eps, ps). Submitted to the Proceedings of
  the Princeton's 250th Anniversary Conference on Critical Problems in Physics","R. B. Palmer, J. C. Gallardo",physics,test
Muon-Muon and other High Energy Colliders,"Parameters are given of 4 TeV and 0.5 TeV (c-of-m) high luminosity muon-muon Colliders. We discuss the various systems, starting from the proton accelerator needed to generate the muons and proceeding through muon cooling, acceleartion and storage in a collider ring. Detector background, polarization are analyzed. We also look at other type of colliders (hadron, lepton and photon-photon) for comparison. Technical problems in obtaining increased energy in each type of machine are presented. Their relative size and probable relative costs are discussed.","96 pages, 50 (eps,ps,ai) figures LaTeX","R. B. Palmer, J. C. Gallardo",physics,train
Wire scanners in low energy accelerators,"Fast wire scanners are today considered as part of standard instrumentation in high energy synchrotrons. The extension of their use to synchrotrons working at lower energies, where Coulomb scattering can be important and the transverse beam size is large, introduces new complications considering beam heating of the wire, composition of the secondary particle shower and geometrical consideration in the detection set-up. A major problem in treating these effects is that the creation of secondaries in a thin carbon wire by a energetic primary beam is difficult to describe in an analytical way. We are here presenting new results from a full Monte Carlo simulation of this process yielding information on heat deposited in the wire, particle type and energy spectrum of secondaries and angular dependence as a function of primary beam energy. The results are used to derive limits for the use of wire scanners in low energy accelerators.","20 pages, 8 Postscript figures, uses elsart.cls","P. Elmfors, A. Fasso, M. Huhtinen, M. Lindroos, J. Olsfors, U. Raich",physics,train
Comment on Enhanced TKE Dissipation under Breaking Waves,"It is noted that the results of recent experiments on the enhancement of turbulent kinetic energy (TKE) dissipation below surface waves can be stated as follows. TKE dissipation is enhanced by a factor $15 H_{ws}/z$ at depths $0.5 H_{ws} < z < 20 H_{ws}$ with respect to the wall-layer result $\epsilon = u_{*w}^3/\kappa z$, where $u_{*w}$ is the friction velocity in water and $H_{ws}$ is the significant wind-sea wave height. For open ocean conditions, this reduces in most cases to an enhancement factor $10^6 u_{*w}^2/gz \approx U_{10}^2/gz$.","2 pages, LaTeX, 1 ps figure",Gerrit Burgers,physics,train
On the mechanism of decadal oscillations in a coarse resolution ocean model,"The mechanism that causes an interdecadal oscillation in a coarse resolution sector ocean model forced by mixed boundary conditions is studied. The oscillation is characterized by large fluctuations in convective activity and air/sea heat exchange on a decadal time scale. When the convective activity is large, a strengthening of the southeastward surface flow advects more relatively fresh water from the northwestern part of the basin into the convective area, which reduces the convective activity. Similarly, when the convective activity is small, the flow of relatively fresh water is weak, which enables the expansion of the convective area. The oscillation critically depends on how the ocean circulation, and especially the surface circulation, responds to anomalous convective activity. Horizontal boundaries turn out to play an important role in the dynamical response of the ocean circulation. That the dynamical reponse is essential to the oscillation is confirmed with two simple (conceptual) models, and some idealized ocean experiments.","45 pages, Latex, psfig, submitted to J. Phys. Oceanogr","G. Lenderink, R. J. Haarsma",physics,train
A comparison of two operational wave assimilation methods,"A comparison is carried out between two operational wave forecasting/assimilation models for the North Sea, with the emphasis on the assimilation schemes. One model is the WAM model, in combination with an optimal interpolation method (OIP). The other model, DASWAM, consists of the third generation wave model PHIDIAS in combination with an approximate implementation of the adjoint method. In an experiment over the period February 19 - March 30, 1993, the models are driven by the same wind field (HIRLAM analysis winds), and the same observation data set is assimilated. This set consists of a) spectra from three pitch-and-roll buoys and b) Synthetic Aperture Radar (SAR) spectra from the ERS-1 satellite. Three analysis/forecast runs are performed: one without assimilation, one with assimilation of buoy measurements only, and one with all data assimilated. For validation, observations from four buoys, altimeter data from ERS-1 and Topex-Poseidon, and scatterometer data from ERS-1 are used. A detailed analysis of the ""Wadden Storm"" (February 20-22) shows the very different nature of the two assimilation schemes: the wave and wind field corrections of the WAM/OIP scheme are all in the vicinity of the observations, whereas the DASWAM adjustments are more of a global nature. The impact of some individual buoy and SAR observations is visualized. A comparison of the performance of the two schemes is somewhat obscured by the very different behaviour of the two first-guess runs. A statistical analysis over the whole 39-day period gives the following results. In a comparison with buoy observations it is shown that a positive impact of wave data assimilation remains until about 12 hours in forecast in","46 pages, 13 figures, latex","A. C. Voorrips, C. de Valk",physics,train
The El Nino Stochastic Oscillator,"Anomalies during an El Nino are dominated by a single, irregularly oscillating, mode. Equatorial dynamics has been linked to delayed-oscillator models of this mode. Usually, the El Nino mode is regarded as an unstable mode of the coupled atmosphere system and the irregularity is attributed to noise and possibly chaos. Here a variation on the delayed oscillator is explored. In this stochastic-oscillator view, El Nino is a stable mode excited by noise. It is shown that the autocorrelation function of the observed NINO3.4 index is that of a stochastic oscillator, within the measurement uncertainty. Decadal variations as would occur in a stochastic oscillator are shown to be comparable to those observed, only the increase in the long-term mean around 1980 is rather large. The observed dependence of the seasonal cycle on the variance and the correlation is so large that it can not be attributed to the natural variability of a stationary stochastic oscillator. So the El Ni\~{n}o stochastic-oscillator parameters must depend on the season. A forecast model based on the stochastic oscillator with a variance that depends on the season has a skill that approaches that of more comprehensive statistical models: over the period 1982-1993, the anomaly correlation is 0.65 for two-season lead forecasts.","20 pages, 9 figures",Gerrit Burgers,physics,train
On the El-Nino Teleconnection to Spring Precipitation in Europe,"In a statistical analysis of more than a century of data we find a strong connection between strong warm El Nino winter events and high spring precipitation in a band from Southern England eastwards into Asia. This relationship is an extension of the connection mentioned by Kiladis and Diaz (1989), and much stronger than the winter season teleconnection that has been the subject of other studies. Linear correlation coefficients between DJF NINO3 indices and MAM precipitation are higher than r=0.3 for individual stations, and as high as r=0.49 for an index of precipitation anomalies around 50N from 5W to 35E. The lagged correlation suggests that south-east Asian surface temperature anomalies may act as intermediate variables.","latex, 14 pages, 9 figures (epsfig)","Geert Jan van Oldenborgh, Gerrit Burgers, Albert Klein Tank",physics,train
"11-Year Warm Cloud Modification Experiment in Maharashtra State, India","A warm cloud modification experiment was carried out in an area of 4800 Sq.Km in the Pune region,India, during the 11-summer monsoon (June-September) seasons (1973-74, 1976, 1979-86). A double-area cross-over design with area randomization was adopted and an instrumented aircraft was used for seeding and cloud physical measurements. Finely pulverised salt (sodium chloride) particles were released into the monsoon clouds (cumulus and stratocumulus) during aircraft penetrations into the clouds at a height of 200-300 m above the cloud-base. The warm cloud responses to salt seeding are found to be critically dependent on the cloud physical characteristics e.g., vertical thickness and liquid water content. Clouds with vertical thickness greater than 1 km, LWC greater than 0.5 gm/cubic m when seeded with salt particles (modal diameter 10 micro m, concentration 1 per litre of cloud air) produced increase in rainfall of 24 per cent significant at 4 per cent level. Shallow clouds (vertical thickness less than 1 km, LWC less than 0.5 gm/cubic m) when seeded showed tendency for dissipation. The cloud physical observations made in not-seeded (control) and seeded (target) clouds have provided some useful evidence to test the applicability of the warm cloud modification hypothesis. The results of the cloud model computations suggested that moderate convergence at the cloud-base is essential for the cloud growth and development of precipitation in the real world. Hygroscopic particle seeding of warm clouds under favourable dynamical conditions (convergence at the cloud-base level) may result in the acceleration of the collision-coalescence process resulting in the enhancement of rainfall.","26 pages, 9 figures. Submitted for consideration of its publication
  in the Journal of Applied Meteorology, 1998",A. S. R. Murty et. al,physics,val
A possible explanation for Earth's climatic changes in the past few million years,"The astronomical theory of Milankovitch relates the changes of Earth' past climate to variations in insolation caused by oscillations of the orbital parameters. However, this theory has problems to account for some major observed phenomena of the past few million years. Here, we present an alternative explanation for these phenomena. It is based on the idea that the solar system until quite recently contained an additional massive object of planetary size. This object, called Z, is assumed to have moved on a highly eccentric orbit bound to the sun. It influenced Earth's climate through a gas cloud of evaporated material. Calculations show that more than once during the last 3.2 Myr it even approached the Earth close enough to provoke a significant shift of the geographic position of the poles. The last of these shifts terminated Earth's Ice Age epoch about 11.5 kyr ago. The origin and fate of Z is also discussed.","18 pages, 7 figures, typos corrected and some references added","W. Woelfli, W. Baltensperger",physics,test
Using Rigorous Ray Tracing to Incorporate Reflection into the Parabolic Approximation,"We present a parabolic approximation that incorporates reflection. With this approximation, there is no need to solve the parabolic equation for a coupled pair of solutions consisting of the incident and reflected waves. Rather, this approximation uses a synthetic wave whose spectral components manifest the incident and reflected waves.","4 pages, LaTeX 2.09. No figures. Key words: ocean acoustics,
  parabolic approximation, parabolic equation, backscatter, propagation",Edward R. Floyd,physics,train
Radiation of mixed layer near-inertial oscillations into the ocean interior,"The radiation from the mixed layer into the interior of the ocean of near-inertial oscillations excited by a passing storm in the presence of the beta effect is reconsidered as an initial-value problem. Making use of the fact that the mixed layer depth is much smaller than the total depth of the ocean, the solution is obtained in the limit of an ocean that is effectively infinitely deep. For a uniform initial condition, analytical results for the velocity, horizontal kinetic energy density and fluxes are obtained. The resulting decay of near-inertial mixed layer energy in the presence of the beta effect occurs on a timescale similar to that observed.","15 pages, 5 figures","Jeff Moehlis, Stefan G. Llewellyn Smith",physics,val
Monodisperse approximation in the metastable phase decay,A new simple method for the first order phase transition kinetics is suggested. The metastable phase consumption can be imagined in frames of the modisperse approximation for the distribution of the droplets sizes. In all situations of the metastable phase decay this approximation leads to negligible errors in the total number of droplets appeared in the system. An evident advantage of the presented method is the possibility to investigate the situation of the metastable phase decay on several sorts of heterogeneous centers.,18 pages LATEX,V. Kurasov,physics,val
On-a-chip biosensing based on all-dielectric nanoresonators,"Nanophotonics has become a key enabling technology in biomedicine with great promises in early diagnosis and less invasive therapies. In this context, the unique capability of plasmonic noble metal nanoparticles to concentrate light on the nanometer scale has widely contributed to biosensing and enhanced spectroscopy. Recently, high-refractive index dielectric nanostructures featuring low loss resonances have been proposed as a promising alternative to nanoplasmonics, potentially offering better sensing performances along with full compatibility with the microelectronics industry. In this letter we report the first demonstration of biosensing with silicon nanoresonators integrated in state-of-the-art microfluidics. Our lab-on-a-chip platform enables detecting Prostate Specific Antigen (PSA) cancer marker in human serum with a sensitivity that meets clinical needs. These performances are directly compared with its plasmonic counterpart based on gold nanorods. Our work opens new opportunities in the development of future point-of-care devices towards a more personalized healthcare.",,"Ozlem Yavas, Mikael Svedendahl, Paulina Dobosz, Vanesa Sanz, Romain Quidant",physics,train
A THz Slot Antenna Optimization Using Analytical Techniques,"Slot antennas are very popular microwave antennas and slotted wave guides are used for high frequency radar systems. A thin slot in an infinite ground plane is the complement to a dipole in free space. This was described by H.G. Booker [2] who extended Babinet's principle from optics to show that the slot will have the same radiation pattern as a dipole such that the E and H fields are swapped. As a result, the polarization is rotated, so that radiation from vertical slot is polarized horizontally. In this work we show how analytical techniques can be used for optimization of THz slot antennas, the analysis is then corroborated by using a numerical simulation which validates the performance parameters predicted by the analytical technique.","7 pages, 14 figures","Shay Rozenberg, Asher Yahalom",physics,train
Can Distribution Grids Significantly Contribute to Transmission Grids' Voltage Management?,"Power generation in Germany is currently transitioning from a system based on large, central, thermal power plants to one that heavily relies on small, decentral, mostly renewable power generators. This development poses the question how transmission grids' reactive power demand for voltage management, covered by central power plants today, can be supplied in the future. In this work, we estimate the future technical potential of such an approach for the whole of Germany. For a 100% renewable electricity scenario we set the possible reactive power supply in comparison with the reactive power requirements that are needed to realize the simulated future transmission grid power flows. Since an exact calculation of distribution grids' reactive power potential is difficult due to the unavailability of detailed grid models on such scale, we optimistically estimate the potential by assuming a scaled, averaged distribution grid model connected to each of the transmission grid nodes. We find that for all except a few transmission grid nodes, the required reactive power can be fully supplied from the modeled distribution grids. This implies that - even if our estimate is overly optimistic - distributed reactive power provisioning will be a technical solution for many future reactive power challenges.",,"Sabine Auer, Florian Steinke, Wang Chunsen, Andrei Szabo, Rudolf Sollacher",physics,val
Self-supporting structure design in additive manufacturing through explicit topology optimization,"One of the challenging issues in additive manufacturing (AM) oriented topology optimization is how to design structures that are self-supportive in a manufacture process without introducing additional supporting materials. In the present contribution, it is intended to resolve this problem under an explicit topology optimization framework where optimal structural topology can be found by optimizing a set of explicit geometry parameters. Two solution approaches established based on the Moving Morphable Components (MMC) and Moving Morphable Voids (MMV) frameworks, respectively, are proposed and some theoretical issues associated with AM oriented topology optimization are also analyzed. Numerical examples provided demonstrate the effectiveness of the proposed methods.","81 pages, 45 figures","Xu Guo, Jianhua Zhou, Weisheng Zhang, Zongliang Du, Chang Liu, Ying Liu",physics,train
Nuclear Data and Fuel/Assembly Manufacturing Uncertainties Analysis and Preliminary Validation of SUACL,"As the sensitivity and uncertainty analysis of nuclear system can provide more confident bounds for the Best-estimate Prediction used to assess the performance and safety of nuclear plant, the uncertainty and sensitivity analysis has been a component of analysis of nuclear system. Both the cross section uncertainty and the uncertainty of parameters of fuel/assembly manufacturing are analyzed in this paper. All results of SUACL were found in accordance with the results of reference codes.238U and 235U play an important role in determining the uncertainty of Keff in TMI-1 cell. The uncertainty of Keff in MOX is mainly affected by 239Pu and 238U. It is obvious that the uncertainty mostly depends on the covariance library and insensitivities to cross section library. The uncertainties based on the covariance library obtained from ENDF/B-VII.1 differ from the result of JENDL4.0, which verified the relationship of covariance matrix and the uncertainty of cross section. And the parameters of fuel/assembly manufacturing uncertainty are comparable to uncertainty of some cross section, especially the 235U concentration, clad thickness. The uncertainty analysis of these parameters is of great significance to evaluate the parameter of actual cell and help to improve the model simulated. More attentions need paid to improve the accuracy of the parameters analysis talked in the paper.",,"JiaYi Xu, Xu Bo Ma, Fan Lu, Yi Xue Chen",physics,val
Pinhole induced efficiency variation in perovskite solar cells,"Process induced efficiency variation is a major concern for all thin film solar cells, including the emerging perovskite based solar cells. In this manuscript, we address the effect of pinholes or process induced surface coverage aspects on the efficiency of such solar cells through detailed numerical simulations. Interestingly, we find the pinhole size distribution affects the short circuit current and open circuit voltage in contrasting manners. Specifically, while the Jsc is heavily dependent on the pinhole size distribution, surprisingly, the Voc seems to be only nominally affected by it. Further, our simulations also indicate that, with appropriate interface engineering, it is indeed possible to design a nanostructured device with efficiencies comparable to that of ideal planar structures. Additionally, we propose a simple technique based on terminal IV characteristics to estimate the surface coverage in perovskite solar cells.",,"Sumanshu Agarwal, Pradeep R. Nair",physics,test
Giant electrostrain of 0.57% in a periodically orthogonal poled lead titanate zirconate ceramic via reversible domain switching,"The widely used ferroelectric ceramics based actuators always suffer from small output strains (typically ~0.1-0.15%). Non-180{\deg} domain switching can generate large strain in ferroelectrics but it is usually irreversible. In this work, we tailored the domain structures in a soft lead titanate zirconate (PZT) ceramic by periodically orthogonal poling. The non-180{\deg} switching in this domain-engineered PZT ceramics turns to be reversible, resulting in giant electrostrains up to 0.57% under a field of 2kV/mm (dynamic d33*(=S/E) of 2850pm/V). The large electrostrain keeps quite stable and even slightly increases after 10000 cycles of loading, which is very promising for next-generation large-strain actuators.","11 pages,6 figures","Faxin Li, Qiangzhong Wang, Hongchen Miao",physics,val
"Tunable, synchronized frequency down-conversion in magnetic lattices with defects","We study frequency conversion in nonlinear mechanical lattices, focusing on a chain of magnets as a model system. We show that by inserting mass defects at suitable locations, we can introduce localized vibrational modes that nonlinearly couple to extended lattice modes. The nonlinear interaction introduces an energy transfer from the high-frequency localized modes to a low-frequency extended mode. This system is capable of autonomously converting energy between highly tunable input and output frequencies, which need not be related by integer harmonic or subharmonic ratios. It is also capable of obtaining energy from multiple sources at different frequencies with a tunable output phase, due to the defect synchronization provided by the extended mode. Our lattice is a purely mechanical analog of an opto-mechanical system, where the localized modes play the role of the electromagnetic field, and the extended mode plays the role of the mechanical degree of freedom.",,"Marc Serra-Garcia, Miguel Molerón, Chiara Daraio",physics,train
The Response of Conductive-Fiber Reinforced Composites to Electric Field,"An analytical procedure, which couples electric, magnetic, thermal and mechanical effects is presented for the prediction of the response of unidirectional fiber-reinforced composites that are subjected to electric field, applied in the fibers' direction. It is assumed that at least one of the phases of the composite (e.g., the fibers) is electrically conductive, and that all phases are thermally conductive. The composite is assumed to occupy a finite, symmetric domain which is discretized into a double array of subcells. The governing equations, with the interfacial and boundary conditions, are satisfied in the integral sense. The externally applied field generates electric current, which induces a magnetic field as well as temperature increase. The mechanical deformation of the composite results from the combined effect of the ponderomotive force, which is created by the magnetic field, and the temperature distribution within the constituents. The purpose of the present paper is three-fold. (a) To perform quantitative analysis of the model for the ponderoromotive force in deformable media. (b) To present computational strong-form treatment of the magneto-mechanical boundary-value problem in a composite. (c) To suggest a computational apparatus for deriving the response of a sensor/actuator excited by an applied electric field or electric field gradient. Application is given, presenting the magnetic, thermal and mechanical field distributions, as well as the macroscopic (global) response of a composite, which consists, for simplicity, of two iron fibers embedded in an epoxy matrix.","32 pages, 18 figures","Nathan Perchikov, Jacob Aboudi",physics,val
The Effects of Superheating Treatment on Distribution of Eutectic Silicon Particles in A357-Continuous Stainless Steel Composite,"In the present study, superheating treatment has been applied on A357 reinforced with 0.5 wt. % (Composite 1) and 1.0 wt.% (Composite 2) continuous stainless steel composite. In Composite 1 the microstructure displayed poor bonding between matrix and reinforcement interface. Poor bonding associated with large voids also can be seen in Composite 1. The results also showed that coarser eutectic silicon (Si) particles were less intensified around the matrix-reinforcement interface. From energy dispersive spectrometry (EDS) elemental mapping, it was clearly shown that the distribution of eutectic Si particles were less concentrated at poor bonding regions associated with large voids. Meanwhile in Composite 2, the microstructure displayed good bonding combined with more concentrated finer eutectic Si particles around the matrix-reinforcement interface. From EDS elemental mapping, it was clearly showed more concentrated of eutectic Si particles were distributed at the good bonding area. The superheating prior to casting has influenced the microstructure and tends to produce finer, rounded and preferred oriented {\alpha}-Al dendritic structures.","6 pages, 6 figures","Mazlee Mohd Noor, Shamsul Baharin Jamaludin",physics,test
Time-Dependent Local Density Approximation for Collective Excitations of Atomic Clusters,"We discuss the calculation of collective excitations in atomic clusters using the time-dependent local density approximation. In principle there are many formulations of the TDLDA, but we have found that a particularly efficient method for large clusters is to use a coordinate space mesh and the algorithms for the operators and the evolution equations that had been developed for the nuclear time-dependent Hartree-Fock theory. The TDLDA works remarkably well to describe the strong excitations in alkali metal clusters and in carbon clusters. We show as an example the benzene molecule, which has two strong features in its spectrum. The systematics of the linear carbon chains is well reproduced, and may be understood in rather simple terms.",12 pages in Postscript,"G. F. Bertsch, K. Yabana",physics,train
Nonradiative Electronic Deexcitation Time Scales in Metal Clusters,"The life-times due to Auger-electron emission for a hole on a deep electronic shell of neutral and charged sodium clusters are studied for different sizes. We consider spherical clusters and calculate the Auger-transition probabilities using the energy levels and wave functions calculated in the Local-Density-Approximation (LDA). We obtain that Auger emission processes are energetically not allowed for neutral and positively charged sodium clusters. In general, the Auger probabilities in small Na$_N^-$ clusters are remarkably different from the atomic ones and exhibit a rich size dependence. The Auger decay times of most of the cluster sizes studied are orders of magnitude larger than in atoms and might be comparable with typical fragmentation times.","11 pages, 4 figures. Accepted for publication in Phys. Rev. B","M. E. Garcia, Ll. Serra, F. Garcias, K. H. Bennemann",physics,val
Oscillator strengths with pseudopotentials,The time-dependent local-density approximation (TDLDA) is shown to remain accurate in describing the atomic response of IB elements under the additional approximation of using pseudopotentials to treat the effects of core electrons. This extends the work of Zangwill and Soven who showed the utility of the all-electron TDLDA in the atomic response problem.,13 pages including 3 Postscript figures,"K. Yabana, G. F. Bertsch",physics,train
Cluster ionization via two-plasmon excitation,"We calculate the two-photon ionization of clusters for photon energies near the surface plasmon resonance. The results are expressed in terms of the ionization rate of a double plasmon excitation, which is calculated perturbatively. For the conditions of the experiment by Schlipper et al., we find an ionization rate of the order of 0.05-0.10 fs^(-1). This rate is used to determine the ionization probability in an external field in terms of the number of photons absorbed and the duration of the field. The probability also depends on the damping rate of the surface plasmon. Agreement with experiment can only be achieved if the plasmon damping is considerably smaller than its observed width in the room-temperature single-photon absorption spectrum.",17 pages and 6 PostScript figures,"G. F. Bertsch, N. Van Giai, N. Vinh Mau",physics,train
Dissociative Autoionization in (1+2)-photon Above Threshold Excitation of H2 Molecules,"We have theoretically studied the effect of dissociative autoionization on the photoelectron energy spectrum in (1+2)-photon above threshold ionization(ATI) of H2 molecules. We have considered excitation from the ground state X-singlet-Sigma-g+(v=0,j) to the doubly excited autoionizing states of singlet-Sigma-u+ and singlet-Pi-u+ symmetry, via the intermediate resonant B-singlet-Sigma-u+(v=5,j) states. We have shown that the photoelectron energy spectrum is oscillatory in nature and shows three distinct peaks above the photoelectron energy 0.7 eV. This feature has been observed in a recent experiment by Rottke et al, J. Phys. B, Vol. 30, p-4049 (1997).",11 pages and 4 figures,"Krishna Rai Dastidar, Ratan Kumar Das",physics,test
Noncollinear magnetic ordering in small Chromium Clusters,"We investigate noncollinear effects in antiferromagnetically coupled clusters using the general, rotationally invariant form of local spin-density theory. The coupling to the electronic degrees of freedom is treated with relativistic non-local pseudopotentials and the ionic structure is optimized by Monte-Carlo techniques. We find that small chromium clusters (N \le 13) strongly favor noncollinear configurations of their local magnetic moments due to frustration. This effect is associated with a significantly lower total magnetization of the noncollinear ground states, ameliorating the disagreement between Stern-Gerlach measurements and previous collinear calculations for Cr_{12} and Cr_{13}. Our results further suggest that the trend to noncollinear configurations might be a feature common to most antiferromagnetic clusters.","9 pages, RevTeX plus .eps/.ps figures","C. Kohl, G. F. Bertsch",physics,val
Optical response of small silver clusters,"The time-dependent local density approximation is applied to the optical response of the silver clusters, Ag_2, Ag_3, Ag_8 and Ag_9^+. The calculation includes all the electrons beyond the closed-shell Ag^{+11} ionic core, thus including for the first time explicitly the filled d-shell in the response. The excitation energy of the strong surface plasmon near 4 eV agrees well with experiment. The theoretical transition strength is quenched by a factor of 4 with respect to the pure s-electron sum rule in Ag_8 due to the d-electrons. A comparable amount of strength lies in complex states below 6 eV excitation. The total below 6 eV, about 50% of the s sum rule, is consistent with published experiments.",13 pages RevTex and 9 Postscript figures,"K. Yabana, G. F. Bertsch",physics,val
Orbital Magnetic Dipole Mode in Deformed Clusters: A Fully Microscopic Analysis,"The orbital M1 collective mode predicted for deformed clusters in a schematic model is studied in a self-consistent random-phase-approximation approach which fully exploits the shell structure of the clusters. The microscopic mechanism of the excitation is clarified and the close correlation with E2 mode established. The study shows that the M1 strength of the mode is fragmented over a large energy interval. In spite of that, the fraction remaining at low energy, well below the overwhelming dipole plasmon resonance, is comparable to the strength predicted in the schematic model. The importance of this result in view of future experiments is stressed.","10 pages, 3 Postscript figures, uses revtex","V. O. Nesterenko, W. Kleinig, F. F. de Souza Cruz, N. Lo Iudice",physics,train
Quantum Monte Carlo study of the H- impurity in small helium clusters,"We report ground state energies and structural properties for small helium clusters (4He) containing an H- impurity computed by means of variational and diffusion Monte Carlo methods. Except for 4He_2H- that has a noticeable contribution from collinear geometries where the H- impurity lies between the two 4He atoms, our results show that our 4He_NH- clusters have a compact 4He_N subsystem that binds the H- impurity on its surface. The results for $N\geq 3$ can be interpreted invoking the different features of the minima of the He-He and He-H- interaction potentials.","12 pages, 7 Ps figures","M. Casalegno, M. Mella, G. Morosi, D. Bressanini",physics,train
Tight-binding molecular dynamic study of silver clusters,"Tight-binding molecular dynamics (TBMD) is used to study the structural and electronic properties of silver clusters. The ground state structures of Ag clusters up to 21 atoms are optimized via TBMD combined with genetic algorithm (GA). The detailed comparison with {\em ab initio} results on small Ag$_n$ clusters (n=3-9) proves the validity of the tight-bind model. The clusters are found to undergo a transition from ``electronic order'' to ``atomic order'' at n=10. This is due to s-d mixing at such size. The size dependence of electronic properties such as density of states (DOS), s-d band separation, HOMO-LUMO gap, and ionization potentials are discussed. Magic number behavior at Ag$_2$, Ag$_8$, Ag$_{14}$, Ag$_{18}$, Ag$_{20}$ is obtained, in agreement with the prediction of electronic ellipsoid shell model. It is suggested that both the electronic and geometrical shell exist in the coinage metal clusters and they play a significant role in determining cluster properties.","10 pages, 6 figures",Jijun Zhao,physics,train
Retarded long-range potentials for the alkali-metal atoms and a perfectly conducting wall,The retarded long-range potentials for hydrogen and alkali-metal atoms in their ground states and a perfectly conducting wall are calculated. The potentials are given over a wide range of atom-wall distances and the validity of the approximations used is established.,"RevTeX, epsf, 11 pages, 2 figs","M. Marinescu, A. Dalgarno, J. F. Babb",physics,val
Eight-component differential equation for leptonium,"It is shown that the potential for lepton-antilepton bound states (leptonium) is the Fourier transform of the first Born approximation to the QED scattering amplitude in an 8-component equation, while 16-component equations are excluded. The Fourier transform is exact at all cms energies $-\infty < E < \infty$; the resulting atomic spectrum is explicitly CPT-invariant.","10 pages; no figures. The complete paper, including figures, is also
  available via anonymous ftp at ftp://ttpux2.physik.uni-karlsruhe.de/ , or via
  www at http://www-ttp.physik.uni-karlsruhe.de/cgi-bin/preprints/","R. Haeckl, V. Hund, H. Pilkuhn",physics,train
Formation of antihydrogen atoms in an ultra-cold positron-antiproton plasma,We discuss the formation of antihydrogen atoms ($\bar{\rm H}$) in an ultra-cold positron-antiproton plasma. For positron densities $n_p\agt 10^8$ cm$^{-3}$ the characteristic formation time of stable $\bar{H}$ is determined by collisional relaxation of highly excited atoms produced in the process of 3-body Thompson recombination. Relying on the mechanisms of ``replacement collisions'' and ``transverse collisional drift'' we find a bottleneck in the relaxation kinetics and analyze the physical consequences of this phenomenon.,"A talk given on ITAMP Workshop on Exotic Atoms, July 11-13, 1996;
  submitted to Physics Letters A; 3 pages, RevTeX",P. O. Fedichev,physics,train
Coherent Population Trapping with Losses on the Sodium D1 Line Hanle Effect,"We consider the coherent population trapping phenomenon in a thermal sodium atomic beam. We compare the different coherent population trapping schemes that can be established on the D1 line using the Zeeman sublevels of a given ground hyperfine state. The coherent population trapping preparation is examined by means of a Hanle effect configuration. The efficiency of the coherent population trapping phenomenon has been examined in presence of optical pumping into hyperfine levels external to those of the excited transition. We show that both the contrast and the width of the coherent population trapping resonance strongly decrease when the optical pumping rate is increased. In the experiment, the loss rate due to optical pumping has been controlled by means of a laser repump of variable intensity.","17 pages, RevTex and 8 figures, PostScript","F. Renzoni, W. Maichen, L. Windholz, E. Arimondo",physics,train
Ramsey type Sub-Recoil Cooling,We experimentally study the motion of atoms interacting with a periodically pulsed near resonant standing wave. For discrete pulse frequencies we observe a comb-like momentum distribution. The peaks have widths of 0.3 recoil momenta and a spacing which is an integer multiple of the recoil momentum. The atomic population is trapped in ground states which periodically evolve to dark states each time the standing wave is switched on.,"4 pages, 3 figures. LaTeX/RevTeX (uses psfig). Submitted to Phys.
  Rev. Lett","Frank Sander, Thibaut Devolder, Tilman Esslinger, Theodor W. Hansch",physics,val
Band Population Measurements in a Purely Optical Dark Lattice,"We create a dark optical lattice structure using a blue detuned laser field coupling an atomic ground state of total angular momentum F simultaneously to two excited states with angular momenta F and F-1, or F and F+1. The atoms are trapped at locations of purely circular polarization. The cooling process efficiently accumulates almost half of the atomic population in the lowest energy band which is only weakly coupled to the light field. The populations of the two lowest energy bands reaches 70%. Kinetic energies on the order of the recoil energy are obtained by adiabatically reducing the optical potential. The band populations are directly mapped on free particle momentum intervals by this adiabatic release. In an experiment with subrecoil momentum resolution we measure the band populations and find good absolute agreement with the theoretically calculated steady state band populations.","4 pages, 4 figures. LaTeX/RevTeX (uses psfig). Submitted to OSA TOPS
  Volume on Ultracold Atoms and BEC '96","Frank Sander, Tilman Esslinger, Theodor W. Hansch, Herwig Stecher, Helmut Ritsch",physics,test
An all-optical gray lattice for atoms,We create a gray optical lattice structure using a blue detuned laser field coupling an atomic ground state of angular momentum J simultaneously to two excited states with angular momenta J and J-1. The atoms are cooled and trapped at locations of purely circular polarization. The cooling process efficiently accumulates almost half of the atomic population in the lowest energy band which is only weakly coupled to the light field. Very low kinetic temperatures are obtained by adiabatically reducing the optical potential. The dynamics of this process is analysed using a full quantum Monte Carlo simulation. The calculations explicitly show the mapping of the band populations on the corresponding momentum intervals of the free atom. In an experiment with subrecoil momentum resolution we measure the band populations and find excellent absolut agreement with the theoretical calculations.,"8 pages, 8 figures. LaTeX/RevTeX (uses epsfig). Scheduled for Phys.
  Rev. A (Dec 01, 1996)","H. Stecher, H. Ritsch, P. Zoller, F. Sander, T. Esslinger, T. W. Hansch",physics,train
On the squared spin-orbit correction to the positronium fine-structure splitting,"In the recent paper by Zhang the order $\alpha^4 R_{\infty}$ corrections to the positronium P levels were reconsidered. Those calculations confirm our corresponding results, except for the contribution due to the squared spin-orbit interaction. We present here a new derivation of our previous result for this last correction, this derivation being to our opinion both simple and convincing.","3 pages, Latex","I. B. Khriplovich, A. I. Milstein, A. S. Yelkhovsky",physics,train
Ejection Energy of Photoelectrons in Strong Field Ionization,"We show that zero ejection energy of the photoelectrons is classically impossible for hydrogen-like ions, even when field ionization occurs adiabatically. To prove this we transform the basic equations to those describing two 2D anharmonic oscillators. The same method yields an alternative way to derive the anomalous critical field of hydrogen-like ions. The analytical results are confirmed and illustrated by numerical simulations. PACS Number: 32.80.Rm","7 pages, REVTeX, postscript file including the figures is available
  at http://www.physik.th-darmstadt.de/tqe/dieter/publist.html or via anonymous
  ftp from ftp://tqe.iap.physik.th-darmstadt.de/pub/dieter/publ_I_pra_pre.ps,
  accepted for publication in Phys. Rev. A",D. Bauer,physics,train
Adiabatically changing the phase-space density of a trapped Bose gas,"We show that the degeneracy parameter of a trapped Bose gas can be changed adiabatically in a reversible way, both in the Boltzmann regime and in the degenerate Bose regime. We have performed measurements on spin-polarized atomic hydrogen in the Boltzmann regime demonstrating reversible changes of the degeneracy parameter (phase-space density) by more than a factor of two. This result is in perfect agreement with theory. By extending our theoretical analysis to the quantum degenerate regime we predict that, starting close enough to the Bose-Einstein phase transition, one can cross the transition by an adiabatic change of the trap shape.","4 pages, 3 figures, Latex, submitted to PRL","P. W. H. Pinkse, A. Mosk, M. Weidemüller, M. W. Reynolds, T. W. Hijmans, J. T. M. Walraven",physics,train
Numerical observation of non-axisymmetric vesicles in fluid membranes,"By means of Surface Evolver (Exp. Math,1,141 1992), a software package of brute-force energy minimization over a triangulated surface developed by the geometry center of University of Minnesota, we have numerically searched the non-axisymmetric shapes under the Helfrich spontaneous curvature (SC) energy model. We show for the first time there are abundant mechanically stable non-axisymmetric vesicles in SC model, including regular ones with intrinsic geometric symmetry and complex irregular ones. We report in this paper several interesting shapes including a corniculate shape with six corns, a quadri-concave shape, a shape resembling sickle cells, and a shape resembling acanthocytes. As far as we know, these shapes have not been theoretically obtained by any curvature model before. In addition, the role of the spontaneous curvature in the formation of irregular crenated vesicles has been studied. The results shows a positive spontaneous curvature may be a necessary condition to keep an irregular crenated shape being mechanically stable.","RevTex, 14 pages. A hard copy of 8 figures is available on request","Yan Jie, Liu Quan-Hui, Liu Ji-Xing, Ou-Yang Zhong-Can",physics,val
Experimental evidence for a power law in electroencephalographic $α$-wave dynamics,"We perform an experimental study of the time behavior of the $\alpha$-wave events occuring in human electroencephalographic signals. We find that the fraction of the time spent in an $\alpha$-burst of time size $\tau$ exhibits a scaling behavior as a function of $\tau$. The corresponding exponent is equal to 1.75$\pm$0.13. We therefore point out the existence of a new power law appearing in physiology. Furhtermore, we show that our experimental result may have a possible explanation within a class of Self-Organized Critical (SOC) models recently proposed by Boettcher and Paczuski. In particular, one of these models, when properly re-interpreted, seems to be consistent both with our result and a commonly accepted physiological description of the possible origin of $\alpha$-wave events.","7 pages, 2 figures","Y. Georgelin, L. Poupard, R. Sartene, J. C. Wallet",physics,test
DNA - Nanoelectronics: Realization of a Single Electron Tunneling Transistor and a Quantum Bit Element,"Based on the understanding that chemical bonds can act as tunnel junctions in the Coulomb blockade regime, and on the technical ability to coat a DNA strand with metal, we suggest that DNA can be used to built logical devices. We discuss two explicit examples: a Single Electron Tunneling Transistor (SET) and a Quantum Bit Element. These devices would be literally in the nano-meter scale and would be able to operate at room temperature. In addition they would be identical to each other, highly stable and would have a self assembly property.","3 pages, RevTex, 4 PostScript figures","Eshel Ben-Jacob, Ziv Hermon, Shay Caspi",physics,val
The Scaling Behaviour of Stochastic Minimization Algorithms in a Perfect Funnel Landscape,"We determined scaling laws for the numerical effort to find the optimal configurations of a simple model potential energy surface (PES) with a perfect funnel structure that reflects key characteristics of the protein interactions. Generalized Monte-Carlo methods(MCM, STUN) avoid an enumerative search of the PES and thus provide a natural resolution of the Levinthal paradox. We find that the computational effort grows with approximately the eighth power of the system size for MCM and STUN, while a genetic algorithm was found to scale exponentially. The scaling behaviour of a derived lattice model is also rationalized.","accepted for publication in Phys. Rev. E, January 1999","K. Hamacher, W. Wenzel",physics,train
A Note on Eye Movement,"In a simplified fashion, the motion of the eyeball in its orbit consists of rotations around a fixed point. Therefore, this motion can be described in terms of the Euler's angles of rigid body dynamics. However, there is a physiological constraint in the motion of the eye which reduces to two its degrees of freedom. This paper reviews the basic features of the kinematics of the eye and the laws governing its motion.",,"Oscar Bolina, L. H. A. Monteiro",physics,val
Order parametr for design of proteinlike heteropolymers,"preprint withdrawn. A revised version of this paper, with different authors appears in E. Nelson, P. Wolynes, and J. Onuchic, in Optimization in computational chemistry and molecular biology, C. Floudas and P. Pardalos editors, (1999)). The main failing of my approach in these papers is the fact that the Hamiltonian and order parameters are based on pair distances only, and therefore do not break the local gauge (reflection) symmetry. Consequently, the order parameters cannot detect the difference between (for example) a partially compact topology and its mirror image. I take full responsibility for this problem, the withdrawal of this preprint, and the comments made above. Erik D. Nelson","16 pages, 5 figures, figures 4 and 5 have two .eps files each
  WITHDRAWN by submitter due to weakness of approach","E. Nelson, L. Ten Eyck, J. Onuchic",physics,val
Structural information from multilamellar liposomes at full hydration: full q-range fitting with high quality X-ray data,"We present a novel method for analyzing Small Angle X-ray Scattering data on multilamellar phospholipid bilayer systems at full hydration. The method utilizes a modified Caille' theory structure factor in combination with a Gaussian model representation of the electron density profile such that it accounts also for the diffuse scattering between Bragg peaks. Thus, the method can retrieve structural information even if only a few orders of diffraction are observed. We further introduce a new procedure to derive fundamental parameters, such as area per lipid, membrane thickness, and number of water molecules per lipid, directly from the electron density profile without the need of additional volumetric measurements. The theoretical apparatus is applied to experimental data on 1-palmitoyl-2-oleoyl-sn-glycero-3-phosphocholine and 1,2-dipalmitoyl-sn-glycero-3-phosphoethanolamine liposome preparations.","37 pages, from MS Word, includes references, 2 tables, figure
  captions & 6 figures. Paper submitted to Phys. Rev. E (Nov. 1999)","Georg Pabst, Michael Rappolt, Heinz Amenitsch, Peter Laggner",physics,train
X-Ray Kinematography of Temperature-Jump Relaxation Probes the Elastic Properties of Fluid Bilayers,"The response kinetics of liquid crystalline phosphatidylcholine bilayer stacks to rapid, IR-laser induced temperature jumps has been studied by millisecond time-resolved x-ray diffraction. The system reacts on the fast temperature change by a discrete bilayer compression normal to its surface and a lateral bilayer expansion. Since water cannot diffuse from the excess phase into the interbilayer water region within the 2 ms duration of the laser pulse, the water layer has to follow the bilayer expansion, by an anomalous thinning. Structural analysis of a 20 ms diffraction pattern from the intermediate phase indicates that the bilayer thickness remains within the limits of isothermal equilibrium values. Both, the intermediate structure and its relaxation into the original equilibrium L_(alpha)-phase, depend on the visco-elastic properties of the bilayer/water system. We present an analysis of the relaxation process by an overdamped one-dimensional oscillation model revealing the concepts of Hooke's law for phospholipid bilayers on a supramolecular basis. The results yield a constant bilayer repulsion and viscosity within Hooke's regime suggesting that the hydrocarbon chains act as a buffer for the supplied thermal energy. The bilayer compression is a function of the initial temperature and the temperature amplitude, but is independent of the chain length.","40 pages, from MS Word, 9 figures. Paper submitted for publication to
  Biophys. J. (Dec. 1999)","Georg Pabst, Michael Rappolt, Heinz Amenitsch, Sigrid Bernstorff, Peter Laggner",physics,train
Physical Aspects of Axonemal Beating and Swimming,"We discuss a two-dimensional model for the dynamics of axonemal deformations driven by internally generated forces of molecular motors. Our model consists of an elastic filament pair connected by active elements. We derive the dynamic equations for this system in presence of internal forces. In the limit of small deformations, a perturbative approach allows us to calculate filament shapes and the tension profile. We demonstrate that periodic filament motion can be generated via a self-organization of elastic filaments and molecular motors. Oscillatory motion and the propagation of bending waves can occur for an initially non-moving state via an instability termed Hopf bifurcation. Close to this instability, the behavior of the system is shown to be independent of microscopic details of the axoneme and the force-generating mechanism. The oscillation frequency however does depend on properties of the molecular motors. We calculate the oscillation frequency at the bifurcation point and show that a large frequency range is accessible by varying the axonemal length between 1 and 50$\mu$m. We calculate the velocity of swimming of a flagellum and discuss the effects of boundary conditions and externally applied forces on the axonemal oscillations.","14 pages, 8 figures, REVTEX","Sebastien Camalet, Frank Julicher",physics,val
The Architecture of Idiotypic Networks: Percolation and Scaling Behaviour,"We investigate a model where idiotypes (characterizing B-lymphocytes and antibodies of an immune system) and anti-idiotypes are represented by complementary bitstrings of a given length d allowing for a number of mismatches (matching rules). In this model, the vertices of the hypercube in dimension d represent the potential repertoire of idiotypes. A random set of (with probability p) occupied vertices corresponds to the expressed repertoire of idiotypes at a given moment. Vertices of this set linked by the above matching rules build random clusters. We give a structural and statistical characterisation of these clusters - or in other words - of the architecture of the idiotypic network. Increasing the probability p one finds at a critical p a percolation transition where for the first time a large connected graph occures with probability one. Increasing p further, there is a second transition above which the repertoire is complete in the sense that any newly introduced idiotype finds a complementary anti-idiotype. We introduce structural characteristics such as the mass distributions and the fragmentation rate for random clusters, and determine the scaling behaviour of the cluster size distribution near the percolation transition, including finite size corrections. We find that slightly above the percolation transition the large connected cluster (the central part of the idiotypic network) consists typically of one highly connected part and a number of weakly connected constituents and coexists with a number of small, isolated clusters. This is in accordance with the picture of a central and a peripheral part of the idiotypic network and gives some support to idealized architectures of the central part used in recent dynamical mean field models.","20 pages, 12 figures, Calculations in Section IV are explained in
  more detail. Data in Figs. 3 and 9 are normalized to enable comparison. Typos
  are removed","Markus Brede, Ulrich Behn",physics,test
A Simplified Approach to Optimally Controlled Quantum Dynamics,"A new formalism for the optimal control of quantum mechanical physical observables is presented. This approach is based on an analogous classical control technique reported previously[J. Botina, H. Rabitz and N. Rahman, J. chem. Phys. Vol. 102, pag. 226 (1995)]. Quantum Lagrange multiplier functions are used to preserve a chosen subset of the observable dynamics of interest. As a result, a corresponding small set of Lagrange multipliers needs to be calculated and they are only a function of time. This is a considerable simplification over traditional quantum optimal control theory[S. shi and H. Rabitz, comp. Phys. Comm. Vol. 63, pag. 71 (1991)]. The success of the new approach is based on taking advantage of the multiplicity of solutions to virtually any problem of quantum control to meet a physical objective. A family of such simplified formulations is introduced and numerically tested. Results are presented for these algorithms and compared with previous reported work on a model problem for selective unimolecular reaction induced by an external optical electric field.","Revtex, 29 pages (incl. figures)","Jair Botina, Herschel Rabitz, Naseem Rahman",physics,val
Influence of the Head Group Size on the Direction of Tilt in Langmuir Monolayers,"A model of rods with heads of variable size, which are confined to a planar surface, is used to study the influence of the head group size on tilted phases in Langmuir monolayers. Simple free energy considerations as well as exact zero temperature calculations indicate that molecules with small head groups tilt towards next nearest neighbors, and molecules with larger head groups towards nearest neighbors. This provides a possible explanation for recent experimental results, and for details of the generic phase diagram for fatty acid monolayers.",to appear in J. Chem. Phys,"F. Schmid, H. Lange",physics,val
Origin of entropy convergence in hydrophobic hydration and protein folding,An information theory model is used to construct a molecular explanation why hydrophobic solvation entropies measured in calorimetry of protein unfolding converge at a common temperature. The entropy convergence follows from the weak temperature dependence of occupancy fluctuations for molecular-scale volumes in water. The macroscopic expression of the contrasting entropic behavior between water and common organic solvents is the relative temperature insensitivity of the water isothermal compressibility. The information theory model provides a quantitative description of small molecule hydration and predicts a negative entropy at convergence. Interpretations of entropic contributions to protein folding should account for this result.,"Phys. Rev. Letts. (in press 1996), 3 pages, 3 figures","Shekhar Garde, Gerhard Hummer, Angel E. Garcia, Michael E. Paulaitis, Lawrence R. Pratt",physics,train
Application of a symmetry-adapted algebraic model to the vibratioinal spectrum of methane,The stretching and bending vibrations of methane are studied in the framework of a symmetry-adapted algebraic model. The model is based on the realization of the one-dimensional Morse potential in terms of a $U(2)$ algebra. For the 44 observed energies we obtain a fit with a r.m.s. deviation of 1.16 cm$^{-1}$ which is an order of magnitude more accurate than previous algebraic calculations.,"5 pages, invited talk at ``21st International Colloquium on Group
  Theoretical Methods in Physics'', Goslar, Germany, July 15-20, 1996","R. Lemus, F. Perez-Bernal, A. Frank, R. Bijker, J. M. Arias",physics,train
A symmetry-adapted algebraic approach to molecular spectroscopy,"We apply a symmetry-adapted algebraic model to the vibrational excitations in D_3h and T_d molecules. A systematic procedure is used to establish the relation between the algebraic and configuration space formulations. In this way we have identified interaction terms that were absent in previous formulations of the vibron model. The inclusion of these new interactions leads to reliable spectroscopic predictions. We illustrate the method for the D_3h triatomic molecules, H_3^+, Be_3 and Na_3, and the T_d molecules, Be_4 and CH_4.","16 pages with 4 tables, invited talk at `Symmetries in Science IX',
  August 6-10, 1996","A. Frank, R. Lemus, R. Bijker, F. Perez-Bernal, J. M. Arias",physics,val
Optical response of small carbon clusters,"We apply the time-dependent local density approximation (TDLDA) to calculate dipole excitations in small carbon clusters. A strong low-frequency mode is found which agrees well with observation for clusters C_n with n in the range 7-15. The size dependence of the mode may be understood simply as the classical resonance of electrons in a conducting needle. For a ring geometry, the lowest collective mode occurs at about twice the frequency of the collective mode in the linear chain, and this may also be understood in simple terms.","19 pages, Latex(Revtex), and 7 figures Postscript; to be published in
  Zeit. Phys. D; contact is bertsch@phys.washington.edu","K. Yabana, G. F. Bertsch",physics,train
A general algebraic model for vibrational molecular spectroscopy,"We present a symmetry-adapted version of the vibron model and discuss an application to D_{3h} triatomic molecules: H_3^+, Be_3 and Na_3^+.","3 pages, invited talk at `21st International Colloquium on Group
  Theoretical Methods in Physics', Goslar, Germany, July 15-20, 1996","A. Frank, R. Lemus, F. Perez-Bernal, R. Bijker, J. M. Arias",physics,train
Dimensional perturbation theory for vibration-rotation spectra of linear triatomic molecules,"A very efficient large-order perturbation theory is formulated for the nuclear motion of a linear triatomic molecule. To demonstrate the method, all of the experimentally observed rotational energies, with values of $J$ almost up to 100, for the ground and first excited vibrational states of CO$_2$ and for the ground vibrational states of N$_2$O and of OCS are calculated. All coupling between vibration and rotation is included. The perturbation expansions reported here are rapidly convergent. The perturbation parameter is $D^{-1/2}$, where $D$ is the dimensionality of space. Increasing $D$ is qualitatively similar to increasing the angular momentum quantum number $J$. Therefore, this approach is especially suited for states with high rotational excitation. The computational cost of the method scales only as $JN_v^{5/3}$, where $N_v$ is the size of the vibrational basis set.","submitted to Journal of Chemical Physics, 23 pages, REVTeX, no
  figures","Andrei A. Suvernev, David Z. Goodson",physics,train
A collaborative theoretical and experimental study of the structure and electronic excitation spectrum of the BAr and B(Ar)2 complexes,"We report the investigation of the 3s <- 2p transition in the BAr2 cluster. In a supersonic expansion of B atoms entrained in Ar, at high beam source backing pressures we observe several features in the fluorescence excitation spectrum which cannot be assigned to the BAr diatom. Using BAr(X, B) potential energy curves which reproduce our experimental observations on this molecule and an Ar-Ar interaction potential, we employ a pairwise additive model, along with variational and diffusion Monte-Carlo treatments of the nuclear motion, to determine the lowest vibrational state of the BAr2 cluster. A subsequent simulation of the fluorescence excitation spectrum reproduces nearly quantitatively the strongest feature in our experimental spectrum not assignable to BAr. Because of the barrier in the BAr(B 2Sigma+) potential energy curve, the 3s <- 2p transition in the BAr2 cluster is predicted to have an asymmetric profile, as is found experimentally.","a pdf file (5 kB) containing the abstract can be retrieved as
  ftp://mha-ibm2.umd.edu/pub/publications/BAr2.abs.pdf a pdf file (325 kB)
  containing the entire manuscript can be retrieved as
  ftp://mha-ibm2.umd.edu/pub/publications/BAr2.ms.pdf To appear in J. Chem.
  Phys. 106 (1997) 8 April issue.","Millard H. Alexander, Andrew Walton, Moonbong Yang, Xin Yang, Eunsook Hwang, Paul J. Dagdigian",physics,train
"He Scattering from Random Adsorbates, Disordered Compact Islands and Fractal Submonolayers: Intensity Manifestations of Surface Disorder","A theoretical study is made on He scattering from three fundamental classes of disordered ad-layers: (a) Translationally random adsorbates, (b) disordered compact islands and (c) fractal submonolayers. The implications of the results to experimental studies of He scattering from disordered surfaces are discussed, and a combined experimental-theoretical study is made for Ag submonolayers on Pt(111). Some of the main theoretical findings are: (1) Structural aspects of the calculated intensities from translationally random clusters were found to be strongly correlated with those of individual clusters. (2) Low intensity Bragg interference peaks appear even for scattering from very small ad-islands, and contain information on the ad-island local electron structure. (3) For fractal islands, just as for islands with a different structure, the off-specular intensity depends on the parameters of the He/Ag interaction, and does not follow a universal power law as previously proposed in the literature. In the experimental-theoretical study of Ag on Pt(111), we use first experimental He scattering data from low-coverage (single adsorbate) systems to determine an empirical He/Ag-Pt potential of good quality. Then, we carry out He scattering calculations for high coverage and compare with experiments. The conclusions are that the actual experimental phase corresponds to small compact Ag clusters of narrow size distribution, translationally disordered on the surface.","36 double-spaced pages, 10 figures; accepted by J. Chem. Phys.,
  scheduled to appear March 8. More info available at
  http://www.fh.huji.ac.il/~dani/","A. T. Yinnon, D. A. Hamburger, I. Farbman, R. B. Gerber, P. Zeppenfeld, M. A. Krzyzowski, G. Comsa",physics,val
A Note on the Relativistic Covariance of the $B-$ Cyclic Relations,It is shown that the Evans-Vigier modified electrodynamics is compatible with the Relativity Theory.,"ReVTeX file, 14pp., no figures",Valeri V. Dvoeglazov,physics,train
Classical $v_{gr} \neq c$ solutions of Maxwell equations and the tunneling photon effect,We propose a very simple but general method to construct solutions of Maxwell equations propagating with a group velocity $v_{gr} \neq c$. Applications to wave guides and a possible description of the known experimental evidences on photonic tunneling are discussed.,"11 pages, Latex2e; to be published in Phys. Lett. A",S. Esposito,physics,train
Nonlinear Maxwell Equations,A new relativistic invariant version of nonlinear Maxwell equations is offerred. Some properties of these equations are considered.,"6 pages, LaTex",G. A. Kotel'nikov,physics,train
Mechanical interpretation of existence theorems in a nonlinear Dirichlet problem,"The existence of radial solutions of a nonlinear Dirichlet problem in a ball is translated to the language of Mechanics, i.e. to requirements on the time of motion of a particle in an external potential and under the action of a viscosity force. This approach reproduces existing theorems and, in principle, provides a method for the analysis of the general case. Examples of new theorems are given, which prove the usefulness of this qualitative method.","13 pages, LaTeX, 7 figures not included, to appear in Ciencias
  Matematicas (Havana)",Augusto Gonzalez,physics,test
An Approach to Maxwell Equations in Uniformly Accelerated Spherical Coordinates by Newman-Penrose Method,Variables are separated in Maxwell equations by the Newman-Penrose method of isotropic complex tetrade in the uniformly accelerated spherical coordinate system. Particular solutions are obtained in terms of spin 1 spherical harmonics. PACS: 03.50.De,"6 pages, LaTeX 2.09; e-mail: zafar@suninp.tashkent.su",Z. Ya Turakulov,physics,val
Theorem on the proportionality of inertial and gravitational masses in classical mechanics,"We considered the problem of the proportionality of inertial and gravitational masses in classical mechanics. We found that the kinetic energy of a material mass point m in a circular motion with a constant angular velocity around another material point M depends only on its gravitational mass. This fact, together with the known result that the straight line is a circumference with an infinite radius, allowed us to prove the proportionality between the inertial and gravitational masses.","ReVTeX file, 10pp","Andrew E. Chubykalo, Stoyan J. Vlaev",physics,val
To Foundations of Classical Electrodynamics,In the present work foundations of the law of the energy conservation and the introduction of particles in the classical electrodynamics are discussed. We pay attention to a logic error which takes place at an interpretation of the Poynting's theorem as the law of conservation of energy. It was shown that the laws of conservation of energy and momentum of the system of electromagnetic fields and charged particles does not follow from the equations of electrodynamics and the violation of these laws is displayed at the energy change of particles. Particular examples are considered which make it possible to restrict a possible kind of fields of a non-electromagnetic origin. We hope that this work will permit to produce a more comprehensive analysis and to stimulate the next step to the development of the foundations of the classical and quantum electrodynamics.,"20 pages, LaTeX, Internal Report FIAN 1975, the Preprint FIAN No 196,
  1980. This paper is the Preprint FIAN No 35, 1997 enlarged by Appendix, some
  Comments and foot-notes. Presented to Uspekhi Phyzicheskich Nauk",E. G. Bessonov,physics,train
Long Wavelength Broadband Sources of Coherent Radiation,Some considerations of long wavelength and broadband radiation sources based on the emission of the coherent radiation by a train of short relativistic electron bunches moving in an open resonator along an arc-like or undulator trajectories and some new versions of the transition radiation sources and long wavelength sources based on storage rings are presented.,"30 pages, LaTeX, Preprint FIAN No 35, 1996","Yu. Shibata, E. G. Bessonov",physics,train
Asymptotic conditions of motion for radiating charged particles,"Approximate asymptotic conditions on the motion of compact, electrically charged particles are derived within the framework of general relativity using the Einstein- Infeld-Hoffmann (EIH) surface integral method. While superficially similar to the Abraham-Lorentz and Lorentz-Dirac (ALD) equations of motion, these conditions differ from them in several fundamental ways. They are not equations of motion in the usual sense but rather a set of conditions which these motions must obey in the asymptotic future of an initial value surface. In addition to being asymptotic, these conditions of motion are approximate and apply, as do the original EIH equations, only to slowly moving systems. Also, they do not admit the run- away solutions of these other equations. As in the original EIH work, they are integrability conditions gotten from integrating the empty-space (i.e., source free) Einstein-Maxwell equations of general relativity over closed two-surfaces surrounding the sources of the fields governed by these equations. No additional ad hoc assumptions, such as the form of a force law or the introduction of inertial reaction terms, needed to derive the ALD equations are required for this purpose. Nor is there a need for any of the infinite mass renormalizations that are required in deriving these other equations.",15 pages,James L. Anderson,physics,train
The geometry of spacetime with superluminal phenomena,Recent theoretical results show the existence of arbitrary speeds (0 <= v < \infty) solutions of all relativistic wave equations. Some recent experiments confirm the results for sound waves. The question arises naturally: What is the appropriate geometry of spacetime to describe superluminal phenomena? In this paper we present a spacetime model that incorporates the valid results of Relativity Theory and yet describes coherently superluminal phenomena without paradoxes.,"16 pages, Amstex, amsppt style","T. Matolcsi, W. A. Rodrigues Jr",physics,train
Harmonic analysis of random number generators and multiplicative groups of residue class rings,"The spectral test of random number generators (R.R. Coveyou and R.D. McPherson, 1967) is generalized. The sequence of random numbers is analyzed explicitly not just via their n-tupel distributions. The generalized analysis of many generators becomes possible due to a theorem on the harmonic analysis of multiplicative groups of residue class rings. We find that the mixed multiplicative generator with power of two modulus does not pass the extended test with an ideal result. Best qualities has a new generator with the recursion formula X(k+1)=a*X(k)+c*int(k/2) mod 2^d. We discuss the choice of the parameters a, c for very large moduli 2^d and present an implementation of the suggested generator with d=256, a=2^128+2^64+2^32+62181, c=(2^160+1)*11463.","38 pages, LaTeX, AMSsymbols, 12 BigTeX figures",Oliver Schnetz,physics,val
Harmonic analysis of random number generators,"The spectral test of random number generators (R.R. Coveyou and R.D. McPherson, 1967) is generalized. The sequence of random numbers is analyzed explicitly, not just via their n-tupel distributions. We find that the mixed multiplicative generator with power of two modulus does not pass the extended test with an ideal result. Best qualities has a new generator with the recursion formula X(k+1)=a*X(k)+c*int(k/2) mod 2^d. We discuss the choice of the parameters a, c for very large moduli 2^d and present an implementation of the suggested generator with d=256, a=2^128+2^64+2^32+62181, c=(2^160+1)*11463.","21 pages, LaTeX, AMSsymbols, 8 BigTeX figures",Oliver Schnetz,physics,train
A Fast Algorithm for High-Dimensional Markov Processes with Finite Sets of Transition Rates,"The discrete class algorithm presented in this paper is an efficient simulation tool for stochastic processes governed by a reasonably small set of transition rates. The algorithm is presented, its performance compared to prevailing methods and applications to epitaxial growth and neuronal models are sketched. Source code is available from the author's WWW-site.","4 pages, LaTeX, AMSmath, epsfig, nolta (included); 1 ps figure, 1 gif
  figure; source code available from
  http://www.physik.rwth-aachen.de/group/thphys/tpd/dietmar/classalg_engl.html","Hans E. Plesser, Dietmar Wendt",physics,train
Simultaneously Dissipative Operators And The Infinitesimal Moore Effect In Interval Spaces,"One of shortcomings of stepwise interval methods is the following. The intervals determining the solution of a system are often expanded in the course of time irrespective of the method and step used (the {\em Moore effect}). We introduce the notion of general {\em interval spaces} and study the infinitesimal Moore effect (IME) in these spaces. We obtain the local conditions of absence of the IME in terms of Jacobi matrices field. The relation between the absence of IME and simultaneous dissipativity of the Jacobi matrices is established. We study simultaneously dissipative operators in $\Bbb{R}^n$. A linear operator $A$ is {\em dissipative} with respect to a norm $\|...\|$ if $\| \exp (At) \| \leq 1$ at all $t \geq 0$. For each norm, the dissipative operator form a closed convex cone. An operator $A$ is {\em stable dissipative} if it belongs to the interior of this cone. The family of linear operators $\{A_\alpha \}$ is called {\em simultaneously dissipative}, if there exists a norm with respect to which all the operators are dissipative. We studied general properties of such families. For example, let the family $\{A_\alpha \}$ be finite and generate a nilpotent Lee algebra and let for each $A_\alpha$ there exist a norm with respect to which it is dissipative. Then $\{A_\alpha \}$ is simultaneously dissipative. Let the family $\{A_\alpha \}$ be compact and generate solvable Lee algebra, and let the spectrum of each operator $A_\alpha $ lie in the open left half-plane. Then $\{A_\alpha \}$ is simultaneously stable dissipative, i.e. there exists a norm with respect to which all $A_\alpha $ are stable dissipative. We study the conditions of simultaneous dissipativity of the matrices of rank one and discussed their application to equations of {\em mass action law} kinetics.","40 pages, correction of format","A. N. Gorban, Yu. I. Shokin, V. I. Verbitskii",physics,val
K-system generator of pseudorandom numbers on Galois field,We analyze the structure of the periodic trajectories of the K-system generator of pseudorandom numbers on rational sublattice which coincides with the Galois field. The period of the trajectories increases as a function of lattice size and the dimension of the K-matrix. We emphasize the connection of this approach with the one which is based on primitive matrices over Galois fields.,"14 pages, Latex","G. G. Athanasiu, E. G. Floratos, G. K. Savvidy",physics,train
Modeling Metallic Microstructure Using Moving Finite Elements,We present an efficient method for anealing 3d metallic grains using Gradient Weighted Moving Finite Elements (GWMFE). The initial grain microstructure is generated from Monte-Carlo evolution of a an effective discrete model on the initial (frozen) unstructured grid generated for the external geometry of the GWMFE calculation.,"2 pages, RevTeX file, 2 postscript figures attached","Andrew Kuprat, J. Tinka Gammel",physics,train
Hurst's Rescaled Range Statistical Analysis for Pseudorandom Number Generators used in Physical Simulations,The rescaled range statistical analysis (R/S) is proposed as a new method to detect correlations in pseudorandom number generators used in Monte Carlo simulations. In an extensive test it is demonstrated that the RS analysis provides a very sensitive method to reveal hidden long run and short run correlations. Several widely used and also some recently proposed pseudorandom number generators are subjected to this test. In many generators correlations are detected and quantified.,"12 pages, 12 figures, 6 tables. Replaces previous version to correct
  citation [19]",B. M. Gammel,physics,val
Monte Carlo Simulation of Comptonization in Inhomogeneous Media,Comptonization is the process in which photon spectrum changes due to multiple Compton scatterings in the electronic plasma. It plays an important role in the spectral formation of astrophysical X-ray and gamma-ray sources. There are several intrinsic limitations for the analytical method in dealing with the Comptonization problem and Monte Carlo simulation is one of the few alternatives. We describe an efficient Monte Carlo method that can solve the Comptonization problem in a fully relativistic way. We expanded the method so that it is capable of simulating Comptonization in the media where electron density and temperature varies discontinuously from one region to the other and in the isothermal media where density varies continuously along photon paths. The algorithms are presented in detail to facilitate computer code implementation. We also present a few examples of its application to the astrophysical research.,"12 pages, 4 figures, Postscript file, in press (""Computers in
  Physics"", Vol. 11, No. 6)",Xin-Min Hua,physics,train
Parallelization of adaptive MC Integrators,"Monte Carlo (MC) methods for numerical integration seem to be embarassingly parallel on first sight. When adaptive schemes are applied in order to enhance convergence however, the seemingly most natural way of replicating the whole job on each processor can potentially ruin the adaptive behaviour. Using the popular VEGAS-Algorithm as an example an economic method of semi-micro parallelization with variable grain-size is presented and contrasted with another straightforward approach of macro-parallelization. A portable implementation of this semi-micro parallelization is used in the xloops-project and is made publicly available.","10 pages, LaTeX2e, 1 pstricks-figure included and 2 eps-figures
  inserted via epsfig. To appear in Comput. Phys. Commun",Richard Kreckel,physics,train
The 3-dimensional Fourier grid Hamiltonian method,"A method to compute the bound state eigenvalues and eigenfunctions of a Schr\""{o}dinger equation or a spinless Salpeter equation with central interaction is presented. This method is the generalization to the three-dimensional case of the Fourier grid Hamiltonian method for one-dimensional Schr\""{o}dinger equation. It requires only the evaluation of the potential at equally spaced grid points and yields the radial part of the eigenfunctions at the same grid points. It can be easily extended to the case of coupled channel equations and to the case of non-local interactions.","13 pages, 1 figure. RevTeX file. To appear in J. Comput. Phys","F. Brau, C. Semay",physics,train
Monte Carlo Implementation of Gaussian Process Models for Bayesian Regression and Classification,"Gaussian processes are a natural way of defining prior distributions over functions of one or more input variables. In a simple nonparametric regression problem, where such a function gives the mean of a Gaussian distribution for an observed response, a Gaussian process model can easily be implemented using matrix computations that are feasible for datasets of up to about a thousand cases. Hyperparameters that define the covariance function of the Gaussian process can be sampled using Markov chain methods. Regression models where the noise has a t distribution and logistic or probit models for classification applications can be implemented by sampling as well for latent values underlying the observations. Software is now available that implements these methods using covariance functions with hierarchical parameterizations. Models defined in this way can discover high-level properties of the data, such as which inputs are relevant to predicting the response.",,Radford M. Neal,physics,val
The Analysis of Data from Continuous Probability Distributions,"Conventional statistics begins with a model, and assigns a likelihood of obtaining any particular set of data. The opposite approach, beginning with the data and assigning a likelihood to any particular model, is explored here for the case of points drawn randomly from a continuous probability distribution. A scalar field theory is used to assign a likelihood over the space of probability distributions. The most likely distribution may be calculated, providing an estimate of the underlying distribution and a convenient graphical representation of the raw data. Fluctuations around this maximum likelihood estimate are characterized by a robust measure of goodness-of-fit. Its distribution may be calculated by integrating over fluctuations. The resulting method of data analysis has some advantages over conventional approaches.","8 pages, 2 figures, REVTeX",Timothy E. Holy,physics,train
Objective Bayesian Statistics,"Bayesian inference --- although becoming popular in physics and chemistry --- is hampered up to now by the vagueness of its notion of prior probability. Some of its supporters argue that this vagueness is the unavoidable consequence of the subjectivity of judgements --- even scientific ones. We argue that priors can be defined uniquely if the statistical model at hand possesses a symmetry and if the ensuing confidence intervals are subjected to a frequentist criterion. Moreover, it is shown via an example taken from recent experimental nuclear physics, that this procedure can be extended to models with broken symmetry.","8 pages, RevTeX, 1 figure submitted to Phys. Rev. Let","O. -A. Al-Hujaj, H. L. Harney",physics,train
Experiments on Critical Phenomena in a Noisy Exit Problem,"We consider noise-driven exit from a domain of attraction in a two-dimensional bistable system lacking detailed balance. Through analog and digital stochastic simulations, we find a theoretically predicted bifurcation of the most probable exit path as the parameters of the system are changed, and a corresponding nonanalyticity of the activation energy. We also investigate the extent to which the bifurcation is related to the local breaking of time-reversal invariance.","4 pages, 5 figures, REVTEX","D. G. Luchinsky, R. S. Maier, R. Mannella, P. V. E. McClintock, D. L. Stein",physics,val
BAYES-LIN: An object-oriented environment for Bayes linear local computation,"BAYES-LIN is an extension of the LISP-STAT object-oriented statistical computing environment, which adds to LISP-STAT some object prototypes appropriate for carrying out local computation via message-passing between clique-tree nodes of Bayes linear belief networks. Currently the BAYES-LIN system represents a rather low-level set of tools for a back-end computational engine, together with diagnostic graphics for understanding the effects of adjustments on the moral graph. A GUI front end, allowing interactive formulation of DAG models could be easily added, but is currently missing from the system. This document provides a very brief introduction to the system, by means of a work-through of two example computations, followed by a list of variables, functions, objects and methods provided by the system.","21 pages, 12 PostScript figures",Darren J Wilkinson,physics,val
Non-commutative time-frequency tomography,"The characterization of non-stationary signals requires joint time and frequency information. However, time (t) and frequency (omega) being non-commuting variables there cannot be a joint probability density in the (t,omega) plane and the time-frequency distributions, that have been proposed, have difficult interpretation problems arising from negative or complex values and spurious components. As an alternative we propose to obtain time-frequency information by looking at the marginal distributions along rotated directions in the (t,omega) plane. The rigorous probability interpretation of the marginal distributions avoids all interpretation ambiguities. Applications to signal analysis and signal detection are discussed as well as an extension of the method to other pairs of non-commuting variables.","13 pages Latex, 10 ps-figures e-mail: vilela@alf4.cii.fc.ul.pt","V. I. Man'ko, R. Vilela Mendes",physics,val
Characteristic functions and process identification by neural networks,"Principal component analysis (PCA) algorithms use neural networks to extract the eigenvectors of the correlation matrix from the data. However, if the process is non-Gaussian, PCA algorithms or their higher order generalisations provide only incomplete or misleading information on the statistical properties of the data. To handle such situations we propose neural network algorithms, with an hybrid (supervised and unsupervised) learning scheme, which constructs the characteristic function of the probability distribution and the transition functions of the stochastic process. Illustrative examples are presented, which include Cauchy and Levy-type processes","11 pages Latex, 12 figures in a combined ps-file","Joaquim A. Dente, R. Vilela Mendes",physics,train
Cross Validated Non parametric Bayesianism by Markov Chain Monte Carlo,"Completely automatic and adaptive non-parametric inference is a pie in the sky. The frequentist approach, best exemplified by the kernel estimators, has excellent asymptotic characteristics but it is very sensitive to the choice of smoothness parameters. On the other hand the Bayesian approach, best exemplified by the mixture of gaussians models, is optimal given the observed data but it is very sensitive to the choice of prior. In 1984 the author proposed to use the Cross-Validated gaussian kernel as the likelihood for the smoothness scale parameter h, and obtained a closed formula for the posterior mean of h based on Jeffreys's rule as the prior. The practical operational characteristics of this bayes' rule for the smoothness parameter remained unknown for all these years due to the combinatorial complexity of the formula. It is shown in this paper that a version of the metropolis algorithm can be used to approximate the value of h producing remarkably good completely automatic and adaptive kernel estimators. A close study of the form of the cross validated likelihood suggests a modification and a new approach to Bayesian Non-parametrics in general.","11 pages 3 figures. Added the missing references;
  http://omega.albany.edu:8008",Carlos C. Rodriguez,physics,val
Using projections and correlations to approximate probability distributions,"A method to approximate continuous multi-dimensional probability density functions (PDFs) using their projections and correlations is described. The method is particularly useful for event classification when estimates of systematic uncertainties are required and for the application of an unbinned maximum likelihood analysis when an analytic model is not available. A simple goodness of fit test of the approximation can be used, and simulated event samples that follow the approximate PDFs can be efficiently generated. The source code for a FORTRAN-77 implementation of this method is available.","14 pages including 7 figures. The source code implementing the
  methods described in the paper are available from:
  ftp://ftp.physics.carleton.ca/pub/opal/karlen/procor",Dean Karlen,physics,val
On the determination of probability density functions by using Neural Networks,"It is well known that the output of a Neural Network trained to disentangle between two classes has a probabilistic interpretation in terms of the a-posteriori Bayesian probability, provided that a unary representation is taken for the output patterns. This fact is used to make Neural Networks approximate probability density functions from examples in an unbinned way, giving a better performace than ``standard binned procedures''. In addition, the mapped p.d.f. has an analytical expression.",13 pages including 3 eps figures. Submitted to Comput. Phys. Commun,"Lluis Garrido, Aurelio Juste",physics,train
Partnerships For Physics Teaching Reform -- a crucial role for universities and colleges,"To meet National Standards recommended by the National Research Council for high school physics, inservice teachers must be integrated into the physics community. They must be empowered by access to resources of the physics community and by sustained support for their professional development. To that end, university and college physics departments must assume an essential role in establishing and maintaining the necessary local infrastructure. Nevertheless, this can be done within their current systems at negligible cost by forming partnerships with local alliances of inservice teachers. Practical details have been worked out, and working partnerships have been established in several localities. This effort should be extended to a national infrastructure for reform of physics teaching in community colleges as well as in high schools. Most teachers are eager to participate in teaching reform.","11 pages, 2 figures, PDF format","David Hestenes, Jane Jackson",physics,test
Ideal Gas in a Finite Container,"The thermodynamics of an ideal gas enclosed in a box of volume a1 x a2 x a3 at temperature T is considered. The canonical partition function of the system is expressed in terms of complete elliptic integrals of the first kind, whose argument obeys a transcendental equation. For high and low temperatures we derive explicitly the main finite-volume corrections to the standard thermodynamic quantities.","13 pages total (Latex source), including one table and one ps figure",M. I. Molina,physics,val
A Elasticidade Relativista,"The purpose of this paper is to make clear the difference between rigid and undeformable bodies in Relativity. The error of confusing these two concepts has survived up to the present day treatises. We hope it will not persist in the XXI century treatises. The large majority of relativists do not know the formulae for the relativistic elasticity of rigid bodies (Mc Crea 1952,Brotas 1968). The paradoxes of the rotating disk and of the 3-degrees of freedom of rigidies bodies in Relativity are in the domain of relativistic elasticity.","Latex file in portuguese language (23 pages). Key words: relativity,
  rigid body, paradoxes,rotating disk",A. Brotas,physics,test
Renormalizing Recitation Grades,"I discuss issue of how to adjust recitation grades given by different instructors in a large course, taking into account and correcting for differences in standards among the instructors, while preserving the effects of differences in average student performance among the recitation sections.","10 pages, 4 figures, LaTeX, epsf",Joel A. Shapiro,physics,train
"Potential Momentum, Gauge Theory, and Electromagnetism in Introductory Physics","If potential energy is the timelike component of a four-vector, then there must be a corresponding spacelike part which would logically be called the potential momentum. The potential four-momentum consisting of the potential momentum and the potential energy taken together is just the gauge field of the associated force times the charge associated with that force. The canonical momentum is the sum of the ordinary and potential momenta. Refraction of matter waves by a discontinuity in a gauge field can be used to explore the effects of gauge fields at an elementary level. Using this tool it is possible to show how the Lorentz force law of electromagnetism follows from gauge theory. The resulting arguments are accessible to students at the level of the introductory calculus-based physics course and tie together classical and quantum mechanics, relativity, gauge theory, and electromagnetism. The resulting economy of presentation makes it easier to include modern physics in the one year course normally available for teaching introductory physics.","12 pages, 7 figures, LaTeX",David J. Raymond,physics,test
The Quantized Hall Effect. (Lab Tutorial. In German.),"This paper is a lab tutorial (and a theory primer) for the integral quantum Hall effect experiment as conducted at Applied Solid State Physics, University of Bochum, Germany.","Version 2.01 (30.06.97), 119 pages, 26 figures, 6 tables, 78
  references",Ralf D. Tscheuschner,physics,train
Introduction to the Fock Quantization of the Maxwell Field,"In this article we give an introduction to the Fock quantization of the Maxwell field. At the classical level, we treat the theory in both the covariant and canonical phase space formalisms. The approach is general since we consider arbitrary (globally-hyperbolic) space-times. The Fock quantization is shown to be equivalent to the definition of a complex structure on the classical phase space. As examples, we consider stationary space-times as well as ordinary Minkowski space-time. The account is pedagogical in spirit and is tailored to beginning graduate students. The paper is selfcontained and is intended to fill an existing gap in the literature.","21 pages, Revtex file, no figures",Alejandro Corichi,physics,val
Aberration and Special Relativity,Section 7 of Einstein's 1905 electrodynamics paper gives frequency-shift and aberration formulae that together describe an elongated ellipsoidal wavefront. A Lorentz contraction of this ellipsoid solves most (but not all) of the associated relativistic problems.,"Approximately 2300 words, with three figures. Nine GIFs, including
  equations. Submitted to Am.J.Phys. on 03/Jun/98; eric_baird@compuserve.com",Eric Baird,physics,train
Ruler-changes and Relative Velocity,"Simple signal-propagation effects make receding objects seem contracted and approaching objects seem elongated. These effects are theoretically photographable, and are proportional in strength to the frequency-change in the object's emitted light. In a one-dimensional version of the ""barn-pole"" experiment, a ""moving"" object's photographed image can appear doubly length-dilated according to fixed-aether theory, but only singly length-dilated according to SR. This expected difference might be charitably described as a form of photographable Lorentz contraction.","HTML+GIF. The contraction values originally given in section V(A)
  were wrong and have been corrected, and section V has been rewritten to
  improve readability. Changes are documented in the HTML file header",Eric Baird,physics,val
Some Remarks on the Question of Charge Densities in Stationary-Current-Carrying Conductors,"Recently, some discussions arose as to the definition of charge and the value of the density of charge in stationary-current-carrying conductors. We stress that the problem of charge definition comes from a misunderstanding of the usual definition. We provide some theoretical elements which suggest that positive and negative charge densities are equal in the frame of the positive ions.","14 pages, TeX, macro newsym.tex included","Liana Baroni, Enrico Montanari, Alessandro D. Pesci",physics,train
Jets from Collapsing Bubbles,"When an asymmetric bubble collapses it generally produces a well defined high velocity jet. This is remarkable because one might expect such a collapse to produce a complex or chaotic flow rather than an ordered one. I present a dimensional argument for the ubiquity of jets from collapsing bubbles, and model the aspherical collapse of a bubble with pieces of Rayleigh's solution for spherical collapse and its cylindrical analogue. This model explains the ubiquity of jet formation in aspherical collapse, and predicts the shape and velocity profile of the resulting jet. These predictions may be tested in the laboratory or by numerical calculation. An application to solid spall is suggested.","10 pp., tex",J. I. Katz,physics,train
Boundary-layer control by electric fields: A feasibility study,"A problem of great concern in aviation and submarine propulsion is the control of the boundary layer and, in particular, the methods to extend the laminar region as a means to decrease noise and fuel consumption. In this paper we study the flow of air along an airfoil when a layer of ionized gas and a longitudinal electric field are created in the boundary layer region. By deriving scaling solutions and more accurate numerical solutions we discuss the possibility of achieving significant boundary layer control for realistic physical parameters. Practical design formulas and criteria are obtained. We also discuss the perspectives for active control of the laminar-to-turbulent transition fluctuations by electromagnetic field modulation.",18 pages Latex and 5 ps-figures,"R. Vilela Mendes, J. A. Dente",physics,train
An instability criterion for a finite amplitude localized disturbance in a shear flow of electrically conducting fluids,"The stability of shear flows of electrically conducting fluids, with respect to finite amplitude three-dimensional localized disturbances is considered. The time evolution of the fluid impulse integral, characterizing such disturbances, for the case of low magnetic Reynolds number is obtained by integrating analytically the vorticity equation. Analysis of the resulted equation reveals a new instability criterion.","10 pages in LaTex, no figures, accepted in Phys. Fluids","V. Levinski, I. Rapoport, J. Cohen",physics,train
A two-dimensional network simulator for two-phase flow in porous media,"We investigate a two-dimensional network simulator capable of modeling different time dependencies in two-phase drainage displacements. In particular, we focus on the temporal evolution of the pressure due to capillary and viscous forces and the time dependence of the interface between the two liquids. The dynamics of the capillary effect are taken into account and we report on high accuracy pressure measurements. Moreover, the simulator includes important features in drainage, like burst dynamics of the invading fluid and simultaneous flow of two liquids in a section of a tube. The validity of the model is checked by comparing simulation results with well known experimental properties in drainage displacement.","22 pages, LaTeX, 14 figures, Postscript","Eyvind Aker, Knut Jorgen Maloy, Alex Hansen, G. George Batrouni",physics,train
Dispersion Relation of a Ferrofluid Layer of Any Thickness and Viscosity in a Normal Magnetic Field; Asymptotic Regimes,"We have calculated the general dispersion relationship for surface waves on a ferrofluid layer of any thickness and viscosity, under the influence of a uniform vertical magnetic field. The amplification of these waves can induce an instability called peaks instability (Rosensweig instability). The expression of the dispersion relationship requires that the critical magnetic field and the critical wavenumber of the instability depend on the thickness of the ferrofluid layer. The dispersion relationship has been simplified into four asymptotic regimes: thick or thin layer and viscous or inertial behaviour. The corresponding critical values are presented. We show that a typical parameter of the ferrofluid enables one to know in which regime, viscous or inertial, the ferrofluid will be near the onset of instability.","21 pages, 6 eps figures, Latex, to be published in Journal de
  Physique II","Berengere Abou, Gilles Neron de Surgy, Jose-Eduardo Wesfreid",physics,train
Averaging theory for the structure of hydraulic jumps and separation in laminar free-surface flows,"We present a simple viscous theory of free-surface flows in boundary layers, which can accommodate regions of separated flow. In particular this yields the structure of stationary hydraulic jumps, both in their circular and linear versions, as well as structures moving with a constant speed. Finally we show how the fundamental hydraulic concepts of subcritical and supercritical flow, originating from inviscid theory, emerge at intermediate length scales in our model.","6 EPSI figs included by psfig; 4 pages; to appear in PRL, vol.79,
  1038 (Aug.11, 1997)","Tomas Bohr, Vachtang Putkaradze, Shinya Watanabe",physics,val
Nonuniqueness and Turbulence,"The possibility is considered that turbulence is described by differential equations for which uniqueness fails maximally, at least in some limit. The inviscid Burgers equation, in the context of Onsager's suggestion that turbulence should be described by a negative absolute temperature, is such a limit. In this picture, the onset of turbulence coincides with the proliferation of singularities which characterizes the failure of uniqueness.","5 pages, Latex, 4 figures, Submitted to Phys. Rev. Letters",Mark A. Peterson,physics,val
On the absence of dissipative instability of negative energy waves in hydrodynamic shear flows,"Stability criterion for the surface gravity capillary waves in a flowing two-layered fluid system with viscous dissipation is investigated. It is seen that the dissipative instability of negative energy waves is absent,- contrary to what earlier authors have concluded. Their error is identified to arise from an erroneous choice of the dissipation law, in which the wave profile velocity is wrongly equated to the particle velocity. Our corrected dissipation law is also shown to restore Galilean invariance to the stability condition of the system.","Revtex file, 4 pgs, no figs","S. Chatterjee, P. S. Joarder",physics,train
Odd Viscosity,"When time reversal is broken the viscosity tensor can have a non vanishing odd part. In two dimensions, and only then, such odd viscosity is compatible with isotropy. Elementary and basic features of odd viscosity are examined by considering solutions of the wave and Navier-Stokes equations for hypothetical fluids where the stress is dominated by odd viscosity.",13 pages. Revised version,J. E. Avron,physics,train
Progressive internal gravity waves with bounded upper surface climbing a triangular obstacle,"In this paper we discuss a theoretical model for the interfacial profiles of progressive non-linear waves which result from introducing a triangular obstacle, of finite height, attached to the bottom below the flow of a stratified, ideal, two layer fluid, bounded from above by a rigid boundary. The derived equations are solved by using a nonlinear perturbation method. The dependence of the interfacial profile on the triangular obstacle size, as well as its dependence on some flow parameters, such as the ratios of depths and densities of the two fluids, have been studied.",,"Mina B. Abd-el-malek, Malak N. Makar",physics,train
"Dark Matter, Mass Scales Sequence, and Superstructure in the Universe (with extension and summary)","We extend mass scale sequence to a mass tree. From mass tree, the evolution of the universe is described by three stages: chaos, inflation and expansion. The first two stages have c mutations and the inflation appears as a step by step fission process of black holes. The dark matter particles with low mass (neutrino and delta particle) are described in a dual SM or two-fold SM with new symmetry and new interaction, and delta-particle is like inert neutrino but has baryon number (L-B conservation). We emphasize how to search for delta-particle, how to research critical energy, critical density, background particles, and spherical universe. Critical density relates to a type of pseudo-balance black holes (or celestial bodies). Suppose the minimum black hole radius equal to proton radius means we live in a spherical universe, which belong to a big universe, mainly characterized by proton.",20 pages,"Wuliang Huang, Xiaodong Huang",physics,train
Developments in time analysis of particle and photon tunnelling,"A compact analysis of development and prospects in the study of the tunnelling evolution is given. A new systematization of various approaches to defining tunnelling times in the light of time as a quantum mechanical observable is proposed. The problem of superluminal group velocities, without violations of special relativity, is also taken in account. Then a particular attention is devoted to the presentation of new results on the analogy between particle and photon tunnelling and analysis of the causality validity during tunnelling. [PACS nos. 03.40.Kf, 03.50.De, 41.20.Jb, 41.20.Bt, 42.25.Bs, 03.30.+p, 03.65.-w].","standard LaTex file, using REVTex. This work was presented at
  Adriatico Research Conference ``Tunnelling and its implications'',
  (International Centre for Theoretical Physics, Trieste, Italy) (30 July-2
  August 1996). Number of pages:36. The figures will be sent by fax to SLAC and
  to interested people. internet:
  http://www.fi.infn.it/unifi/persone/docente.htm","V. S. Olkhovsky, A. Agresti",physics,train
A New View of the Universe,"A new, very different physical model of the universe is proposed. Its virtues include unifying relativity and quantum mechanics, and particles with de Broglie waves. It also appears to provide a truly unified physical basis for electromagnetic, gravitational and nuclear forces. The basic system is a four-dimensional Euclidean space, containing an array of nonlinear ""flow"" waves. These repeat in one dimension, called [phi]. As in Newtonian mechanics, time is treated as an additional, unidirectional parameter describing the evolution of the system. Nevertheless, this wave system is shown be inherently relativistic. Further self-organizing patterns arise within the overall wave structure. Called ""wavicles,"" these have intrinsic quantized fields, ""spin,"" and rest energy, and represent elementary particles. Relativistic expressions are derived for particle behavior in scalar, vector and gravitational potentials. Proper representations of these potentials, based on the wave fields and associated [phi] flows of wavicles, are also obtained. As in the causal quantum mechanics of de Broglie and Bohm, wavicles exist continuously and follow definite, stochastic trajectories. Although experimentally equivalent to Einstein's special relativity, this theory differs fundamentally from his general relativity and the associated Big Bang model. According to Linde, the latter predict a large-scale space-time curvature roughly 60 orders of magnitude greater than observed values. Here a flat large-scale geometry is predicted, in agreement with the observed distribution of galaxies. This theory is also consistent with recent observations pertaining to the age of the universe.","95 pages PostScript, with 27 figures included. The fonts with
  Ghostscript 4.01 or higher will be more readable than earlier versions. The
  images for pages 10 and 12, the complete paper, and a PDF version are
  available at http://www.psych.ucsb.edu/~krogh/site.htm",Ben Kristoffen,physics,train
Does antimatter emit a new light ?,"We identify a number of problematic aspects of current classical and quantum theories of antimatter; we introduce a new mathematical formalism which is an antiautomorphic image of that of matter equivalent to charge conjugation at the operator level, but applicable from Newton's equations to quantum mechanics; we show that the emerging new theory of antimatter recovers known experimental data on electroweak interactions; we finally identity the following predictions of the theory: 1) reversal in the field of matter of the gravitational curvature (antigravity) for stable antiparticles and their bound states, such as the anti-hydrogen atom; 2) conventional (attractive) gravity for a bound state of an elementary particle and its antiparticle, such as the positronium; and 3) prediction that the anti- hydrogen atom emits a new photon which coincides with the conventional photon for all electroweak interactions but experiences repulsion in the gravitational field of matter.","18 pages, TEX, in press at Hyperfine Inter",R. M. Santilli,physics,train
"Space, Time and Superluminal Particles","If textbook Lorentz invariance is actually a property of the equations describing a sector of matter above some critical distance scale, several sectors of matter with different critical speeds in vacuum can coexist and an absolute rest frame (the vacuum rest frame, possibly related to the local rest frame of the expanding Universe) may exist without contradicting the apparent Lorentz invariance felt by ""ordinary"" particles (particles with critical speed in vacuum equal to c , the speed of light). The real geometry of space-time will then be different from standard Lorentz invariance, and the Poincare relativity principle will be a local (in space and time), approximate sectorial property. It seems natural to assume that particles with critical speed in vacuum different from c are superluminal. We illustrate such a scenario using as an example a spinorial space-time where the modulus of the spinor, associated to the time variable, is the size of an expanding Universe. Several properties of superluminal particles, and of matter without a universal relativity principle, are discussed in view of experimental applications. If the vacuum rest frame is close to that suggested by the cosmic microwave background, experimental searches for superluminal particles on earth should mainly contemplate a laboratory speed range around 10E3 c , even for very high energy superluminal cosmic rays. The detectability of several consequences of the new scenario is briefly discussed.",18 pages,Luis Gonzalez-Mestres,physics,train
A note on the light velocity anisotropy,"In the framework of linear transformations between inertial systems, there are no physical reasons for assuming any anisotropy in the one-way velocity of light.","7 pages,Latex",B. Preziosi,physics,train
Lorentz Invariance and Superluminal Particles,"If textbook Lorentz invariance is actually a property of the equations describing a sector of matter above some critical distance scale, several sectors of matter with different critical speeds in vacuum can coexist and an absolute rest frame (the vacuum rest frame, possibly related to the local rest frame of the expanding Universe) may exist without contradicting the apparent Lorentz invariance felt by ""ordinary"" particles (particles with critical speed in vacuum equal to $c$ , the speed of light). Sectorial Lorentz invariance, reflected by the fact that all particles of a given dynamical sector have the same critical speed in vacuum, will then be an expression of a fundamental sectorial symmetry (e.g. preonic grand unification or extended supersymmetry) protecting a parameter of the equations of motion. We study the breaking of Lorentz invariance in such a scenario, with emphasis on mixing between the ""ordinary"" sector and a superluminal sector, and discuss with examples the consequences of existing data. The sectorial universality of the value of the high-energy speed in vacuum, even exact, does not necessarily imply that Lorentz invariance is not violated and does not by itself exclude the possibility to produce superluminal particles at accelerators or to find them in experiments devoted to high-energy cosmic rays. Similarly, the stringent experimental bounds on Lorentz symmetry violation at low energy cannot be extrapolated to high-energy phenomena. Several basic questions related to possible effects of Lorentz symmetry violation are discussed, and potential signatures are examined.",10 pages,Luis Gonzalez-Mestres,physics,train
Einstein's Violation of General Covariance,"Einstein rejected the differential law of energy-momentum conservation $ T^{\mu\nu}_{;\nu} = 0 $. In doing so, he violated the principle of general covariance. Here, we prove the conservation law $ T^{\mu\nu}_{;\nu} = 0 $ and discuss its significance for general relativity.","4 pages, LaTeX; some rewording",Kenneth Dalton,physics,val
A Baryonic Correction to General Relativity,"The baryon overdensity and the matching of the big bang explosion energy with gravitation can be solved by a cyclical baryonic bounce model with correction to the stress-energy tensor. Subtracting accretion energy from the CMBR allows enough baryons in nucleosynthesis to close the universe. Collapse to infinite density states must be prevented by energy losses at supranuclear densities. As long as the Einstein tensor is coupled to the stress-energy tensor, any quantum correction must involve an energy sink.","14 pages latex, 2 postscript figures; email drosenbergmd@mcimail.com",David E. Rosenberg,physics,train
Conceivable new recycling of nuclear waste by nuclear power companies in their plants,We outline the basic principles and the needed experiments for a conceivable new recycling of nuclear waste by the power plants themselves to avoid its transportation and storage to a (yet unknown) dumping area. Details are provided in an adjoining paper and in patents pending.,"17 pages, LaTEX. PACS 03.65.-w; 21.10.Hw; 21.10.Ky; For additional
  information please contact the Institute for Basic Research at ibr@gte.net or
  http://home1.gte.net/ibr",Ruggero Maria Santilli,physics,train
Earthquake source parameters and fault kinematics in the Eastern California Shear Zone,"Based on waveform data from a profile of aftershocks following the north-south trace of the June 28, 1992 Landers rupture across the Mojave desert, we construct a new velocity model for the Mojave region which features a thin, slow crust. Using this model, we obtain source parameters, including depth and duration, for each of the aftershocks in the profile, and in addition, any significant (M>3.7) Joshua Tree--Landers aftershock between April, 1992 and October, 1994 for which coherent TERRAscope data were available. In all, we determine source parameters and stress-drops for 45 significant (M_w > 4) earthquakes associated with the Joshua Tree and Landers sequences, using a waveform grid-search algorithm. Stress drops for these earthquakes appear to vary systematically with location, with respect to previous seismic activity, proximity to previous rupture (i.e., with respect to the Landers rupture), and with tectonic province. In general, for areas north of the Pinto Mountain fault, stress-drops of aftershocks located off the faults involved with the Landers rupture are higher than those located on the fault, with the exception of aftershocks on the newly recognized Kickapoo (Landers) fault. Stress drops are moderate south of the Pinto Mountain fault, where there is a history of seismic swarms but no single through-going fault. In contrast to aftershocks in the eastern Transverse ranges, and related to the 1992 Big Bear, California, sequence, Landers events show no clear relationship between stress-drop and depth. Instead, higher stress-drop aftershocks appear to correlate with activity on nascent faults, or those which experienced relatively small slip during mainshock rupture.","27 pages, 15 figures, to appear in Bull. Seism. Soc. Am","Laura E. Jones, Donald V. Helmberger",physics,train
An Automatic Method for Determination of Lg Arrival Times Using Wavelet Transforms,"The regional phase Lg is used to estimate location and magnitude for sources closer than 1500 km. The complexity of Lg waveforms makes it difficult to consistently determine Lg arrival time, thus affecting source location with a single station or array. This study tests an automatic method for timing Lg arrivals using wavelet transforms to decompose the Lg signal into its components localized both in time and scale. A Continuous Wavelet Transform (CWT) using a Daubechies order two (db2) wavelet is applied to 10 seconds of raw data, containing the start of Lg. Initial positioning of the window is obtained using the standard Lg travel time tables. The coefficients at scale 8 from the db2 decomposition are squared and the resulting time series is represented by an approximation of the 4'th level Discrete Wavelet Transform (DWT) using a Haar wavelet. A threshold detector is then applied to the resulting time series to determine the Lg arrival time. The method was tested using well located earthquakes (USGS) and explosions from known mines (mb less than 4.0), recorded on the vertical components at TXAR (Lajitas, Texas) and PDAR (Pinedale, Wyoming) arrays. The Lg arrival time was automatically picked with a standard deviation of less than 1.5 seconds (less than 10 km location error) for well known locations. Location errors are larger with the increase in distance and smaller with the increase in signal to noise ratio of events.","27 pages, PDF, 13 EPS figures submitted to Seismological Research
  Letters","Ileana M. Tibuleac, E. T. Herrin",physics,train
A brief History of the Earth,The possibility of an increasing gravitational constant $G$ and its implication on the Earth's history are discussed. The model is consistent with geophysical and astronomical data. The number of days in early epochs predicted by the model is in agreement with those obtained from fossil corals. The model predicts that the Earth was initially cold and is gradually heating up during its course of evolution. The exact law for the variation of $G$ is still to be obtained from the variation of the Earth's parameters with cosmic expansion.,"7 pages of LateX, 5 figures with macro epsf",Arbab I. Arbab,physics,train
GIST: A tool for Global Ionospheric Tomography using GPS ground and LEO d ata and sources of opportunity with applications in instrument calibration,"Ionospheric tomography using GPS data has been reported in the literature and even the application to radar altimeter calibration was succesfully carried out in a recent work. We here present a new software tool, called Global Ionospheric Stochastic Tomography software (GIST), and its powerful capability for ingesting GPS data from different sources (ground stations, receivers on board LEO for navigation and occultation purposes) and other data such as altimetry data to yield global maps with dense coverage and inherent calibration of the instruments. We show results obtained including 106 IGS ground stations, GPS/MET low rate occultation data, TOPEX/POSEIDON GPS data from the navigation antenna and NASA Radar Altimeter with the additional benefit of a direct estimation of the NRA bias. The possibility of ingesting different kinds of ionospheric data into the tomographic model suggest a way to accurately monitor the ionosphere with direct application to single frequency instrument calibration.","8 pages, 4 figures 8 postscript files","A. Flores, G. Ruffini, A. Rius, E. Cardellach",physics,test
"Some Wave-Related, Heavy Mineral Placer Deposits","Examples of heavy mineral placer deposits are presented in which wave reflection, refraction, diffraction and resonance would appear to have played a major concentrating role. Their geometry is compared with the computer generated patterns predicted for the reflection, refraction and diffraction of surface waves moving over fairly simple, idealised bathymetries. Much of this work is founded on the idea that similar sediments document equivalent (or once equivalent) flow-tractional environments. Most of the examples could be satisfactorily explained in this fashion. It may therefore be possible to ignore the exact physics of the boundary layer, longshore and tidal return currents etc. at the scale on which these examples occur, leaving the way open for the qualitative use of results obtained using the likes of the mild slope wave equation. A ``Monte Carlo'' approach based on wave induced tractions should therefore succeed in elucidating presently known heavy mineral placer deposits and, consequently, in predicting other deposits which remain as yet undiscovered.","26 pages, 15 figures, a preliminary study so controversial it may be
  worth a read","S. J. Childs, F. A. Shillington",physics,test
Seismic Wave Recording by 2S-Seismographs,"Researchers of seismic waves may construct a new seismographic recording adding one seismometer to each component of a conventional seismic station. The two identical conventional seismometers are set up in position of perpendicular and are connected in parallel feeding one recording device (digital or analog). This use of the seismometers (which they may be both horizontal or, one is vertical) is called ""two seismometers seismograph"" or simply ""2S-S"". 2S-seismograph performs new capabilities: 1.-it cause to a higher gain which is based on directly ground motion energy from the two orthogonal components of signals, 2.-it has a much smoother response curve than that of the single use of seismometer,3.-because of this smoothing, we are able to apply a higher level of static magnification which cause to widening the response at its both ends, therefore, 2S-System enable to work with a larger dynamic range frequency, 4.- it has a directional and motional filtering property which may be used in some cases advantageously, The contribution of ""1"", ""2"", ""3"" and ""4"" correspond to unique instrumental improvements for which seismography are ever needed. Data which are obtained from the 2S-Ss have also more advantageous properties comparing with even that of ARRAY's: 5.-it is possible to record signals with their larger plane components all the time by a second 2S-S connected with the opposite ends, 6.-seismic wave types (P,S,R,L) can often be recorded separately on a separated 2S-seismogram since researchers usually deal with a known area of research, 7.-some implicit weak signals, which can not be readable as a phase on the conventional seismograms, become recorded newly and readably by the 2S-Ss","14 pages, 3 figures",Ruhi Gurcan,physics,train
"Geometry of River Networks I: Scaling, Fluctuations, and Deviations","This article is the first in a series of three papers investigating the detailed geometry of river networks. Large-scale river networks mark an important class of two-dimensional branching networks, being not only of intrinsic interest but also a pervasive natural phenomenon. In the description of river network structure, scaling laws are uniformly observed. Reported values of scaling exponents vary suggesting that no unique set of scaling exponents exists. To improve this current understanding of scaling in river networks and to provide a fuller description of branching network structure, we report here a theoretical and empirical study of fluctuations about and deviations from scaling. We examine data for continent-scale river networks such as the Mississippi and the Amazon and draw inspiration from a simple model of directed, random networks. We center our investigations on the scaling of the length of sub-basin's dominant stream with its area, a characterization of basin shape known as Hack's law. We generalize this relationship to a joint probability density and show that fluctuations about scaling are substantial. We find strong deviations from scaling at small scales which can be explained by the existence of linear network structure. At intermediate scales, we find slow drifts in exponent values indicating that scaling is only approximately obeyed and that universality remains indeterminate. At large scales, we observe a breakdown in scaling due to decreasing sample space and correlations with overall basin shape. The extent of approximate scaling is significantly restricted by these deviations and will not be improved by increases in network resolution.","16 pages, 13 figures, Revtex4, submitted to PRE","Peter Sheridan Dodds, Daniel H. Rothman",physics,val
Geometry of River Networks II: Distributions of Component Size and Number,"The structure of a river network may be seen as a discrete set of nested sub-networks built out of individual stream segments. These network components are assigned an integral stream order via a hierarchical and discrete ordering method. Exponential relationships, known as Horton's laws, between stream order and ensemble-averaged quantities pertaining to network components are observed. We extend these observations to incorporate fluctuations and all higher moments by developing functional relationships between distributions. The relationships determined are drawn from a combination of theoretical analysis, analysis of real river networks including the Mississippi, Amazon and Nile, and numerical simulations on a model of directed, random networks. Underlying distributions of stream segment lengths are identified as exponential. Combinations of these distributions form single-humped distributions with exponential tails, the sums of which are in turn shown to give power law distributions of stream lengths. Distributions of basin area and stream segment frequency are also addressed. The calculations identify a single length-scale as a measure of size fluctuations in network components. This article is the second in a series of three addressing the geometry of river networks.","16 pages, 13 figures, 4 tables, Revtex4, submitted to PRE","Peter Sheridan Dodds, Daniel H. Rothman",physics,val
Geometry of River Networks III: Characterization of Component Connectivity,"River networks serve as a paradigmatic example of all branching networks. Essential to understanding the overall structure of river networks is a knowledge of their detailed architecture. Here we show that sub-branches are distributed exponentially in size and that they are randomly distributed in space, thereby completely characterizing the most basic level of river network description. Specifically, an averaged view of network architecture is first provided by a proposed self-similarity statement about the scaling of drainage density, a local measure of stream concentration. This scaling of drainage density is shown to imply Tokunaga's law, a description of the scaling of side branch abundance along a given stream, as well as a scaling law for stream lengths. This establishes the scaling of the length scale associated with drainage density as the basic signature of self-similarity in river networks. We then consider fluctuations in drainage density and consequently the numbers of side branches. Data is analyzed for the Mississippi River basin and a model of random directed networks. Numbers of side streams are found to follow exponential distributions as are stream lengths and inter-tributary distances along streams. Finally, we derive the joint variation of side stream abundance with stream length, affording a full description of fluctuations in network structure. Fluctuations in side stream numbers are shown to be a direct result of fluctuations in stream lengths. This is the last paper in a series of three on the geometry of river networks.","16 pages, 13 figures, 1 table, Revtex4, submitted to PRE","Peter Sheridan Dodds, Daniel H. Rothman",physics,train
"Instantaneous response of the ionosphere to a sudden commencement of the strong magnetic storm of April 6, 2000","We developed a new technology for global detection of atmospheric disturbances, on the basis of phase measurements of the total electron content (TEC) using an international GPS networks. Temporal dependencies of TEC are obtained for a set of spaced receivers of the GPS network simultaneously for the entire set of visible satellites. These series are subjected to filtering in the selected range of oscillation periods using known algorithms for spatio-temporal analysis of signals. An ""instantaneous"" ionospheric response to the sudden commencement of a strong magnetic storm of April 6, 2000 was detected. On the dayside of the Earth the largest value of the net response amplitude was found to be of order 0.8*10^16 m^-2 (1--2 % of the background TEC value), and the delay with respect to the SC in mid-latitudes was about 200 s. In higher latitudes the delay goes as long as 15 min. On the nightside these values are 0.2*10^16 m^-2 and 30 min, respectively. The velocity of the traveling disturbance from the middle to high latitudes on the dayside as well as from the dayside to the nightside was about 10-20 km/s.","EmTeX-386, 3 pages, 3 figures","E. L. Afraimovich, E. A. Kosogorov, L. A. Leonovich, O. S. Lesyuta, I. I. Ushakov",physics,train
Ludwig Boltzmann -- A Pioneer of Modern Physics,"In two respects Ludwig Boltzmann was a pioneer of quantum mechanics. First because in his statistical interpretation of the second law of thermodynamics he introduced the theory of probability into a fundamental law of physics and thus broke with the classical prejudice, that fundamental laws have to be strictly deterministic. Even Max Planck had not been ready to accept Boltzmann's statistical methods until 1900. With Boltzmann's pioneering work the probabilistic interpretation of quantum mechanics had already a precedent. In fact in a paper in 1897 Boltzmann had already suggested to Planck to use his statistical methods for the treatment of black body radiation. The second pioneering step towards quantum mechanics was Boltzmann's introduction of discrete energy levels. Boltzmann used this method already in his 1872 paper on the H-theorem. One may ask whether Boltzmann considered this procedure only as a mathematical device or whether he attributed physical significance to it. In this connection Ostwald reports that when he and Planck tried to convince Boltzmann of the superiority of purely thermodynamic methods over atomism at the Halle Conference in 1891 Boltzmann suddenly said: ``I see no reason why energy shouldn't also be regarded as divided atomically.'' Finally I would like to mention, that Boltzmann in his lectures on Natural Philosophy in 1903 already anticipated the equal treatment of space coordinates and time introduced in the theory of special relativity. Furthermore in the lectures by Boltzmann and his successor Fritz Hasen\""ohrl in Vienna the students learned already about noneuclidean geometry, so that they could immediately start to work when Einstein's general theory of relativity had been formulated.","5 pages, Latex",D. Flamm,physics,train
Historical Note on the Relativistic Theories of Electromagnetism,"Quantum electrodynamics is the well-accepted theory. However, we feel it is useful to look at formalisms that provide alternative ways to describe light, because in the recent years the development of quantum field theories based primarily on the gauge principle has encountered considerable difficulties. There is a wide variety of generalized theories and they are characterized mainly by the introduction of additional parameters and/or longitudinal modes of electromagnetism. The Majorana-Oppenheimer form of electrodynamics, the Sachs' theory of Elementary Matter, the analysis of the action-at-a-distance concept, presented recently by Chubykalo and Smirnov-Rueda, and the analysis of the claimed `longitudinality' of the antisymmetric tensor field after quantization are reviewed in this essay. We also list recent advances in the Weinberg 2(2J+1) formalism (which is built on First Principles) and in the Majorana theory of neutral particles. These may serve as starting points for constructing a quantum theory of light.","PDF file, 20pp",Valeri V. Dvoeglazov,physics,val
History and outlook of statistical physics,"This paper gives a short review of the history of statistical physics starting from D. Bernoulli's kinetic theory of gases in the 18th century until the recent new developments in nonequilibrium kinetic theory in the last decades of this century. The most important contributions of the great physicists Clausius, Maxwell and Boltzmann are sketched. It is shown how the reversibility and the recurrence paradox are resolved within Boltzmann's statistical interpretation of the second law of thermodynamics. An approach to classical and quantum statistical mechanics is outlined. Finally the progress in nonequilibrium kinetic theory in the second half of this century is sketched starting from the work of N.N. Bogolyubov in 1946 up to the progress made recently in understanding the diffusion processes in dense fluids using computer simulations and analytical methods.","12 pages, Latex",D. Flamm,physics,val
When an experiment is crucial?,"Although we accept that Physics is, as a last resort, an experimental science, the relationship between theory and experiment is far away from being trivial. Any experiment is always explained within a determinate theoretical context and, at the same time, an experiment can give suggestions for theories or even can bring new theoretical challenges. Thus, we cannot say without ambiguity when an experiment is a crucial one.","20 pages, latex, no figures, in portugues",V. Pleitez,physics,train
"The ""fingers"" of the physics","The passage of particles through matter is one of the principal ways to investigate nature. In this article, we would like to outline the most important stages in the development of the theory about the stopping power.","14 pages, no figures. Accepted for publication on the Annales de la
  Fondation Luis de Broglie",Luigi Foschini,physics,val
Short range gravitational fields: Rise and fall of the fifth force,"During the 80's, some experiments and the repetitions of old ones, lead to the hypothesis of a fifth force. Nevertheless, a more accurate research was not able to confirm this hypothesis. This article wants to go over again the most important steps of the event.","12 pages, no figures",Luigi Foschini,physics,train
"Catalog of the scientific manuscripts left by Ettore Majorana (with a Recollection of E.Majorana, sixty years after his disappearance)","Ettore Majorana, perhaps the greatest Italian theoretical physicist of this century (Enrico Fermi compared him to Galilei and Newton), disappeared misteriously from Naples in 1938, when he was 31. In the first part of this work we outline his scientific personality (on the basis of letters, documents, testimonies collected by us in about twenty years) and the significance of some parts of his publications. In the second part of this paper we set forth some brief information about the unpublished scientific manuscripts left by E.Majorana and known to us till this moment (most of which are deposited at the ""Domus Galilaeana"" in Pisa, Italy), and present a preliminary Catalogue of them prepared in collaboration with M.Baldo and R.Mignani. [The present material is mainly taken from our book ""Il Caso Majorana: Epistolario, Documenti, Testimonianze"" (Mondadori, Milan, 1987,1991; Di Renzo, Rome, 2000-2008): We address to such a book (c/o www.direnzo.it, ""Arcobaleno"" series) all the readers interested in more and deeper information; as well as, for more technical topics, to the subsequent volumes reproducing e.g. part of the scientific manuscripts left unpublished by Ettore Majorana: see, for instance, the e-print arXiv:0709.1183v1[physics.hist-ph].]","LaTeX file, in Italian; 81 pages (replaced with some more info on
  recent literature and about the existing copyrights). A preliminary version
  of this article appeared in due time in the Journal indicated below",Erasmo Recami,physics,test
Searching for Shakespeare in the Stars,"The question of the authorship of Shakespeare's plays has long been debated. The two leading contenders are W. Shakspere (1564-1616) and Edward de Vere the 13th Earl of Oxford (1550-1604). Here I note that Shakespeare's references to important events and discoveries in astronomy and geophysics in 1572 and 1600, but not to similarly important events of 1604, 1609 and 1610, especially given Shakespeare's frequent references to and knowledge of the physical sciences, might be able to shed some light on the authorship question.",,Eric Lewin Altschuler,physics,val
"Certainty and Uncertainty in the Practice of Science: Electrons, Muons, and Taus","During the past one hundred years three related elementary particles - the electron, the muon, and the tau - were discovered by very different scientific techniques. The author, who received the Wolf Prize and the Nobel Prize for the discovery of the tau, uses this history to discuss certainty and uncertainty in the practice of science. While the emphasis is on the practice of scientific research, the paper also explains for the non-physicist some basic ideas in elementary particle science.","36 pages, 14 figures, to be published in Science at the Turn of the
  Millenium; removal of incorrect equations",M. L. Perl,physics,train
The Road to Stueckelberg's Covariant Perturbation Theory as Illustrated by Successive Treatments of Compton Scattering,We review the history of the road to a manifestly covariant perturbative calculus within quantum electrodynamics from the early semi-classical results of the mid-twenties to the complete formalism of Stueckelberg in 1934. We chose as our case study the calculation of the cross-section of the Compton effect. We analyse Stueckelberg's paper extensively. This is our first contribution to a study of his fundamental contributions to the theoretical physics of twentieth century.,"This paper is a ""working-physicist"" version of a paper to be
  published in Studies in History and Philosophy of Modern Physics","J. Lacki, H. Ruegg, V. Telegdi",physics,test
Characterising a Si(Li) detector element for the SIXA X-ray spectrometer,"The detection efficiency and response function of a Si(Li) detector element for the SIXA spectrometer have been determined in the 500 eV to 5 keV energy range using synchrotron radiation emitted at a bending magnet of the electron storage ring BESSY, which is a primary radiation standard. The agreement between the measured spectrum and the model calculation is better than 2%. PACS: 95.55.Ka; 07.85.Nc; 29.40.Wk; 85.30.De Keywords: Si(Li) detectors, X-ray spectrometers, detector calibration, X-ray response, spectral lineshape","11 pages, 11 PostScript figures, uses elsart.sty, submitted to Nucl.
  Instrum. Meth. A","T. Tikkanen, S. Kraft, F. Scholze, R. Thornagel, G. Ulm",physics,train
The ring imaging Cherenkov detector for the BRAHMS experiment at RHIC,"A ring imaging Cherenkov counter, to be read out by four 100-channel PMTs, is a key element of the BRAHMS experiment. We report here the most recent results obtained tested at the BNL AGS using several radiator gases, including the heavy fluorocarbon C4F10. Ring radii were measured for different particles (pions, muons, and electrons) for momenta ranging from 2 to 12 GeV/c employing pure C4F10 as radiator.",3 pages 3 figures,"R. Debbe, S. Gushue, B. Moskowitz, J. Olness, F. Videbaek",physics,train
Characterisation of low pressure VPE GaAs diodes before and after 24 GeV/c proton irradiation,"GaAs Schottky diode detectors have been fabricated upon Low Pressure Vapour Phase Epitaxial GaAs. The devices were characterised before and after a $1.25 \times 10^{14}$~cm$^{-2}$ 24GeV/c proton fluence. The as fabricated Ti-GaAs barrier height was measured, via two electrical methods, to be $0.81\pm0.005$ and $0.85\pm0.01$~eV and a space charge density of $2.8 \pm 0.2 \times 10^{14}$~cm$^{-3}$ was determined. The current was greater than that expected for an ideal barrier with the excess attributed to generation current from the bulk. The charge collection efficiency, determined from front alpha illumination and 60 keV gamma irradiation, was inexcess of 95% at 50V reverse bias. After irradiation the reverse current, measured for a bias of 200V at 20$^{o}$~C, increased from 90~nA to 1500~nA due to radiation induced generation centres. Deep levels were showed to be present using capacitance techniques. The charge collection of the device determined from front alpha illumination fell to $32\pm5$% at a reverse bias of 200V.","9 pages. 14 postscript figures + 1 postscript preprint logo + 1 LaTeX
  file + 1 style file. Also available at
  http://ppewww.ph.gla.ac.uk/preprints/97/03/","R. L. Bates, C. Da'Via, V. O'Shea, C. Raine, K. M. Smith, R. Adams",physics,train
The effects of radiation on Gallium Arsenide radiation detectors,"Semi-insulating, undoped, Liquid Encapsulated Czochralski (SI-U LEC) GaAs detectors have been irradiated with 1MeV neutrons, 24GeV/c protons, and 300MeV/c pions. The maximum fluences used were 6, 3, and 1.8~10$^{14}$ particles/cm$^{2}$ respectively. For all three types of irradiation the charge collection efficiencies (cce) of the detector are reduced due to the reduction in the electron and hole mean free paths. Pion and proton irradiations produce a greater reduction in cce than neutron irradiation with the pions having the greatest effect. The effect of annealing the detectors at room temperature, at 200$^{o}$C and at 450$^{o}$C with a flash lamp have been shown to reduce the leakage current and increase the cce of the irradiated detectors. The flash-lamp anneal produced the greatest increase in the cce from 26% to 70% by increasing the mean free path of the electrons. Two indium-doped samples were irradiated with 24GeV/c protons and demonstrated no improvement over SI U GaAs with respect to post-irradiation cce.","12 pages. 10 postscript figures + 1 postscript preprint logo + 1
  LaTeX file + 1 style file. Also available at
  http://ppewww.ph.gla.ac.uk/preprints/97/04/","R. L. Bates, C. Da'Via, S. D'Auria, V. O'Shea, C. Raine, K. M. Smith",physics,train
Recent results on GaAs detectors - 137,The present understanding of the charge collection in GaAs detectors with respect to the materials used and its processing are discussed. The radiation induced degradation of the charge collection efficiency and the leakage current of the detectors are summarised. The status of strip and pixel detectors for the ATLAS experiment are reported along with the latest results from GaAs X-ray detectors for non-high energy physics applications.,"7 pages. 4 postscript figures + 1 postscript preprint logo + 1 LaTeX
  file + 1 style file. Also available at
  http://ppewww.ph.gla.ac.uk/preprints/97/05/","R. L. Bates, M. Campbell, C. Da'Via, S. D'Auria, V. O'Shea, C. Raine, K. M. Smith",physics,val
An optical readout for a fibre tracker,"The performance of 16 and 64 channel photomultipliers coupled to scintillating fibres has been tested. The devices are sensitive to single photoelectrons, show little gain losses for magnetic fields up to 100 Gauss and have moderate optical cross-talk. The maximum channel to channel gain variations reach a factor two for the 16 channel version and a factor of four for the 64 channel PM. The measurements and simulations indicate that the photomultipliers are well suited for the light detection in fibre trackers.","11 pages, 9 pictures","M. Enkelmann, U. Werthenbach, G. Zech, T. Zeuner",physics,train
The GRAAL high resolution BGO calorimeter and its energy calibration and monitoring system,We describe the electromagnetic calorimeter built for the GRAAL apparatus at the ESRF. Its monitoring system is presented in detail. Results from tests and the performance obtained during the first GRAAL experiments are given. The energy calibration accuracy and stability reached is a small fraction of the intrinsic detector resolution.,"19 pages, 14 figures, submitted to Nuclear Instruments and Methods","F. Ghio, B. Girolami, M. Capogni, L. Casano, L. Ciciani, A. D'Angelo, R. Di Salvo, L. Hu, D. Moricciani, L. Nicoletti, G. Nobili, C. Schaerf, P. Levi Sandri, M. Castoldi, A. Zucchiatti, V. Bellini",physics,train
Radiation Induced Damage in GaAs Particle Detectors,The motivation for investigating the use of GaAs as a material for detecting particles in experiments for High Energy Physics (HEP) arose from its perceived resistance to radiation damage. This is a vital requirement for detector materials that are to be used in experiments at future accelerators where the radiation environments would exclude all but the most radiation resistant of detector types.,"5 pages. PS file only - original in WORD Also available at
  http://ppewww.ph.gla.ac.uk/preprints/97/06/","R. L. Bates, C. Da'Via, V. O'Shea, A. Pickford, C. Raine, K. M. Smith",physics,train
Preliminary Results for LP VPE X-Ray Detectors,"Thick epitaxial layers have been grown using Low Pressure Vapour Phase Epitaxy techniques with low free carrier concentrations . This type of material is attractive as a medium for X-ray detection, because of its high conversion efficiency for X-rays in the medically interesting energy range.","4 pages. PS file only - original in WORD. Also available at
  http://ppewww.ph.gla.ac.uk/preprints/97/07/","R. Adams, R. Bates, C. Da Via, N. P. Johnson, V. O'Shea, A. Pickford, C. Raine, K. Smith",physics,val
AC-coupled GaAs microstrip detectors with a new type of integrated bias resistors,"Full size single-sided GaAs microstrip detectors with integrated coupling capacitors and bias resistors have been fabricated on 3'' substrate wafers. PECVD deposited SiO_2 and SiO_2/Si_3N_4 layers were used to provide coupling capacitaces of 32.5 pF/cm and 61.6 pF/cm, respectively. The resistors are made of sputtered CERMET using simple lift of technique. The sheet resistivity of 78 kOhm/sq. and the thermal coefficient of resistance of less than 4x10^-3 / degree C satisfy the demands of small area biasing resistors, working on a wide temperature range.","20 pages, 9 figures, to be published in NIM A","R. Irsigler, R. Geppert, R. Goeppert, M. Hornung, J. Ludwig, M. Rogalla, K. Runge, Th. Schmid, A. Soldner-Rembold, M. Webel, C. Weber",physics,train
A Method to Determine the In-Air Spatial Spread of Clinical Electron Beams,"We propose and analyze in detail a method to measure the in-air spatial spread parameter of clinical electron beams. Measurements are performed at the center of the beam and below the adjustable collimators sited in asymmetrical configuration in order to avoid the distortions due to the presence of the applicator. The main advantage of our procedure lies in the fact that the dose profiles are fitted by means of a function which includes, additionally to the Gaussian step usually considered, a background which takes care of the dose produced by different mechanisms that the Gaussian model does not account for. As a result, the spatial spread is obtained directly from the fitting procedure and the accuracy permits a good determination of the angular spread. The way the analysis is done is alternative to that followed by the usual methods based on the evaluation of the penumbra width. Besides, the spatial spread found shows the quadratic-cubic dependence with the distance to the source predicted by the Fermi-Eyges theory. However, the corresponding values obtained for the scattering power are differing from those quoted by ICRU nr. 35 by a factor ~2 or larger, what requires of a more detailed investigation.","11 pages, 5 Postscript figures, to be published in Medical Physics","M. Vilches, J. C. Zapata, D. Guirado, D. Fernández, D. Burgos, A. M. Lallena",physics,train
Assessing the risk from the depleted uranium weapons used in Operation Allied Force,"The conflict in Yugoslavia has been a source of great concern due to the radiological and toxic hazard posed by the alleged presence of depleted uranium in NATO weapons. In the present study some worst-case scenaria are assumed in order to assess the risk for Yugoslavia and its neighboring countries . The risk is proved to be negligible for the neighboring countries while for Yugoslavia itself evidence is given that any increase in total long-term cancer mortality will be so low that it will remain undetected. Local radioactive hotspots such as DU weapons fragments and abandoned battle tanks, fortified or contaminated with DU, constitute a post-war hazard which is not studied in this article.",All Comments are Welcome,Theodore E. Liolios,physics,train
"The RR interval spectrum, the ECG signal and aliasing","A reliable spectral analysis requires sampling rate at least twice as large as the frequency bound, otherwise the analysis will be unreliable and plagued with aliasing distortions. The RR samplings do not satisfy the above requirements and therefore their spectral analysis might be unreliable. In order to demonstrate the feasibility of aliasing in RR spectral analysis, we have done an experiment which have shown clearly how the aliasing was developed. In the experiments, one of us (A.G) had kept his high breathing rate constant with the aid of metronome for more than 5 minutes. The breathing rate was larger than one-half the heart rate. Very accurate results were obtained and the resulting aliasing well understood. To our best knowledge this is the first controlled experiment of this kind coducted on humans. We compared the RR spectral analysis with the spectrum of the ECG signals from which the RR intervals were extracted. In the significant for RR analysis frequencies (below one-half Hertz) significant differences were observed. In conclusion we recommend to study the spectral analysis of the ECG signal in the free of aliasing frequency range.","27 pages, 12 figures","A. Gersten, O. Gersten, A. Ronen, Y. Cassuto",physics,train
Generalized Optimal Current Patterns and Electrical Safety in EIT,"There are a number of constraints which limit the current and voltages which can be applied on a multiple drive electrical imaging system. One obvious constraint is to limit the maximum Ohmic power dissipated in the body. Current patterns optimising distinguishability with respect to this constraint are singular functions of the difference of transconductance matrices with respect to the power norm. (the optimal currents of Isaacson). If one constrains the total current ($L^1$ norm) the optimal patterns are pair drives. On the other hand if one constrains the maximum current on each drive electrode (an $L^\infty$ norm), the optimal patterns have each drive channel set to the maximum source or sink current value. In this paper we consider appropriate safety constraints and discuss how to find the optimal current patterns with those constraints.","paper for Conference on Biomedical Applications of Electrical
  Impedance Tomography University College London, April 5 - 7, 2000 Revised
  version, some small changes as well as typos corrected","William R. B. Lionheart, Jari Kaipio, Christopher N. McLeod",physics,train
Military use of depleted uranium: assessment of prolonged population exposure,"This work is an exposure assessment for a population living in an area contaminated by use of depleted uranium (DU) weapons. RESRAD 5.91 code is used to evaluate the average effective dose delivered from 1, 10, 20 cm depths of contaminated soil, in a residential farmer scenario. Critical pathway and group are identified in soil inhalation or ingestion and children playing with the soil, respectively. From available information on DU released on targeted sites, both critical and average exposure can leave to toxicological hazards; annual dose limit for population can be exceeded on short-term period (years) for soil inhalation. As a consequence, in targeted sites cleaning up must be planned on the basis of measured concentration, when available, while special cautions have to be adopted altogether to reduce unaware exposures, taking into account the amount of the avertable dose.","13 pages, Latex","C. Giannardi, D. Dominici",physics,train
The Uncertainty Relationship In Magnetic Resonance Imaging (MRI),The uncertainty relationship in MRI is shown. The result of uncertainty relationship is compared with other factors influencing the resolution of MRI. Our estimations show that the uncertainty relationship is of no significance in practice.,"4 pages, no figure","Huagang Yan, Zhixiang Liu",physics,test
A comparison of delayed radiobiological effects of depleted-uranium munitions versus fourth-generation nuclear weapons,"It is shown that the radiological burden due to the battlefield use of circa 400 tons of depleted-uranium munitions in Iraq (and of about 40 tons in Yugoslavia) is comparable to that arising from the hypothetical battle-field use of more than 600 kt (respectively 60 kt) of high-explosive equivalent pure-fusion fourth-generation nuclear weapons. Despite the limited knowledge openly available on existing and future nuclear weapons, there is sufficient published information on their physical principles and radiological effects to make such a comparison. In fact, it is shown that this comparison can be made with very simple and convincing arguments so that the main technical conclusions of the paper are undisputable -- although it would be worthwhile to supplement the hand calculations presented in the paper by more detailed computer simulations in order to consolidate the conclusions and refute any possible objections.","To appear in the Proceedings of the 4th Int. Conf. of the Yugoslav
  Nuclear Society, Belgrade, Sep.30 - Oct.4, 2002, 14 pages, 2 tables. Version
  2: Reference [9] updated","Andre Gsponer, Jean-Pierre Hurni, Bruno Vitale",physics,train
Non-linear quantization for arbitrary distributions and applications to Medical Image Processing,"We report the development of a scalar quantization approach that helps build tables of decision and reconstruction levels for any probability density function (pdf). Several example pdf's are used for illustration: Uniform, Gaussian, Laplace, one-sided Rayleigh, and Gamma (One sided and double-sided symmetrical). The main applications of the methodology are principally aimed at Multiresolution Image compression where generally the Stretched Exponential pdf is encountered. Specialising to this important case, we perform quantization and information entropy calculations from selected medical MRI (Magnetic Resonance Imaging) pictures of the human brain. The image histograms are fitted to a Stretched exponential model and the corresponding entropies are compared.",10 tables and 9 figures,C. Tannous,physics,val
Electron capture decay of indium-111 human carbonic anhydrase I: A time differential K X ray coincidence perturbed angular correlation study,"The relaxation effects in the perturbed angular correlation spectra of indium-111 human carbonic anhydrase I (HCA I) are the result of chemical transmutation and/or the complex Auger cascades that follow the electron capture decay of indium-111. Time differential K X ray coincidence perturbed angular correlation (PAC) spectroscopy shows that these relaxation effects are independent of the Auger cascade intensity. This suggests that chemical transmutation is responsible for the relaxation effects, and that bond breaking and damage product formation around the decay site resulting from localized energy deposition by Auger and Coster-Kronig electrons probably occur in the microsecond time regime. Numerical simulations of chemical transmutation relaxation effects in the time differential PAC spectrum of indium-111 HCA I are also presented.","Six pages, 3 vector Postscript figures, REVTeX 4 format. The original
  version is on pages 106-120 in Biophysical Aspects of Auger Processes, AAPM
  Symposium Proceedings No. 8, edited by R. W. Howell, V. R. Narra, K. S. R.
  Sastry, and D. V. Rao, AIP, Woodbury, New York, 1992. Figures 2 and 3 of this
  E-print version are much easier to interpret because they have a ten-fold
  expanded vertical axis. Over a decade of advances in nuclear technologies
  make much higher precision experiments feasible today",Christopher Haydock,physics,train
"GPCALMA, a mammographic CAD in a GRID connection","Purpose of this work is the development of an automatic system which could be useful for radiologists in the investigation of breast cancer. A breast neoplasia is often marked by the presence of microcalcifications and massive lesions in the mammogram: hence the need for tools able to recognize such lesions at an early stage. GPCALMA (Grid Platform Computer Assisted Library for MAmmography), a collaboration among italian physicists and radiologists, has built a large distributed database of digitized mammographic images (at this moment about 5500 images corresponding to 1650 patients). This collaboration has developed a CAD (Computer Aided Detection) system which, installed in an integrated station, can also be used for digitization, as archive and to perform statistical analysis. With a GRID configuration it would be possible for the clinicians tele- and co-working in new and innovative groupings ('virtual organisations') and, using the whole database, by the GPCALMA tools several analysis can be performed. Furthermore the GPCALMA system allows to be abreast of the CAD technical progressing into several hospital locations always with remote working by GRID connection. We report in this work the results obtained by the GPCALMA CAD software implemented with a GRID connection.","6 pages, 4 figures, to appear in CARS 2003 Proceedings, Computer
  Assisted Radiology and Surgery 17th International Congress and Exhibition,
  London, June 25-28, 2003","U. Bottigli, P. G. Cerello, P. Delogu, M. E. Fantacci, F. Fauci, B. Golosio, A. Lauria, E. Lopez Torres, R. Magro, G. L. Masala, P. Oliva, R. Palmiero, G. Raso, A. Retico, S. Stumbo, S. Tangaro",physics,train
Numerical Study on Space-Time Pulse Compression,"A numerical study of the properties of Gaussian pulses propagating in planar waveguide under the combined effect of positive Kerr-type nonlinearity, diffraction in planar waveguides and anomalous or normal dispersion, is presented. It is demonstrated how the relative strength of dispersion and diffraction, the strength of nonlinearity and the initial spatial and temporal pulse chirps effect on the parameters of pulse compression, such as the maximal compression factor and the distance to the point of maximal compression.","19 pages, LaTeX, 7 Postscript figures. To be published in Optical and
  Quantum Electronics",M. E. Pietrzyk,physics,val
Power Switching in Hybrid Coherent Couplers,"We report on a theoretical and numerical investigation of the switching of power in new hybrid models of nonlinear coherent couplers consisting of optical slab waveguides with various orders of nonlinearity. The first model consists of two guides with second-order instead of the usual third-order susceptibilities as typified by the Jensen coupler. This second-order system is shown to have a power self-trapping transition at a critical power greater than the third-order susceptibility coupler. Next, we consider a mixed coupler composed of a second-order guide coupled to a third-order guide and show that, although it does not display a rigorous self-trapping transition, for a particular choice of parameters it does show a fairly abrupt trapping of power at a lower power than in the third-order coupler. By coupling this mixed nonlinear pair to a third, purely linear guide, the power trapping can be brought to even lower levels and in this way a satisfactory switching profile can be achieved at less than one sixth the input power needed in the Jensen coupler.","Latex source,17 pages, 5 figures","W. D. Deering, M. I. Molina",physics,train
Stokes Parameters as a Minkowskian Four-vector,"It is noted that the Jones-matrix formalism for polarization optics is a six-parameter two-by-two representation of the Lorentz group. It is shown that the four independent Stokes parameters form a Minkowskian four-vector, just like the energy-momentum four-vector in special relativity. The optical filters are represented by four-by-four Lorentz-transformation matrices. This four-by-four formalism can deal with partial coherence described by the Stokes parameters. A four-by-four matrix formulation is given for decoherence effects on the Stokes parameters, and a possible experiment is proposed. It is shown also that this Lorentz-group formalism leads to optical filters with a symmetry property corresponding to that of two-dimensional Euclidean transformations.","RevTeX, 22 pages, no figures, submitted to Phys. Rev. E","D. Han, Y. S. Kim, Marilyn E. Noz",physics,train
A Numerical Study of Absorption by Multilayered Biperiodic Structures,"We study the electromagnetic scattering by multilayered biperiodic aggregates of dielectric layers and gratings of conducting plates. We show that the characteristic lengths of such structures provide a good control of absorption bands. The influence of the physical parameters of the problem (sizes, impedances) is discussed.","10 pages, revtex, osa aps sty, 13 eps figures","G. Berginc, C. Bourrely, C. Ordenovic, B. Torresani",physics,train
Propagation of a short laser pulse in a plasma,"The propagation of an electromagnetic pulse in a plasma is studied for pulse durations that are comparable to the plasma period. When the carrier frequency of the incident pulse is much higher than the plasma frequency, the pulse propagates without distortion at its group speed. When the carrier frequency is comparable to the plasma frequency, the pulse is distorted and leaves behind it an electromagnetic wake.","6 pages, 5 figures, REVTeX. To be published in Physical Review E,
  vol. 56, December 1, 1997","Borge Nodland, C. J. McKinstrie",physics,train
Space-Time Approach to Scattering from Many Body Systems,"We present scattering from many body systems in a new light. In place of the usual van Hove treatment, (applicable to a wide range of scattering processes using both photons and massive particles) based on plane waves, we calculate the scattering amplitude as a space-time integral over the scattering sample for an incident wave characterized by its correlation function which results from the shaping of the wave field by the apparatus. Instrument resolution effects - seen as due to the loss of correlation caused by the path differences in the different arms of the instrument are automatically included and analytic forms of the resolution function for different instruments are obtained. The intersection of the moving correlation volumes (those regions where the correlation functions are significant) associated with the different elements of the apparatus determines the maximum correlation lengths (times) that can be observed in a sample, and hence, the momentum (energy) resolution of the measurement. This geometrical picture of moving correlation volumes derived by our technique shows how the interaction of the scatterer with the wave field shaped by the apparatus proceeds in space and time. Matching of the correlation volumes so as to maximize the intersection region yields a transparent, graphical method of instrument design. PACS: 03.65.Nk, 3.80 +r, 03.75, 61.12.B",Latex document with 6 figs,"R. Gaehler, J. Felber, F. Mezei, R. Golub",physics,train
"On Localized ""X-shaped"" Superluminal Solutions to Maxwell Equations","In this paper we extend for the case of Maxwell equations the ""X-shaped"" solutions previously found in the case of scalar (e.g., acoustic) wave equations. Such solutions are localized in theory, i.e., diffraction-free and particle-like (wavelets), in that they maintain their shape as they propagate. In the electromagnetic case they are particularly interesting, since they are expected to be Superluminal. We address also the problem of their practical, approximate production by finite (dynamic) radiators. Finally, we discuss the appearance of the X-shaped solutions from the purely geometric point of view of the Special Relativity theory. [PACS nos.: 03.50.De; 1.20.Jb; 03.30.+p; 03.40.Kf; 14.80.-j. Keywords: X-shaped waves; localized solutions to Maxwell equations; Superluminal waves; Bessel beams; Limited-dispersion beams; electromagnetic wavelets; Special Relativity; Extended Relativity].","Replaced in order to add the missing Figures. Paper of 33 pages with
  6 Figures, originally submitted for pub. on March 1, 1996 (nineteen
  ninety-six), and appeared in print two years later:",Erasmo Recami,physics,train
Scattering Integral Equations for Diffusive Waves. Detection of Objects Buried in Diffusive Media in the Presence of Interfaces,This paper has been withdrawn by the authors until some changes are made.,"17 RevTex pages, 12 PS figures. This paper has been withdrawn by the
  authors until some changes are made","J. Ripoll, M. Nieto-Vesperinas",physics,train
Thirring Solitons in the presence of dispersion,"The effect of dispersion or diffraction on zero-velocity solitons is studied for the generalized massive Thirring model describing a nonlinear optical fiber with grating or parallel-coupled planar waveguides with misaligned axes. The Thirring solitons existing at zero dispersion/diffraction are shown numerically to be separated by a finite gap from three isolated soliton branches. Inside the gap, there is an infinity of multi-soliton branches. Thus, the Thirring solitons are structurally unstable. In another parameter region (far from the Thirring limit), solitons exist everywhere.","12 pages, Latex. To appear in Phys. Rev. Lett","Alan R Champneys, Boris A Malomed, Mark J friedman",physics,train
Giant phase-conjugate reflection with a normal mirror in front of an optical phase-conjugator,"We theoretically study reflection of light by a phase-conjugating mirror preceded by a partially reflecting normal mirror. The presence of a suitably chosen normal mirror in front of the phase conjugator is found to greatly enhance the total phase-conjugate reflected power, even up to an order of magnitude. Required conditions are that the phase-conjugating mirror itself amplifies upon reflection and that constructive interference of light in the region between the mirrors takes place. We show that the phase-conjugate reflected power then exhibits a maximum as a function of the transmittance of the normal mirror.","8 pages, 3 figures, RevTex","M. Blaauboer, D. Lenstra, A. Lodder",physics,train
Resistive Magnetohydrodynamic Equilibria in a Torus,"It was recently demonstrated that static, resistive, magnetohydrodynamic equilibria, in the presence of spatially-uniform electrical conductivity, do not exist in a torus under a standard set of assumed symmetries and boundary conditions. The difficulty, which goes away in the ``periodic straight cylinder approximation,'' is associated with the necessarily non-vanishing character of the curl of the Lorentz force, j x B. Here, we ask if there exists a spatial profile of electrical conductivity that permits the existence of zero-flow, axisymmetric r esistive equilibria in a torus, and answer the question in the affirmative. However, the physical properties of the conductivity profile are unusual (the conductivity cannot be constant on a magnetic surface, for example) and whether such equilibria are to be considered physically possible remains an open question.","17 pages, 4 figures","David Montgomery, Jason W. Bates, H. Ralph Lewis",physics,test
Toroidal Vortices in Resistive Magnetohydrodynamic Equilibria,"Resistive steady states in toroidal magnetohydrodynamics (MHD), where Ohm's law must be taken into account, differ considerably from ideal ones. Only for special (and probably unphysical) resistivity profiles can the Lorentz force, in the static force-balance equation, be expressed as the gradient of a scalar and thus cancel the gradient of a scalar pressure. In general, the Lorentz force has a curl directed so as to generate toroidal vorticity. Here, we calculate, for a collisional, highly viscous magnetofluid, the flows that are required for an axisymmetric toroidal steady state, assuming uniform scalar resistivity and viscosity. The flows originate from paired toroidal vortices (in what might be called a ``double smoke ring'' configuration), and are thought likely to be ubiquitous in the interior of toroidally driven magnetofluids of this type. The existence of such vortices is conjectured to characterize magnetofluids beyond the high-viscosity limit in which they are readily calculable.","17 pages, 4 figures","David Montgomery, Jason W. Bates, Shuojun Li",physics,train
Nonlinear Two-dimensional potential plasma wake waves,"The condition for potential description of the wake waves,generated by flat or cylindrical driving electron bunch in cold plasma is derived. The two-dimensional nonlinear equation for potential valid for small values of that is obtained and solved by the separation of variables. Solutions in the form of cnoidal waves,existing behind the moving bunch at small values of vertical coordinate,are obtained.In particular,at some boundary conditions,corresponding to blow-out regime in the underdense plasma,the solution represents by a solitary nonlinear wave. Approximate solution is also obtained using the method of multiple sacales. The indications are obtained that the dependense of the amplitudes on longitudinal coordinate determines essentially,even in the first approximation,by driving bunch charge distribution.The wake wave amplitude can increase at some conditions along the longitudinal distance from the rear part of the bunch.","18 pages,latex",A. Amatuni,physics,train
Quantum Molecular Dynamics of Partially Ionized Plasmas,"We study a partially ionized hydrogen plasma by means of quantum molecular dynamics, which is based on wave packets. We introduce a new model which distinguishes between free and bound electrons. The free electrons are modelled as Gaussian wave packets with fixed width. For the bound states the 1s-wave function of the hydrogen atom is assumed. In our simulations we obtain thermodynamic properties in the equilibrium such as the internal energy and the degree of ionization. The degree of ionization is in good agreement with theoretical predictions. The thermodynamic functions agree well with results from quantum statistics for 10000K < T < 40000K.","13 pages, Latex with 5 postscript figures, to be published in Phys.
  Lett. A","W. Ebeling, B. Militzer",physics,train
Current-Voltage Characteristic of a Partially Ionized Plasma in Cylindrical Geometry,"The properties of a partially ionized plasma in a long cylindrical tube subject to a uniform axial electric field are investigated. The plasma is maintained by an external ionizing source balanced by bulk and surface recombinations. Collisions between neutrals, whose density greatly exceeds the density of charged particles, and of neutrals with ions are sufficiently effective for their velocity distribution to be close to a Maxwellian with the same uniform temperature, independent of the external field. The behavior of the plasma is described by a collisional two-fluid scheme with charge neutrality in the interior of the tube. Approximate nonlinear equations for the hydrodynamical moments are obtained from a Boltzmann equation in which electron-neutral, electron-ion and electron-electron collisions are all important. It is found that under certain circumstances the current, and the temperature of the electrons undergo a drastic change, with hysteresis, as the electric field is varied.","TeX file, 20 pages, 4 figures available upon request. email:
  lebowitz@math.rutgers.edu, rokhlenk@math.rutgers.edu","Joel L. Lebowitz, Alexander Rokhlenko",physics,val
Cylindrical ideal magnetohydrodynamic equilibria with incompressible flows,"It is proved that (a) the solutions of the ideal magnetohydrodynamic equation, which describe the equlibrium states of a cylindrical plasma with purely poloidal flow and arbitrary cross sectional shape [G. N. Throumoulopoulos and G. Pantis, Plasma Phys. and Contr. Fusion 38, 1817 (1996)] are also valid for incompressible equlibrium flows with the axial velocity component being a free surface quantity and (b) for the case of isothermal incompressible equilibria the magnetic surfaces have necessarily circular cross section.","7 pages, latex, no figures","G. N. Throumoulopoulos, H. Tasso",physics,train
Kinetics of a Model Weakly Ionized Plasma in the Presence of Multiple Equilibria,"We study, globaly in time, the velocity distribution $f(v,t)$ of a spatially homogeneous system that models a system of electrons in a weakly ionized plasma, subjected to a constant external electric field $E$. The density $f$ satisfies a Boltzmann type kinetic equation containing a full nonlinear electron-electron collision term as well as linear terms representing collisions with reservoir particles having a specified Maxwellian distribution. We show that when the constant in front of the nonlinear collision kernel, thought of as a scaling parameter, is sufficiently strong, then the $L^1$ distance between $f$ and a certain time dependent Maxwellian stays small uniformly in $t$. Moreover, the mean and variance of this time dependent Maxwellian satisfy a coupled set of nonlinear ODE's that constitute the ``hydrodynamical'' equations for this kinetic system. This remain true even when these ODE's have non-unique equilibria, thus proving the existence of multiple stabe stationary solutions for the full kinetic model. Our approach relies on scale independent estimates for the kinetic equation, and entropy production estimates. The novel aspects of this approach may be useful in other problems concerning the relation between the kinetic and hydrodynamic scales globably in time.","30 pages, in TeX, to appear in Archive for Rational Mechanics and
  Analysis: author's email addresses: carlen@math.gatech.ed,
  resposit@hilbert.rutgers.edu, lebowitz@math.rutgers.edu,
  MARRA@axtov1.roma2.infn.it, rokhlenk@math.rutgers.edu","E. Carlen, R. Esposito, J. L. Lebowitz, R. Marra, A. Rokhlenko",physics,train
General dispersion equation for oscillations and waves in non-collisional Maxwellian plasmas,"We propose a new and effective method to find plasma oscillatory and wave modes. It implies searching a pair of poles of two-dimensional (in coordinate $x$ and time $t$) Laplace transform of self-consistent plasma electric field $E(x,t) \to E_{p_1p_2}$, where $p_1 \equiv -i \omega$, $p_2 \equiv i k$ are Laplace transform parameters, that is determining a pair of zeros of the following equation $$\frac1{E_{p_1p_2}} = 0 .$$ This kind of conditional equation for searching double poles of $E_{p_1p_2}$ we call ``general dispersion equation'', so far as it is used to find the pair values ($\omega^{(n)}, k^{(n)}$), $n=1, 2, ...$ . It differs basically from the classic dispersion equation $\epsilon_l(\omega,k) = 0$ (and is not its generalization), where $\epsilon_l$ is longitudinal dielectric susceptibility, its analytical formula being derived according to Landau analytical continuation. In distinction to $\epsilon_l$, which is completely plasma characteristic, the function $E_{p_1p_2}$ is defined by initial and boundary conditions and allows one to find all the variety of asymptotical plasma modes for each concrete plasma problem. In this paper we demonstrate some possibilities of applying this method to the simplest cases of collisionless ion-electron plasma and to electron plasma with collisions described by a collision-relaxation term $-\nu f^{(1)}$.","8 pages, uses revtex.sty[prb,aps]",V. N. Soshnikov,physics,train
Streamer propagation in magnetic field,The propagation of a streamer near an insulating surface under the influence of a transverse magnetic field is theoretically investigated. In the weak magnetic field limit it is shown that the trajectory of the streamer has a circular form with a radius that is much larger than the cyclotron radius of an electron. The charge distribution within the streamer head is strongly polarized by the Lorentz force exerted perpendicualr to the streamer velocity. A critical magnetic field for the branching of a streamer is estimated. Our results are in good agreement with available experimental data.,"11pages, RevTex, no figures","V. N. Zhuravlev, T. Maniv, I. D. Vagner, P. Wyder",physics,train
Possibility of Microturbulence Diagnostics in a Magnetically Confined Plasma Using Multiple Scattering Effects,The idea of new diagnostics method for the small-scale irregular structures of magnetically confined plasma is suggested in the present paper. The method can be based on measurements of intensity attenuation of the normal sounding waves. Anomalous attenuation arises due to multiple scattering effects investigated earlier for ionospheric radio propagation. It has been shown that multiple scattering regime can realize in a tokamak plasma. Calculations of normal sounding wave anomalous attenuation in a tokamak plasma have been carried out. This quantity is large enough to be registered experimentally.,"7 pages of TEX, 5 figures (pcx). Any comments and suggestions about
  the paper can be mailed to authors: zabotin@iphys.rnd.runnet.ru","E. S. Kovalenko, N. A. Zabotin",physics,train
Book Review of Quantum Field Theory by Lewis H. Ryder,"Book Review of Quantum Field Theory by Lewis H. Ryder. An observation on Ryder's derivation of Dirac equation is made. The review ends as, ""A rare combination of a thorough understanding and appreciation of the essential logical structure of quantum field theory and deep pedagogic skills have intermingled to create a masterpiece on the elementary introduction to quantum field theory in less than five hundred pages... . Without reservations, I give my strongest recommendation to every beginning student of physics to acquire and read Quantum Field Theory by L. H. Ryder.""",Foundations of Physics (in Press),D. V. Ahluwalia,physics,train
Aging Random Walks,"Aging refers to the property of two-time correlation functions to decay very slowly on (at least) two time scales. This phenomenon has gained recent attention due to experimental observations of the history dependent relaxation behavior in amorphous materials (``Glasses'') which pose a challenge to theorist. Aging signals the breaking of time-translational invariance and the violation of the fluctuation dissipation theorem during the relaxation process. But while the origin of aging in disordered media is profound, and the discussion is clad in the language of a well-developed theory, systems as simple as a random walk near a wall can exhibit aging. Such a simple walk serves well to illustrate the phenomenon and some of the physics behind it.","11 pages, REVTEX, 3 postscript figures included",Stefan Boettcher,physics,train
Quantum-Classical System: Simple Harmonic Oscillator,"Problems concerning with application of quantum rules on classical phenomena have been widely studied, for which lifted up the idea about quantization and uncertainty principle. Energy quantization on classical example of simple harmonic oscillator has been reviewed in this paper.","9 pages, no figures, uses LaTeX, a review article",Tri Sulistiono,physics,train
"Book Review: The Quantum Theory of Fields, Vol. I and II by S. Weinberg","Review of the two volume set ""The Quantum Theory of Fields"" by S. Weinberg is presented.",An important note on dark matter and Wigner classes added,D. V. Ahluwalia,physics,val
A Simple Model for Predicting Sprint Race Times Accounting for Energy Loss on the Curve,"The mathematical model of J. Keller for predicting World Record race times, based on a simple differential equation of motion, predicted quite well the records of the day. One of its shortcoming is that it neglects to account for a sprinter's energy loss around a curve, a most important consideration particularly in the 200m--400m. An extension to Keller's work is considered, modeling the aforementioned energy loss as a simple function of the centrifugal force acting on the runner around the curve. Theoretical World Record performances for indoor and outdoor 200m are discussed, and the use of the model at 300m is investigated. Some predictions are made for possible 200m outdoor and indoor times as run by Canadian 100m WR holder Donovan Bailey, based on his 100m final performance at the 1996 Olympic Games in Atlanta.","20pp, latex; submitted to the ""Canadian Journal of Physics""",J. R. Mureika,physics,val
And the Winner Is . . . Predicting the Outcome of the 150m Showdown,"Using the model framework for curve running as described in physics/9704022, the possible outcome of the 150m ""One to One"" showdown between sprinters Donovan Bailey and Michael Johnson are discussed (to be run 01 Jun 1997 at Skydome in Toronto, Ontario, Canada).","7pp, LaTeX; layman-targeted article; related to methods of
  physics/9704022",J. R. Mureika,physics,train
What really are the best 100m performances?,"A quick and fun investigation into the effects of correcting for wind assistance/resistance and drag on 100m sprint performances. Considered are World 100m rankings, as well as Canadian rankings","Layman-targeted paper; submitted to ""Athletics: The Canadian National
  Track and Field Magazine""",J. R. Mureika,physics,val
Testing the Sprint Curve Model using the 150m Bailey-Johnson Showdown,"Recently, a simple model was derived to account for a sprinter's energy loss around a curve, based on previous sprint models for linear races. This paper offers a quick test of the model's precision by comparing split times from Donovan Bailey's 150m ``Challenge of Champions'' race at Skydome on June 1st, 1997. The discrepancy in the track configuration which almost prompted Bailey to drop from the race is also addressed.","8 pages, LaTeX",J. R. Mureika,physics,val
What was the fastest 100m final?,"In a previous article (physics/9705004), the best 100m performances in track and field were determined by accounting for wind effects and atmospheric drag. In this report, I seek to ascertain what was the ""fastest"" 100m final through a statistical analysis of the competitors' times. Considered are the 100 finals from the 1984-1996 Olympic Games, the 1983-1997 World Championships, and the 1996 Grand Prix Final from Lausanne, SWI, in which Frank Fredericks (Namibia) recorded the only sub-9.90s time ever into a head-wind (9.86s, -0.4 m/s).","13 pp, LaTeX. Based on methods outlined in physics/9705004",J. R. Mureika,physics,train
Another Dash into the Record Books (wind: -2.1 m/s),"In the wake of numerous injuries and Donovan Bailey's media-stamped ""sub-par"" 100m victory of 10.03s at the 1997 Canadian Track and Field Championships, a medal hope at the 1997 World Championships seems grim for the Olympic Champion and World Record holder. However, when one considers that the 10.03s was run into a hefty head-wind (-2.1 m/s), a simple correction for this effect can help to restore Canada's faith in their sprint hero -- not to mention rewrite the record books again.","7pp, LaTeX; 2nd in a series, following physics/9705004 and preceeding
  physics/9709017",J. R. Mureika,physics,train
"International Workshop on the Future of Physics and Society, Debrecen, Hungary, 4-6 March 1999, Workshop Summary","The Debrecen workshop was one of a number held in preparation for the UNESCO-ICSU World Conference on Science, which will be held in Budapest, June 1999. A report representing the views of the workshop, prepared for that conference and containing a number of recommended actions, is included with this summary. The workshop affirmed the ongoing importance of physics for its own sake and as part of our culture, as a key element in our increasingly unified science and as an essential contributor to the solution of environmental and energy problems. The problems faced by physics as an activity and as an educational subject were discussed and actions for both society as a whole and the physics community itself were put forward.","LaTeX, 8 pages processed",Raymond S. Mackintosh,physics,train
Golden Section and the Art of Painting,"A statistical study on 565 works of art of different great painters was done and it was calculated the ratio of the 2 sides of a paintings. Assuming that all the painters under discussion enter in a statistics with equal weights it is shown that the average value obtained for the ratio of the sides is 1.34. This value, determined experimentally is significantly different from the value of the Golden Section F=1.618, which is a theoretical ratio, obtained from an abstract, mathematical theory, which supposedly ought to impress on a painting a supreme harmony.","Latex manuscript, 4 pages, 2 eps figures",Agata Olariu,physics,train
Physicists Thriving with Paperless Publishing,"The Stanford Linear Accelerator Center (SLAC) and Deutsches Elektronen Synchrotron (DESY) libraries have been comprehensively cataloguing the High Energy Particle Physics (HEP) literature online since 1974. The core database, SPIRES-HEP, now indexes over 400,000 research articles, with almost 50% linked to fulltext electronic versions (this site now has over 15 000 hits per day). This database motivated the creation of the first site in the United States for the World Wide Web at SLAC. With this database and the invention of the Los Alamos E-print archives in 1991, the HEP community pioneered the trend to ""paperless publishing"" and the trend to paperless access; in other words, the ""virtual library."" We examine the impact this has had both on the way scientists research and on paper-based publishing. The standard of work archived at Los Alamos is very high. 70% of papers are eventually published in journals and another 20% are in conference proceedings. As a service to authors, the SPIRES-HEP collaboration has been ensuring that as much information as possible is included with each bibliographic entry for a paper. Such meta-data can include tables of the experimental data that researchers can easily use to perform their own analyses as well as detailed descriptions of the experiment, citation tracking, and links to full-text documents.","17 pages, Invited talk at the AAAS Meeting, February 2000 in
  Washington, DC",Heath B. O'Connell,physics,val
What is research?,"Doing research is fighting, what any other thing the human being could do? Fight against powers or to get powers, that depends on us. Science can be a revolution or deadlocked idleness. Still waters, without hitting the stones along their history, trend to form bogs.","This article was published in a collection of critical reviews by
  scientists of how physics and astronomy get done: ""Against the Tide"",
  published by Universal Publishers. It is freely available at:
  http://www.archivefreedom.org/tide.htm",Martin Lopez-Corredoira,physics,train
Words for Nobel prizes,We present the statistics of the significant nouns and adjectives of social impact figuring in the nominations of the Nobel prizes in Physics and Chemistry over the period of the awards from 1901 to 2001,5 pages,"J. M. Moran-Mirabal, H. C. Rosu",physics,train
Peer review in context,"Scientific publishing is in a transition between the old paper-bound, static forms and the new electronic media with its interactive, dynamic possibilities. This takes place in the context of imploding library budgets and exploding magazine costs. The scientists as authors, reviewers and editors of scientific journals are exposed to an increased pressure by the their administrations and the public towards quantification, objectification and certification of scientific achievements. The ``publication roulette'' resulting from low-quality editorial procedures often amounts to malign censorship, which not only is experienced as a frustration by the authors, but is also delaying and hampering the progress of science. It also leads to a waste of funds under the cover of pseudo-objectivity and pseudo-legitimacy of financial decisions. Different solutions are outlined and discussed. As concerns scientific publishing, an e-print service should be established, which, in continuation of existing e-servers such as arxiv.org, is operated either directly by the United Nations Educational, Scientific and Cultural Organization, or by an international consortium. In order to become generally accepted by the scientists, certification criteria must be provided, which would make it possible to successfully pursue a scientific career besides the traditional peer reviewed print publications.","22 pages, presented at ODOK '03 in Salzburg, Austria, September
  23-26, 2003 (see http://voeb.uibk.ac.at/odok2003/svozil.pdf for a German
  version), and at the INST conference ""The Unifying Aspects of Cultures"",
  Vienna, November 7-9, 2003",Karl Svozil,physics,train
Depleted-Uranium Weapons: the Whys and Wherefores,"The only military application in which depleted-uranium (DU) alloys out-perform present-day tungsten alloys is long-rod penetration into a main battle-tank's armor. However, this advantage is only on the order of 10%, and it disappears when the comparison is made in terms of actual lethality of complete anti-tank systems instead of laboratory-type steel penetration capability. Therefore, new micro- and nano-engineered tungsten alloys may soon out-perform DU alloys, enabling the production of tungsten munition which will be better than existing uranium munition, and whose overall life-cycle cost will be lower, due to the absence of the problems related to the radioactivity of uranium. The reasons why DU weapons have been introduced and used are analysed from the perspective that their radioactivity must have played an important role in the decision making process. It is found that DU weapons belong to the diffuse category of low-radiological-impact nuclear weapons to which emerging types of low-yield (i.e., fourth generation) nuclear explosives also belong. It is concluded that the battlefield use of DU during the 1991 Gulf War, which broke a 46-year-long taboo against the intentional use or induction of radioactivity in combat, has created a military and legal precedent which has trivialized the combat use of radioactive materials, and therefore made the use of nuclear weapons more probable.","Postface to a book to be published by the Bertrand Russell
  Foundation, Final version with acknowledgments, 33 pages",Andre Gsponer,physics,val
"Compositional analyses of a Reutlingen Bronze Age sword discovered at Giurgiu, Romania","The compositional scheme of a Bronze Age sword, found near the town of Giurgiu in Romania has been determined by the method of particle-induced X-ray emission (PIXE), at the tandem accelerator of the National Institute for Physics and Nuclear Engineering from Bucharest, Magurele, Romania. The results of the analyses and the comparison with the composition of other swords from the same geographic area, the Danubian plane from Bulgaria and Transylvania regions, show that the sword from Giurgiu could be relatively associated with the swords from Bulgaria, having also the same stylistic, temporal and geographical similitude.","12 pages, 2 figures","Agata Olariu, Emilian Alexandrescu, Alexandru Avram, Teodor Badica",physics,test
Monitoring the Digital Divide,"It is increasingly important to support the large numbers of scientists working in remote areas and having low -bandwidth access to the Internet. This will continue to be the case for years to come since there is evidence from PingER performance measurements that the, so-called, digital divide is not decreasing. In this work, we review the collaborative work of The Abdus Salam International Center for Theoretical Physics (ICTP) in Trieste -a leading organization promoting science dissemination in the developing world- and SLAC in Stanford, to monitor by PingER, Universities and Research Institutions all over the developing world following the recent Recommendations of Trieste to help bridge the digital divide. As a result, PingER's deployment now covers the real-time monitoring of worldwide Internet performance and, in particular, West and Central Africa for the first time. We report on theresults from the ICTP sites and quantitatively identify regions with poor performance, identify trends, discuss experiences and future work.","Talk from the 2003 Computing in High Energy and Nuclear Physics
  (CHEP03), La Jolla, Ca, USA, March 2003, 6 pages, PDF","E. Canessa, H. A. Cerdeira, W. Matthews, R. L. Cottrell",physics,train
Effect of the Fast Nuclear Electromagnetic Pulse on the Electric Power Grid Nationwide: A Different View,"This paper primarily considers the potential effects of a single high-altitude nuclear burst on the U.S. power grid. A comparison is made between EMP and natural phenomena such as lightning. This paper concludes that EMP is no more harmful to the power grid than its counterparts in nature. An upper limit of the electric field of the very fast, high-amplitude EMP is derived from first principles. The resulting values are significantly lower than the commonly presented values. Additional calculations show that the ionization produced by a nuclear burst severely attenuates the EMP.","22 pages, 3 figures, 6 tables",Mario Rabinowitz,physics,train
Pick-up ion dynamics at the structured quasi-perpendicular shock,We study the pickup ion dynamics and mechanism of multiple reflection and acceleration at the structured quasi-perpendicular supercritical shock. The motion of the pickup ions in the shock is studied analytically and numerically using the test particle analysis in the model shock front. The analysis shows that slow pickup ions may be accelerated at the shock ramp to high energies. The maximum ion energy is determined by the fine structure of the electro-magnetic field at the shock ramp and decreases when the angle between magnetic field and shock normal decreases. Evolution of pickup ion distribution across the nearly-perpendicular shock and pickup ion spectrum is also studied by direct numerical analysis.,"LaTeX (elsart.cls), packages: times,amsmath,amssymb; 15 pages + 13
  figures (GIF). To appear in Planetary and Space Science.","D. Zilbersher, M. Gedalin",physics,train
The determination of shock ramp width using the noncoplanar magnetic field component,"We determine a simple expression for the ramp width of a collisionless fast shock, based upon the relationship between the noncoplanar and main magnetic field components. By comparing this predicted width with that measured during an observation of a shock, the shock velocity can be determined from a single spacecraft. For a range of low-Mach, low-beta bow shock observations made by the ISEE-1 and -2 spacecraft, ramp widths determined from two-spacecraft comparison and from this noncoplanar component relationship agree within 30%. When two-spacecraft measurements are not available or are inefficient, this technique provides a reasonable estimation of scale size for low-Mach shocks.","6 pages, LaTeX (aguplus + agutex);
  packages:amsmath,times,graphicx,float, psfrag,verbatim; 3 postscript figures
  called by the file; submitted to Geophys. Res. Lett","J. A. Newbury, C. T. Russell, M. Gedalin",physics,test
A New Pleiades Member at the Lithium Substellar Boundary,"We present the discovery of an object in the Pleiades open cluster, named Teide 2, with optical and infrared photometry which place it on the cluster sequence slightly below the expected substellar mass limit. We have obtained low- and high-resolution spectra that allow us to determine its spectral type (M6), radial velocity and rotational broadening; and to detect H$_\alpha$ in emission and Li I 670.8 nm in absorption. All the observed properties strongly support the membership of Teide 2 into the Pleiades. This object has an important role in defining the reappearance of lithium below the substellar limit in the Pleiades. The age of the Pleiades very low-mass members based on their luminosities and absence or presence of lithium is constrained to be in the range 100--120 Myr.","17 pages, 3 figures","E. L. Martin, G. Basri, J. E. Gallegos, R. Rebolo, M. R. Zapatero-Osorio, V. J. S. Bejar",physics,train
UN/ESA Workshops on Basic Space Science: An Update on Their Achievements,"During the second half of the twentieth century, expensive observatories are being erected at La Silla (Chile), Mauna Kea (Hawai), Las Palmas (Canary Island), and Calar Alto (Spain), to name a view. In 1990, at the beginning of The Decade of Discovery in Astronomy and Astrophysics (Bahcall [2]), the UN/ESA Workshops on Basic Space Science initiated the establishment of small astronomical telescope facilities, among them many particularly supported by Japan, in developing countries in Asia and the Pacific (Sri Lanka, Philippines), Latin America and the Caribbean (Colombia, Costa Rica, Honduras, Paraguay), and Western Asia (Egypt, Jordan, Morocco). The annual UN/ESA Workshops continue to pursue an agenda to network these small observatory facilities through similar research and education programmes and at the same time encourage the incorporation of cultural elements predominant in the respective cultures. Cross-cultural integration and multi-lingual scientific cooperation may well be a dominant theme in the new millennium (Pyenson [20]). This trend is supported by the notion that astronomy has deep roots in virtually every human culture, that it helps to understand humanity's place in the vast scale of the Universe, and that it increases the knowledge of humanity about its origins and evolution=2E Two of these Workshops have been organized in Europe (Germany 1996 and France 2000) to strengthen cooperation between developing and industrialized countries.","LaTeX, 10 pages",H. J. Haubold,physics,train
Modeling of Liquid Water on CM Meteorite Parent Bodies and Implications for Amino Acid Racemization,"We have constructed an asteroid model with the intent of tracking the radial and temporal dependence of temperature and composition throughout a 100-km diameter CM-type parent body, with emphasis on constraining the temperature and duration of a liquid water phase. We produce a non-uniform distribution where liquid water persists longest and is hottest in the deepest zones and the regolith never sees conditions appropriate to aqueous alteration. We apply the model predictions of the liquid water characteristics to the evolution of amino acids. IN some regions of the parent body, very little change occurs in the amino acids, but for the majority of the asteroid, complete racemization or even destruction occurs. We attempt to match our thermal model results with CM meteorite observations, but thus far, our model does not produce scenarios that are fully consistent with these observations.",31 pages plus 1 page of color figures; accepted by Icarus,"Barbara A. Cohen, Robert F. Coker",physics,train
Enhanced Phase Space Diffusion due to Chaos in Relativistic Electron- Whistler Mode Wave Particle Interactions in Planetary Magnetospheres,"The chaotic interaction between electrons and whistler mode waves has been shown to provide a mechanism for enhanced diffusion in phase space. Pitch angle diffusion is relevant for the scattering of electrons into the loss cones, thus providing a source for auroral precipitating electrons. A single whistler mode wave propagating parallel to the background magnetic field has resonance with the electrons but the process is not stochastic. The presence of a second, oppositely directed whistler wave has been shown previously to introduce stochasticity into the system, thus enhancing phase space diffusion. Here we generalise previous work to include relativistic effects. The full relativistic Lorentz equations are solved numerically to permit application to a more extensive parameter space. We consider parameters scaled to intrinsic planetary magnetospheres, for electron populations with 'pancake' velocity distributions i.e. large anisotropies in velocity space. We show that the diffusion is rapid, occuring on timescales of the order of tens of electron gyroperiods, and is strongly sensitive to the wave amplitude, the wave frequency and the perpendicular velocity. Using Voyager 1 data we give an estimate of the whistler wave amplitude in the Io torus at Jupiter and show that the two whistler mechanism produces pitch angle diffusion of up to 10 degrees from an initial pancake distribution, on millisecond timescales.","14 pages, latex, 5 figures, submittes to PSS","W J Wykes, S. C. Chapman, G. Rowlands",physics,train
3-D extent of the main ionospheric trough--a case study,"The EISCAT radar system has been used for the first time in a four-beam meridional mode. The FAST satellite and ALIS imaging system is used in conjunction to support the radar data, which was used to identify a main ionospheric trough. With this large latitude coverage the trough was passed in 2.5 hours period. Its 3-dimensional structure is investigated and discussed. It is found that the shape is curved along the auroral oval, and that the trough is wider closer to the midnight sector. The position of the trough coincide rather well with various statistical models and this trough is found to be a typical one.","6 pages, 2 figures, LaTeX. Minor text updates","M. Hedin, I. Häggström, A. Pellinen-Wannberg, L. Andersson, U. Brändström, B. Gustavsson, Å. Steen, A. Westman, G. Wannberg, T. v Eyken, T. Aso, C. Cattell, C. W. Carlson, D. Klumpar",physics,train
Auroral field-aligned currents by incoherent scatter plasma line observations in the E region,"The aim of the Swedish-Japanese EISCAT campaign in February 1999 was to measure the ionospheric parameters inside and outside the auroral arcs. The ion line radar experiment was optimised to probe the E-region and lower F-region with as high a speed as possible. Two extra channels were used for the plasma line measurements covering the same altitudes, giving a total of 3 upshifted and 3 downshifted frequency bands of 25 kHz each. For most of the time the shifted channels were tuned to 3 (both), 4 (up), 5.5 (down) and 6.5 (both) MHz. Weak signals are seen whenever the radar is probing the diffuse aurora, corresponding to the relatively low plasma frequencies. At times when auroral arcs pass the radar beam, significant increases in return power are observed. Many cases with simultaneously up and down shifted plasma lines are recorded. In spite of the rather active environment, the highly optimised measurements enable investigation of the properties of the plasma lines. A modified theoretical incoherent scatter spectrum is used to explain the measurements. The general trend is an upgoing field-aligned current in the diffuse aurora, confirmed with a full fit of the combined ion and plasma line spectra. There are also cases with strong suprathermal currents indicated by large differences in signal strength between up- and downshifted plasma lines.","20 pages, 15 figures, LaTeX. Minor updates","Ingemar Haggstrom, Mikael Hedin, Takehiko Aso, Asta Pellinen-Wannberg, Assar Westman",physics,val
Enhanced Pitch Angle Diffusion due to Electron-Whistler Interactions during Disturbed Times,"During periods of increased magnetospheric activity, whistler wave emissions have been observed with increased wave amplitudes. We consider a pitch angle diffusion mechanism that is shown to scale with whistler wave amplitude and hence is 'switched on' during these periods of intense activity. We consider the interaction between relativistic electrons and two oppositely directed, parallel propagating whistler mode waves. We show that for intense whistlers this process is stochastic and results in strong electron pitch angle diffusion. We show that the interaction is rapid, occur on timescales of the order of tens of electron gyroperiods and that the interaction is sensitive to wave amplitude, wave frequency and electron energy.","4 pages, 4 figures, presented at ics5 conference","W Wykes, S C Chapman, G Rowlands",physics,train
Test of Cosmic Spatial Isotropy for Polarized Electrons Using a Rotatable Torsion Balance,"To test the cosmic spatial isotropy, we use a rotatable torsion balance carrying a transversely spin-polarized ferrimagnetic Dy_{6}Fe_{23} mass. With a rotation period of one hour, the period of anisotropy signal is reduced from one sidereal day by about 24 times, and hence the 1/f noise is greatly reduced. Our present experimental results constrain the cosmic anisotropy Hamiltonian H = C_{1} sigma_{1} + C_{2} sigma_{2} + C_{3} sigma_{3} (sigma_{3} is in the axis of earth rotation) to (C_{1}^{2} +C_{2}^{2})^{1/2} = (1.8 +- 5.3) X 10^{-21} eV and | C_{3} | = (1.2 +- 3.5) X 10^{-19} eV. This improves the previous limits on (C_{1},C_{2}) by 120 times and C_{3} by a factor of 800.","6 pages, 3 figures","Li-Shing Hou, Wei-Tou Ni, Yu-Chu M. Li",physics,val
Photon Statistics of a Two-Mode Squeezed Vacuum,"We investigate the general case of the photon distribution of a two-mode squeezed vacuum and show that the distribution of photons among the two modes depends on four parameters: two squeezing parameters, the relative phase between the two oscillators and their spatial orientation. The distribution of the total number of photons depends only on the two squeezing parameters. We derive analytical expressions and present pictures for both distributions.","LATEX, 6 pages, Contribution to the third International Workshop on
  Squeezed States and Uncertainty Relations, Baltimore, August 1993","G. Schrade, V. M. Akulin, W. P. Schleich, V. I. Man'ko",physics,train
The Emergence of Classicality via Decoherence: Beyond the Caldeira-Legget Environment,"Maximally predictive states, as defined in recent work by Zurek, Habib and Paz, are studied for more elaborate environment models than a linear coupling. An environment model which includes spatial correlations in the noise is considered in the non-dissipative regime. The Caldeira-Leggett model is also reconsidered in the context of an averaging procedure which produces a completely positive form for the quantum master equation. In both cases, the maximally predictive states for the harmonic oscillator are the coherent states, which is the same result found by Zurek,Habib and Paz for the Caldeira-Legget environment.","LaTeX, 5 pages, (to appear in Proceedings of the 4th Drexel Symposium
  on Quantum Nonintegrability)",Michael R. Gallis,physics,val
"String Theory, Black Holes and Klein's Lemma","This is a writeup of a talk given at the Oskar Klein Centenery Symposium, Stockholm, September 19-21, 1994. It is an essay on the black hole information paradox and its connection with thermodynamics and the foundations of quantum mechanics.","17 pages, Latex",Ulf H. Danielsson,physics,val
On the Stronger Statement of Levinson's Theorem for the Dirac Equation,"Recently a stronger statement of Levinson's theorem for the Dirac equation was presented, where the limits of the phase shifts at $E=\pm M$ are related to the numbers of nodes of radial functions at the same energies, respectively. However, in this letter we show that this statement has to be modified because the limits of the phase shifts may be negative for the Dirac equation.",,Zhong-Qi Ma,physics,train
Kochen-Specker theorem for 8-dimensional space,"A Kochen-Specker contradiction is produced with 36 vectors in a real 8-dimensional Hilbert space. These vectors can be combined into 30 distinct projection operators (14 of rank 2, and 16 of rank 1). A state-specific variant of this contradiction requires only 13 vectors, a remarkably low number for 8 dimensions.",LaTeX 8 pages,"Michael Kernaghan, Asher Peres",physics,train
Infinite matrices may violate the associative law,"The momentum operator for a particle in a box is represented by an infinite order Hermitian matrix $P$. Its square $P^2$ is well defined (and diagonal), but its cube $P^3$ is ill defined, because $P P^2\neq P^2 P$. Truncating these matrices to a finite order restores the associative law, but leads to other curious results.",final version in J. Phys. A28 (1995) 1765-1770,"Ofir E. Alon, Nimrod Moiseyev, Asher Peres",physics,val
"A general formulation of discrete-time quantum mechanics, restrictions on the action and the relation of unitarity to the existence theorem for initial-value problems","A general formlulation for discrete-time quantum mechanics, based on Feynman's method in ordinary quantum mechanics, is presented. It is shown that the ambiguities present in ordinary quantum mechanics (due to noncommutativity of the operators), are no longer present here. Then the criteria for the unitarity of the evolution operator is examined. It is shown that the unitarity of the evolution operator puts restrictions on the form of the action, and also implies the existence of a solution for the classical initial-value problem.","13 pages, TeX",M. Khorrami,physics,val
Superconvergent Perturbation Method in Quantum Mechanics,"An analogue of Kolmogorov's superconvergent perturbation theory in classical mechanics is constructed for self adjoint operators. It is different from the usual Rayleigh--Schr\""odinger perturbation theory and yields expansions for eigenvalues and eigenvectors in terms of functions of the perturbation parameter.","11 pages, LaTeX",Wolfgang Scherer,physics,train
Quantum Averaging I: Poincaré--von Zeipel is Rayleigh--Schrödinger,"An exact analogue of the method of averaging in classical mechanics is constructed for self--adjoint operators. It is shown to be completely equivalent to the usual Rayleigh--Schr\""odinger perturbation theory but gives the sums over intermediate states in closed form expressions. The anharmonic oscillator and the Henon--Heiles system are treated as examples to illustrate the quantum averaging method.","12 pages, LaTeX, to appear in Journ. Phys. A",Wolfgang Scherer,physics,train
Two Mode Quantum Systems: Invariant Classification of Squeezing Transformations and Squeezed States,"A general analysis of squeezing transformations for two mode systems is given based on the four dimensional real symplectic group $Sp(4,\Re)\/$. Within the framework of the unitary metaplectic representation of this group, a distinction between compact photon number conserving and noncompact photon number nonconserving squeezing transformations is made. We exploit the $Sp(4,\Re)-SO(3,2)\/$ local isomorphism and the $U(2)\/$ invariant squeezing criterion to divide the set of all squeezing transformations into a two parameter family of distinct equivalence classes with representative elements chosen for each class. Familiar two mode squeezing transformations in the literature are recognized in our framework and seen to form a set of measure zero. Examples of squeezed coherent and thermal states are worked out. The need to extend the heterodyne detection scheme to encompass all of $U(2)\/$ is emphasized, and known experimental situations where all $U(2)\/$ elements can be reproduced are briefly described.","Revtex 37 pages, Latex figures included","Arvind, B. Dutta, N. Mukunda, R. Simon",physics,test
"Higgs line bundles, Green-Lazarsfeld sets,and maps of Kähler manifolds to curves","Let $X$ be a compact K\""ahler manifold. The set $\cha(X)$ of one-dimensional complex valued characters of the fundamental group of $X$ forms an algebraic group. Consider the subset of $\cha(X)$ consisting of those characters for which the corresponding local system has nontrivial cohomology in a given degree $d$. This set is shown to be a union of finitely many components that are translates of algebraic subgroups of $\cha(X)$. When the degree $d$ equals 1, it is shown that some of these components are pullbacks of the character varieties of curves under holomorphic maps. As a corollary, it is shown that the number of equivalence classes (under a natural equivalence relation) of holomorphic maps, with connected fibers, of $X$ onto smooth curves of a fixed genus $>1$ is a topological invariant of $X$. In fact it depends only on the fundamental group of $X$.",5 pages,Donu Arapura,mathematics,val
A theory of algebraic cocycles,"We introduce the notion of an algebraic cocycle as the algebraic analogue of a map to an Eilenberg-MacLane space. Using these cocycles we develop a ``cohomology theory"" for complex algebraic varieties. The theory is bigraded, functorial, and admits Gysin maps. It carries a natural cup product and a pairing to $L$-homology. Chern classes of algebraic bundles are defined in the theory. There is a natural transformation to (singular) integral cohomology theory that preserves cup products. Computations in special cases are carried out. On a smooth variety it is proved that there are algebraic cocycles in each algebraic rational $(p,p)$-cohomology class.",5 pages,"Eric M. Friedlander, H. Blaine Lawson Jr.",mathematics,train
Zariski Geometries,We characterize the Zariski topologies over an algebraically closed field in terms of general dimension-theoretic properties. Some applications are given to complex manifold and to strongly minimal sets.,9 pages,"Ehud Hrushovski, Boris Zilber",mathematics,train
Configuration spaces and the space of rational curves on a toric variety,"The space of holomorphic maps from $S^2$ to a complex algebraic variety $X$, i.e. the space of parametrized rational curves on $X$, arises in several areas of geometry. It is a well known problem to determine an integer $n(D)$ such that the inclusion of this space in the corresponding space of continuous maps induces isomorphisms of homotopy groups up to dimension $n(D)$, where $D$ denotes the homotopy class of the maps. The solution to this problem is known for an important but special class of varieties, the generalized flag manifolds: such an integer may be computed, and $n(D)\to\infty$ as $D\to\infty$. We consider the problem for another class of varieties, namely, toric varieties. For smooth toric varieties and certain singular ones, $n(D)$ may be computed, and $n(D)\to\infty$ as $D\to\infty$. For other singular toric varieties, however, it turns out that $n(D)$ cannot always be made arbitrarily large by a suitable choice of $D$.",6 pages,Martin A. Guest,mathematics,test
Stable vector bundles on algebraic surfaces,"We prove an existence result for stable vector bundles with arbitrary rank on an algebraic surface, and determine the birational structure of certain moduli space of stable bundles on a rational ruled surface.",,"Wei-ping Li, Zhenbo Qin",mathematics,train
Toric Intersection Theory for Affine Root Counting,"Given any polynomial system with fixed monomial term structure, we give explicit formulae for the generic number of roots with specified coordinate vanishing restrictions. For the case of affine space minus an arbitrary union of coordinate hyperplanes, these formulae are also the tightest possible upper bounds on the number of isolated roots. We also characterize, in terms of sparse resultants, precisely when these upper bounds are attained. Finally, we reformulate and extend some of the prior combinatorial results of the author on which subsets of coefficients must be chosen generically for our formulae to be exact. Our underlying framework provides a new toric variety setting for computational intersection theory in affine space minus an arbitrary union of coordinate hyperplanes. We thus show that, at least for root counting, it is better to work in a naturally associated toric compactification instead of always resorting to products of projective spaces.",,J. Maurice Rojas,mathematics,train
On Hyper Kähler manifolds associated to Lagrangean Kähler submanifolds of $T^*{\Bbb C}^n$,"For any Lagrangean K\""ahler submanifold $M \subset T^*{\Bbb C}^n$, there exists a canonical hyper K\""ahler metric on $T^*M$. A K\""ahler potential for this metric is given by the generalized Calabi Ansatz of the theoretical physicists Cecotti, Ferrara and Girardello. This correspondence provides a method for the construction of (pseudo) hyper K\""ahler manifolds with large automorphism group. Using it, a class of pseudo hyper K\""ahler manifolds of complex signature $(2,2n)$ is constructed. For any hyper K\""ahler manifold $N$ in this class a group of automorphisms with a codimension one orbit on $N$ is specified. Finally, it is shown that the bundle of intermediate Jacobians over the moduli space of gauged Calabi Yau 3-folds admits a natural pseudo hyper K\""ahler metric of complex signature $(2,2n)$.",,Vicente Cortés,mathematics,train
Rational curves and ampleness properties of the tangent bundle of algebraic varieties,"The purpose of this paper is to translate positivity properties of the tangent bundle (and the anti-canonical bundle) of an algebraic manifold into existence and movability properties of rational curves and to investigate the impact on the global geometry of the manifold $X$. Among the results we prove are these: \quad If $X$ is a projective manifold, and ${\cal E} \subset T_X$ is an ample locally free sheaf with $n-2\ge rk {\cal E}\ge n$, then $X \simeq \EP_n$. \quad Let $X$ be a projective manifold. If $X$ is rationally connected, then there exists a free $T_X$-ample family of (rational) curves. If $X$ admits a free $T_X$-ample family of curves, then $X$ is rationally generated.",,"Frédéric Campana, Thomas Peternell",mathematics,train
Quantum cohomology of projective bundles over P^n,"In this paper, we attempt to determine the quantum cohomology of projective bundles over the projective space P^n. In contrast to the previous examples, the relevant moduli spaces in our case frequently do not have expected dimensions. It makes the calculation more difficult. We overcome this difficulty by using excessive intersection theory.",,"Zhenbo Qin, Yongbin Ruan",mathematics,train
Extensions of vector bundles and rationality of certain moduli spaces of stable bundles,"In this paper, it is proved that certain stable rank-3 vector bundles can be written as extensions of line bundles and stable rank-2 bundles. As an application, we show the rationality of certain moduli spaces of stable rank-3 bundles over the projective plane P^2.",,"Wei-ping Li, Zhenbo Qin",mathematics,val
Some non-analytic-hypoelliptic sums of squares of vector fields,"Certain second-order partial differential operators, which are expressed as sums of squares of real-analytic vector fields in $\Bbb R^3$ and which are well known to be $C^\infty$ hypoelliptic, fail to be analytic hypoelliptic.",4 pages,Michael Christ,mathematics,train
A steepest descent method for oscillatory Riemann-Hilbert problems,"In this announcement we present a general and new approach to analyzing the asymptotics of oscillatory Riemann-Hilbert problems. Such problems arise, in particular, in evaluating the long-time behavior of nonlinear wave equations solvable by the inverse scattering method. We will restrict ourselves here exclusively to the modified Korteweg de Vries (MKdV) equation, $$y_t-6y^2y_x+y_{xxx}=0,\qquad -\infty<x<\infty,\ t\ge0, y(x,t=0)=y_0(x),$$ but it will be clear immediately to the reader with some experience in the field, that the method extends naturally and easily to the general class of wave equations solvable by the inverse scattering method, such as the KdV, nonlinear Schr\""odinger (NLS), and Boussinesq equations, etc., and also to ``integrable'' ordinary differential equations such as the Painlev\'e transcendents.",6 pages. Abstract added in migration.,"Percy Deift, Xin Zhou",mathematics,test
Semilinear wave equations,"We survey existence and regularity results for semi-linear wave equations. In particular, we review the recent regularity results for the $u^5$-Klein Gordon equation by Grillakis and this author and give a self-contained, slightly simplified proof.",34 pages,Michael Struwe,mathematics,train
A sharp pointwise bound for functions with $L^2$-Laplacians on arbitrary domains and its applications,"For all functions on an arbitrary open set $\Omega\subset\R^3$ with zero boundary values, we prove the optimal bound \[ \sup_{\Omega}|u| \leq (2\pi)^{-1/2} \left(\int_{\Omega}|\nabla u|^2 \,dx\, \int_{\Omega}|\Delta u|^2 \,dx\right)^{1/4}. \] The method of proof is elementary and admits generalizations. The inequality is applied to establish an existence theorem for the Burgers equation.",5 pages,Wenzheng Xie,mathematics,val
user's guide to viscosity solutions of second order partial differential equations,"The notion of viscosity solutions of scalar fully nonlinear partial differential equations of second order provides a framework in which startling comparison and uniqueness theorems, existence theorems, and theorems about continuous dependence may now be proved by very efficient and striking arguments. The range of important applications of these results is enormous. This article is a self-contained exposition of the basic theory of viscosity solutions.",67 pages,"Michael G. Crandall, Hitoshi Ishii, Pierre-Louis Lions",mathematics,train
Smooth static solutions of the Einstein-Yang/Mills equation,"We consider the Einstein/Yang-Mills equations in $3+1$ space time dimensions with $\SU(2)$ gauge group and prove rigorously the existence of a globally defined smooth static solution. We show that the associated Einstein metric is asymptotically flat and the total mass is finite. Thus, for non-abelian gauge fields the Yang/Mills repulsive force can balance the gravitational attractive force and prevent the formation of singularities in spacetime.",4 pages,"Joel Smoller, Arthur G. Wasserman, Shing-Tung Yau, J. Bryce McLeod",mathematics,test
A new result for the porous medium equation derived from the Ricci flow,"Given $\Bbb R^2, $ with a ``good'' complete metric, we show that the unique solution of the Ricci flow approaches a soliton at time infinity. Solitons are solutions of the Ricci flow, which move only by diffeomorphism. The Ricci flow on $\Bbb R^2$ is the limiting case of the porous medium equation when $m$ is zero. The results in the Ricci flow may therefore be interpreted as sufficient conditions on the initial data, which guarantee that the corresponding unique solution for the porous medium equation on the entire plane asymptotically behaves like a ``soliton-solution''.",5 pages,Lang-Fang Wu,mathematics,train
A Formula for Finding a Potential from Nodal Lines,"In this announcement we consider an eigenvalue problem which arises in the study of rectangular membranes. The mathematical model is an elliptic equation, in potential form, with Dirichlet boundary conditions. We have shown that the potential is uniquely determined, up to an additive constant, by a subset of the nodal lines of the eigenfunctions. A formula is given which, when the additive constant is fixed, yields an approximation to the potential at a dense set of points. An estimate is presented for the error made by the formula.",7 pages,"Joyce R. McLaughlin, Ole H. Hald",mathematics,train
Local Solvability For a Class of Partial Differential Operators With Double Characteristics,"A necessary and sufficient condition for local solvability is presented for the linear partial differential operators $-X^2-Y^2+ia(x)[X,Y]$ in $\bold R^3=\{(x,y,t)\}$, where $X=\partial_x,\; Y=\partial_y+x^k\partial_t$, and $a\in C^{\infty}(\bold R^1)$ is real valued, for each positive integer $k$.",,"Michael Christ, Georgi Karadzhov",mathematics,train
Global Irregularity For Degenerate Elliptic Operators,"Examples are given of degenerate elliptic operators on smooth, compact manifolds that are not globally regular in $C^\infty$. These operators degenerate only in a rather mild fashion. Certain weak regularity results are proved, and an interpretation of global irregularity in terms of the associated heat semigroup is given.",,Michael Christ,mathematics,val
A counterexample to the rigidity conjecture for rings,An example is constructed of a local ring and a module of finite type and finite projective dimension over that ring such that the module is not rigid. This shows that the rigidity conjecture is false.,4 pages,Raymond C. Heitmann,mathematics,train
Ideals associated to two sequences and a matrix,"Let $\u_{1\times n}$, $\X_{n\times n}$, and $\v_{n\times 1}$ be matrices of indeterminates, $\Adj \X$ be the classical adjoint of $\X$, and $H(n)$ be the ideal $I_1(\u\X)+I_1(\X\v)+I_1(\v\u-\Adj \X)$. Vasconcelos has conjectured that $H(n)$ is a perfect Gorenstein ideal of grade $2n$. In this paper, we obtain the minimal free resolution of $H(n)$; and thereby establish Vasconcelos' conjecture.",,Andrew R. Kustin,mathematics,train
On the Betti numbers of some Gorenstein ideals,"Assume $R$ is a polynomial ring over a field and $I$ is a homogeneous Gorenstein ideal of codimension $g\ge3$ and initial degree $p\ge2$. We prove that the number of minimal generators $\nu(I_p)$ of $I$ that are in degree $p$ is bounded above by $\nu_0={p+g-1\choose g-1}-{p+g-3\choose g-1}$, which is the number of minimal generators of the defining ideal of the extremal Gorenstein algebra of codimension $g$ and initial degree $p$. Further, $I$ is itself extremal if $\nu(I_p)=\nu_0$.",,"Matthew Miller, Rafael H. Villarreal",mathematics,train
Laurent coefficients and Ext of finite graded modules,"Let $R=\bigoplus_{n\ges0}R_n$ be a graded commutative ring generated over a field $K=R_0$ by homogeneous elements $x_1,\dots,x_e$ of positive degrees $d_1,\dots,d_e$. The Hilbert-Serre Theorem shows that for each finite graded $R$--module $M=\bigoplus_{n\in\BZ}M_n$ the {\it Hilbert series\/} $\sum_{n\in\BZ}(\rank_K M_n)t^n$ is the Laurent expansion around $0$ of a rational function $$ H_M(t)=\frac{q_M(t)}{\prod_{i=1}^e(1-t^{d_i})} $$ with $q_M(t)\in\BZ[t,\ti]$. We demonstrate that Laurent expansions $\left[M\right]_z$ of $H_M(t)$ around other points $z$ of the extended complex plane $\overline\BC$ also carry important structural information.",,"Luchezar L. Avramov, Ragnar-Olaf Buchweitz, Judith D. Sally",mathematics,train
Analogs of Gröbner Bases in Polynomial Rings over a Ring,"In this paper we will define analogs of Gr\""obner bases for $R$-subalgebras and their ideals in a polynomial ring $R[x_1,\ldots,x_n]$ where $R$ is a noetherian integral domain with multiplicative identity and in which we can determine ideal membership and compute syzygies. The main goal is to present and verify algorithms for constructing these Gr\""obner basis counterparts. As an application, we will produce a method for computing generators for the first syzygy module of a subset of an $R$-subalgebra of $R[x_1,\ldots,x_n]$ where each coordinate of each syzygy must be an element of the subalgebra.",,J. Lyn Miller,mathematics,train
Links of prime ideals and their Rees algebras,"In a previous paper we exhibited the somewhat surprising property that most direct links of prime ideals in Gorenstein rings are equimultiple ideals with reduction number $1$. This led to the construction of large families of Cohen--Macaulay Rees algebras. The first goal of this paper is to extend this result to arbitrary Cohen--Macaulay rings. The means of the proof are changed since one cannot depend so heavily on linkage theory. We then study the structure of the Rees algebra of these links, more specifically we describe their canonical module in sufficient detail to be able to characterize self--linked prime ideals. In the last section multiplicity estimates for classes of such ideals are established.",,"Alberto Corso, Claudia Polini",mathematics,val
Hilbert functions of graded algebras over Artinian rings,"In this paper we give an effective characterization of Hilbert functions and polynomials of standard algebras over an Artinian equicharacteristic local ring; the cohomological properties of such algebras are also studied. We describe algorithms to check the admissibility of a given function or polynomial as a Hilbert function or polynomial, and to produce a standard algebra with a given Hilbert function.",,Cristina Blancafort,mathematics,train
Extremal Betti Numbers and Applications to Monomial Ideals,"In this short note we introduce a notion of extremality for Betti numbers of a minimal free resolution, which can be seen as a refinement of the notion of Mumford-Castelnuovo regularity. We show that extremal Betti numbers of an arbitrary submodule of a free S-module are preserved when taking the generic initial module. We relate extremal multigraded Betti numbers in the minimal resolution of a square free monomial ideal with those of the monomial ideal corresponding to the Alexander dual simplicial complex and generalize theorems of Eagon-Reiner and Terai. As an application we give easy (alternative) proofs of classical criteria due to Hochster, Reisner, and Stanley.","Minor revision. 15 pages, Plain TeX with epsf.tex, 8 PostScript
  figures, PostScript file available also at
  http://www.math.columbia.edu/~psorin/eprints/monbetti.ps","Dave Bayer, Hara Charalambous, Sorin Popescu",mathematics,train
Permanental Ideals,"The principal result is a primary decomposition of ideals generated by the (2x2)-subpermanents of a generic matrix. These permanental ideals almost always have embedded components and their minimal primes are of three distinct heights. Thus the permanental ideals are almost never Cohen-Macaulay, in contrast with determinantal ideals.",13 pages,"R. Laubenbacher, I. Swanson",mathematics,train
Multiplicative Invariants and Semigroup Algebras,"Let G be a finite group acting by automorphism on a lattice A, and hence on the group algebra S=k[A]. The algebra of G-invariants in S is called an algebra of multiplicative invariants. We investigate when algebras of multiplicative invariants are semigroup algebras. In particular, we present an explicit version of a result of Farkas stating that multiplicative invariants of finite reflection groups are indeed semigroup algebras. On the other hand, multiplicative invariants arising from fixed point free actions are shown to never be semigroup algebras. In particular, this holds whenever G has odd prime order.","AMS-LateX, 16 pages, 1 figure",Martin Lorenz,mathematics,val
"On the cohomology of SL(2,Z[1/p])","In this paper we compute the integral cohomology of the discrete groups SL(2,Z[1/p]), where p is any prime.",,"Alejandro Adem, Nadim Naffah",mathematics,val
"On Combinatorial Descriptions of Homotopy Groups of $ΣK(π,1)$","We give a combinatorial description of homotopy groups of $\Sigma K(\pi,1)$. In particular, all of the homotopy groups of the $3$-sphere are combinatorially given.",,Jie Wu,mathematics,train
"On the Homology of Configuration Spaces $C((M,M_o)\times {\bold R}^n; X)$","The homology with coefficients in a field of the configuration spaces $C(M\times \bold R ^n,M_o\times \bold R ^n;X)$ is determined in this paper.",,Jie Wu,mathematics,test
On Combinatorial Calculations for the James--Hopf maps,We give some formulas of the James-Hopf maps by using combinatorial methods. An application is to give a product decomposition of the spaces $\Omega\Sigma^2(X)$.,,Jie Wu,mathematics,train
A Product Decomposition of $Ω^3_0Σ${\bf R}$P^2$,We give a specific product decomposition of the base-point path connected component of the triple loop space of the suspension of the projective plane.,,Jie Wu,mathematics,test
Homotopy Lie groups,"Homotopy Lie groups, recently invented by W.G. Dwyer and C.W. Wilkerson, represent the culmination of a long evolution. The basic philosophy behind the process was formulated almost 25 years ago by Rector in his vision of a homotopy theoretic incarnation of Lie group theory. What was then technically impossible has now become feasible thanks to modern advances such as Miller's proof of the Sullivan conjecture and Lannes's division functors. Today, with Dwyer and Wilkerson's implementation of Rector's vision, the tantalizing classification theorem seems to be within grasp. Supported by motivating examples and clarifying exercises, this guide quickly leads, without ignoring the context or the proof strategy, from classical finite loop spaces to the important definitions and striking results of this new theory.",16 pages,Jesper M. Møller,mathematics,train
Topological transformation groups,This paper surveys some results and methods in topological transformation groups.,,"Alejandro Adem, James F. Davis",mathematics,train
The combinatorics of Steenrod operations on the cohomology of Grassmannians,"The study of the action of the Steenrod algebra on the mod $p$ cohomology of spaces has many applications to the topological structure of those spaces. In this paper we present combinatorial formulas for the action of Steenrod operations on the cohomology of Grassmannians, both in the Borel and the Schubert picture. We consider integral lifts of Steenrod operations, which lie in a certain Hopf algebra of differential operators. The latter has been considered recently as a realization of the Landweber-Novikov algebra in complex cobordism theory; it also has connections with the action of the Virasoro algebra on the boson Fock space. Our formulas for Steenrod operations are based on combinatorial methods which have not been used before in this area, namely Hammond operators and the combinatorics of Schur functions. We also discuss several applications of our formulas to the geometry of Grassmannians.",,Cristian Lenart,mathematics,train
Symmetric spectra,"The long hunt for a symmetric monoidal category of spectra finally ended in success with the simultaneous discovery of the third author's discovery of symmetric spectra and the Elmendorf-Kriz-Mandell-May category of S-modules. In this paper we define and study the model category of symmetric spectra, based on simplicial sets and topological spaces. We prove that the category of symmetric spectra is closed symmetric monoidal and that the symmetric monoidal structure is compatible with the model structure. We prove that the model category of symmetric spectra is Quillen equivalent to Bousfield and Friedlander's category of spectra. We show that the monoidal axiom holds, so that we get model categories of ring spectra and modules over a given ring spectrum.","77 pages. This version corrects some errors in the section on
  topological symmetric spectra","Mark Hovey, Brooke Shipley, Jeff Smith",mathematics,val
Symmetric ring spectra and topological Hochschild homology,"Symmetric spectra were introduced by Jeff Smith as a symmetric monoidal category of spectra. In this paper, a detection functor is defined which detects stable equivalences of symmetric spectra. This detection functor is useful because the classic stable homotopy groups do not detect stable equivalences in symmetric spectra. One of the advantages of a symmetric monoidal category of spectra is that one can define topological Hochschild homology on ring spectra simply by mimicking the Hochschild complex from algebra. Using the detection functor mentioned above, this definition of topological Hochschild homology is shown to agree with Bokstedt's original definition. In particular, this shows that Bokstedt's definition is correct even for non-connective non-convergent symmetric ring spectra.",,Brooke Shipley,mathematics,train
The $\bal$\ and $\bcl$\ Bailey Transform and Lemma,"We announce a higher-dimensional generalization of the Bailey Transform, Bailey Lemma, and iterative ``Bailey chain'' concept in the setting of basic hypergeometric series very well-poised on unitary $A_{\ell}$ or symplectic $C_{\ell}$ groups. The classical case, corresponding to $A_1$ or equivalently $\roman U(2)$, contains an immense amount of the theory and application of one-variable basic hypergeometric series, including elegant proofs of the Rogers-Ramanujan-Schur identities. In particular, our program extends much of the classical work of Rogers, Bailey, Slater, Andrews, and Bressoud.",6 pages,"Stephen C. Milne, Glenn M. Lilly",mathematics,train
Convolution polynomials,"The polynomials that arise as coefficients when a power series is raised to the power $x$ include many important special cases, which have surprising properties that are not widely known. This paper explains how to recognize and use such properties, and it closes with a general result about approximating such polynomials asymptotically.",,Donald E. Knuth,mathematics,val
Johann Faulhaber and sums of powers,"Early 17th-century mathematical publications of Johann Faulhaber contain some remarkable theorems, such as the fact that the $r$-fold summation of $1^m,2^m,...,n^m$ is a polynomial in $n(n+r)$ when $m$ is a positive odd number. The present paper explores a computation-based approach by which Faulhaber may well have discovered such results, and solves a 360-year-old riddle that Faulhaber presented to his readers. It also shows that similar results hold when we express the sums in terms of central factorial powers instead of ordinary powers. Faulhaber's coefficients can moreover be generalized to factorial powers of noninteger exponents, obtaining asymptotic series for $1^{\alpha}+2^{\alpha}+...+n^{\alpha}$ in powers of $n^{-1}(n+1)^{-1}$.",,Donald E. Knuth,mathematics,test
Singularities of the Radon transform,"Singularities of the Radon transform of a piecewise smooth function $f(x)$, $x\in R^n$, $n\geq 2$, are calculated. If the singularities of the Radon transform are known, then the equations of the surfaces of discontinuity of $f(x)$ are calculated by applying the Legendre transform to the functions, which appear in the equations of the discontinuity surfaces of the Radon transform of $f(x)$; examples are given. Numerical aspects of the problem of finding discontinuities of $f(x)$, given the discontinuities of its Radon transform, are discussed.",7 pages,"Alexander G. Ramm, Alexander I. Zaslavsky",mathematics,test
"Best uniform rational approximation of $x^α$ on $[0,1]$","A strong error estimate for the uniform rational approximation of $x^\alpha$ on $[0,1]$ is given, and its proof is sketched. Let $E_{nn}(x^\alpha,[0,1])$ denote the minimal approximation error in the uniform norm. Then it is shown that $$\lim_{n\to\infty}e^{2\pi\sqrt{\alpha n}}E_{nn}(x^\alpha,[0,1]) = 4^{1+\alpha}|\sin\pi\alpha|$$ holds true for each $\alpha>0$.",7 pages,Herbert Stahl,mathematics,train
On weighted transplantation and multipliers for Laguerre expansions,"Using the standard square--function method (based on the Poisson semigroup), multiplier conditions of H\""ormander type are derived for Laguerre expansions in $L^p$--spaces with power weights in the $A_p$-range; this result can be interpreted as an ``upper end point'' multiplier criterion which is fairly good for $p$ near $1$ or near $\infty $. A weighted generalization of Kanjin's \cite{kan} transplantation theorem allows to obtain a ``lower end point'' multiplier criterion whence by interpolation nearly ``optimal'' multiplier criteria (in dependance of $p$, the order of the Laguerre polynomial, the weight).",,"Krzysztof Stempak, Walter Trebels",mathematics,train
Associated Stieltjes-Carlitz polynomials and a generalization of Heun's differential equation.,The generating function of Stieltjes-Carlitz polynomials is a solution of Heun's differential equation and using this relation Carlitz was the first to get exact closed forms for some Heun functions. Similarly the associated Stieltjes-Carlitz polynomials lead to a new differential equation which we call associated Heun. Thanks to the link with orthogonal polynomials we are able to deduce two integral relations connecting associated Heun functions with different parameters and to exhibit the set of associated Heun functions which generalize Carlitz's. Part of these results were used by the author to derive the Stieltjes transform of the measure of orthogonality for the associated Stieltjes-Carlitz polynomials using asymptotic analysis; here we present a new derivation of this result.,,Galliano Valent,mathematics,train
"A high-school algebra wallet-sized proof, of the Bieberbach conjecture After L. Weinstein]","Weinstein's[2] brilliant short proof of de Branges'[1] theorem can be made yet much shorter(modulo routine calculations), completely elementary (modulo L\""owner theory), self contained(no need for the esoteric Legendre polynomials' addition theorem), and motivated(ditto), as follows.",,"Shalosh B. Ekhad, Doron Zeilberger",mathematics,train
Using sums of squares to prove that certain entire functions have only real zeros,"It is shown how sums of squares of real valued functions can be used to give new proofs of the reality of the zeros of the Bessel functions $J_\alpha (z)$ when $\alpha \ge -1,$ confluent hypergeometric functions ${}_0F_1(c\/; z)$ when $c>0$ or $0>c>-1$, Laguerre polynomials $L_n^\alpha(z)$ when $\alpha \ge -2,$ and Jacobi polynomials $P_n^{(\alpha,\beta)}(z)$ when $\alpha \ge -1$ and $ \beta \ge -1.$ Besides yielding new inequalities for $|F(z)|^2,$ where $F(z)$ is one of these functions, the derived identities lead to inequalities for $\partial |F(z)|^2/\partial y$ and $\partial ^2 |F(z)|^2/\partial y^2,$ which also give new proofs of the reality of the zeros.",,George Gasper Jr,mathematics,train
On necessary multiplier conditions for Laguerre expansions,The necessary multiplier conditions for Laguerre expansions derived in Gasper and Trebels \cite{laguerre} are supplemented and modified. This allows us to place Markett's Cohen type inequality \cite{cohen} (up to the $\log $--case) in the general framework of necessary conditions.,,"George Gasper Jr, Walter Trebels",mathematics,train
Alternating sign matrices and domino tilings,"We introduce a family of planar regions, called Aztec diamonds, and study the ways in which these regions can be tiled by dominoes. Our main result is a generating function that not only gives the number of domino tilings of the Aztec diamond of order $n$ but also provides information about the orientation of the dominoes (vertical versus horizontal) and the accessibility of one tiling from another by means of local modifications. Several proofs of the formula are given. The problem turns out to have connections with the alternating sign matrices of Mills, Robbins, and Rumsey, as well as the square ice model studied by Lieb.",,"Noam Elkies, Greg Kuperberg, Michael Larsen, James Propp",mathematics,train
A Short Proof of Jacobi's Formula for the Number of Representations of an Integer as a Sum of Four Squares,"A short and elementary proof, and a finite-form generalization, are given of Jacobi's formula for the number of ways of writing an integer as a sum of four squares (that implies Lagrange's famous 1777 theorem.)",Plain TeX,"George Andrews, Shalsoh B. Ekhad, Doron Zeilberger",mathematics,train
Theorems for a Price: Tomorrow's Semi-Rigorous Mathematical Culture,"The future of mathematics is described, by using the WZ algorithmic proof theory as a parable.",Plain TeX,Doron Zeilberger,mathematics,train
A WZ proof of Ramanujan's Formula for Pi,"Ramanujan's series for Pi, that appeared in his famous letter to Hardy, is given a one-line WZ proof.",Plain TeX,"Shalosh B. Ekhad, Doron Zeilberger",mathematics,train
Chu's 1303 Identity Implies Bombieri's 1990 Norm-Inequality [via an Identity of Beauzamy and Dégot],"The Vandermonde-Chu Binomial Coefficients Identity is shown to imply Bombieri's deep norm inequalities, via identities of Beauzamy-D\'egot, and Reznick.",Plain TeX,Doron Zeilberger,mathematics,val
Combinatorial Proofs of Capelli's and Turnbull's Identities from Classical Invariant Theory,Capelli's and Turnbull's classical identities are given elegant combinatorial proofs.,Plain TeX,"Dominique Foata, Doron Zeilberger",mathematics,train
The Dinitz problem solved for rectangles,"The Dinitz conjecture states that, for each $n$ and for every collection of $n$-element sets $S_{ij}$, an $n\times n$ partial latin square can be found with the $(i,j)$\<th entry taken from $S_{ij}$. The analogous statement for $(n-1)\times n$ rectangles is proven here. The proof uses a recent result by Alon and Tarsi and is given in terms of even and odd orientations of graphs.",7 pages,Jeannette C. M. Janssen,mathematics,train
The sandwich theorem,"This report contains expository notes about a function $\vartheta(G)$ that is popularly known as the Lov\'asz number of a graph~$G$. There are many ways to define $\vartheta(G)$, and the surprising variety of different characterizations indicates in itself that $\vartheta(G)$ should be interesting. But the most interesting property of $\vartheta(G)$ is probably the fact that it can be computed efficiently, although it lies ``sandwiched'' between other classic graph numbers whose computation is NP-hard. I~have tried to make these notes self-contained so that they might serve as an elementary introduction to the growing literature on Lov\'asz's fascinating function.",,Donald E. Knuth,mathematics,val
How Joe Gillis Discovered Combinatorial Special Function Theory,"How Enumerative Combinatorics met Special Functions, thanks to Joe Gillis",Plain TeX,Doron Zeilberger,mathematics,train
The Graphical Major Index,"A generalization of the classical statistics ``maj'' and ``inv'' (the major index and number of inversions) on words is introduced, parameterized by arbitrary graphs on the underlying alphabet. The question of characterizing those graphs that lead to equi-distributed ""inv"" and ""maj"" is posed and answered.",Plain TeX,"Dominique Foata, Doron Zeilberger",mathematics,train
Nuclear and Trace Ideals in Tensored *-Categories,"We generalize the notion of nuclear maps from functional analysis by defining nuclear ideals in tensored *-categories. The motivation for this study came from attempts to generalize the structure of the category of relations to handle what might be called ``probabilistic relations''. The compact closed structure associated with the category of relations does not generalize directly, instead one obtains nuclear ideals. We introduce the notion of nuclear ideal to analyze these classes of morphisms. In compact closed categories, we see that all morphisms are nuclear, and in the category of Hilbert spaces, the nuclear morphisms are the Hilbert-Schmidt maps. We also introduce two new examples of tensored *-categories, in which integration plays the role of composition. In the first, morphisms are a special class of distributions, which we call tame distributions. We also introduce a category of probabilistic relations which was the original motivating example. Finally, we extend the recent work of Joyal, Street and Verity on traced monoidal categories to this setting by introducing the notion of a trace ideal. For a given symmetric monoidal category, it is not generally the case that arbitrary endomorphisms can be assigned a trace. However, we can find ideals in the category on which a trace can be defined satisfying equations analogous to those of Joyal, Street and Verity. We establish a close correspondence between nuclear ideals and trace ideals in a tensored *-category, suggested by the correspondence between Hilbert-Schmidt operators and trace operators on a Hilbert space.","43 pages, Revised version","S. Abramsky, R. Blute, P. Panangaden",mathematics,train
Basic Bicategories,"A concise guide to very basic bicategory theory, from the definition of a bicategory to the coherence theorem.",11 pages; LaTeX 2e with Paul Taylor's diagram macros,Tom Leinster,mathematics,train
Applications of Rewriting Systems and Groebner Bases to Computing Kan Extensions and Identities Among Relations,"This thesis concentrates on the development and application of rewriting and Groebner basis methods to a range of combinatorial problems. Chapter Two contains the most important result, which is the application of Knuth-Bendix procedures to Kan extensions, showing how rewriting provides a useful method for attempting to solve a variety of combinatorial problems which can be phrased in terms of Kan extensions. Chapter Three shows that the standard Knuth-Bendix algorithm is step-for-step a special case of Buchberger's algorithm. The one-sided cases and higher dimensions are considered. Chapter Four relates rewrite systems, Groebner bases and automata. Automata which only accept irreducibles, and automata which output reduced forms are discussed for presentations of Kan extensions. Reduction machines for rewrite systems are identified with standard output automata and the reduction machines devised for algebras are expressed as Petri nets. Chapter Five uses the completion of a group rewriting system to algorithmically determine a contracting homotopy necessary in order to compute the set of generators for the module of identities among relations using the covering groupoid methods devised by Brown and Razak Salleh. Reducing the resulting set of submodule generators is identified as a Groebner basis problem. Algorithms are implemented in GAP3.","1998 PhD thesis, LaTeX2e 105 pages, most typos corrected",Anne Heyworth,mathematics,train
K-Theory for Triangulated Categories III(A): The Theorem of the Heart,"This is the fourth installment of a series. The main point of the entire series is the following: given a triangulated category T, it is possible to attach to it a K-theory space.",94 pages,Amnon Neeman,mathematics,train
fc-multicategories,"fc-multicategories are a very general kind of two-dimensional structure, encompassing bicategories, monoidal categories, double categories and ordinary multicategories. We define them and explain how they provide a natural setting for two familiar categorical ideas. The first is the bimodules construction, traditionally carried out on suitably cocomplete bicategories but perhaps more naturally carried out on fc-multicategories. The second is enrichment: there is a theory of categories enriched in an fc-multicategory, extending the usual theory of enrichment in a monoidal category. We finish by indicating how this work is just the simplest case of a much larger phenomenon.",Notes for talk at PSSL 70; 8 pages,Tom Leinster,mathematics,test
On Ideals and Homology in Additive Categories,"Ideals are used to define homological functors for additive categories. In abelian categories the ideals corresponding to the usual universal objects are principal, and the construction reduces, in a choice dependent way, to homology groups. Applications are considered: derived categories and functors.","10 pages, AMS-LaTex; v.2 includes applications to derived categories
  and functors (preliminary version)",Lucian M. Ionescu,mathematics,train
Grothendieck Categories,"The general theory of Grothendieck categories is presented. We systemize the principle methods and results of the theory, showing how these results can be used for studying rings and modules.","AMS-LaTeX, 60 pages",Grigory Garkusha,mathematics,train
Algebraic duality for partially ordered sets,"For an arbitrary partially ordered set $P$ its {\em dual} $P^*$ is built as the collection of all monotone mappings $P\to\2$ where $\2=\{0,1\}$ with $0<1$. The set of mappings $P^*$ is proved to be a complete lattice with respect to the pointwise partial order. The {\em second dual} $P^{**}$ is built as the collection of all morphisms of complete lattices $P^*\to\2$ preserving universal bounds. Then it is proved that the partially ordered sets $P$ and $P^{**}$ are isomorphic.","latex209, 6 pages",Roman R. Zapatrin,mathematics,val
Coherence in Substructural Categories,"It is proved that MacLane's coherence results for monoidal and symmetric monoidal categories can be extended to some other categories with multiplication; namely, to relevant, affine and cartesian categories. All results are formulated in terms of natural transformations equipped with ``graphs'' (g-natural transformations), and corresponding morphism theorems are given as consequences. Using these results, some basic relations between the free categories of these classes are obtained.",19 pages,Z. Petric,mathematics,train
From Coherent Structures to Universal Properties,"Given a 2-category $\twocat{K}$ admitting a calculus of bimodules, and a 2-monad T on it compatible with such calculus, we construct a 2-category $\twocat{L}$ with a 2-monad S on it such that: (1)S has the adjoint-pseudo-algebra property. (2)The 2-categories of pseudo-algebras of S and T are equivalent. Thus, coherent structures (pseudo-T-algebras) are transformed into universally characterised ones (adjoint-pseudo-S-algebras). The 2-category $\twocat{L}$ consists of lax algebras for the pseudo-monad induced by T on the bicategory of bimodules of $\twocat{K}$. We give an intrinsic characterisation of pseudo-S-algebras in terms of representability. Two major consequences of the above transformation are the classifications of lax and strong morphisms, with the attendant coherence result for pseudo-algebras. We apply the theory in the context of internal categories and examine monoidal and monoidal globular categories (including their monoid classifiers) as well as pseudo-functors into $\Cat$.",to appear in Journal of Pure and Applied Algebra,Claudio Hermida,mathematics,train
On the Removable Singularities for Meromorphic Mappings,"If E is a nonempty closed subset of the locally finite Hausdorff (2n-2)-measure on an n-dimensional complex manifold M and all points of E are nonremovable for a meromorphic mapping of M \ E into a compact K\""ahler manifold, then E is a pure (n-1)-dimensional complex analytic subset of M.",,E. M. Chirka,mathematics,train
Szegö kernels for certain unbounded domains in $\Bbb C^2$,No abstract available.,,Friedrich Haslinger,mathematics,train
Domains in $\cx {n+1}$ with Noncompact Automorphism Group. II,No abstract available.,,"Eric Bedford, Sergey Pinchuk",mathematics,val
Zero sets of some classes of entire functions,A method of constructing an entire function with given zeros and estimates of growth is suggested. It gives a possibility to describe zero sets of certain classes of entire functions of one and several variables in terms of growth of volume of these sets in certain polycylinders.,,Alexander Russakovskii,mathematics,train
Analytic varieties versus integral varieties of Lie algebras of vector fields,"We associate to any germ of an analytic variety a Lie algebra of tangent vector fields, the {\it tangent algebra}. Conversely, to any Lie algebra of vector fields an analytic germ can be associated, the {\it integral variety}. The paper investigates properties of this correspondence: The set of all tangent algebras is characterized in purely Lie algebra theoretic terms. And it is shown that the tangent algebra determines the analytic type of the variety.",4 pages,"Herwig Hauser, Gerd Muller",mathematics,train
Holomorphic curvature of Finsler metrics and complex geodesics,"In his famous 1981 paper, Lempert proved that given a point in a strongly convex domain the complex geodesics (i.e., the extremal disks) for the Kobayashi metric passing through that point provide a very useful fibration of the domain. In this paper we address the question whether, given a smooth complex Finsler metric on a complex manifold, it is possible to give purely differential geometric properties of the metric ensuring the existence of such a fibration in complex geodesics of the manifold. We first discuss at some length the notion of holomorphic sectional curvature for a complex Finsler metric; then, using the differential equation of complex geodesics we obtained in a previous paper, we show that for every pair (point, tangent vector) there is a (only a segment if the metric is not complete) complex geodesic passing through the point tangent to the given vector iff the Finsler metric is K\""ahler, has constant holomorphic sectional curvature -4 and satisfies a simmetry condition on the curvature tensor. Finally, we show that a complex Finsler metric of constant holomorphic sectional curvature -4 satisfying the given simmetry condition on the curvature is necessarily the Kobayashi metric.",,"Marco Abate, Giorgio Patrizio",mathematics,train
Sequences of analytic disks,"The subject considered in this paper has, at least, three points of interest. Suppose that we have a sequence of one-dimensional analytic varieties in a domain in $\Bbb C^n$. The cluster of this sequence consists from all points in the domains such that every neighbourhood of such points intersects with infinitely many different varieties. The first question is: what analytic properties does the cluster inherit from varieties? We give a sufficient criterion when the cluster contains an analytic disk, but it follows from examples of Stolzenberg and Wermer that, in general, clusters can contain no analytic disks. So we study algebras of continuous function on clusters, which can be approximated by holomorphic functions or polynomials, and show that this algebras possess some analytic properties in all but explicitly pathological and uninteresting cases. Secondly, we apply and results about clusters to polynomial hulls and maximal functions, finding remnants of analytic structures there too. And, finally, due to more and more frequent appearances of analytic disks as tools in complex analysis, it seems to be interesting to look at their sequences to establish terminology, basic notation and properties.",,Evgeny A. Poletsky,mathematics,val
A counterexample to the Arakelyan Conjecture,A ``self--similar'' example is constructed that shows that a conjecture of N. U. Arakelyan on the order of decrease of deficiencies of an entire function of finite order is not true.,6 pages,Alexandre Erëmenko,mathematics,train
The Green function of Teichmüller spaces with applications,"We describe briefly a new approach to some problems related to Teichm\""uller spaces, invariant metrics, and extremal quasiconformal maps. This approach is based on the properties of plurisubharmonic functions, especially of the plurisubharmonic Green function. The main theorem gives an explicit representation of the Green function for Teichm\""uller spaces by the Kobayashi-Teichm\""uller metric of these spaces. This leads to various applications. In particular, this gives a new characterization of extremal quasiconformal maps.",5 pages,Samuel L. Krushkal,mathematics,train
Radó theorem and its generalization for CR-mappings,"The following theorem is proved: Let M be a locally Lipschitz hypersurface in C^n with one-sided extension property at each point (e.g., without analytic discs). Let S be a closed subset of M and f : M \ S ---> C^m \ E is a CR-mapping of class L^{\infty} such that the cluster set of f on S along of Lebesque points of f is contained in a closed complete pluripolar set E. Then there is a CR-mapping \~f : M ---> C^m of class L^{\infty}(M) such that \~f |M\S = f. It follows also that S is removable for CR \cap L^{\infty} (M \ S).",plain TeX,E. M. Chirka,mathematics,train
A cohomology for vector valued differential forms,"A rather simple natural outer derivation of the graded Lie algebra of all vector valued differential forms with the Fr\""olicher-Nijenhuis bracket turns out to be a differential and gives rise to a cohomology of the manifold, which is functorial under local diffeomorphisms. This cohomology is determined as the direct product of the de Rham cohomology space and the graded Lie algebra of ""traceless"" vector valued differential forms, equipped with a new natural differential concomitant as graded Lie bracket. We find two graded Lie algebra structures on the space of differential forms. Some consequences and related results are also discussed.",,"Peter W. Michor, Hubert Schicketanz",mathematics,train
Nonunique tangent maps at isolated singularities of harmonic maps,"Shoen and Uhlenbeck showed that ``tangent maps'' can be defined at singular points of energy minimizing maps. Unfortunately these are not unique, even for generic boundary conditions. Examples are discussed which have isolated singularities with a continuum of distinct tangent maps.",6 pages,Brian White,mathematics,train
Graded derivations of the algebra of differential forms associated with a connection,"In the main part of this paper a connection is just a fiber projection onto a (not necessarily integrable) distribution or sub vector bundle of the tangent bundle. Here curvature is computed via the Froelicher-Nijenhuis bracket, and it is complemented by cocurvature and the Bianchi identity still holds. In this situation we determine the graded Lie algebra of all graded derivations over the horizontal projection of a connection and we determine their commutation relations. Finally, for a principal connection on a principal bundle and the induced connection on an associated bundle we show how one may pass from one to the other. The final results relate derivations on vector bundle valued forms and derivations over the horizontal projection of the algebra of forms on the principal bundle with values in the standard vector space.",,Peter W. Michor,mathematics,train
The action of the diffeomorphism group on the space of immersions,"We study the action of the diffeomorphism group $\Diff(M)$ on the space of proper immersions $\Imm_{\text{prop}}(M,N)$ by composition from the right. We show that smooth transversal slices exist through each orbit, that the quotient space is Hausdorff and is stratified into smooth manifolds, one for each conjugacy class of isotropy groups.",,"Vincente Cervera, Francisca Mascaró, Peter W. Michor",mathematics,val
The relation between systems and associated bundles,"It is shown that a strong system of vector fields on a fiber bundle in the sense of [Modugno, M. Systems of connections and invariant lagrangians. In: Differential geometric methods in theoretical physics, Proc. 15th Int. Conf., DGM, Clausthal/FRG 1986, 518-534 World Scientific Publishing Co. (1987)] is induced from a principal fiber bundle if and only if each vertical vector field of the system is complete.",,Peter W. Michor,mathematics,val
Commutators of flows and fields,"The well known formula $[X,Y]=\tfrac12\tfrac{\partial^2}{\partial t^2}|_0 (\Fl^Y_{-t}\o\Fl^X_{-t}\o\Fl^Y_t\o\Fl^X_t)$ for vector fields $X$, $Y$ is generalized to arbitrary bracket expressions and arbitrary curves of local diffeomorphisms.",,"Markus Mauhart, Peter W. Michor",mathematics,train
Geodesics on spaces of almost hermitian structures,A natural metric on the space of all almost hermitian structures on a given manifold is investigated.,,"Olga Gil-Medrano, Peter W. Michor",mathematics,val
One cannot hear the shape of a drum,"We use an extension of Sunada's theorem to construct a nonisometric pair of isospectral simply connected domains in the Euclidean plane, thus answering negatively Kac's question, ``can one hear the shape of a drum?'' In order to construct simply connected examples, we exploit the observation that an orbifold whose underlying space is a simply connected manifold with boundary need not be simply connected as an orbifold.",5 pages,"Carolyn Gordon, David L. Webb, Scott Wolpert",mathematics,val
Characteristic classes for $G$-structures,Let $G\subset GL(V)$ be a linear Lie group with Lie algebra $\frak g$ and let $A(\frak g)^G$ be the subalgebra of $G$-invariant elements of the associative supercommutative algebra $A(\frak g)= S(\frak g^*)\otimes \La(V^*)$. To any $G$-structure $\pi:P\to M$ with a connection $\omega$ we associate a homomorphism $\mu_\omega:A(\frak g)^G\to \Omega(M)$. The differential forms $\mu_\omega(f)$ for $f\in A(\frak g)^G$ which are associated to the $G$-structure $\pi$ can be used to construct Lagrangians. If $\omega$ has no torsion the differential forms $\mu_\omega(f)$ are closed and define characteristic classes of a $G$-structure. The induced homomorphism $\mu'_\omega:A(\g)^G\to H^*(M)$ does not depend on the choice of the torsionfree connection $\omega$ and it is the natural generalization of the Chern Weil homomorphism.,,"Dimitri Alekseevsky, Peter W. Michor",mathematics,train
Adding handles to the helicoid,"There exist two new embedded minimal surfaces, asymptotic to the helicoid. One is periodic, with quotient (by orientation-preserving translations) of genus one. The other is nonperiodic of genus one.",8 pages,David A. Hoffman,mathematics,test
Conformal dynamics problem list,This is a list of unsolved problems given at the Conformal Dynamics Conference which was held at SUNY Stony Brook in November 1989. Problems were contributed by the editor and the other authors.,,"Ben Bielefeld, Adrien Douady, Curt McMullen, Jack Milnor, Misuhiro Shishikura, Folkert Tangerman, Peter Veerman",mathematics,val
Remarks on iterated cubic maps,"This note will discuss the dynamics of iterated cubic maps from the real or complex line to itself, and will describe the geography of the parameter space for such maps. It is a rough survey with few precise statements or proofs, and depends strongly on work by Douady, Hubbard, Branner and Rees.",,John W. Milnor,mathematics,train
One-dimensional maps and Poincaré metric,"Invertible compositions of one-dimensional maps are studied which are assumed to include maps with non-positive Schwarzian derivative and others whose sum of distortions is bounded. If the assumptions of the Koebe principle hold, we show that the joint distortion of the composition is bounded. On the other hand, if all maps with possibly non-negative Schwarzian derivative are almost linear-fractional and their nonlinearities tend to cancel leaving only a small total, then they can all be replaced with affine maps with the same domains and images and the resulting composition is a very good approximation of the original one. These technical tools are then applied to prove a theorem about critical circle maps.",,Grzegorz Swiatek,mathematics,val
Dynamics of certain smooth one-dimensional mappings I: The $C^{1+α}$-Denjoy-Koebe distortion lemma,"We prove a technical lemma, the $C^{1+\alpha }$-Denjoy-Koebe distortion lemma, estimating the distortion of a long composition of a $C^{1+\alpha }$ one-dimensional mapping $f:M\mapsto M$ with finitely many, non-recurrent, power law critical points. The proof of this lemma combines the ideas of the distortion lemmas of Denjoy and Koebe.",,Yunping Jiang,mathematics,train
Dynamics of certain smooth one-dimensional mappings II: geometrically finite one-dimensional mappings,"We study geometrically finite one-dimensional mappings. These are a subspace of $C^{1+\alpha}$ one-dimensional mappings with finitely many, critically finite critical points. We study some geometric properties of a mapping in this subspace. We prove that this subspace is closed under quasisymmetrical conjugacy. We also prove that if two mappings in this subspace are topologically conjugate, they are then quasisymmetrically conjugate. We show some examples of geometrically finite one-dimensional mappings.",,Yunping Jiang,mathematics,test
A partial description of the parameter space of rational maps of degree two: Part 2,"This continues the investigation of a combinatorial model for the variation of dynamics in the family of rational maps of degree two, by concentrating on those varieties in which one critical point is periodic. We prove some general results about nonrational critically finite degree two branched coverings, and finally identify the boundary of the rational maps in the combinatorial model, thus completing the proofs of results announced in Part 1.",,Mary Rees,mathematics,test
Expanding direction of the period doubling operator,"We prove that the period doubling operator has an expanding direction at the fixed point. We use the induced operator, a ``Perron-Frobenius type operator'', to study the linearization of the period doubling operator at its fixed point. We then use a sequence of linear operators with finite ranks to study this induced operator. The proof is constructive. One can calculate the expanding direction and the rate of expansion of the period doubling operator at the fixed point.",,"Yunping Jiang, Takehiko Morita, Dennis Sullivan",mathematics,train
The Hausdorff dimension of the boundary of the Mandelbrot set and Julia sets,"It is shown that the boundary of the Mandelbrot set $M$ has Hausdorff dimension two and that for a generic $c \in \bM$, the Julia set of $z \mapsto z^2+c$ also has Hausdorff dimension two. The proof is based on the study of the bifurcation of parabolic periodic points.",,Mitsuhiro Shishikura,mathematics,train
Critical circle maps near bifurcation,"We estimate harmonic scalings in the parameter space of a one-parameter family of critical circle maps. These estimates lead to the conclusion that the Hausdorff dimension of the complement of the frequency-locking set is less than $1$ but not less than $1/3$. Moreover, the rotation number is a H\""{o}lder continuous function of the parameter.",,"Jacek Graczyk, Grzegorz Swiatek",mathematics,train
The Teichmüller space of an Anosov diffeomorphism of $T^2$,"In this paper we consider the space of smooth conjugacy classes of an Anosov diffeomorphism of the two-torus. The only 2-manifold that supports an Anosov diffeomorphism is the 2-torus, and Franks and Manning showed that every such diffeomorphism is topologically conjugate to a linear example, and furthermore, the eigenvalues at periodic points are a complete smooth invariant. The question arises: what sets of eigenvalues occur as the Anosov diffeomorphism ranges over a topological conjugacy class? This question can be reformulated: what pairs of cohomology classes (one determined by the expanding eigenvalues, and one by the contracting eigenvalues) occur as the diffeomorphism ranges over a topological conjugacy class? The purpose of this paper is to answer this question: all pairs of H\""{o}lder reduced cohomology classes occur.",,Elise E. Cawley,mathematics,train
Factorizations of natural embeddings of l_p^n int L_r,"This is a continuation of the paper [FJS] with a similar title. Several results from there are strengthened, in particular: 1. If T is a ""natural"" embedding of l_2^n into L_1 then, for any well-bounded factorization of T through an L_1 space in the form T=uv with v of norm one, u well-preserves a copy of l_1^k with k exponential in n. 2. Any norm one operator from a C(K) space which well-preserves a copy of l_2^n also well-preserves a copy of l_{\infty}^k with k exponential in n. As an application of these and other results we show the existence, for any n, of an n-dimensional space which well-embeds into a space with an unconditional basis only if the latter contains a copy of l_{\infty}^k with k exponential in n.",,"Tadek Figiel, William B. Johnson, Gideon Schechtman",mathematics,test
The Rademacher cotype of operators from $l_\infty^N$,"We show that for any operator $T:l_\infty^N\to Y$, where $Y$ is a Banach space, that its cotype 2 constant, $K_2(T)$, is related to its $(2,1)$-summing norm, $\pi_{2,1}(T)$, by $K_2(T) \le c \log\log N \pi_{2,1}(T) $. Thus, we can show that there is an operator $T:C(K)\to Y$ that has cotype 2, but is not 2-summing.",,"Stephen J. Montgomery-Smith, Michel Talagrand",mathematics,train
Operators which factor through Banach lattices not containing c_0,"In this supplement to [GJ1], [GJ3], we give an intrinsic characterization of (bounded, linear) operators on Banach lattices which factor through Banach lattices not containing a copy of $c_0$ which complements the characterization of [GJ1], [GJ3] that an operator admits such a factorization if and only if it can be written as the product of two operators neither of which preserves a copy of $c_0$. The intrinsic characterization is that the restriction of the second adjoint of the operator to the ideal generated by the lattice in its bidual does not preserve a copy of $c_0$. This property of an operator was introduced by C. Niculescu [N2] under the name ``strong type B"".",,"Nassif Ghoussoub, William B. Johnson",mathematics,train
Integral Operators on Spaces of Continuous Vector-valued Functions,"Let $X$ be a compact Hausdorff space, let $E$ be a Banach space, and let $C(X,E)$ stand for the Banach space of $E$-valued continuous functions on $X$ under the uniform norm. In this paper we characterize Integral operators (in the sense of Grothendieck) on $C(X,E)$ spaces in term of their representing vector measures. This is then used to give some applications to Nuclear operators on $C(X,E)$ spaces.",,Paulette Saab,mathematics,val
Nuclear operators on spaces of continuous vector-valued functions,"Let $\Omega$ be a compact Hausdorff space, let $E$ be a Banach space, and let $C(\Omega, E)$ stand for the Banach space of all $E$-valued continuous functions on $\Omega$ under supnorm. In this paper we study when nuclear operators on $C(\Omega, E)$ spaces can be completely characterized in terms of properties of their representing vector measures. We also show that if $F$ is a Banach space and if $T:\ C(\Omega, E)\rightarrow F$ is a nuclear operator, then $T$ induces a bounded linear operator $T^\#$ from the space $C(\Omega)$ of scalar valued continuous functions on $\Omega$ into $\slN(E,F)$ the space of nuclear operators from $E$ to $F$, in this case we show that $E^*$ has the Radon-Nikodym property if and only if $T^\#$ is nuclear whenever $T$ is nuclear.",,"Paulette Saab, Brenda Smith",mathematics,train
Complemented subspaces of spaces obtained by interpolation,"If Z is a quotient of a subspace of a separable Banach space X, and V is any separable Banach space, then there is a Banach couple (A_0,A_1) such that A_0 and A_1 are isometric to $X\oplus V$, and any intermediate space obtained using the real or complex interpolation method contains a complemented subspace isomorphic to Z. Thus many properties of Banach spaces, including having non-trivial cotype, having the Radon-Nikodym property, and having the analytic unconditional martingale difference sequence property, do not pass to intermediate spaces.",,"D. J. H. Garling, Stephen J. Montgomery-Smith",mathematics,val
Permutations of the Haar system,"General permutations acting on the Haar system are investigated. We give a necessary and sufficient condition for permutations to induce an isomorphism on dyadic BMO. Extensions of this characterization to Lipschitz spaces $\lip, (0<p\leq1)$ are obtained. When specialized to permutations which act on one level of the Haar system only, our approach leads to a short straightforward proof of a result due to E.M.Semyonov and B.Stoeckert.",,Paul F. X. Müller,mathematics,val
On the complemented subspaces of X_p,In this paper we prove some results related to the problem of isomorphically classifying the complemented subspaces of $X_{p}$. We characterize the complemented subspaces of $X_{p}$ which are isomorphic to $X_{p}$ by showing that such a space must contain a canonical complemented subspace isomorphic to $X_{p}.$ We also give some characterizations of complemented subspaces of $X_{p}$ isomorphic to $\ell_{p}\oplus \ell_{2}.$,,Dale E. Alspach,mathematics,train
p-summing operators on injective tensor products of spaces,"Let $X,Y$ and $Z$ be Banach spaces, and let $\prod_p(Y,Z) (1\leq p<\infty)$ denote the space of $p$-summing operators from $Y$ to $Z$. We show that, if $X$ is a {\it \$}$_\infty$-space, then a bounded linear operator $T: X\hat \otimes_\epsilon Y\longrightarrow Z$ is 1-summing if and only if a naturally associated operator $T^#: X\longrightarrow \prod_1(Y,Z)$ is 1-summing. This result need not be true if $X$ is not a {\it \$}$_\infty$-space. For $p>1$, several examples are given with $X=C[0,1]$ to show that $T^#$ can be $p$-summing without $T$ being $p$-summing. Indeed, there is an operator $T$ on $C[0,1]\hat \otimes_\epsilon \ell_1$ whose associated operator $T^#$ is 2-summing, but for all $N\in \N$, there exists an $N$-dimensional subspace $U$ of $C[0,1]\hat \otimes_\epsilon \ell_1$ such that $T$ restricted to $U$ is equivalent to the identity operator on $\ell^N_\infty$. Finally, we show that there is a compact Hausdorff space $K$ and a bounded linear operator $T:\ C(K)\hat \otimes_\epsilon \ell_1\longrightarrow \ell_2$ for which $T^#:\ C(K)\longrightarrow \prod_1(\ell_1, \ell_2)$ is not 2-summing.",,"Stephen J. Montgomery-Smith, Paulette Saab",mathematics,train
Some deviation inequalities,"We introduce a concentration property for probability measures on $\scriptstyle{R^n}$, which we call Property~($\scriptstyle\tau$); we show that this property has an interesting stability under products and contractions (Lemmas 1,~2,~3). Using property~($\scriptstyle\tau$), we give a short proof for a recent deviation inequality due to Talagrand. In a third section, we also recover known concentration results for Gaussian measures using our approach.}",,Bernard Maurey,mathematics,train
Simple proofing of Jordan's theorem,Here is present short proofing of Jordan's theorem about dividing of flat on two disjoint subsets by one closed curve.,"1 page, 1 picture",Oleg V. Goodyckov,mathematics,val
"A Concise and Direct Proof of ""Fermat's Last Theorem""","The recently developed proof of Fermat's Last Theorem is very lengthy and difficult, so much so as to be beyond all but a small body of specialists. While certainly of value in the developments that resulted, that proof could not be, nor was offered as being, possibly the proof Fermat had in mind. The present proof being brief, direct and concise is a candidate for being what Fermat had in mind. It is also completely accessible to any one trained in common algebra. That critical suggestions offered by significant mathematics authorities have been unable to invalidate this concise and direct proof would tend to be major confirmation that: The proof stands, valid and not validly challenged.","4 pages. Changes are correction of typographical errors and clearer
  presentation of latter part. http://www.The-Origin.org",Roger Ellman,mathematics,val
The Theory of Ultralogics Part I,"As of the date of this version, this monograph (parts I and II) contains all of the known technical results relative to the Robinson-styled nonstandard modeling of natural languages and certain associated linguistic processes such as deduction via consequence operators among other concepts. These results have direct application to the construction of the GGU-model, the GID-model, the GD-model, the MA-model and also apply to philosophy, psychology, properton theory and other aspects of the Nonstandard Physical World (NSP-world).","Nonstandard Analysis. Part I is composed of sections 1 - 6 inclusive.
  Plain Tex, pages 1 - 60, duplex reproduction format. For details of an
  application to a solution to the General Grand Unification problem see
  http://arxiv.org/abs/astro-ph/9903110 Following Robinson, the foundations
  have been altered by adding the set of all words to the ground set",Robert A. Herrmann,mathematics,train
The Theory of Ultralogics Part II,"As of this date of this version, this monograph (part I and II) contains most of the technical results relative to the Robinson-styled nonstandard modeling of natural languages and certain associated linguistic processes such as deduction via consequence operators among other concepts. These results have direct application to the construction of the GGU-model, GID-model, D-world model, MA-model and also apply to philosophy, psychology, properton theory and other aspects of the Nonstandard Physical World (NSP-world).","Nonstandard Analysis. Part II is composed of sections 7 - 11. Plain
  Tex, pages 61 - 130, duplex reproduction format. For part I, see
  http://xxx.lanl.gov/abs/math.GM/9903081 In this version, a major font error
  is corrected and section 11.3 is completely revised with simplifications.
  arXiv admin note: substantial text overlap with arXiv:astro-ph/9903110",Robert A. Herrmann,mathematics,val
Riemann Hypothesis,"Through an equivalent condition on the Farey series set forth by Franel and Landau, we prove Riemann Hypothesis for the Riemann zeta-function and the Dirichlet L-function.",7 pages,Chengyan Liu,mathematics,train
Sieve Method and Landau Problem,"We solve Landau's four unattackable problems, including Goldbach Conjecture and Twin Prime Conjecture through sieve method.",6 pages,Chengyan Liu,mathematics,val
Tactical games & behavioral self-organization,"The interactive game theoretical approach to tactics and behavioral self-organization is developed. Though it uses the interactive game theoretical formalization of dialogues as psycholinguistic phenomena, the crucial role is played by the essentially new concept of a tactical game. Applications to the perception processes and related subjects (memory, recollection, image understanding, imagination) are discussed together with relations to the computer vision and pattern recognition (the dynamical formation of patterns and perception models during perception as a result of its self-organization) and computer games (modelling of the tactical behavior and self-organization, tactical RPG and elaboration of new tactical game techniques). The appendix is devoted to the operative computer games and the user programming of operative units in a multi-user online operative computer game.","AMSTEX, 17 pages",Denis V. Juriev,mathematics,train
A counting method for finding rational approximates to arbitrary order roots of integers,"It is shown that for finding rational approximates to m'th root of any integer to any accuracy one only needs the ability to count and to distinguish between m different classes of objects. To every integer N can be associated a 'replacement rule' that generates a word W* from another word W consisting of symbols belonging to a finite 'alphabet' of size m. This rule applied iteratively on almost any initial word W0, yields a sequence of words {Wi} such that the relative frequency of different symbols in the word Wi approaches powers of the m'th root of N as i tends to infinity",,"Ashok Kumar Gupta, Ashok Kumar Mittal",mathematics,train
A `replacement sequence' method for finding the largest real root of an integer monic polynomial,"To every integer monic polynomial of degree m can be associated a `replacement rule' that generates a word W* from another word W consisting of symbols belonging to a finite `alphabet' of size 2m. This rule applied iteratively on almost any initial word Wo, yields a sequence of words {Wi}. From acount of different symbols in the word Wi, one can obtain a rational approximate to the largest real root of the polynomial.","4 pages, no figures","A. K. Gupta, A. K. Mittal",mathematics,train
Simple Divisibility Rules for the 1st 1000 Prime Numbers,Simple divisibility rules are given for the 1st 1000 prime numbers.,14 pages,C. C. Briggs,mathematics,train
"Another homogeneous, non-bihomogeneous Peano continuum","K. Kuperberg found a locally connected, finite-dimensional continuum which is homogeneous but not bihomogeneous. We give a similar but simpler example. Like previous constructions, the example is locally a Cartesian product of Menger spaces. The new idea is to choose a fundamental group in which not every element is conjugate to its inverse.",3 pages,Greg Kuperberg,mathematics,train
A hereditarily indecomposable tree-like continuum without the fixed point property,A hereditarily indecomposable tree-like continuum without the fixed point property is constructed. The example answers a question of Knaster and Bellamy.,16 pages,Piotr Minc,mathematics,train
More on sg-compact spaces,"The aim of this paper is to continue the study of sg-compact spaces, a topological notion much stronger than hereditary compactness. We investigate the relations between sg-compact and $C_2$-spaces and the interrelations to hereditarily sg-closed sets.",8 pages,"Julian Dontchev, Maximilian Ganster",mathematics,train
What is supertopology?,"We discuss the problem of finding an analogue of the concept of a topological space in supergeometry, motivated by a search for a procedure to compactify a supermanifold along odd coordinates. In particular, we examine the topologies naturally arising on the sets of points of locally ringed superspaces, and show that in the presence of a nontrivial odd sector such topologies are never compact. The main outcome of our discussion is that not only the usual framework of supergeometry (the theory of locally ringed spaces), but the more general approach of the functor of points, need to be further enlarged.","30 pages, LaTeX 2e","Ugo Bruzzo, Vladimir Pestov",mathematics,train
Some covering properties of the $α$-topology,"Recently, Mr\v{s}evi\'{c} and Reilly discussed some covering properties of a topological space and its associated $\alpha$-topology in both topological and bitopological ways. The main aim of this paper is to investigate some common and controversial covering properties of $\cal T$ and ${\cal T}^{\alpha}$.",11 pages,"Francisco G. Arenas, Jiling Cao, Julian Dontchev, Maria Luz Puertas",mathematics,val
Unification approach to the separation axioms between $T_0$ and completely Hausdorff,"The aim of this paper is to introduce a new weak separation axiom that generalizes the separation properties between $T_1$ and completely Hausdorff. We call a topological space $(X,\tau)$ a $T_{\kappa,\xi}$-space if every compact subset of $X$ with cardinality $\leq \kappa$ is $\xi$-closed, where $\xi$ is a general closure operator. We concentrate our attention mostly on two new concepts: kd-spaces and $T_{1/3}$-spaces.",11 pages,"Francisco G. Arenas, Julian Dontchev, Maria Luz Puertas",mathematics,train
Idealization of some weak separation axioms,"An ideal is a nonempty collection of subsets closed under heredity and finite additivity. The aim of this paper is to unify some weak separation properties via topological ideals. We concentrate our attention on the separation axioms between $T_0$ and $T_2$. We prove that if $(X,\tau,{\cal I})$ is a semi-Alexandroff $T_{\cal I}$-space and $\cal I$ is a $\tau$-boundary, then $\cal I$ is completely codense.",9 pages,"Francisco G. Arenas, Julian Dontchev, Maria Luz Puertas",mathematics,val
A remark on $β$-locally closed sets,"The aim of this note is to show that every subset of a given topological space is the intersection of a preopen and a preclosed set, therefore $\beta$-locally closed, and that every topological space is $\beta$-submaximal.","Mem. Fac. Sci. Kochi Univ. Ser. A Math., 20 (1999), to appear","Julian Dontchev, Maximilian Ganster",mathematics,train
An answer to a question of Coleman on scattered sets,"The aim of this paper is to show that every scattered subset of a dense-in-itself semi-$T_D$-space is nowhere dense. We are thus able to answer a recent question of Coleman in the affirmative. In terms of Digital Topology, we prove that in semi-$T_D$-spaces with no open screen, trace spaces have no consolidations.",5 pages,"Julian Dontchev, Maximilian Ganster",mathematics,train
On p-closed spaces,In this paper we will continue the study of p-closed spaces. This class of spaces is strictly placed between the class of strongly compact spaces and the class of quasi-H-closed spaces. We will provide new characterizations of p-closed spaces and investigate their relationships with some other classes of topological spaces.,,"Julian Dontchev, Maximilian Ganster, Takashi Noiri",mathematics,train
Efficient representation of perm groups,"This note presents an elementary version of Sims's algorithm for computing strong generators of a given perm group, together with a proof of correctness and some notes about appropriate low-level data structures. Upper and lower bounds on the running time are also obtained. (Following a suggestion of Vaughan Pratt, we adopt the convention that perm $=$ permutation, perhaps thereby saving millions of syllables in future research.)",,Donald E. Knuth,mathematics,train
"The 1-, 2-, and 3-characters determine a group","A set of invariants for a finite group is described. These arise naturally from Frobenius' early work on the group determinant and provide an answer to a question of Brauer. Whereas it is well known that the ordinary character table of a group does not determine the group uniquely, it is a consequence of the results presented here that a group is determined uniquely by its ``3-character'' table.",3 pages,"Hans-Jürgen Hoehnke, Kenneth W. Johnson",mathematics,train
On the Burnside problem on periodic groups,"It is proved that the free $m$-generated Burnside groups $\Bbb{B}(m,n)$ of exponent $n$ are infinite provided that $m>1$, $n\ge2^{48}$.",4 pages,Sergei V. Ivanov,mathematics,train
Musings on Magnus,"The object of this paper is to describe a simple method for proving that certain groups are residually torsion-free nilpotent, to describe some new parafree groups and to raise some new problems in honour of the memory of Wilhelm Magnus.","AMS-Tex, 8 pages, no figures. To appear in Trans. Am. Math. Soc",Gilbert Baumslag,mathematics,val
"(p,q,r)-Generations for Janko Groups $J_1$ and $J_2$",No abstract is available,"AMS-LaTex, 8 pages, no figures",Jamshid Moori,mathematics,val
Almost Convex Groups and the Eight Geometries,"If $M$ is a closed Nil geometry 3-manifold then $\pi_1(M)$ is almost convex with respect to a fairly simple ``geometric'' generating set. If $G$ is a central extension or a ${\Bbb Z}$-extension of a word hyperbolic group, then $G$ is also almost convex with respect to some generating set. Combining these with previously known results shows that if $M$ is a closed 3-manifold with one of Thurston's eight geometries, $\pi_1(M)$ is almost convex with respect to some generating set if and only if the geometry in question is not Sol.","Plain Tex, 14 pages, no figures","Michael Shapiro, Melany Stein",mathematics,train
Sur un generalisation del notion de producto libere amalgamate de gruppos,"In ``A remark about the description of free products of groups'', Proc. Cambgridge Philos. Soc 62(1966), io ha studite lo que occurre in le circumstantia que un gruppo $G$ ha un subensemble $P$ tal que tote elemento de $G$ es representabile unicamente per un verbo reducite in $P$. Il eveni que tal $P$ es multo como un producto libere. Que occurre quando le representation per verbo reducite es unic solmente modulo le sorta de equivalentia que interveni in le theoria del productos libere amalgamate? In iste articulo, io determina le structura internal del subensemble $P$ (io los appella ``pregruppos''), e prova, sequente le methodo de van der Waerden, que su gruppo universal ha le proprietate desiderate. Multe interessante exemplos pote esser trovate; tote semble simile aliquanto al productos libere amalgamate; sed il es nulle simple maniera de construer los omne ex ordinari tal productos.","AMS-Tex, 10 pages, no figures",John R. Stallings,mathematics,val
A note on Context Sensitive languages and Word Problems,"Anisimov and Seifert show that a group has a regular word problem ifand only if it is finite. Muller and Schupp (together with Dunwoody's accessibility result) show that a group has context free word problem if and only if it is virtually free. In this note, we exhibit a class of groups where the word problem is as close as possible to being a context sensitive language. This class includes the automatic groups and is closed under passing to finitely generated subgroups. Consequently, it is quite large, including many groups which are not finitely presented.","AMS-Tex, 3 pages, no figures",Michael Shapiro,mathematics,train
Automatic structures and boundaries for graphs of groups,"We study the synchronous and asynchronous automatic structures on the fundamental group of a graph of groups in which each edge group is finite. Up to a natural equivalence relation, the set of biautomatic structures on such a graph product bijects to the product of the sets of biautomatic structures on the vertex groups. The set of automatic structures is much richer. Indeed, it is dense in the infinite product of the sets of automatic structures of all conjugates of the vertex groups. We classify these structures by a class of labelled graphs which ``mimic"" the underlying graph of the graph of groups. Analogous statements hold for asynchronous automatic structures. We also discuss the boundaries of these structures.","Plain Tex, 24 pages, no figures","Walter D. Neumann, Michael Shapiro",mathematics,train
The Bieri-Neumann-Strebel invariants for graph groups,"Given a finite simplicial graph ${\cal G}$, the graph group $G{\cal G}$"" is the group with generators in one-to-one correspondence with the vertices of ${\cal G}$ and with relations stating two generators commute if their associated vertices are adjacent in ${\cal G}$. The Bieri-Neumann-Strebel invariant can be explicitly described in terms of the original graph ${\cal G}$ and hence there is an explicit description of the distribution of finitely generated normal subgroups of $G{\cal G}$ with abelian quotient. We construct Eilenberg-MacLane spaces for graph groups and find partial extensions of this work to the higher dimensional invariants.","Plain Tex, 19 pages, no figures","John Meier, Leonard Vanwyk",mathematics,train
Möbius invariance of knot energy,"A physically natural potential energy for simple closed curves in $\bold R^3$ is shown to be invariant under M\""obius transformations. This leads to the rapid resolution of several open problems: round circles are precisely the absolute minima for energy; there is a minimum energy threshold below which knotting cannot occur; minimizers within prime knot types exist and are regular. Finally, the number of knot types with energy less than any constant $M$ is estimated.",5 pages,"Steve Bryson, Michael H. Freedman, Zheng-Xu He, Zhenghan Wang",mathematics,val
New points of view in knot theory,"In this article we shall give an account of certain developments in knot theory which followed upon the discovery of the Jones polynomial in 1984. The focus of our account will be recent glimmerings of understanding of the topological meaning of the new invariants. A second theme will be the central role that braid theory has played in the subject. A third will be the unifying principles provided by representations of simple Lie algebras and their universal enveloping algebras. These choices in emphasis are our own. They represent, at best, particular aspects of the far-reaching ramifications that followed the discovery of the Jones polynomial.",35 pages. Abstract added in migration.,Joan S. Birman,mathematics,train
Topology of homology manifolds,"We construct examples of nonresolvable generalized $n$-manifolds, $n\geq 6$, with arbitrary resolution obstruction, homotopy equivalent to any simply connected, closed $n$-manifold. We further investigate the structure of generalized manifolds and present a program for understanding their topology.",5 pages,"John L. Bryant, Steven C. Ferry, Washington Mio, Shmuel Weinberger",mathematics,val
Quasipositivity as an obstruction to sliceness,"For an oriented link $L \subset S^3 = \Bd\!D^4$, let $\chi_s(L)$ be the greatest Euler characteristic $\chi(F)$ of an oriented 2-manifold $F$ (without closed components) smoothly embedded in $D^4$ with boundary $L$. A knot $K$ is {\it slice} if $\chi_s(K)=1$. Realize $D^4$ in $\C^2$ as $\{(z,w):|z|^2+|w|^2\le1\}$. It has been conjectured that, if $V$ is a nonsingular complex plane curve transverse to $S^3$, then $\chi_s(V\cap S^3)=\chi(V\cap D^4)$. Kronheimer and Mrowka have proved this conjecture in the case that $V\cap D^4$ is the Milnor fiber of a singularity. I explain how this seemingly special case implies both the general case and the ``slice-Bennequin inequality'' for braids. As applications, I show that various knots are not slice (e.g., pretzel knots like $\Pscr(-3,5,7)$; all knots obtained from a positive trefoil $O\{2,3\}$ by iterated untwisted positive doubling). As a sidelight, I give an optimal counterexample to the ``topologically locally-flat Thom conjecture''.",9 pages,Lee Rudolph,mathematics,val
Alexander's and Markov's theorems in dimension four,Alexander's and Markov's theorems state that any link type in $R^3$ is represented by a closed braid and that such representations are related by some elementary operations called Markov moves. We generalize the notion of a braid to that in 4-dimensional space and establish an analogue of these theorems.,4 pages,Seiichi Kamada,mathematics,train
Extremal length estimates and product regions in Teichmüller space,"We study the Teichm\""uller metric on the Teichm\""uller space of a surface of finite type, in regions where the injectivity radius of the surface is small. The main result is that in such regions the Teichm\""uller metric is approximated up to bounded additive distortion by the sup metric on a product of lower dimensional spaces. The main technical tool in the proof is the use of estimates of extremal lengths of curves in a surface based on the geometry of their hyperbolic geodesic representatives.",,Yair Minsky,mathematics,val
A User's Guide to the Mapping Class Group: Once Punctured Surfaces,"This document is a practical guide to computations using an automatic structure for the mapping class group of a once-punctured, oriented surface $S$. We describe a quadratic time algorithm for the word problem in this group, which can be implemented efficiently with pencil and paper. The input of the algorithm is a word, consisting of ``chord diagrams'' of ideal triangulations and elementary moves, which represents an element of the mapping class group. The output is a word called a ``normal form'' that uniquely represents the same group element.",,Lee Mosher,mathematics,test
Exceptional surgery on knots,"Let $M$ be an irreducible, compact, connected, orientable 3-manifold whose boundary is a torus. We show that if $M$ is hyperbolic, then it admits at most six finite/cyclic fillings of maximal distance 5. Further, the distance of a finite/cyclic filling to a cyclic filling is at most 2. If $M$ has a non-boundary-parallel, incompressible torus and is not a generalized 1-iterated torus knot complement, then there are at most three finite/cyclic fillings of maximal distance 1. Further, if $M$ has a non-boundary-parallel, incompressible torus and is not a generalized 1- or 2-iterated torus knot complement and if $M$ admits a cyclic filling of odd order, then $M$ does not admit any other finite/cyclic filling. Relations between finite/cyclic fillings and other exceptional fillings are also discussed.",7 pages,"Steven Boyer, Xingru Zhang",mathematics,val
On the geometric and topological rigidity of hyperbolic 3-manifolds,A homotopy equivalence between a hyperbolic 3-manifold and a closed irreducible 3-manifold is homotopic to a homeomorphsim provided the hyperbolic manifold satisfies a purely geometric condition. There are no known examples of hyperbolic 3-manifolds which do not satisfy this condition.,5 pages,David Gabai,mathematics,train
The Structure and Enumeration of Link Projections,We define a decomposition of link projections whose pieces we call atoroidal graphs. We describe a surgery operation on these graphs and show that all atoroidal graphs can be generated by performing surgery repeatedly on a family of well known link projections. This gives a method of enumerating atoroidal graphs and hence link projections by recomposing the pieces of the decomposition.,,Martin Bridgeman,mathematics,val
Editors' remarks (on two complexity theory surveys in the Bulletin),"The authors discuss the role of controversy in mathematics as a preface to two opposing articles on computational complexity theory: ""Some basic information on information-based complexity theory"" by Beresford Parlett [math.NA/9201266] and ""Perspectives on information-based complexity"" by J. F. Traub and Henryk Wo\'zniakowski [math.NA/9201269].",2 pages. Abstract added in migration.,"Morris W. Hirsch, Richard S. Palais",mathematics,train
Two notes on notation,"The author advocates two specific mathematical notations from his popular course and joint textbook, ""Concrete Mathematics"". The first of these, extending an idea of Iverson, is the notation ""[P]"" for the function which is 1 when the Boolean condition P is true and 0 otherwise. This notation can encourage and clarify the use of characteristic functions and Kronecker deltas in sums and integrals. The second notation puts Stirling numbers on the same footing as binomial coefficients. Since binomial coefficients are written on two lines in parentheses and read ""n choose k"", Stirling numbers of the first kind should be written on two lines in brackets and read ""n cycle k"", while Stirling numbers of the second kind should be written in braces and read ""n subset k"". (I might say ""n partition k"".) The written form was first suggested by Imanuel Marx. The virtues of this notation are that Stirling partition numbers frequently appear in combinatorics, and that it more clearly presents functional relations similar to those satisfied by binomial coefficients.",Abstract added by Greg Kuperberg,Donald E. Knuth,mathematics,test
``Theoretical mathematics'': Toward a cultural synthesis of mathematics and theoretical physics,"Is speculative mathematics dangerous? Recent interactions between physics and mathematics pose the question with some force: traditional mathematical norms discourage speculation, but it is the fabric of theoretical physics. In practice there can be benefits, but there can also be unpleasant and destructive consequences. Serious caution is required, and the issue should be considered before, rather than after, obvious damage occurs. With the hazards carefully in mind, we propose a framework that should allow a healthy and positive role for speculation.",13 pages,"Arthur Jaffe, Frank Quinn",mathematics,train
"Responses to ``Theoretical Mathematics: Toward a cultural synthesis of mathematics and theoretical physics'', by A. Jaffe and F. Quinn",This article is a collection of letters solicited by the editors of the Bulletin in response to a previous article by Jaffe and Quinn [math.HO/9307227]. The authors discuss the role of rigor in mathematics and the relation between mathematics and theoretical physics.,30 pages. Abstract added in migration.,"Michael Atiyah, Armand Borel, G. J. Chaitin, Daniel Friedan, James Glimm, Jeremy J. Gray, Morris W. Hirsch, Saunder MacLane, Benoit B. Mandelbrot, David Ruelle, Albert Schwarz, Karen Uhlenbeck, René Thom, Edward Witten, Christopher Zeeman",mathematics,train
Response to comments on ``Theoretical mathematics'',"The authors discuss various objections and rejoinders in the collected responses [math.HO/9404229,math.HO/9404236] to their original article on the relationship between mathematics and theoretical physics [math.HO/9307227].",4 pages. Abstract added in migration.,"Arthur Jaffe, Frank Quinn",mathematics,train
Editor's column (on an article by Jaffe and Quinn),"This note is a preface to various responses [math.HO/9404229,math.HO/9404236] to an opinion piece by Jaffe and Quinn [math.HO/9307227] on the relationship between mathematics and theoretical physics.",2 pages. Abstract added in migration.,Richard S. Palais,mathematics,train
On proof and progress in mathematics,"In response to Jaffe and Quinn [math.HO/9307227], the author discusses forms of progress in mathematics that are not captured by formal proofs of theorems, especially in his own work in the theory of foliations and geometrization of 3-manifolds and dynamical systems.",17 pages. Abstract added in migration.,William P. Thurston,mathematics,val
Electronic Mathematics Journals,"In the Forum section of the November, 1993 Notices of the American Mathematical Society, John Franks discussed the electronic journal of the future. Since then, the New York Journal of Mathematics, the first electronic general mathematics journal, has begun publication. In this article, we explore the issues of electronic journal publishing in the context of this new project. We also discuss future developments.","7 pages, latex, nyj class",Mark Steinberger,mathematics,train
Mathematics Journals Should Be Electronic and Free,"Many important journal functions would be lost if the mathematical community replaced all paper journals with electronic media. Electronic media are useful for some purposes, but they will not be the basis for a publishing revolution in the near future.","Submitted by proxy with permission from the author. The original is
  available at http://www.ams.org/notices/199708/page2.html",Steven G. Krantz,mathematics,val
"Interactive games, dialogues and the verbalization","The note is devoted to an interactive game theoretic formalization of dialogues as psycholinguistic phenomena and the unraveling of a hidden dialogue structure of 2-person differential interactive games. In the field-theoretic description of interactive games the dialogues are defined naively as interactive games of discrete time with intention fields of continuous time; the correct mathematical formulation is proposed. The states and the controls of a dialogue correspond to the speech whereas the intention fields describe the understanding. In the case of dialogues the main inverse problem is to describe geometrical and algebraical properties of the understanding. On the other hand, a precise mathematical definition of dialogues allows to formulate a problem of the unraveling of a hidden dialogue structure of any 2-person differential interactive game. Such procedure is called the verbalization. It means that the states of a differential interactive game are interpreted as intention fields of a hidden dialogue and the problem is to describe such dialogue completely. If a 2-person differential interactive game is verbalizable one is able to consider many linguistic (e.g. the formal grammar of a related hidden dialogue) or psycholinguistic (e.g. the dynamical correlation of various implications) aspects of it.",,Denis V. Juriev,mathematics,test
On Bounded-Weight Error-Correcting Codes,"This paper computationally obtains optimal bounded-weight, binary, error-correcting codes for a variety of distance bounds and dimensions. We compare the sizes of our codes to the sizes of optimal constant-weight, binary, error-correcting codes, and evaluate the differences.","10 pages, 3 tables","Russell Bent, Michael Schear, Lane A. Hemaspaandra, Gabriel Istrate",computer science,train
Long Nonbinary Codes Exceeding the Gilbert - Varshamov Bound for any Fixed Distance,"Let A(q,n,d) denote the maximum size of a q-ary code of length n and distance d. We study the minimum asymptotic redundancy \rho(q,n,d)=n-log_q A(q,n,d) as n grows while q and d are fixed. For any d and q<=d-1, long algebraic codes are designed that improve on the BCH codes and have the lowest asymptotic redundancy \rho(q,n,d) <= ((d-3)+1/(d-2)) log_q n known to date. Prior to this work, codes of fixed distance that asymptotically surpass BCH codes and the Gilbert-Varshamov bound were designed only for distances 4,5 and 6.",Submitted to IEEE Trans. on Info. Theory,"Sergey Yekhanin, Ilya Dumer",computer science,train
On Expanders Graphs: Parameters and Applications,"We give a new lower bound on the expansion coefficient of an edge-vertex graph of a $d$-regular graph. As a consequence, we obtain an improvement on the lower bound on relative minimum distance of the expander codes constructed by Sipser and Spielman. We also derive some improved results on the vertex expansion of graphs that help us in improving the parameters of the expander codes of Alon, Bruck, Naor, Naor, and Roth.","Submitted to SIAM J. DAM on Feb. 1, 2001",H. L. Janwa A. K. Lal,computer science,train
Improved error bounds for the erasure/list scheme: the binary and spherical cases,We derive improved bounds on the error and erasure rate for spherical codes and for binary linear codes under Forney's erasure/list decoding scheme and prove some related results.,"18 pages, 3 figures. Submitted to IEEE Transactions on Informatin
  Theory in May 2001, will appear in Oct. 2004 (tentative)",Alexander Barg,computer science,val
Distance distribution of binary codes and the error probability of decoding,"We address the problem of bounding below the probability of error under maximum likelihood decoding of a binary code with a known distance distribution used on a binary symmetric channel. An improved upper bound is given for the maximum attainable exponent of this probability (the reliability function of the channel). In particular, we prove that the ``random coding exponent'' is the true value of the channel reliability for code rate $R$ in some interval immediately below the critical rate of the channel. An analogous result is obtained for the Gaussian channel.","16 pages, 3 figures. Submitted to IEEE Transactions on Information
  Theory. The revision was done for a final journal version (it may still be
  different from the published version)","Alexander Barg, Andrew McGregor",computer science,train
Iterative Quantization Using Codes On Graphs,"We study codes on graphs combined with an iterative message passing algorithm for quantization. Specifically, we consider the binary erasure quantization (BEQ) problem which is the dual of the binary erasure channel (BEC) coding problem. We show that duals of capacity achieving codes for the BEC yield codes which approach the minimum possible rate for the BEQ. In contrast, low density parity check codes cannot achieve the minimum rate unless their density grows at least logarithmically with block length. Furthermore, we show that duals of efficient iterative decoding algorithms for the BEC yield efficient encoding algorithms for the BEQ. Hence our results suggest that graphical models may yield near optimal codes in source coding as well as in channel coding and that duality plays a key role in such constructions.",10 pages,"Emin Martinian, Jonathan S. Yedidia",computer science,train
Improved Upper Bound for the Redundancy of Fix-Free Codes,"A variable-length code is a fix-free code if no codeword is a prefix or a suffix of any other codeword. In a fix-free code any finite sequence of codewords can be decoded in both directions, which can improve the robustness to channel noise and speed up the decoding process. In this paper we prove a new sufficient condition of the existence of fix-free codes and improve the upper bound on the redundancy of optimal fix-free codes.",,Sergey Yekhanin,computer science,train
The Dynamics of Group Codes: Dual Abelian Group Codes and Systems,"Fundamental results concerning the dynamics of abelian group codes (behaviors) and their duals are developed. Duals of sequence spaces over locally compact abelian groups may be defined via Pontryagin duality; dual group codes are orthogonal subgroups of dual sequence spaces. The dual of a complete code or system is finite, and the dual of a Laurent code or system is (anti-)Laurent. If C and C^\perp are dual codes, then the state spaces of C act as the character groups of the state spaces of C^\perp. The controllability properties of C are the observability properties of C^\perp. In particular, C is (strongly) controllable if and only if C^\perp is (strongly) observable, and the controller memory of C is the observer memory of C^\perp. The controller granules of C act as the character groups of the observer granules of C^\perp. Examples of minimal observer-form encoder and syndrome-former constructions are given. Finally, every observer granule of C is an ""end-around"" controller granule of C.","30 pages, 11 figures. To appear in IEEE Trans. Inform. Theory, 2004","G. David Forney Jr., Mitchell D. Trott",computer science,train
Source Coding With Distortion Side Information At The Encoder,"We consider lossy source coding when side information affecting the distortion measure may be available at the encoder, decoder, both, or neither. For example, such distortion side information can model reliabilities for noisy measurements, sensor calibration information, or perceptual effects like masking and sensitivity to context. When the distortion side information is statistically independent of the source, we show that in many cases (e.g, for additive or multiplicative distortion side information) there is no penalty for knowing the side information only at the encoder, and there is no advantage to knowing it at the decoder. Furthermore, for quadratic distortion measures scaled by the distortion side information, we evaluate the penalty for lack of encoder knowledge and show that it can be arbitrarily large. In this scenario, we also sketch transform based quantizers constructions which efficiently exploit encoder side information in the high-resolution limit.","10 pages, 3 figures","Emin Martinian, Gregory W. Wornell, Ram Zamir",computer science,val
Shannon meets Wiener II: On MMSE estimation in successive decoding schemes,"We continue to discuss why MMSE estimation arises in coding schemes that approach the capacity of linear Gaussian channels. Here we consider schemes that involve successive decoding, such as decision-feedback equalization or successive cancellation.","9 pages, 5 figures. To appear in Proc. 2004 Allerton Conf.
  (Monticello, IL), Sept. 2004; final version",G. David Forney Jr,computer science,train
A Comparison of Continuously Controlled and Controlled K-theory,"We define an unreduced version of the e-controlled lower $K$-theoretic groups of Ranicki and Yamasaki, and Quinn. We show that the reduced versions of our groups coincide (in the inverse limit and its first derived, $\lim^1$) with those of Ranicki and Yamasaki. We also relate the controlled groups to the continuously controlled groups of Anderson and Munkholm, and to the Quinn homology groups of Quinn.",,"Douglas R. Anderson, Francis X. Connolly, Hans J. Munkholm",mathematics,train
Cohomology of uniformly powerful p-groups,"Studies the cohomology of p-central, powerful, p-groups with a certain extension property. These groups are naturally associated to Lie algebras. The paper develops a machinery that calculates the first few terms of the Bockstein spectral sequence in terms of the associated Lie algebras. This is then used to obtain results on the integral cohomology of these groups.",,"William Browder, Jonathan Pakianathan",mathematics,train
Lifting Lie algebras over the residue field of a discrete valuation ring,"Studies among other things, the question of whether a Lie algebra over Z/(p^k)Z lifts to one over Z/(p^(k+1))Z. An obstruction theory is developed and examples of Fp-Lie algebras which don't lift to Lie algebras over Z/p^2Z are discussed. An example of an application of the result: A Fp-Lie algebra L with H^3(L, ad)=0 will lift to a p-adic Lie algebra.",,"William Browder, Jonathan Pakianathan",mathematics,test
Analytic cyclic cohomology,"We prove excision in entire and periodic cyclic cohomology and construct a Chern-Connes character for Fredholm modules over a C*-algebra without summability restrictions, taking values in a variant of Connes's entire cyclic cohomology. Before these results can be obtained, we have to sort out some fundamental questions about the class of algebras on which to define entire cyclic cohomology. The right domain of definition for entire cyclic cohomology is the category of complete bornological algebras. For these algebras, we define a bivariant cohomology theory, called analytic cyclic cohomology, that contains Connes's entire cyclic cohomology as a special case. The definition of analytic cyclic cohomology is based on the Cuntz-Quillen approach to cyclic cohomology theories using tensor algebras and X-complexes. The appropriate completion of the tensor algebra that yields analytic cyclic cohomology can be understood using an appropriate notion of analytic nilpotence. In addition, we develop the elementary theory of analytic cyclic cohomology (smooth homotopy invariance, stability, Chern character in K-theory).","112 pages This is my thesis prepared under the supervision of Joachim
  Cuntz at the Universitaet Muenster",Ralf Meyer,mathematics,train
On the K-theory of local fields,"The authors establish a connection between the Quillen K-theory of certain local fields and the de Rham-Witt complex of their rings of integers with logarithmic poles at the maximal ideal. They consider fields K that are complete discrete valuation fields of characteristic zero with perfect residue fields k of characteristic p > 2. They evaluate the K-theory with Z/p^v-coefficients of K, and verify the Lichtenbaum-Quillen conjecture for K.","Abstract added in migration; 113 pages, published version","Lars Hesselholt, Ib Madsen",mathematics,train
Infinitesimal K-theory,"In this paper we study the fiber F of the rational Jones-Goodwillie character $$ F:=\hofiber(ch:K^\rat(A)@>>>HN^\rat(A)) $$ going from K-theory to negative cyclic homology of associative rings. We describe this fiber F in terms of sheaf cohomology. We prove that, for $n\ge 1$, there is an isomorphism: $$ \pi_n(F)\cong H^{-n}_{inf}(A,K^\rat) $$ between the homotopy of the fiber and the hypercohomology groups of $K^\rat$ on a non-commutative version of Grothendieck's infinitesimal site.","31 pages, uses xy macros",Guillermo Cortiñas,mathematics,val
Cyclic homology of commutative algebras over general ground rings,"We consider commutative algebras and chain DG algebras over a fixed commutative ground ring $k$ as in the title. We are concerned with the problem of computing the cyclic (and Hochschild) homology of such algebras via free DG-resolutions $\Lambda V @>>> A$. We find spectral sequences $$E^2_{p,q}=H_p(\Lambda V\otimes\Gamma^q(dV))\Rightarrow HH_{p+q}(\Lambda V)$$ and $${E'}^2_{\pq}=H_p(\Lambda V\otimes\Gamma^{\le q}(dV)) \Rightarrow HC_{p+q}(\Lambda V)$$ The algebra $\Lambda V\otimes\Gamma(dV)$ is a divided power version of the de Rham algebra; in the particular case when $k$ is a field of characteristic zero, the spectral sequences above agree with those found by Burghelea and Vigu\'e (Cyclic homology of commutative algebras I, Lecture Notes in Math. {\bf 1318} (1988) 51-72), where it is shown they degenerate at the $E^2$ term. For arbitrary ground rings we prove here (Theorem 2.3) that if $V_n=0$ for $n\ge 2$ then $E^2=E^\infty$. From this we derive a formula for the Hochschild homology of flat complete intersections in terms of a filtration of the complex for crystalline cohomology, and find a description of ${E'}^2$ also in terms of crystalline cohomology (theorem 3.0). The latter spectral sequence degenerates for complete intersections of embedding dimension $\le 2$ (Corollary 3.1). Without flatness assumptions, our results can be viewed as the computation Shukla (cyclic) homology (T. Pirashvili, F. Waldhausen; Mac Lane homology and topological Hochschild homology, J. Pure Appl. Algebra{\bf 82} (1992) 81-98).","10 pages, AmsTex",Guillermo Cortiñas,mathematics,train
On the derived functor analogy in the Cuntz-Quillen framework for cyclic homology,"Cuntz and Quillen have shown that for algebras over a field $k$ with $char(k)=0$, periodic cyclic homology may be regarded, in some sense, as the derived functor of (non-commutative) de Rham (co-)homology. The purpose of this paper is to formalize this derived functor analogy. We show that the localization ${Def}^{-1}\Cal{PA}$ of the category $\Cal{PA}$ of countable pro-algebras at the class of (infinitesimal) deformations exists (in any characteristic) (Theorem 3.2) and that, in characteristic zero, periodic cyclic homology is the derived functor of de Rham cohomology with respect to this localization (Corollary 5.4). We also compute the derived functor of rational $K$-theory for algebras over $\Bbb Q$, which we show is essentially the fiber of the Chern character to negative cyclic homology (Theorem 6.2).","22 pages, AmsTex, uses xy.tex for commutative diagrams",Guillermo Cortiñas,mathematics,test
On the Leibniz cohomology of vector fields,"I. M. Gelfand and D. B. Fuks have studied the cohomology of the Lie algebra of vector fields on a manifold. In this article, we generalize their main tools to compute the Leibniz cohomology, by extending the two spectral sequences associated to the diagonal and the order filtration. In particular, we determine some new generators for the diagonal Leibniz cohomology of the Lie algebra of vector fields on the circle.",12 pages,"Alessandra Frabetti, Friedrich Wagemann",mathematics,train
Equivariant K-groups of spheres with actions of involutions,"We calculate the R(G)-algebra structure on the reduced equivariant K-groups of two-dimensional spheres on which a compact Lie group G acts as involutions. In particular, the reduced equivariant K-groups are trivial if G is abelian, which shows that the previous Y. Yang's calculation in [Yan95] is not true.","7 pages, AMS-LaTeX v1.2","Jin-Hwan Cho, Mikiya Masuda",mathematics,train
A note on canonical functions,We construct a generic extension in which the aleph_2 nd canonical function on aleph_1 exists.,,"Thomas Jech, Saharon Shelah",mathematics,train
"Categoricity over P for first order T or categoricity for phi in L_{omega_1 omega} can stop at aleph_k while holding for aleph_0, ..., aleph_{k-1}","Suppose L is a relational language and P in L is a unary predicate. If M is an L-structure then P(M) is the L-structure formed as the substructure of M with domain {a: M models P(a)}. Now suppose T is a complete first order theory in L with infinite models. Following Hodges, we say that T is relatively lambda-categorical if whenever M, N models T, P(M)=P(N), |P(M)|= lambda then there is an isomorphism i:M-> N which is the identity on P(M). T is relatively categorical if it is relatively lambda-categorical for every lambda. The question arises whether the relative lambda-categoricity of T for some lambda >|T| implies that T is relatively categorical. In this paper, we provide an example, for every k>0, of a theory T_k and an L_{omega_1 omega} sentence varphi_k so that T_k is relatively aleph_n-categorical for n < k and varphi_k is aleph_n-categorical for n<k but T_k is not relatively beth_k-categorical and varphi_k is not beth_k-categorical.",,"Bradd Hart, Saharon Shelah",mathematics,train
The primal framework. I,"This the first of a series of articles dealing with abstract classification theory. The apparatus to assign systems of cardinal invariants to models of a first order theory (or determine its impossibility) is developed in [Sh:a]. It is natural to try to extend this theory to classes of models which are described in other ways. Work on the classification theory for nonelementary classes [Sh:88] and for universal classes [Sh:300] led to the conclusion that an axiomatic approach provided the best setting for developing a theory of wider application. In the first chapter we describe the axioms on which the remainder of the article depends and give some examples and context to justify this level of generality. The study of universal classes takes as a primitive the notion of closing a subset under functions to obtain a model. We replace that concept by the notion of a prime model. We begin the detailed discussion of this idea in Chapter II. One of the important contributions of classification theory is the recognition that large models can often be analyzed by means of a family of small models indexed by a tree of height at most omega. More precisely, the analyzed model is prime over such a tree. Chapter III provides sufficient conditions for prime models over such trees to exist.",,"John T. Baldwin, Saharon Shelah",mathematics,train
Full reflection of stationary sets below aleph_omega,"It is consistent that for every n >= 2, every stationary subset of omega_n consisting of ordinals of cofinality omega_k where k = 0 or k <= n-3 reflects fully in the set of ordinals of cofinality omega_{n-1}. We also show that this result is best possible.",,"Thomas Jech, Saharon Shelah",mathematics,train
The Hanf numbers of stationary logic. II. Comparison with other logics,"We show that the ordering of the Hanf number of L_{omega, omega}(wo) (well ordering), L^c_{omega, omega} (quantification on countable sets), L_{omega, omega}(aa) (stationary logic) and second order logic, have no more restraints provable in ZFC than previously known (those independence proofs assume CON(ZFC) only). We also get results on corresponding logics for L_{lambda, mu} .",,Saharon Shelah,mathematics,train
"Strong partition relations below the power set: consistency, was Sierpinski right, II?","We continue here [She88] but we do not rely on it. The motivation was a conjecture of Galvin stating that 2^{omega} >= omega_2 + omega_2-> [omega_1]^{n}_{h(n)} is consistent for a suitable h: omega-> omega. In section 5 we disprove this and give similar negative results. In section 3 we prove the consistency of the conjecture replacing omega_2 by 2^omega, which is quite large, starting with an Erd\H{o}s cardinal. In section 1 we present iteration lemmas which are needed when we replace omega by a larger lambda and in section 4 we generalize a theorem of Halpern and Lauchli replacing omega by a larger lambda .",This is a slightly corrected version of an older paper,Saharon Shelah,mathematics,val
Viva la difference I: Nonisomorphism of ultrapowers of countable models,We show that it is not provable in ZFC that any two countable elementarily equivalent structures have isomorphic ultrapowers relative to some ultrafilter on omega .,,Saharon Shelah,mathematics,train
The primal framework. II. Smoothness,This is the second in a series of articles developing abstract classification theory for classes that have a notion of prime models over independent pairs and over chains. It deals with the problem of smoothness and establishing the existence and uniqueness of a `monster model'. We work here with a predicate for a canonically prime model.,,"John T. Baldwin, Saharon Shelah",mathematics,test
On a conjecture of Tarski on products of cardinals,"We look at an old conjecture of A. Tarski on cardinal arithmetic and show that if a counterexample exists, then there exists one of length omega_1 + omega .",,"Thomas Jech, Saharon Shelah",mathematics,test
A partition theorem for pairs of finite sets,"Every partition of [[omega_1]^{< omega}]^2 into finitely many pieces has a cofinal homogeneous set. Furthermore, it is consistent that every directed partially ordered set satisfies the partition property if and only if it has finite character.",,"Thomas Jech, Saharon Shelah",mathematics,train
Piercing convex sets,"A family of sets has the $(p,q)$ property if among any $p$ members of the family some $q$ have a nonempty intersection. It is shown that for every $p\ge q\ge d+1$ there is a $c=c(p,q,d)<\infty$ such that for every family $\scr F$ of compact, convex sets in $R^d$ that has the $(p,q)$ property there is a set of at most $c$ points in $R^d$ that intersects each member of $\scr F$. This extends Helly's Theorem and settles an old problem of Hadwiger and Debrunner.",5 pages,"Noga Alon, Daniel J. Kleitman",mathematics,train
A characterization of convex hyperbolic polyhedra and of convex polyhedra inscribed in the sphere,"We describe a characterization of convex polyhedra in $\h^3$ in terms of their dihedral angles, developed by Rivin. We also describe some geometric and combinatorial consequences of that theory. One of these consequences is a combinatorial characterization of convex polyhedra in $\E^3$ all of whose vertices lie on the unit sphere. That resolves a problem posed by Jakob Steiner in 1832.",6 pages,"Craig D. Hodgson, Igor Rivin, Warren D. Smith",mathematics,train
On the Busemann-Petty problem concerning central sections of centrally symmetric convex bodies,"We present a method which shows that in $\Eb$ the Busemann-Petty problem, concerning central sections of centrally symmetric convex bodies, has a positive answer. Together with other results, this settles the problem in each dimension.",5 pages,Richard J. Gardner,mathematics,train
Average kissing numbers for non-congruent sphere packings,"The Koebe circle packing theorem states that every finite planar graph can be realized as the nerve of a packing of (non-congruent) circles in R^3. We investigate the average kissing number of finite packings of non-congruent spheres in R^3 as a first restriction on the possible nerves of such packings. We show that the supremum k of the average kissing number for all packings satisfies 12.566 ~ 666/53 <= k < 8 + 4*sqrt(3) ~ 14.928 We obtain the upper bound by a resource exhaustion argument and the upper bound by a construction involving packings of spherical caps in S^3. Our result contradicts two naive conjectures about the average kissing number: That it is unbounded, or that it is supremized by an infinite packing of congruent spheres.",6 pages,"Greg Kuperberg, Oded Schramm",mathematics,train
The Construction of Self-Similar Tilings,"We give a construction of a self-similar tiling of the plane with any prescribed expansion coefficient $\lambda\in\C$ (satisfying the necessary algebraic condition of being a complex Perron number). For any integer $m>1$ we show that there exists a self-similar tiling with $2\pi/m$-rotational symmetry group and expansion $\lambda$ if and only if either $\lambda$ or $\lambda e^{2\pi i/m}$ is a complex Perron number for which $e^{2\pi i/m}$ is in $\Q[\lambda]$, respectively $Q[\lambda e^{2\pi i/m}]$.",,Richard Kenyon,mathematics,val
The Number of Intersection Points Made by the Diagonals of a Regular Polygon,"We give a formula for the number of interior intersection points made by the diagonals of a regular $n$-gon. The answer is a polynomial on each residue class modulo 2520. We also compute the number of regions formed by the diagonals, by using Euler's formula $V-E+F=2$.","This version corrects a typo that appeared in the 1995 arxiv version
  and also in the SIAM version (specifically coefficient '262' in theorem 1
  appeared incorrectly as '232')","Bjorn Poonen, Michael Rubinstein",mathematics,train
Realization spaces of 4-polytopes are universal,"Let $P\subset\R^d$ be a $d$-dimensional polytope. The {\em realization space} of~$P$ is the space of all polytopes $P'\subset\R^d$ that are combinatorially equivalent to~$P$, modulo affine transformations. We report on work by the first author, which shows that realization spaces of \mbox{4-dimensional} polytopes can be ``arbitrarily bad'': namely, for every primary semialgebraic set~$V$ defined over~$\Z$, there is a $4$-polytope $P(V)$ whose realization space is ``stably equivalent'' to~$V$. This implies that the realization space of a $4$-polytope can have the homotopy type of an arbitrary finite simplicial complex, and that all algebraic numbers are needed to realize all $4$- polytopes. The proof is constructive. These results sharply contrast the $3$-dimensional case, where realization spaces are contractible and all polytopes are realizable with integral coordinates (Steinitz's Theorem). No similar universality result was previously known in any fixed dimension.",10 pages,"Jürgen Richter-Gebert, Günter M. Ziegler",mathematics,train
Highly saturated packings and reduced coverings,"We introduce and study certain notions which might serve as substitutes for maximum density packings and minimum density coverings. A body is a compact connected set which is the closure of its interior. A packing $\cal P$ with congruent replicas of a body $K$ is $n$-saturated if no $n-1$ members of it can be replaced with $n$ replicas of $K$, and it is completely saturated if it is $n$-saturated for each $n\ge 1$. Similarly, a covering $\cal C$ with congruent replicas of a body $K$ is $n$-reduced if no $n$ members of it can be replaced by $n-1$ replicas of $K$ without uncovering a portion of the space, and it is completely reduced if it is $n$-reduced for each $n\ge 1$. We prove that every body $K$ in $d$-dimensional Euclidean or hyperbolic space admits both an $n$-saturated packing and an $n$-reduced covering with replicas of $K$. Under some assumptions on $K\subset \mathbb{E}^d$ (somewhat weaker than convexity), we prove the existence of completely saturated packings and completely reduced coverings, but in general, the problem of existence of completely saturated packings and completely reduced coverings remains unsolved. Also, we investigate some problems related to the the densities of $n$-saturated packings and $n$-reduced coverings. Among other things, we prove that there exists an upper bound for the density of a $d+2$-reduced covering of $\mathbb{E}^d$ with congruent balls, and we produce some density bounds for the $n$-saturated packings and $n$-reduced coverings of the plane with congruent circles.",,"Gabor Fejes Tóth, Greg Kuperberg, Włodzimierz Kuperberg",mathematics,train
Uniformly distributed distances: A geometric application of Jansen's inequality,"Let $d_1\leq d_2\leq\ldots\leq d_{n\choose 2}$ denote the distances determined by $n$ points in the plane. It is shown that $\min\sum_i (d_{i+1}-d_i)^2=O(n^{-6/7})$, where the minimum is taken over all point sets with minimal distance $d_1 \geq 1$. This bound is asymptotically tight.",,"János Pach, Joel Spencer",mathematics,val
Metric Entropy of Homogeneous Spaces,"For a (compact) subset $K$ of a metric space and $\varepsilon > 0$, the {\em covering number} $N(K , \varepsilon )$ is defined as the smallest number of balls of radius $\varepsilon$ whose union covers $K$. Knowledge of the {\em metric entropy}, i.e., the asymptotic behaviour of covering numbers for (families of) metric spaces is important in many areas of mathematics (geometry, functional analysis, probability, coding theory, to name a few). In this paper we give asymptotically correct estimates for covering numbers for a large class of homogeneous spaces of unitary (or orthogonal) groups with respect to some natural metrics, most notably the one induced by the operator norm. This generalizes earlier author's results concerning covering numbers of Grassmann manifolds; the generalization is motivated by applications to noncommutative probability and operator algebras. In the process we give a characterization of geodesics in $U(n)$ (or $SO(m)$) for a class of non-Riemannian metric structures.",,Stanislaw J. Szarek,mathematics,val
Some basic information on information-based complexity theory,"Numerical analysts might be expected to pay close attention to a branch of complexity theory called information-based complexity theory (IBCT), which produces an abundance of impressive results about the quest for approximate solutions to mathematical problems. Why then do most numerical analysts turn a cold shoulder to IBCT? Close analysis of two representative papers reveals a mixture of nice new observations, error bounds repackaged in new language, misdirected examples, and misleading theorems. Some elements in the framework of IBCT, erected to support a rigorous yet flexible theory, make it difficult to judge whether a model is off-target or reasonably realistic. For instance, a sharp distinction is made between information and algorithms restricted to this information. Yet the information itself usually comes from an algorithm, so the distinction clouds the issues and can lead to true but misleading inferences. Another troublesome aspect of IBCT is a free parameter $F$, the class of admissible problem instances. By overlooking $F$'s membership fee, the theory sometimes distorts the economics of problem solving in a way reminiscent of agricultural subsidies. The current theory's surprising results pertain only to unnatural situations, and its genuinely new insights might serve us better if expressed in the conventional modes of error analysis and approximation theory.",26 pages,Beresford N. Parlett,mathematics,val
Perspectives on information-based complexity,"The authors discuss information-based complexity theory, which is a model of finite-precision computations with real numbers, and its applications to numerical analysis.",24 pages. Abstract added in migration.,"J. F. Traub, Henryk Woźniakowski",mathematics,train
Mathematical pressure volume models of the cerebrospinal fluid,"Numerous mathematical models have emerged in the medical literature over the past two decades attempting to characterize the pressure and volume dynamics the central nervous system compartment. These models have been used to study he behavior of this compartment under such pathological clinical conditions s hydrocephalus, head injury and brain edema. The number of different pproaches has led to considerable confusion regarding the validity, accuracy or appropriateness of the various models. In this paper we review the mathematical basis for these models in a mplified fashion, leaving the mathematical details to appendices. We show at most previous models are in fact particular cases of a single basic differential equation describing the evolution in time of the cerebrospinal fluid pressure (CFS). Central to this approach is the hypothsis that the rate change of CSF volume with respect to pressure is a measure of the compliance of the brain tissue which as a consequence leads to particular models epending on the form of the compliance funtion. All such models in fact give essentially no information on the behavior of the brain itself. More recent models (solved numerically using the Finite Element Method) have begun to address this issue but have difficulties due to the lack of information about the mechanical properties of the brain. Suggestions are made on how development of models which account for these chanical properties might be developed.",,"James M. Drake, Sivabal Sivaloganathan, Guiseppe Tenti",mathematics,train
Good rotations,"Numerical integrations in celestial mechanics often involve the repeated computation of a rotation with a constant angle. A direct evaluation of these rotations yields a linear drift of the distance to the origin. This is due to roundoff in the representation of the sine s and cosine c of the angle theta. In a computer, one generally gets c^2 + s^2 <> 1, resulting in a mapping that is slightly contracting or expanding. In the present paper we present a method to find pairs of representable real numbers s and c such that c^2 + s^2 is as close to 1 as possible. We show that this results in a drastic decrease of the systematic error, making it negligible compared to the random error of other operations. We also verify that this approach gives good results in a realistic celestial mechanics integration.","24 pages, 3 figures","M. Henon, J-M. Petit",mathematics,train
Numerical Analysis of Two-Phase Flow in Gas-Dynamic Filter,"This paper presents numerical and analytical investigation of gas flow in gas-dynamic filter - a device for cleaning gas from solid particles with counter flow of large water particles in order to prevent their release to the atmosphere. Ideal and viscous gas flows are considered. It is assumed, that gas flow is stationary, incompressible and plane, thus in the case of ideal gas stream function is considered, and in its terms boundary conditions are formulated. To determine stream function Dirichlet problem for Laplace equation is solved. Numerical solution is obtained using five-point scheme, and analytical - by conformal mapping. It is demonstrated that numerical solution fits very accurately with the analytical one. Then in the already known gas flow field trajectories of particles of different size are calculated in Lagrange formulation, taking into account dust particles as well as filtering water drops. Trajectories of particles of several different sizes under different modes of filter operation were analysed. The adequacy of real and computed flow is demonstrated. Computation of the flow is done using full Navier-Stokes equations. The possibility of formation of rotation and separation zones in the flow is demonstrated.","HTML+GIF from MS Word, originally 14 pages, 6 figures",Ulyan G. Pirumov,mathematics,train
Approximate Models of Dynamic Thermoviscoelasticity Describing Shape-Memory-Alloy Phase Transitions,We consider problems of dynamic viscoelasticity taking into account the coupling of elastic and thermal fields. Efficient approximate models are developed and computational results on thermomechanical behaviour of shape-memory-alloy structures are presented.,"15 pages, 2 figures","R. V. N. Melnik, A. J. Roberts",mathematics,train
Numerical Calculations Using Maple: Why & How?,"The possibility of interaction between Maple and numeric compiled languages in performing extensive numeric calculations is exemplified by the Ndynamics package, a tool for studying the (chaotic) behavior of dynamical systems. Programming hints concerning the construction of Ndynamics are presented. The system command, together with the application of the black-box concept, is used to implement a powerful cooperation between Maple code and some other numeric language code.","Latex2e, 9 pages, 4 figures. All the material (including the package,
  paper, figures) soon to be available on
  http://www.dft.if.uerj.br/symbcomp.htm","E. V. Correa Silva, L. G. S. Duarte, L. A. C. P. da Mota, J. E. F. Skea",mathematics,train
A multi-level algorithm for the solution of moment problems,"We study numerical methods for the solution of general linear moment problems, where the solution belongs to a family of nested subspaces of a Hilbert space. Multi-level algorithms, based on the conjugate gradient method and the Landweber--Richardson method are proposed that determine the ""optimal"" reconstruction level a posteriori from quantities that arise during the numerical calculations. As an important example we discuss the reconstruction of band-limited signals from irregularly spaced noisy samples, when the actual bandwidth of the signal is not available. Numerical examples show the usefulness of the proposed algorithms.",,"Otmar Scherzer, Thomas Strohmer",mathematics,train
Rates of convergence for the approximation of dual shift-invariant systems in $l_2(Z)$,"A shift-invariant system is a collection of functions $\{g_{m,n}\}$ of the form $g_{m,n}(k) = g_m(k-an)$. Such systems play an important role in time-frequency analysis and digital signal processing. A principal problem is to find a dual system $\gamma_{m,n}(k) = \gamma_m(k-an)$ such that each function $f$ can be written as $f = \sum < f, \gamma_{m,n} > g_{m,n}$. The mathematical theory usually addresses this problem in infinite dimensions (typically in $L_2(R)$ or $l_2(Z)$), whereas numerical methods have to operate with a finite-dimensional model. Exploiting the link between the frame operator and Laurent operators with matrix-valued symbol, we apply the finite section method to show that the dual functions obtained by solving a finite-dimensional problem converge to the dual functions of the original infinite-dimensional problem in $l_2(Z)$. For compactly supported $g_{m,n}$ (FIR filter banks) we prove an exponential rate of convergence and derive explicit expressions for the involved constants. Further we investigate under which conditions one can replace the discrete model of the finite section method by the periodic discrete model, which is used in many numerical procedures. Again we provide explicit estimates for the speed of convergence. Some remarks on tight frames complete the paper.",,Thomas Strohmer,mathematics,val
A Levinson-Galerkin algorithm for regularized trigonometric approximation,"Trigonometric polynomials are widely used for the approximation of a smooth function $f$ from a set of nonuniformly spaced samples $\{f(x_j)\}_{j=0}^{N-1}$. If the samples are perturbed by noise, controlling the smoothness of the trigonometric approximation becomes an essential issue to avoid overfitting and underfitting of the data. Using the polynomial degree as regularization parameter we derive a multi-level algorithm that iteratively adapts to the least squares solution of optimal smoothness. The proposed algorithm computes the solution in at most $\cal{O}(NM + M^2)$ operations ($M$ being the polynomial degree of the approximation) by solving a family of nested Toeplitz systems. It is shown how the presented method can be extended to multivariate trigonometric approximation. We demonstrate the performance of the algorithm by applying it in echocardiography to the recovery of the boundary of the Left Ventricle.",,Thomas Strohmer,mathematics,train
On the Selberg class of Dirichlet series: small degrees,"In the study of Dirichlet series with arithmetic significance there has appeared (through the study of known examples) certain expectations, namely (i) if a functional equation and Euler product exists, then it is likely that a type of Riemann hypothesis will hold, (ii) that if in addition the function has a simple pole at the point s=1, then it must be a product of the Riemann zeta-function and another Dirichlet series with similar properties, and (iii) that a type of converse theorem holds, namely that all such Dirichlet series can be obtained by considering Mellin transforms of automorphic forms associated with arithmetic groups.",,"J. Brian Conrey, Amit Ghosh",mathematics,val
Algorithms in algebraic number theory,"In this paper we discuss the basic problems of algorithmic algebraic number theory. The emphasis is on aspects that are of interest from a purely mathematical point of view, and practical issues are largely disregarded. We describe what has been done and, more importantly, what remains to be done in the area. We hope to show that the study of algorithms not only increases our understanding of algebraic number fields but also stimulates our curiosity about them. The discussion is concentrated of three topics: the determination of Galois groups, the determination of the ring of integers of an algebraic number field, and the computation of the group of units and the class group of that ring of integers.",34 pages,Hendrik W. Lenstra Jr.,mathematics,val
Additive functions on shifted primes,Best possible bounds are obtained for the concentration function of an additive arithmetic function on sequences of shifted primes.,6 pages,P. D. T. A. Elliott,mathematics,train
Selberg's Conjectures and Artin $L$-functions,"The author reviews results and conjectures of Selberg on a class of Dirichlet series functions which share properties with the Riemann zeta function, and he relates this work to the theory of Artin L-functions.",14 pages,M. Ram Murty,mathematics,val
A report on Wiles' Cambridge lectures,"In lectures at the Newton Institute in June of 1993, Andrew Wiles announced a proof of a large part of the Taniyama-Shimura Conjecture and, as a consequence, Fermat's Last Theorem. This report for nonexperts discusses the mathematics involved in Wiles' lectures, including the necessary background and the mathematical history.",24 pages,"Karl Rubin, Alice Silverberg",mathematics,train
Mean values of Dedekind sums,"For a positive integer k and an arbitrary integer h, the Dedekind sum s(h,k) was first studied by Dedekind because of the prominent role it plays in the transformation theory of the Dedekind eta-function, which is a modular form of weight 1/2 for the full modular group SL_2(Z). There is an extensive literature about the Dedekind sums. Rademacher [8] has written an introductory book on the subject.",,"J. Brian Conrey, Eric Fransen, Robert Klein, Clayton Scott",mathematics,train
Zeta functions do not determine class numbers,"We show that two number fields with the same zeta function, and even with isomorphic adele rings, do not necessarily have the same class number.",3 pages,"Bart de Smit, Robert Perlis",mathematics,train
The Dimension of the Space of Cusp Forms of Weight One,"A new upper bound is given for the dimension of the space of holomorphic cusp forms of weight one and prime level $q$: $$ \hbox{dim}\, S_1(q) << q^{11/12} \log^4{q} $$ with an absolute implied constant.",,William Duke,mathematics,val
On Calculations of Zeros of Various L-functions,"As we have shown several years ago [Y2], zeros of $L(s, \Delta )$ and $L^(2)(s, \Delta )$ can be calculated quite efficiently by a certain experimental method. Here $\Delta$ denotes the cusp form of weight 12 with respect to SL$(2, Z)$ and $L(s, \Delta )$ (resp. $L^(2)(s, \Delta )$) denotes the standard (resp. symmetric square) $L$-function attached to $\Delta$. The purpose of this paper is to show that this method can be applied to a wide class of $L$-functions so that we can obtain precise numerical values of their zeros.",,Hiroyuki Yoshida,mathematics,val
Conformal Characters and Theta Series,We describe the construction of vector valued modular forms transforming under a given congruence representation of the modular group SL$(\bold Z)$ in terms of theta series. We apply this general setup to obtain closed and easily computable formulas for conformal characters of rational models of $W$-algebras.,,"Wolgang Eholzer, Nils-Peter Skoruppa",mathematics,train
The Mackey-Gleason Problem,"Let $A$ be a von Neumann algebra with no direct summand of Type $\roman I_2$, and let $\scr P(A)$ be its lattice of projections. Let $X$ be a Banach space. Let $m\:\scr P(A)\to X$ be a bounded function such that $m(p+q)=m(p)+m(q)$ whenever $p$ and $q$ are orthogonal projections. The main theorem states that $m$ has a unique extension to a bounded linear operator from $A$ to $X$. In particular, each bounded complex-valued finitely additive quantum measure on $\scr P(A)$ has a unique extension to a bounded linear functional on $A$.",6 pages,"L. J. Bunce, J. D. Maitland Wright",mathematics,train
"Voiculescu theorem, Sobolev lemma, and extensions of smooth algebras","We present the analytic foundation of a unified B-D-F extension functor $\operatorname{Ext}_\tau$ on the category of noncommutative smooth algebras, for any Fr\'echet operator ideal $\Cal K_\tau$. Combining the techniques devised by Arveson and Voiculescu, we generalize Voiculescu's theorem to smooth algebras and Fr\'echet operator ideals. A key notion involved is $\tau$-smoothness, which is verified for the algebras of smooth functions, via a noncommutative Sobolev lemma. The groups $\operatorname{Ext}_\tau$ are computed for many examples.",6 pages,Xiaolu Wang,mathematics,train
A splitting property for subalgebras of tensor products,"We prove a basic result about tensor products of a $\text{II}_1$ factor with a finite von Neumann algebra and use it to answer, affirmatively, a question asked by S. Popa about maximal injective factors.",4 pages,Liming Ge,mathematics,train
"Bourgain algebras, minimal envelopes, minimal support sets, and some applications",We explicitly compute certain Douglas algebras that are invariant under both the Bourgain map and the minimal envelope map. We also compute the Bourgain algebra and the minimal envelope of the maximal subalgebras of a certain singly generated Douglas algebra.,,Carroll Guillory,mathematics,train
Relative cohomology of Banach algebras,"Let $A$ be a Banach algebra, not necessarily unital, and let $B$ be a closed subalgebra of $A$. We establish a connection between the Banach cyclic cohomology group $ {\cal{HC}}^n(A)$ of $A$ and the Banach $B$-relative cyclic cohomology group $ {\cal{HC}}^n_B(A) $ of $A$. We prove that, for a Banach algebra $A$ with a bounded approximate identity and an amenable closed subalgebra $B$ of $A$, up to topological isomorphism, ${\cal{HC}}^n(A) = {\cal{HC}}^n_B(A) $ for all $n \ge 0$. We also establish a connection between the Banach simplicial or cyclic cohomology groups of $A$ and those of the quotient algebra $A/I$ by an amenable closed bi-ideal $I$. The results are applied to the calculation of these groups for certain operator algebras, including von Neumann algebras.","J. Operator Theory, 1999",Zinaida A. Lykova,mathematics,test
Some conditions on Douglas algebras that imply the invariance of the minimal envelope map,We give several conditions on certain families of Douglas algebras that imply that the minimal envelope of the given algebra is the algebra itself. We also prove that the minimal envelope of the intersection of two Douglas algebras is the intersection of their minimal envelope.,,Carroll Guillory,mathematics,train
Algebras associated with Blaschke products of type {\it G},"Let $\Omega$ and $\Omega_{\fin}$ be the sets of all interpolating Blaschke products of type $G$ and of finite type $G$, respectively. Let $E$ and $E_{\fin}$ be the Douglas algebras generated by $H^\infty$ together with the complex conjugates of elements of $\Omega$ and $\Omega_{\fin}$, respectively. We show that the set of all invertible inner functions in $E$ is the set of all finite products of elements of $\Omega$ , which is also the closure of $\Omega$ among the Blaschke products. Consequently, finite convex combinations of finite products of elements of $\Omega$ are dense in the closed unit ball of the subalgebra of $H^\infty$ generated by $\Omega$. The same results hold when we replace $\Omega$ by $\Omega_{\fin}$ and $E$ by $E_{\fin}$.",,"Carroll Guillory, Kin Y. Li",mathematics,val
Fourier-Stieltjes algebras of locally compact groupoids,"This paper gives a first step toward extending the theory of Fourier-Stieltjes algebras from groups to groupoids. If G is a locally compact (second countable) groupoid, we show that B(G), the linear span of the Borel positive definite functions on G, is a Banach algebra when represented as an algebra of completely bounded maps on a C^*-algebra associated with G. This necessarily involves identifying equivalent elements of B(G). An example shows that the linear span of the continuous positive definite functions need not be complete. For groups, B(G) is isometric to the Banach space dual of C^*(G). For groupoids, the best analog of that fact is to be found in a representation of B(G) as a Banach space of completely bounded maps from a C^*-algebra associated with G to a C^*-algebra associated with the equivalence relation induced by G. This paper adds weight to the clues in the earlier study of Fourier-Stieltjes algebras that there is a much more general kind of duality for Banach algebras waiting to be explored.",34 pages,"Arlan Ramsay, Martin E. Walter",mathematics,train
Conjugate operators for finite maximal subdiagonal algebras,"Let $\M$ be a von Neumann algebra with a faithful normal trace $\T$, and let $H^\infty$ be a finite, maximal, subdiagonal algebra of $\M$. Fundamental theorems on conjugate functions for weak$^*$\!-Dirichlet algebras are shown to be valid for non-commutative $H^\infty$. In particular the conjugation operator is shown to be a bounded linear map from $L^p(\M, \T)$ into $L^p(\M, \T)$ for $1 < p < \infty$, and to be a continuous map from $L^1(\M,\T)$ into $L^{1, \infty}(\M,\T)$. We also obtain that if an operator $a$ is such that $|a|\log^+|a| \in L^1(\M,\T)$ then its conjugate belongs to $L^1(\M,\T)$. Finally, we present some partial extensions of the classical Szeg\""o's theorem to the non-commutative setting.",,Narcisse Randrianantoanina,mathematics,train
Excision in Banach simplicial and cyclic cohomology,"We prove that, for every extension of Banach algebras $ 0 \rightarrow B \rightarrow A \rightarrow D \rightarrow 0 $ such that $B$ has a left or right bounded approximate identity, the existence of an associated long exact sequence of Banach simplicial or cyclic cohomology groups is equivalent to the existence of one for homology groups. It follows from the continuous version of a result of Wodzicki that associated long exact sequences exist. In particular, they exist for every extension of $C^*$-algebras.",,Zinaida A. Lykova,mathematics,train
An exact analysis of stable allocation,"Shapley and Scarf introduced a notion of stable allocation between traders and indivisible goods, when each trader has rank-ordered each of the goods. The purpose of this note is to prove that the distribution of ranks after allocation is the same as the distribution of search distances in uniform hashing, when the rank-orderings are independent and uniformly random. Therefore the average sum of final ranks is just $(n+1)H_n-n$, and the standard deviation is O(n). The proof involves a family of interesting one-to-one correspondences between permutations of a special kind.",,Donald E. Knuth,mathematics,val
Two-way rounding,"Given $n$ real numbers $0\leq x_1,...,x_n<1$ and a permutation~$\sigma$ of $\{1,...,n\}$, we can always find $\xbar_1,...,\xbar_n\in\{0,1\}$ so that the partial sums $\xbar_1+... +\xbar_k$ and $\xbar_{\sigma 1}+... +\xbar_{\sigma k}$ differ from the unrounded values $x_1+... + x_k$ and $x_{\sigma 1}+... +x_{\sigma k}$ by at most $n/(n+1)$, for $1\leq k\leq n$. The latter bound is best possible. The proof uses an elementary argument about flows in a certain network, and leads to a simple algorithm that finds an optimum way to round.",,Donald E. Knuth,mathematics,train
Control of nonlinear underactuated systems,"In this paper we introduce a new method to design control laws for non-linear underactuated systems. Our method produces an infinite dimensional family of control laws, whereas most control techniques only produce a finite dimensional family. These control laws each come with a natural Lyapunov function. The inverted pendulum cart is used as an example. In addition, we construct an abstract system which is open loop unstable and cannot be stabilized using any linear control law, and demonstrate that our method produces a stabilizing control law.",17 pages,"Dave Auckly, Lev Kapitanski, Warren White",mathematics,test
Further results on controllability of recurrent neural networks,"This paper studies controllability properties of recurrent neural networks. The new contributions are: (1) an extension of the result in the previous paper ""Complete controllability of continuous-time recurrent neural networks"" (Sontag and Sussmann) to a slightly different model, where inputs appear in an affine form, (2) a formulation and proof of a necessary and sufficient condition, in terms of local-local controllability, and (3) a complete analysis of the 2-dimensional case for which the hypotheses made in previous work do not apply",12 pages,"Eduardo D. Sontag, Y. Qiao",mathematics,train
Feedback Stabilization over Commutative Rings: Further study of the coordinate-free approach,"This paper is concerned with the coordinate-free approach to control systems. The coordinate-free approach is a factorization approach but does not require the coprime factorizations of the plant. We present two criteria for feedback stabilizability for MIMO systems in which transfer functions belong to the total rings of fractions of commutative rings. Both of them are generalizations of Sule's results in [SIAM J. Control Optim., 32-6, 1675-1695(1994)]. The first criterion is expressed in terms of modules generated from a causal plant and does not require the plant to be strictly causal. It shows that if the plant is stabilizable, the modules are projective. The other criterion is expressed in terms of ideals called generalized elementary factors. This gives the stabilizability of a causal plant in terms of the coprimeness of the generalized elementary factors. As an example, a discrete finite-time delay system is considered.",39 pages,"Kazuyoshi Mori, Kenichi Abe",mathematics,train
A Tuner that Accelerates Parameters,"We propose a tuner, suitable for adaptive control and (in its discrete-time version) adaptive filtering applications, that sets the second derivative of the parameter estimates rather than the first derivative as is done in the overwhelming majority of the literature. Comparative stability and performance analyses are presented.","6 pages, 4 figures","Felipe M. Pait, Paulo A Atkinson",mathematics,train
Extremal Optimization: Methods derived from Co-Evolution,"We describe a general-purpose method for finding high-quality solutions to hard optimization problems, inspired by self-organized critical models of co-evolution such as the Bak-Sneppen model. The method, called Extremal Optimization, successively eliminates extremely undesirable components of sub-optimal solutions, rather than ``breeding'' better components. In contrast to Genetic Algorithms which operate on an entire ``gene-pool'' of possible solutions, Extremal Optimization improves on a single candidate solution by treating each of its components as species co-evolving according to Darwinian principles. Unlike Simulated Annealing, its non-equilibrium approach effects an algorithm requiring few parameters to tune. With only one adjustable parameter, its performance proves competitive with, and often superior to, more elaborate stochastic optimization procedures. We demonstrate it here on two classic hard optimization problems: graph partitioning and the traveling salesman problem.","8 pages, Latex, 5 ps-figures included. To appear in ``GECCO-99:
  Proceedings of the Genetic and Evolutionary Computation Conference,'' (Morgan
  Kaufmann, San Francisco, 1999)","Stefan Boettcher, Allon G. Percus",mathematics,train
"Games, predictions, interactivity",This short note is devoted to the unraveling of the hidden interactivity of ordinary games which is an artefact of predictions of the behaviour of other players by the fixed player and describes deviations of their real behaviour from such predictions. A method to improve the predictions is proposed. Applications to the strategical analysis of interactive games are also briefly specified.,"6 pages, AMSTEX",Denis V. Juriev,mathematics,val
Mathematical Problems in the Control of Underactuated Systems,"In this paper we will discuss problems and techniques related to underactuated systems. We give a mathematical formulation of several problems arising from applications, review some standard and new techniques, and pose some interesting and challenging open questions.","15 pages, 5 figures","David Auckly, Lev Kapitanski",mathematics,val
Input-Output-to-State Stability,"This work explores Lyapunov characterizations of the input-output-to-state stability (IOSS) property for nonlinear systems. The notion of IOSS is a natural generalization of the standard zero-detectability property used in the linear case. The main contribution of this work is to establish a complete equivalence between the input-output-to-state stability property and the existence of a certain type of smooth Lyapunov function. As corollaries, one shows the existence of ``norm-estimators'', and obtains characterizations of nonlinear detectability in terms of relative stability and of finite-energy estimates.","Many related papers can be found in:
  http://www.math.rutgers.edu/~sontag","Mikhail Krichman, Eduardo D. Sontag, Yuan Wang",mathematics,val
Coupling and Harnack inequalities for Sierpinski carpets,"Uniform Harnack inequalities for harmonic functions on the pre- and graphical Sierpinski carpets are proved using a probabilistic coupling argument. Various results follow from this, including the construction of Brownian motion on Sierpinski carpets embedded in $\R^d$, $d\geq 3$, estimates on the fundamental solution of the heat equation, and Sobolev and Poincar\'e inequalities.",5 pages,"Martin T. Barlow, Richard F. Bass",mathematics,train
A general decomposition theory for random cascades,"This announcement describes a probabilistic approach to cascades which, in addition to providing an entirely probabilistic proof of the Kahane-Peyri\`ere theorem for independent cascades, readily applies to general dependent cascades. Moreover, this unifies various seemingly disparate cascade decompositions, including Kahane's T-martingale decomposition and dimension disintegration.",7 pages,"Edward C. Waymire, Stanley C. Williams",mathematics,train
The dimension of the Brownian frontier is greater than 1,"Consider a planar Brownian motion run for finite time. The frontier or ``outer boundary'' of the path is the boundary of the unbounded component of the complement. Burdzy (1989) showed that the frontier has infinite length. We improve this by showing that the Hausdorff dimension of the frontier is strictly greater than 1. (It has been conjectured that the Brownian frontier has dimension $4/3$, but this is still open.) The proof uses Jones's Traveling Salesman Theorem and a self-similar tiling of the plane by fractal tiles known as Gosper Islands.",,"Christopher J. Bishop, Peter Jones, Robin Pemantle, Yuval Peres",mathematics,val
No directed fractal percolation in zero area,"We show that fractal (or ""Mandelbrot"") percolation in two dimensions produces a set containing no directed paths, when the set produced has zero area. This improves a similar result by the first author in the case of constant retention probabilities to the case of retention probabilities approaching 1.",,"Lincoln Chayes, Robin Pemantle, Yuval Peres",mathematics,train
Markov chains in a field of traps,A general criterion is given for when a Markov chain trapped with probability p(x) in state x will be almost surely trapped. The quenched (state x is a trap forever with probability p(x)) and annealed (state x traps with probability p(x) on each visit) problems are shown to be equivalent.,,"Robin Pemantle, Stanislav Volkov",mathematics,val
Vertex-reinfoced random walk on Z visits finitely many states,"Vertex-reinforced random walk is defined in Pemantle's (1988) thesis; it is a random walk that is biased to visit sites it has already visited a lot. We show that this reinforcement scheme, in contrast to the scheme of edge-reinforcement, causes random walk on a line to get trapped in a finite set.",,"Robin Pemantle, Stanislav Volkov",mathematics,train
Sets avoided by Brownian motion,"Any fixed cylinder is hit almost surely by a 3-dimensional Brownian motion, but is there a random cylinder that is in the complement? We answer this for cylinders, and then replacing a cylinder with a more general set.",,"O. Adelman, Krzysztof Burdzy, Robin Pemantle",mathematics,val
First passage percolation and a model for competing spatial growth,We generalize Richardson's model by starting with two sites of different colors and giving each new site the color of the site that spawned it. We show that co-existence is possible.,,"Olle Haggstrom, Robin Pemantle",mathematics,val
Paths with exponential intersection tails and oriented percolation,"We show that oriented percolation occurs whenever a condition is satisfied called ""exponential intersection tails"". This condition says that a measure on paths exists for which the probability of two independent paths intersecting in more than k sites is exponentially small in k.",,"Itai Benjamini, Robin Pemantle, Yuval Peres",mathematics,val
The probability that Brownian motion almost covers a line,Lower and upper estimates are given for the probability that the epsilon-enlargement of planar Brownian motion to time 1 (the epsilon sausage) contains a unit line segment. The estimates imply that Brownian motion to time 1 itself contains no line segment.,,Robin Pemantle,mathematics,train
"The multigraded Nijenhuis-Richardson Algebra, its universal property and application",We define two $(n+1)$ graded Lie brackets on spaces of multilinear mappings. The first one is able to recognize $n$-graded associative algebras and their modules and gives immediately the correct differential for Hochschild cohomology. The second one recognizes $n$-graded Lie algebra structures and their modules and gives rise to the notion of Chevalley cohomology.,,"Pierre Lecomte, Peter W. Michor, Hubert Schicketanz",mathematics,train
Towards the Chern-Weil homomormism in non-commutative differential geometry,"In this short review article we sketch some developments which should ultimately lead to the analogy of the Chern-Weil homomorphism for principal bundles in the realm of non-commutative differential geometry. Principal bundles there should have Hopf algebras as structure `cogroups'. Since the usual machinery of Lie algebras, connection forms, etc\., just is not available in this setting, we base our approach on the Fr\""olicher--Nijenhuis bracket.",,"Andreas Cap, Peter W. Michor",mathematics,test
A quantum-group-like structure on noncommutative 2-tori,In this paper we show that in the case of noncommutative two-tori one gets in a natural way simple structures which have analogous formal properties as Hopf algebra structures but with a deformed multiplication on the tensor product.,,"Andreas Cap, Peter W. Michor, Hermann Schichl",mathematics,val
Jaeger's Higman-Sims state model and the B_2 spider,"Jaeger [Geom. Dedicata 44 (1992), 23-52] discovered a remarkable checkerboard state model based on the Higman-Sims graph that yields a value of the Kauffman polynomial, which is a quantum invariant of links. We present a simple argument that the state model has the desired properties using the combinatorial $B_2$ spider [Comm. Math. Phys. 180 (1996), 109-151].",,Greg Kuperberg,mathematics,val
Quantum and braided diffeomorphism groups,"We develop a general theory of `quantum' diffeomorphism groups based on the universal comeasuring quantum group $M(A)$ associated to an algebra $A$ and its various quotients. Explicit formulae are introduced for this construction, as well as dual quasitriangular and braided R-matrix versions. Among the examples, we construct the $q$-diffeomorphisms of the quantum plane $yx=qxy$, and recover the quantum matrices $M_q(2)$ as those respecting its braided group addition law.","36 pages latex with epsf (two figures, not critical)",S. Majid,mathematics,train
Hamiltonian Reduction and the Construction of q-Deformed Extensions of the Virasoro Algebra,"In this paper we employ the construction of Dirac bracket for the remaining current of $sl(2)_q$ deformed Kac-Moody algebra when constraints similar to those connecting the $sl(2)$-WZW model and the Liouville theory are imposed and show that it satisfy the q-Virasoro algebra proposed by Frenkel and Reshetikhin. The crucial assumption considered in our calculation is the existence of a classical Poisson bracket algebra induced, in a consistent manner by the correspondence principle, mapping the quantum generators into commuting objects of classical nature preserving their algebra.","6 pages, latex","E. Batista, J. F. Gomes, I. J. Lautenschleguer",mathematics,val
On Gauss decomposition of quantum groups and Jimbo homomorphism,It is shown that the properties of the Gauss decomposition of quantum groups and the known Jimbo homomorphism permit us to realize these groups as subalgebras of well defined algebras constructed from generators of the corresponding undeformed Lie algebras.,"8 pages, LaTeX, no figures",M. A. Sokolov,mathematics,test
"""Wick Rotations"": The Noncommutative Hyperboloids, and other surfaces of rotations","A ``Wick rotation'' is applied to the noncommutative sphere to produce a noncommutative version of the hyperboloids. A harmonic basis of the associated algebra is given. It is noted that, for the one sheeted hyperboloid, the vector space for the noncommutative algebra can be completed to a Hilbert space, where multiplication is not continuous. A method of constructing noncommutative analogues of surfaces of rotation, examples of which include the paraboloid and the $q$-deformed sphere, is given. Also given are mappings between noncommutative surfaces, stereographic projections to the complex plane and unitary representations. A relationship with one dimensional crystals is highlighted.","Latex, 12 pages, 0 figures, submitted to Lett. Math. Phys",Jonathan Gratus,mathematics,train
Some examples of quantum groups in higher genus,"This is a survey of our construction of current algebras, associated with complex curves and rational differentials. We also study in detail two classes of examples. The first is the case of a rational curve with differentials $z^n dz$; these algebras are ``building blocks'' for the quantum current algebras introduced in our earlier work. The second is the case of a genus $>1$ curve $X$, endowed with a regular differential having only double zeroes.",corrections according to the changes in q-alg/9608005,"B. Enriquez, V. Rubtsov",mathematics,train
"Quantization of Lie bialgebras, IV","This paper is a continuation of ""Quantization of Lie bialgebras, III"" (q-alg/9610030, revised version). In QLB-III, we introduced the Hopf algebra F(R)_\z associated to a quantum R-matrix R(z) with a spectral parameter, and a set of points \z=(z_1,...,z_n). This algebra is generated by entries of a matrix power series T_i(u), i=1,...,n,subject to Faddeev-Reshetikhin-Takhtajan type commutation relations, and is a quantization of the group GL_N[[t]]. In this paper we consider the quotient F_0(R)_\z of F(R)_\z by the relations \qdet_R(T_i)=1, where \qdet_R is the quantum determinant associated to R (for rational, trigonometric, or elliptic R-matrices). This is also a Hopf algebra, which is a quantization of the group SL_N[[t]]. This paper was inspired by the pioneering paper of I.Frenkel and Reshetikhin. The main goal of this paper is to study the representation theory of the algebra F_0(R)_\z and of its quantum double, and show how the consideration of coinvariants of this double (quantum conformal blocks) naturally leads to the quantum Knizhnik-Zamolodchikov equations of Frenkel and Reshetikhin. Our construction for the rational R-matrix is a quantum analogue of the standard derivation of the Knizhnik-Zamolodchikov equations in the Wess-Zumino-Witten model of conformal field theory, and for the elliptic R-matrix is a quantum analogue of the construction of Kuroki and Takebe. Our result is a generalization of the construction of Enriques and Felder, which appeared while this paper was in preparation. Enriques and Felder gave a derivation of the quantum KZ equations from coinvariants in the case of the rational R-matrix and N=2.","22 pages, amstex. This is the 4-th part of the Quantization series,
  starting from q-alg/9506005; in the revised version, some errors in formulas
  in Chapter 5 have been corrected","Pavel Etingof, David Kazhdan",mathematics,test
A new measure of growth for countable-dimensional algebras,"A new dimension function on countable-dimensional algebras (over a field) is described. Its dimension values for finitely generated algebras exactly fill the unit interval $[0,1]$. Since the free algebra on two generators turns out to have dimension 0 (although conceivably some Noetherian algebras might have positive dimension!), this dimension function promises to distinguish among algebras of infinite GK-dimension.",5 pages,"John Hannah, K. C. O'Meara",mathematics,train
Orthomodularity in infinite dimensions; a theorem of M. Solèr,"Maria Pia Sol\`er has recently proved that an orthomodular form that has an infinite orthonormal sequence is real, complex, or quaternionic Hilbert space. This paper provides an exposition of her result, and describes its consequences for Baer $\ast$-rings, infinite-dimensional projective geometries, orthomodular lattices, and Mackey's quantum logic.",30 pages,Samuel S. Holland Jr.,mathematics,train
A number of countable models of a countable supersimple theory,"In this paper, we prove the number of countable models of a countable supersimple theory is either 1 or infinite. This result is an extension of Lachlan's theorem on a superstable theory.",,Byunghan Kim,mathematics,test
The relationship between two commutators,"We clarify the relationship between the linear commutator and the ordinary commutator by showing that in any variety satisfying a nontrivial idempotent Mal'cev condition the linear commutator is definable in terms of the centralizer relation. We derive from this that abelian algebras are quasi-affine in such varieties. We refine this by showing that if A is an abelian algebra and V(A) satifies an idempotent Mal'cev condition which fails to hold in the variety of semilattices, then A is affine.",,"Keith A. Kearnes, Ågnes Szendrei",mathematics,val
Projectivity and isomorphisms of strictly simple algebras,"We describe a sufficient condition for the localization functor to be a categorical equivalence. Using this result we explain how to simplify the test for projectivity. This leads to a description of the strictly simple algebras which are projective in the variety they generate. A byproduct of our efforts is the result that if A and B are strictly simple and generate the same variety, then A=B or else both are strongly abelian.",,"Keith A. Kearnes, Ågnes Szendrei",mathematics,val
Almost orthogonal submatrices of an orthogonal matrix,"Let $A$ be an $n \times M$ matrix whose rows are orthonormal. Let $A_I$ be a submatrix of $A$ whose column indexes belong to the set $I$. Given $\epsilon >0$ we estimate the smallest cardinality of the set $I$, such that the operator $A_I$ is an $\epsilon$-isometry.",,Mark Rudelson,mathematics,val
Self-rectangulating varieties of type 5,"We show that a locally finite variety which omits abelian types is self-regulating if and only if it has a compatible semilattice term operation. Such varieties must have a type-set {5}. These varieties are residually small and, when they are finitely generated, they have definable principal congruences. We show that idempotent varieties with a compatible semilattice term operation have the congruence extension property.",,"Keith A. Kearnes, Ågnes Szendrei",mathematics,test
Tensor product representations for orthosymplectic Lie superalgebras,"We derive a general result about commuting actions on certain objects in braided rigid monoidal categories. This enables us to define an action of the Brauer algebra on the tensor space $V^{\otimes k}$ which commutes with the action of the orthosymplectic Lie superalgebra $\spo(V)$ and the orthosymplectic Lie color algebra $\spo(V,\beta)$. We use the Brauer algebra action to compute maximal vectors in $V^{\otimes k}$ and to decompose $V^{\otimes k}$ into a direct sum of submodules $T^\lambda$. We compute the characters of the modules $T^\lambda$, give a combinatorial description of these characters in terms of tableaux, and model the decomposition of $V^{\otimes k}$ into the submodules $T^\lambda$ with a Robinson-Schensted-Knuth type insertion scheme.",,"Georgia Benkart, Chanyoung Lee Shader, Arun Ram",mathematics,test
A note on Lascar strong types in simple theories,"Let T be a countable, small simple theory. In this paper, we prove for such T, the notion of Lascar Strong type coincides with the notion of a strong type,over an arbitrary set.",,Byunghan Kim,mathematics,train
Modularity prevents tails,We establish a direct correspondence between two congruence poroperties for finite algebras. The first property is that minimal sets of type i omit tails. The second property is that congruence lattices omit pentagons of type i.,,"Keith A. Kearnes, Emil W. Kiss",mathematics,train
The moment mapping for a unitary representation,For any unitary representation of an arbitrary Lie group I construct a moment mapping from the space of smooth vectors of the representation into the dual of the Lie algebra. This moment mapping is equivariant and smooth. For the space of analytic vectors the same construction is possible and leads to a real analytic moment mapping.,,Peter W. Michor,mathematics,val
All unitary representations admit moment mappings,"This is a review of [Michor, Peter W.: The moment mapping for a unitary representation, Ann. Global Anal. Geometry, 8, No 3(1990), 299--313] including a careful description of calculus in infinite dimensions. For any unitary representation of an arbitrary Lie group I construct a moment mapping from the space of smooth vectors of the representation into the dual of the Lie algebra. This moment mapping is equivariant and smooth. For the space of analytic vectors the same construction is possible and leads to a real analytic moment mapping.",,Peter W. Michor,mathematics,train
"Nilpotent orbits, normality, and Hamiltonian group actions",Let $M$ be a $G$-covering of a nilpotent orbit in $\g$ where $G$ is a complex semisimple Lie group and $\g=\text{Lie}(G)$. We prove that under Poisson bracket the space $R[2]$ of homogeneous functions on $M$ of degree 2 is the unique maximal semisimple Lie subalgebra of $R=R(M)$ containing $\g$. The action of $\g'\simeq R[2]$ exponentiates to an action of the corresponding Lie group $G'$ on a $G'$-cover $M'$ of a nilpotent orbit in $\g'$ such that $M$ is open dense in $M'$. We determine all such pairs $(\g\subset\g')$.,7 pages,"Ranee Brylinski, Bertram Kostant",mathematics,train
Homogeneous functions on light cones: the infinitesimal structure of some degenerate principal series representations,"In this paper we study the reducibility, composition series and unitarity of the components of some degenerate principal series representations of $\RMO(p,q)$, $\RMU(p,q)$ and $\SP(p,q)$. This is done by realizing these representations in paces of homogeneous functions on light cones and writing down the explicit actions of the universal enveloping algebra of the group concerned.",74 pages,Roger E. Howe,mathematics,test
An external approach to unitary representations,"The main aim of this paper is to present the ideas which lead first to the solution of the unitarizability problem for $\GL(n)$ over nonarchimedean local fields and to the recognition that the same result holds over archimedean local fields, a result which was proved by Vogan using an internal approach. Let us say that the approach that we are going to present may be characterized as external. At no point do we go into the internal structure of representations.",38 pages. Abstract added in migration.,Marko Tadic,mathematics,train
On the convergence of the zeta function for certain prehomogeneous vector spaces,"Let (G,V) be an irreducible prehomogeneous vector space defined over a number field k, P in k[V] a relative invariant polynomial, and X a rational character of G such that P(gx)=X(g)P(x). Let V_k^{ss}={x \in V_k such that P(x) is not equal to 0}. For x in V_k^{ss}, let G_x be the stabilizer of x, and G_x^0 the connected component of 1 of G_x. We define L_0 to be the set of x in V_k^{ss} such that G_x^0 does not have a non-trivial rational character. We study the zeta function for (G,V).",,Akihiko Yukie,mathematics,val
The moment map for a multiplicity free action,Let $K$ be a compact connected Lie group acting unitarily on a finite-dimensional complex vector space $V$. One calls this a {\em multiplicity-free} action whenever the $K$-isotypic components of $\C[V]$ are $K$-irreducible. We have shown that this is the case if and only if the moment map $\tau:V\rightarrow\k^*$ for the action is finite-to-one on $K$-orbits. This is equivalent to a result concerning \gp s associated with Heisenberg groups that is motivated by the Orbit Method. Further details of this work will be published elsewhere.,6 pages,"Chal Benson, Joe Jenkins, Ronald Lipsman, Gail Ratcliff",mathematics,val
Exceptional Theta-correspondences I,"Let $G$ be a split simply laced group defined over a $p$-adic field $F$. In this paper we study the restriction of the minimal representation of $G$ to various dual pairs in $G$. For example, the restriction of the minimal representation of $E_7$ to the dual pair $G_2 \times{}$Sp(6) gives the non-endoscopic Langlands lift of irreducible representations of $G_2$ to Sp(6).",,"Kay Magaard, Gordan Savin",mathematics,test
"Inversion of an integral transform and ladder representations of U(1,q)","An integral transform for G=U(1,q) is studied. The transform maps the positive spin ladder representations of G on a Bargmann-Segal-Fock space F_n^1,q into a space of polynomial-valued functions on the bounded realization B^q of G/K. An inversion is given for the transform and unitary structures are given for the geometric realization of the positive spin ladder representations over G/K.",,"John D. Lorch, Lisa A. Mantini",mathematics,val
On the automorphism groups of complex homogeneous spaces,"If G is a (connected) complex Lie Group and Z is a generalized flag manifold for G, the the open orbits D of a (connected) real form G_0 of G form an interesting class of complex homogeneous spaces, which play an important role in the representation theory of G_0. We find that the group of automorphisms, i.e., the holomorphic diffeomorphisms, is a finite-dimensional Lie group, except for a small number of open orbits, where it is infinite dimensional. In the finite-dimensional case, we determine its structure. Our results have some consequences in representation theory.",,"Edward G. Dunne, Roger Zierau",mathematics,train
Formality of canonical symplectic complexes and Frobenius manifolds,"It is shown that the de Rham complex of a symplectic manifold $M$ satisfying the hard Lefschetz condition is formal. Moreover, it is shown that the differential Gerstenhaber-Batalin-Vilkoviski algebra associated to such a symplectic structure gives rise, along the lines explained in the papers of Barannikov and Kontsevich [alg-geom/9710032] and Manin [math/9801006], to the structure of a Frobenius manifold on the de Rham cohomology of $M$.","8 pages, LaTeX, corrected typos and citations",S. A. Merkulov,mathematics,train
Almost Complex Structures on $S^2\times S^2$,"In this note we investigate the structure of the space $\Jj$ of smooth almost complex structures on $S^2\times S^2$ that are compatible with some symplectic form. This space has a natural stratification that changes as the cohomology class of the form changes and whose properties are very closely connected to the topology of the group of symplectomorphisms of $S^2\times S^2$. By globalizing standard gluing constructions in the theory of stable maps, we show that the strata of $\Jj$ are Fr\'echet manifolds of finite codimension, and that the normal link of each stratum is a finite dimensional stratified space. The topology of these links turns out to be surprisingly intricate, and we work out certain cases. Our arguments apply also to other ruled surfaces, though they give complete information only for bundles over $S^2$ and $T^2$.","44 pages, Latex",Dusa McDuff,mathematics,train
A Note on Higher Cohomology Groups of Kähler Quotients,"Consider a holomorphic torus action on a possibly non-compact K\""ahler manifold. We show that the higher cohomology groups appearing in the geometric quantization of the symplectic quotient are isomorphic to the invariant parts of the corresponding cohomology groups of the original manifold. For non-Abelian group actions on compact K\""ahler manifolds, this result was proved recently by Teleman and by Braverman. Our approach is applying the holomorphic instanton complex to the prequantum line bundles over the symplectic cuts. We also settle a conjecture of Zhang and the present author on the exact sequence of higher cohomology groups in the context of symplectic cutting.","plain LeTeX, 8 pages",Siye Wu,mathematics,val
On existence of nonformal simply connected symplectic manifolds,Examples of nonformal simply connected symplectic manifolds are constructed.,"2 pages, LaTeX","Ivan K. Babenko, Iskander A. Taimanov",mathematics,val
A limit of toric symplectic forms that has no periodic Hamiltonians,"We calculate the Riemann-Roch number of some of the pentagon spaces defined in [Klyachko,Kapovich-Millson,HK1]. Using this, we show that while the regular pentagon space is diffeomorphic to a toric variety, even symplectomorphic to one under arbitrarily small perturbations of its symplectic structure, it does not admit a symplectic circle action. In particular, within the cohomology classes of symplectic structures, the subset admitting a circle action is not closed.","7 pages, 2 external figures","Jean-Claude Hausmann, Allen Knutson",mathematics,train
On nonformal simply connected symplectic manifolds,For any $N \geq 5$ nonformal simply connected symplectic manifolds of dimension $2N$ are constructed. This disproves the formality conjecture for simply connected symplectic manifolds which was introduced by Lupton and Oprea.,"20 pages, LaTeX; the short announcement see in math.SG/9810065; a
  revised version","Ivan K. Babenko, Iskander A. Taimanov",mathematics,val
A Note on n-ary Poisson Brackets,"A class of n-ary Poisson structures of constant rank is indicated. Then, one proves that the ternary Poisson brackets are exactly those which are defined by a decomposable 3-vector field. The key point is the proof of a lemma which tells that an n-vector $(n\geq3)$ is decomposable iff all its contractions with up to n-2 covectors are decomposable.",,"Peter W. Michor, Izu Vaisman",mathematics,train
Graded Lagrangian submanifolds,"In the usual setup, the grading on Floer homology is relative: it is unique only up to adding a constant. ""Graded Lagrangian submanifolds"" are Lagrangian submanifolds with a bit of extra structure, which fixes the ambiguity in the grading. The idea is originally due to Kontsevich. This paper contains an exposition of the theory. Several applications are given, amongst them: (1) topological restrictions on Lagrangian submanifolds of projective space, (2) the existence of ""symplectically knotted"" Lagrangian spheres on a K3 surface, (3) a result about the symplectic monodromy of weighted homogeneous hypersurface singularities. Revised version: minor modifications, journal reference added.","LaTex2e, 32 pages, one eps figure",Paul Seidel,mathematics,train
Stability for holomorphic spheres and Morse theory,"In this paper we study the question of when does a closed, simply connected, integral symplectic manifold (W,omega) have the stability property for its spaces of based holomorphic spheres? This property states that in a stable limit under certain gluing operators, the space of based holomorphic maps from a sphere to X, becomes homotopy equivalent to the space of all continuous maps, lim_{->} Hol_{x_0}(P^1,X) = Omega^2 X. This limit will be viewed as a kind of stabilization of Hol_{x_0}(P^1,X). We conjecture that this stability holds if and only if an evaluation map E: lim_{->} Hol_{x_0}(P^1,X) -> X is a quasifibration. In this paper we will prove that in the presence of this quasifibration condition, then the stability property holds if and only if the Morse theoretic flow category (defined in [4]) of the symplectic action functional on the Z-cover of the loop space, L~X, defined by the symplectic form, has a classifying space that realizes the homotopy type of L~X. We conjecture that in the presence of this quasifibration condition, this Morse theoretic condition always holds. We will prove this in the case of X a homogeneous space, thereby giving an alternate proof of the stability theorem for holomorphic spheres for a projective homogeneous variety originally due to Gravesen [7].",,"Ralph L. Cohen, John D. S. Jones, Graeme B. Segal",mathematics,train
A note on generating functions,"An afinne-invariant view of generating functions of symplectic transformations of an affine symplectic space is discussed. More generally, it works for symmetric symplectic spaces. The note is completely elementary, but it yields some nice pictures.","2 pages, 4 figures",Pavol Severa,mathematics,test
Trace formulae and inverse spectral theory for Schrödinger operators,"We extend the well-known trace formula for Hill's equation to general one-dimensional Schr\""odinger operators. The new function $\xi$, which we introduce, is used to study absolutely continuous spectrum and inverse problems.",6 pages,"Fritz Gesztesy, Helge Holden, Barry Simon, Zhong Xin Zhao",mathematics,train
Singular continuous spectrum is generic,"In a variety of contexts, we prove that singular continuous spectrum is generic in the sense that for certain natural complete metric spaces of operators, those with singular spectrum are a dense $G_\delta$.",5 pages,"Rafael del Rio, Svetlana Ya. Jitomirskaya, Nikolai G. Makarov, Barry Simon",mathematics,train
Canonical systems and finite rank perturbations of spectra,"We use Rokhlin's Theorem on the uniqueness of canonical systems to find a new way to establish connections between Function Theory in the unit disk and rank one perturbations of self-adjoint or unitary operators. In the n-dimensional case, we prove that for any cyclic self-adjoint operator $A$, operator $A_\lambda= A + \Sigma_{k=1}^n \lambda_k(\cdot,\phi_k)\phi_k$ is pure point for a. e. $\lambda=(\lambda_1,\lambda_2,...,\lambda_n) \in\Bbb R^n$ iff operator $A_\eta=A+\eta(\cdot,\phi_k)\phi_k$ is pure point for a.e.\ $\eta\in\Bbb R$ for $k=1,2,...,n$. We also show that if $A_\lambda$ is pure point for a.e.\ $\lambda\in \Bbb R^n$ then $A_\lambda$ is pure point for a.e.\ $\lambda\in \gamma$ for any analytic curve $\gamma\in\Bbb R^n$.",,Alexei G. Poltoratski,mathematics,train
On the evaluation of the norm of an integral operator associated with the stability of one-electron atoms,The norm of an integral operator occurring in the partial wave decomposition of an operator B introduced by Brown and Ravenhall in a model for relativistic one-electron atoms is determined. The result implies that B is non-negative and has no eigenvalue at 0 when the nuclear charge does not exceed a specified critical value.,14 pages,"V. I. Burenkov, W. D. Evans",mathematics,train
"On the virial theorem for the relativistic operator of Brown and Ravenhall, and the absence of embedded eigenvalues","A virial theorem is established for the operator proposed by Brown and Ravenhall as a model for relativistic one-electron atoms. As a consequence, it is proved that the operator has no eigenvalues greater than $\max(m c^2, 2 \alpha Z - \frac{1}{2})$, where $\alpha$ is the fine structure constant, for all values of the nuclear charge $Z$ below the critical value $Z_c$: in particular there are no eigenvalues embedded in the essential spectrum when $Z \leq 3/4 \alpha$. Implications for the operators in the partial wave decomposition are also described.",To appear in Letters in Math. Physics,"A. A. Balinsky, W. D. Evans",mathematics,val
Extremal properties of the first eigenvalue of Schrödinger-type operators,"Given a separable, locally compact Hausdorff space $X$ and a positive Radon measure $m(dx)$ on it, we study the problem of finding the potential $V(x) \ge 0$ that maximizes the first eigenvalue of the Schr\""odinger-type operator $L+V(x)$; $L$ is the generator of a local Dirichlet form $(a, D[a])$ on $L^2(X, m(dx))$.",15 pages. Accepted for publication on Journal of Functional Analysis,Lino Notarantonio,mathematics,train
"A new approach to inverse spectral theory, II. General real potentials and the connection to the spectral measure","We continue the study of the A-amplitude associated to a half-line Schrodinger operator, -d^2/dx^2+ q in L^2 ((0,b)), b <= infinity. A is related to the Weyl-Titchmarsh m-function via m(-\kappa^2) =-\kappa - \int_0^a A(\alpha) e^{-2\alpha\kappa} d\alpha +O(e^{-(2a -\epsilon)\kappa}) for all \epsilon > 0. We discuss five issues here. First, we extend the theory to general q in L^1 ((0,a)) for all a, including q's which are limit circle at infinity. Second, we prove the following relation between the A-amplitude and the spectral measure \rho: A(\alpha) = -2\int_{-\infty}^\infty \lambda^{-\frac12} \sin (2\alpha \sqrt{\lambda})\, d\rho(\lambda) (since the integral is divergent, this formula has to be properly interpreted). Third, we provide a Laplace transform representation for m without error term in the case b<\infty. Fourth, we discuss m-functions associated to other boundary conditions than the Dirichlet boundary conditions associated to the principal Weyl-Titchmarsh m-function. Finally, we discuss some examples where one can compute A exactly.","41 pages, published version","Fritz Gesztesy, Barry Simon",mathematics,val
Removal of the resolvent-like dependence on the spectral parameter from perturbations,"The spectral problem (A + V(z))\psi=z\psi is considered with A, a self-adjoint operator. The perturbation V(z) is assumed to depend on the spectral parameter z as resolvent of another self-adjoint operator A': V(z)=-B(A'-z)^{-1}B^{*}. It is supposed that the operator B has a finite Hilbert-Schmidt norm and spectra of the operators A and A' are separated. Conditions are formulated when the perturbation V(z) may be replaced with a ``potential'' W independent of z and such that the operator H=A+W has the same spectrum and the same eigenfunctions (more precisely, a part of spectrum and a respective part of eigenfunctions system) as the initial spectral problem. The operator H is constructed as a solution of the non-linear operator equation H=A+V(H) with a specially chosen operator-valued function V(H). In the case if the initial spectral problem corresponds to a two-channel variant of the Friedrichs model, a basis property of the eigenfunction system of the operator H is proved. A scattering theory is developed for H in the case where the operator A has continuous spectrum.","LaTeX, 4 pages, no figures",A. K. Motovilov,mathematics,train
On an Analog of Selberg's Eigenvalue Conjecture for SL_3(Z),"Let H be the homogeneous space associated to the group PGL_3(R). Let X=\Gamma/H where \Gamma=SL_3(Z) and consider the first non-trivial eigenvalue \lambda_1 of the Laplacian on L^2(X). Using geometric considerations, we prove the inequality \lambda_1<pi^2/10. Since the continuous spectrum is represented by the band [1,\infty), our bound on \lambda_1 can be viewed as an analogue of Selberg's eigenvalue conjecture for quotients of the hyperbolic half space.",,"Sultan Catto, Jonathan Huntley, Jay Jorgenson, David Tepper",mathematics,train
The uniqueness of the solution of the Schrodinger equation with discontinuous coefficients,"Consider the Schroeodinger equation: - Du(x) - l(x)u + s(x)u = 0, where D is the Laplacian, l(x) > 0 and s(x) is dominated by l(x). We shall extend the celebrated Kato's result on the asymptotic behavior of the solution to the case where l(x) has unbounded discontinuity. The result will be used to establish the limiting absorption principle for a class of reduced wave operators with discontinuous coefficients.","29 (twenty-nine) pages; no figures; to appear in Reviews of
  Mathematical Physics","Willi Jager, Yoshimi Saito",mathematics,train
Nonparametric Volatility Density Estimation,"We consider two kinds of stochastic volatility models. Both kinds of models contain a stationary volatility process, the density of which, at a fixed instant in time, we aim to estimate. We discuss discrete time models where for instance a log price process is modeled as the product of a volatility process and i.i.d. noise. We also consider samples of certain continuous time diffusion processes. The sampled time instants will be be equidistant with vanishing distance. A Fourier type deconvolution kernel density estimator based on the logarithm of the squared processes is proposed to estimate the volatility density. Expansions of the bias and bounds on the variances are derived.",,"Bert van Es, Peter Spreij, Harry van Zanten",mathematics,train
Asymptotic accuracy of the jackknife variance estimator for certain smooth statistics,We show that that the jackknife variance estimator $v_{jack}$ and the the infinitesimal jackknife variance estimator are asymptotically equivalent if the functional of interest is a smooth function of the mean or a smooth trimmed L-statistic. We calculate the asymptotic variance of $v_{jack}$ for these functionals.,13 pages,Alex D Gottlieb,mathematics,val
Approximating distribution functions by iterated function systems,In this paper an iterated function system on the space of distribution functions is built. The inverse problem is introduced and studied by convex optimization problems. Some applications of this method to approximation of distribution functions and to estimation theory are given.,1 table,"Stefano M. Iacus, Davide La Torre",mathematics,train
Statistical analysis of stochastic resonance with ergodic diffusion noise,"A subthreshold signal is transmitted through a channel and may be detected when some noise -- with known structure and proportional to some level -- is added to the data. There is an optimal noise level, called stochastic resonance, that corresponds to the highest Fisher information in the problem of estimation of the signal. As noise we consider an ergodic diffusion process and the asymptotic is considered as time goes to infinity. We propose consistent estimators of the subthreshold signal and we solve further a problem of hypotheses testing. We also discuss evidence of stochastic resonance for both estimation and hypotheses testing problems via examples.",,Stefano M. Iacus,mathematics,train
Asymptotic normality of kernel type deconvolution estimators,"We derive asymptotic normality of kernel type deconvolution estimators of the density, the distribution function at a fixed point, and of the probability of an interval. We consider the so called super smooth case where the characteristic function of the known distribution decreases exponentially. It turns out that the limit behavior of the pointwise estimators of the density and distribution function is relatively straightforward while the asymptotics of the estimator of the probability of an interval depends in a complicated way on the sequence of bandwidths.",26 pages,"A. J. van Es, H. -W. Uh",mathematics,train
Annuities under random rates of interest - revisited,"In the article we consider accumulated values of annuities-certain with yearly payments with independent random interest rates. We focus on annuities with payments varying in arithmetic and geometric progression which are important basic varying annuities (see Kellison, 1991). They appear to be a generalization of the types studied recently by Zaks (2001). We derive, via recursive relationships, mean and variance formulae of the final values of the annuities. As a consequence, we obtain moments related to the already discussed cases, which leads to a correction of main results from Zaks (2001).",14 pages,"K. Burnecki, A. Marciniuk, A. Weron",mathematics,val
Estimation of Weibull Shape Parameter by Shrinkage Towards an Interval Under Failure Censored Sampling,"This paper is speculated to propose a class of shrinkage estimators for shape parameter beta in failure censored samples from two-parameter Weibull distribution when some 'apriori' or guessed interval containing the parameter beta is available in addition to sample information and analyses their properties. Some estimators are generated from the proposed class and compared with the minimum mean squared error (MMSE) estimator. Numerical computations in terms of percent relative efficiency and absolute relative bias indicate that certain of these estimators substantially improve the MMSE estimator in some guessed interval of the parameter space of beta, especially for censored samples with small sizes. Subsequently, a modified class of shrinkage estimators is proposed with its properties.","20 pages, 2 tables, 1 figure","Housila P. Singh, Sharad Saxena, Jack Allen, Sarjinder Singh, Florentin Smarandache",mathematics,train
Estimating a structural distribution function by grouping,By the method of Poissonization we confirm some existing results concerning consistent estimation of the structural distribution function in the situation of a large number of rare events. Inconsistency of the so called natural estimator is proved. The method of grouping in cells of equal size is investigated and its consistency derived. A bound on the mean squared error is derived.,,"Bert van Es, Stamatis Kolios",mathematics,val
An Illuminating Counterexample,We give a visually appealing counterexample to the proposition that unbiased estimators are better than biased estimators.,"6 pages, LaTeX, To appear in the American Mathematical Monthly",Michael Hardy,mathematics,train
Nonparametric volatility density estimation for discrete time models,We consider discrete time models for asset prices with a stationary volatility process. We aim at estimating the multivariate density of this process at a set of consecutive time instants. A Fourier type deconvolution kernel density estimator based on the logarithm of the squared process is proposed to estimate the volatility density. Expansions of the bias and bounds on the variance are derived.,,"Bert van Es, Peter Spreij, Harry van Zanten",mathematics,val
Dynamic Backtracking,"Because of their occasional need to return to shallow points in a search tree, existing backtracking methods can sometimes erase meaningful progress toward solving a search problem. In this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty. The technique developed is a variant of dependency-directed backtracking that uses only polynomial space while still providing useful control information and retaining the completeness guarantees provided by earlier approaches.","See http://www.jair.org/ for an online appendix and other files
  accompanying this article",M. L. Ginsberg,computer science,train
A Market-Oriented Programming Environment and its Application to Distributed Multicommodity Flow Problems,"Market price systems constitute a well-understood class of mechanisms that under certain conditions provide effective decentralization of decision making with minimal communication overhead. In a market-oriented programming approach to distributed problem solving, we derive the activities and resource allocations for a set of computational agents by computing the competitive equilibrium of an artificial economy. WALRAS provides basic constructs for defining computational market structures, and protocols for deriving their corresponding price equilibria. In a particular realization of this approach for a form of multicommodity flow problem, we see that careful construction of the decision process according to economic principles can lead to efficient distributed resource allocation, and that the behavior of the system can be meaningfully analyzed in economic terms.",See http://www.jair.org/ for any accompanying files,M. P. Wellman,computer science,train
An Empirical Analysis of Search in GSAT,"We describe an extensive study of search in GSAT, an approximation procedure for propositional satisfiability. GSAT performs greedy hill-climbing on the number of satisfied clauses in a truth assignment. Our experiments provide a more complete picture of GSAT's search than previous accounts. We describe in detail the two phases of search: rapid hill-climbing followed by a long plateau search. We demonstrate that when applied to randomly generated 3SAT problems, there is a very simple scaling with problem size for both the mean number of satisfied clauses and the mean branching rate. Our results allow us to make detailed numerical conjectures about the length of the hill-climbing phase, the average gradient of this phase, and to conjecture that both the average score and average branching rate decay exponentially during plateau search. We end by showing how these results can be used to direct future theoretical analysis. This work provides a case study of how computer experiments can be used to improve understanding of the theoretical properties of algorithms.",See http://www.jair.org/ for any accompanying files,"I. P. Gent, T. Walsh",computer science,train
The Difficulties of Learning Logic Programs with Cut,"As real logic programmers normally use cut (!), an effective learning procedure for logic programs should be able to deal with it. Because the cut predicate has only a procedural meaning, clauses containing cut cannot be learned using an extensional evaluation method, as is done in most learning systems. On the other hand, searching a space of possible programs (instead of a space of independent clauses) is unfeasible. An alternative solution is to generate first a candidate base program which covers the positive examples, and then make it consistent by inserting cut where appropriate. The problem of learning programs with cut has not been investigated before and this seems to be a natural and reasonable approach. We generalize this scheme and investigate the difficulties that arise. Some of the major shortcomings are actually caused, in general, by the need for intensional evaluation. As a conclusion, the analysis of this paper suggests, on precise and technical grounds, that learning cut is difficult, and current induction techniques should probably be restricted to purely declarative logic languages.",See http://www.jair.org/ for any accompanying files,"F. Bergadano, D. Gunetti, U. Trinchero",computer science,train
Software Agents: Completing Patterns and Constructing User Interfaces,"To support the goal of allowing users to record and retrieve information, this paper describes an interactive note-taking system for pen-based computers with two distinctive features. First, it actively predicts what the user is going to write. Second, it automatically constructs a custom, button-box user interface on request. The system is an example of a learning-apprentice software- agent. A machine learning component characterizes the syntax and semantics of the user's information. A performance system uses this learned information to generate completion strings and construct a user interface. Description of Online Appendix: People like to record information. Doing this on paper is initially efficient, but lacks flexibility. Recording information on a computer is less efficient but more powerful. In our new note taking softwre, the user records information directly on a computer. Behind the interface, an agent acts for the user. To help, it provides defaults and constructs a custom user interface. The demonstration is a QuickTime movie of the note taking agent in action. The file is a binhexed self-extracting archive. Macintosh utilities for binhex are available from mac.archive.umich.edu. QuickTime is available from ftp.apple.com in the dts/mac/sys.soft/quicktime.","See http://www.jair.org/ for an online appendix and other files
  accompanying this article","J. C. Schlimmer, L. A. Hermens",computer science,val
Decidable Reasoning in Terminological Knowledge Representation Systems,"Terminological knowledge representation systems (TKRSs) are tools for designing and using knowledge bases that make use of terminological languages (or concept languages). We analyze from a theoretical point of view a TKRS whose capabilities go beyond the ones of presently available TKRSs. The new features studied, often required in practical applications, can be summarized in three main points. First, we consider a highly expressive terminological language, called ALCNR, including general complements of concepts, number restrictions and role conjunction. Second, we allow to express inclusion statements between general concepts, and terminological cycles as a particular case. Third, we prove the decidability of a number of desirable TKRS-deduction services (like satisfiability, subsumption and instance checking) through a sound, complete and terminating calculus for reasoning in ALCNR-knowledge bases. Our calculus extends the general technique of constraint systems. As a byproduct of the proof, we get also the result that inclusion statements in ALCNR can be simulated by terminological cycles, if descriptive semantics is adopted.",See http://www.jair.org/ for any accompanying files,"M. Buchheit, F. M. Donini, A. Schaerf",computer science,val
Teleo-Reactive Programs for Agent Control,"A formalism is presented for computing and organizing actions for autonomous agents in dynamic environments. We introduce the notion of teleo-reactive (T-R) programs whose execution entails the construction of circuitry for the continuous computation of the parameters and conditions on which agent action is based. In addition to continuous feedback, T-R programs support parameter binding and recursion. A primary difference between T-R programs and many other circuit-based systems is that the circuitry of T-R programs is more compact; it is constructed at run time and thus does not have to anticipate all the contingencies that might arise over all possible runs. In addition, T-R programs are intuitive and easy to write and are written in a form that is compatible with automatic planning and learning methods. We briefly describe some experimental applications of T-R programs in the control of simulated and actual mobile robots.",See http://www.jair.org/ for any accompanying files,N. Nilsson,computer science,train
Learning the Past Tense of English Verbs: The Symbolic Pattern Associator vs. Connectionist Models,"Learning the past tense of English verbs - a seemingly minor aspect of language acquisition - has generated heated debates since 1986, and has become a landmark task for testing the adequacy of cognitive modeling. Several artificial neural networks (ANNs) have been implemented, and a challenge for better symbolic models has been posed. In this paper, we present a general-purpose Symbolic Pattern Associator (SPA) based upon the decision-tree learning algorithm ID3. We conduct extensive head-to-head comparisons on the generalization ability between ANN models and the SPA under different representations. We conclude that the SPA generalizes the past tense of unseen verbs better than ANN models by a wide margin, and we offer insights as to why this should be the case. We also discuss a new default strategy for decision-tree learning algorithms.","See http://www.jair.org/ for an online appendix and other files
  accompanying this article",C. X. Ling,computer science,val
Substructure Discovery Using Minimum Description Length and Background Knowledge,"The ability to identify interesting and repetitive substructures is an essential component to discovering knowledge in structural data. We describe a new version of our SUBDUE substructure discovery system based on the minimum description length principle. The SUBDUE system discovers substructures that compress the original data and represent structural concepts in the data. By replacing previously-discovered substructures in the data, multiple passes of SUBDUE produce a hierarchical description of the structural regularities in the data. SUBDUE uses a computationally-bounded inexact graph match that identifies similar, but not identical, instances of a substructure and finds an approximate measure of closeness of two substructures when under computational constraints. In addition to the minimum description length principle, other background knowledge can be used by SUBDUE to guide the search towards more appropriate substructures. Experiments in a variety of domains demonstrate SUBDUE's ability to find substructures capable of compressing the original data and to discover structural concepts important to the domain. Description of Online Appendix: This is a compressed tar file containing the SUBDUE discovery system, written in C. The program accepts as input databases represented in graph form, and will output discovered substructures with their corresponding value.","See http://www.jair.org/ for an online appendix and other files
  accompanying this article","D. J. Cook, L. B. Holder",computer science,train
Bias-Driven Revision of Logical Domain Theories,"The theory revision problem is the problem of how best to go about revising a deficient domain theory using information contained in examples that expose inaccuracies. In this paper we present our approach to the theory revision problem for propositional domain theories. The approach described here, called PTR, uses probabilities associated with domain theory elements to numerically track the ``flow'' of proof through the theory. This allows us to measure the precise role of a clause or literal in allowing or preventing a (desired or undesired) derivation for a given example. This information is used to efficiently locate and repair flawed elements of the theory. PTR is proved to converge to a theory which correctly classifies all examples, and shown experimentally to be fast and accurate even for deep theories.",See http://www.jair.org/ for any accompanying files,"M. Koppel, R. Feldman, A. M. Segre",computer science,train
Flysig: Dataflow Oriented Delay-Insensitive Processor for Rapid Prototyping of Signal Processing,"As the one-chip integration of HW-modules designed by different companies becomes more and more popular reliability of a HW-design and evaluation of the timing behavior during the prototype stage are absolutely necessary. One way to guarantee reliability is the use of robust design styles, e.g., delay-insensitivity. For early timing evaluation two aspects must be considered: a) The timing needs to be proportional to technology variations and b) the implemented architecture should be identical for prototype and target. The first can be met also by delay-insensitive implementation. The latter one is the key point. A unified architecture is needed for prototyping as well as implementation. Our new approach to rapid prototyping of signal processing tasks is based on a configurable, delay-insensitive implemented processor called Flysig. In essence, the Flysig processor can be understood as a complex FPGA where the CLBs are substituted by bit-serial operators. In this paper the general concept is detailed and first experimental results are given for demonstration of the main advantages: delay-insensitive design style, direct correspondence between prototyping and target architecture, high performance and reasonable shortening of the design cycle.","6 pages, 10 figures","Wolfram Hardt, Bernd Kleinjohann",computer science,test
Versatile Data Acquisition and Controls for Epics Using Vme-Based Fpgas,Field-Programmable Gate Arrays (FPGAs) have provided Thomas Jefferson National Accelerator Facility (Jefferson Lab) with versatile VME-based data acquisition and control interfaces with minimal development times. FPGA designs have been used to interface to VME and provide control logic for numerous systems. The building blocks of these logic designs can be tailored to the individual needs of each system and provide system operators with read-backs and controls via a VME interface to an EPICS based computer. This versatility allows the system developer to choose components and define operating parameters and options that are not readily available commercially. Jefferson Lab has begun developing standard FPGA libraries that result in quick turn around times and inexpensive designs.,"3 pages, ICALEPCS 2001, T. Allison and R. Foold, Jefferson Lab","T. Allison, R. Flood",computer science,test
A Dual Digital Signal Processor VME Board For Instrumentation And Control Applications,"A Dual Digital Signal Processing VME Board was developed for the Continuous Electron Beam Accelerator Facility (CEBAF) Beam Current Monitor (BCM) system at Jefferson Lab. It is a versatile general-purpose digital signal processing board using an open architecture, which allows for adaptation to various applications. The base design uses two independent Texas Instrument (TI) TMS320C6711, which are 900 MFLOPS floating-point digital signal processors (DSP). Applications that require a fixed point DSP can be implemented by replacing the baseline DSP with the pin-for-pin compatible TMS320C6211. The design can be manufactured with a reduced chip set without redesigning the printed circuit board. For example it can be implemented as a single-channel DSP with no analog I/O.",3 PDF pages,"H. Dong, R. Flood, C. Hovater, J. Musson",computer science,train
SNS Timing System,This poster describes the timing system being designed for Spallation Neutron Source being built at Oak Ridge National lab.,,"B. oerter, R. Nelson, T. Shea, C. Sibley",computer science,train
Synthesis of Low-Power Digital Circuits Derived from Binary Decision Diagrams,"This paper introduces a novel method for synthesizing digital circuits derived from Binary Decision Diagrams (BDDs) that can yield to reduction in power dissipation. The power reduction is achieved by decreasing the switching activity in a circuit while paying close attention to information measures as an optimization criterion. We first present the technique of efficient BDD-based computation of information measures which are used to guide the power optimization procedures. Using this technique, we have developed an algorithm of BDD reordering which leads to reducing the power consumption of the circuits derived from BDDs. Results produced by the synthesis on the ISCAS benchmark circuits are very encouraging.","4 pages, 3 figures, 1 table, ECCTD'01",Denis V. Popel,computer science,train
On the Information Engine of Circuit Design,"This paper addresses a new approach to find a spectrum of information measures for the process of digital circuit synthesis. We consider the problem from the information engine point of view. The circuit synthesis as a whole and different steps of the design process (an example of decision diagram is given) are presented via such measurements as entropy, logical work and information vitality. We also introduce new information measures to provide better estimates of synthesis criteria. We show that the basic properties of information engine, such as the conservation law of information flow and the equilibrium law of information can be formulated.","4 pages, 1 figure, 2 tables, MWSCAS'02","Denis V. Popel, Nawar Al-Hakeem",computer science,train
A High-Level Reconfigurable Computing Platform Software Frameworks,"Reconfigurable computing refers to the use of processors, such as Field Programmable Gate Arrays (FPGAs), that can be modified at the hardware level to take on different processing tasks. A reconfigurable computing platform describes the hardware and software base on top of which modular extensions can be created, depending on the desired application. Such reconfigurable computing platforms can take on varied designs and implementations, according to the constraints imposed and features desired by the scope of applications. This paper introduces a PC-based reconfigurable computing platform software frameworks that is flexible and extensible enough to abstract the different hardware types and functionality that different PCs may have. The requirements of the software platform, architectural issues addressed, rationale behind the decisions made, and frameworks design implemented are discussed.","4 pages, 8 figures","Darran Nathan, Kelvin Lim Mun Kit, Kelly Choo Hon Min, Philip Wong Jit Chin, Andreas Weisensee",computer science,train
Stochastic fuzzy controller,"A standard approach to building a fuzzy controller based on stochastic logic uses binary random signals with an average (expected value of a random variable) in the range [0, 1]. A different approach is presented, founded on a representation of the membership functions with the probability density functions.",Withdrawn by the author,Franc Jurkovic,computer science,train
Exposing Software Defined Radio Functionality To Native Operating System Applications via Virtual Devices,"Many reconfigurable platforms require that applications be written specifically to take advantage of the reconfigurable hardware. In a PC-based environment, this presents an undesirable constraint in that the many already available applications cannot leverage on such hardware. Greatest benefit can only be derived from reconfigurable devices if even native OS applications can transparently utilize reconfigurable devices as they would normal full-fledged hardware devices. This paper presents how Proteus Virtual Devices are used to expose reconfigurable hardware in a transparent manner for use by typical native OS applications.","4 pages, 9 figures",Darran Nathan,computer science,val
Topics in asynchronous systems,"In the paper we define and characterize the asynchronous systems from the point of view of their autonomy, determinism, order, non-anticipation, time invariance, symmetry, stability and other important properties. The study is inspired by the models of the asynchronous circuits.",40 pages,Serban E. Vlad,computer science,train
Nested satisfiability,"A special case of the satisfiability problem, in which the clauses have a hierarchical structure, is shown to be solvable in linear time, assuming that the clauses have been represented in a convenient way.",,Donald E. Knuth,computer science,train
Textbook examples of recursion,"We discuss properties of recursive schemas related to McCarthy's ``91 function'' and to Takeuchi's triple recursion. Several theorems are proposed as interesting candidates for machine verification, and some intriguing open questions are raised.",,Donald E. Knuth,computer science,train
Downward Collapse from a Weaker Hypothesis,"Hemaspaandra et al. proved that, for $m > 0$ and $0 < i < k - 1$: if $\Sigma_i^p \BoldfaceDelta DIFF_m(\Sigma_k^p)$ is closed under complementation, then $DIFF_m(\Sigma_k^p) = coDIFF_m(\Sigma_k^p)$. This sharply asymmetric result fails to apply to the case in which the hypothesis is weakened by allowing the $\Sigma_i^p$ to be replaced by any class in its difference hierarchy. We so extend the result by proving that, for $s,m > 0$ and $0 < i < k - 1$: if $DIFF_s(\Sigma_i^p) \BoldfaceDelta DIFF_m(\Sigma_k^p)$ is closed under complementation, then $DIFF_m(\Sigma_k^p) = coDIFF_m(\Sigma_k^p)$.",,"Edith Hemaspaandra, Lane A. Hemaspaandra, Harald Hempel",computer science,train
Immunity and Simplicity for Exact Counting and Other Counting Classes,"Ko [RAIRO 24, 1990] and Bruschi [TCS 102, 1992] showed that in some relativized world, PSPACE (in fact, ParityP) contains a set that is immune to the polynomial hierarchy (PH). In this paper, we study and settle the question of (relativized) separations with immunity for PH and the counting classes PP, C_{=}P, and ParityP in all possible pairwise combinations. Our main result is that there is an oracle A relative to which C_{=}P contains a set that is immune to BPP^{ParityP}. In particular, this C_{=}P^A set is immune to PH^{A} and ParityP^{A}. Strengthening results of Tor\'{a}n [J.ACM 38, 1991] and Green [IPL 37, 1991], we also show that, in suitable relativizations, NP contains a C_{=}P-immune set, and ParityP contains a PP^{PH}-immune set. This implies the existence of a C_{=}P^{B}-simple set for some oracle B, which extends results of Balc\'{a}zar et al. [SIAM J.Comp. 14, 1985; RAIRO 22, 1988] and provides the first example of a simple set in a class not known to be contained in PH. Our proof technique requires a circuit lower bound for ``exact counting'' that is derived from Razborov's [Mat. Zametki 41, 1987] lower bound for majority.",20 pages,Joerg Rothe,computer science,train
Tally NP Sets and Easy Census Functions,"We study the question of whether every P set has an easy (i.e., polynomial-time computable) census function. We characterize this question in terms of unlikely collapses of language and function classes such as the containment of #P_1 in FP, where #P_1 is the class of functions that count the witnesses for tally NP sets. We prove that every #P_{1}^{PH} function can be computed in FP^{#P_{1}^{#P_{1}}}. Consequently, every P set has an easy census function if and only if every set in the polynomial hierarchy does. We show that the assumption of #P_1 being contained in FP implies P = BPP and that PH is contained in MOD_{k}P for each k \geq 2, which provides further evidence that not all sets in P have an easy census function. We also relate a set's property of having an easy census function to other well-studied properties of sets, such as rankability and scalability (the closure of the rankable sets under P-isomorphisms). Finally, we prove that it is no more likely that the census function of any set in P can be approximated (more precisely, can be n^{\alpha}-enumerated in time n^{\beta} for fixed \alpha and \beta) than that it can be precisely computed in polynomial time.",24 pages,"Judy Goldsmith, Mitsunori Ogihara, Joerg Rothe",computer science,train
The descriptive complexity approach to LOGCFL,"Building upon the known generalized-quantifier-based first-order characterization of LOGCFL, we lay the groundwork for a deeper investigation. Specifically, we examine subclasses of LOGCFL arising from varying the arity and nesting of groupoidal quantifiers. Our work extends the elaborate theory relating monoidal quantifiers to NC1 and its subclasses. In the absence of the BIT predicate, we resolve the main issues: we show in particular that no single outermost unary groupoidal quantifier with FO can capture all the context-free languages, and we obtain the surprising result that a variant of Greibach's ``hardest context-free language'' is LOGCFL-complete under quantifier-free BIT-free projections. We then prove that FO with unary groupoidal quantifiers is strictly more expressive with the BIT predicate than without. Considering a particular groupoidal quantifier, we prove that first-order logic with majority of pairs is strictly more expressive than first-order with majority of individuals. As a technical tool of independent interest, we define the notion of an aperiodic nondeterministic finite automaton and prove that FO translations are precisely the mappings computed by single-valued aperiodic nondeterministic finite transducers.","10 pages, 1 figure","Clemens Lautemann, Pierre McKenzie, Thomas Schwentick, Heribert Vollmer",computer science,val
A Generalized Quantifier Concept in Computational Complexity Theory,"A notion of generalized quantifier in computational complexity theory is explored and used to give a unified treatment of leaf language definability, oracle separations, type 2 operators, and circuits with monoidal gates. Relations to Lindstroem quantifiers are pointed out.",,Heribert Vollmer,computer science,train
The Complexity of Computing Optimal Assignments of Generalized Propositional Formulae,"We consider the problems of finding the lexicographically minimal (or maximal) satisfying assignment of propositional formulae for different restricted formula classes. It turns out that for each class from our framework, the above problem is either polynomial time solvable or complete for OptP. We also consider the problem of deciding if in the optimal assignment the largest variable gets value 1. We show that this problem is either in P or P^NP complete.","17 pages, 1 figure","Steffen Reith, Heribert Vollmer",computer science,val
Hard instance generation for SAT,"We propose an algorithm of generating hard instances for the Satisfying Assignment Search Problem (in short, SAT). The algorithm transforms instances of the integer factorization problem into SAT instances efficiently by using the Chinese Remainder Theorem. For example, it is possible to construct SAT instances with about 5,600 variables that is as hard as factorizing 100 bit integers.",,"Satoshi Horie, Osamu Watanabe",computer science,train
Generalization of automatic sequences for numeration systems on a regular language,"Let L be an infinite regular language on a totally ordered alphabet (A,<). Feeding a finite deterministic automaton (with output) with the words of L enumerated lexicographically with respect to < leads to an infinite sequence over the output alphabet of the automaton. This process generalizes the concept of k-automatic sequence for abstract numeration systems on a regular language (instead of systems in base k). Here, I study the first properties of these sequences and their relations with numeration systems.","10 pages, 3 figures",Michel Rigo,computer science,train
Chip-level CMP Modeling and Smart Dummy for HDP and Conformal CVD Films,"Chip-level CMP modeling is investigated to obtain the post-CMP film profile thickness across a die from its design layout file and a few film deposition and CMP parameters. The work covers both HDP and conformal CVD film. The experimental CMP results agree well with the modeled results. Different algorithms for filling of dummy structure are compared. A smart algorithm for dummy filling is presented, which achieves maximal pattern-density uniformity and CMP planarity.","10 pages, 7 figures; for used software, see
  http://www.cmptechnology.com/","George Yong Liu, Ray F. Zhang, Kelvin Hsu, Lawrence Camilletti",computer science,val
Fast Pricing of European Asian Options with Provable Accuracy: Single-stock and Basket Options,"This paper develops three polynomial-time pricing techniques for European Asian options with provably small errors, where the stock prices follow binomial trees or trees of higher-degree. The first technique is the first known Monte Carlo algorithm with analytical error bounds suitable for pricing single-stock options with meaningful confidence and speed. The second technique is a general recursive bucketing-based scheme that can use the Aingworth-Motwani-Oldham aggregation algorithm, Monte-Carlo simulation and possibly others as the base-case subroutine. This scheme enables robust trade-offs between accuracy and time over subtrees of different sizes. For long-term options or high frequency price averaging, it can price single-stock options with smaller errors in less time than the base-case algorithms themselves. The third technique combines Fast Fourier Transform with bucketing-based schemes for pricing basket options. This technique takes polynomial time in the number of days and the number of stocks, and does not add any errors to those already incurred in the companion bucketing scheme. This technique assumes that the price of each underlying stock moves independently.",22 pages,"Karhan Akcoglu, Ming-Yang Kao, Shuba Raghavan",computer science,val
Shooting Over or Under the Mark: Towards a Reliable and Flexible Anticipation in the Economy,"The real monetary economy is grounded upon monetary flow equilibration or the activity of actualizing monetary flow continuity at each economic agent except for the central bank. Every update of monetary flow continuity at each agent constantly causes monetary flow equilibration at the neighborhood agents. Every monetary flow equilibration as the activity of shooting the mark identified as monetary flow continuity turns out to be off the mark, and constantly generate the similar activities in sequence. Monetary flow equilibration ceaselessly reverberating in the economy performs two functions. One is to seek an organization on its own, and the other is to perturb the ongoing organization. Monetary flow equilibration as the agency of seeking and perturbing its organization also serves as a means of predicting its behavior. The likely organizational behavior could be the one that remains most robust against monetary flow equilibration as an agency of applying perturbations.",,Koichiro Matsuno,computer science,val
Tracing a Faint Fingerprint of the Invisible Hand?,"Any economic agent constituting the monetary economy maintains the activity of monetary flow equilibration for fulfilling the condition of monetary flow continuity in the record, except at the central bank. At the same time, monetary flow equilibration at one economic agent constantly induces at other agents in the economy further flow disequilibrium to be eliminated subsequently. We propose the rate of monetary flow disequilibration as a figure measuring the progressive movement of the economy. The rate of disequilibration was read out of both the Japanese and the United States monetary economy recorded over the last fifty years.",,Koichiro Matsuno,computer science,train
Parallel implementation of the TRANSIMS micro-simulation,"This paper describes the parallel implementation of the TRANSIMS traffic micro-simulation. The parallelization method is domain decomposition, which means that each CPU of the parallel computer is responsible for a different geographical area of the simulated region. We describe how information between domains is exchanged, and how the transportation network graph is partitioned. An adaptive scheme is used to optimize load balancing. We then demonstrate how computing speeds of our parallel micro-simulations can be systematically predicted once the scenario and the computer architecture are known. This makes it possible, for example, to decide if a certain study is feasible with a certain computing budget, and how to invest that budget. The main ingredients of the prediction are knowledge about the parallel implementation of the micro-simulation, knowledge about the characteristics of the partitioning of the transportation network graph, and knowledge about the interaction of these quantities with the computer system. In particular, we investigate the differences between switched and non-switched topologies, and the effects of 10 Mbit, 100 Mbit, and Gbit Ethernet. keywords: Traffic simulation, parallel computing, transportation planning, TRANSIMS",,"Kai Nagel, Marcus Rickert",computer science,train
Analysis of Investment Policy in Belarus,The optimal planning trajectory is analyzed on the basis of the growth model with effectiveness. The saving per capital value has to be rather high initially with smooth decrement in the future years.,"20 pages, 2 figures, 1 table. email: fedia@dragon.bas-net.by",Fedor S. Kilin,computer science,train
An Empirical Model for Volatility of Returns and Option Pricing,"In a seminal paper in 1973, Black and Scholes argued how expected distributions of stock prices can be used to price options. Their model assumed a directed random motion for the returns and consequently a lognormal distribution of asset prices after a finite time. We point out two problems with their formulation. First, we show that the option valuation is not uniquely determined; in particular, stratergies based on the delta-hedge and CAMP (Capital Asset Pricing Model) are shown to provide different valuations of an option. Second, asset returns are known not to be Gaussian distributed. Empirically, distributions of returns are seen to be much better approximated by an exponential distribution. This exponential distribution of asset prices can be used to develop a new pricing model for options that is shown to provide valuations that agree very well with those used by traders. We show how the Fokker-Planck formulation of fluctuations (i.e., the dynamics of the distribution) can be modified to provide an exponential distribution for returns. We also show how a singular volatility can be used to go smoothly from exponential to Gaussian returns and thereby illustrate why exponential returns cannot be reached perturbatively starting from Gaussian ones, and explain how the theory of 'stochastic volatility' can be obtained from our model by making a bad approximation. Finally, we show how to calculate put and call prices for a stretched exponential density.",4 figures; 1 table,"Joseph L. McCauley, Gemunu H. Gunaratne",computer science,val
Agent trade servers in financial exchange systems,"New services based on the best-effort paradigm could complement the current deterministic services of an electronic financial exchange. Four crucial aspects of such systems would benefit from a hybrid stance: proper use of processing resources, bandwidth management, fault tolerance, and exception handling. We argue that a more refined view on Quality-of-Service control for exchange systems, in which the principal ambition of upholding a fair and orderly marketplace is left uncompromised, would benefit all interested parties.","11 pages, 1 figure","David Lyback, Magnus Boman",computer science,train
Parrondo Strategies for Artificial Traders,"On markets with receding prices, artificial noise traders may consider alternatives to buy-and-hold. By simulating variations of the Parrondo strategy, using real data from the Swedish stock market, we produce first indications of a buy-low-sell-random Parrondo variation outperforming buy-and-hold. Subject to our assumptions, buy-low-sell-random also outperforms the traditional value and trend investor strategies. We measure the success of the Parrondo variations not only through their performance compared to other kinds of strategies, but also relative to varying levels of perfect information, received through messages within a multi-agent system of artificial traders.","10 pages, 4 figures","Magnus Boman, Stefan Johansson, David Lyback",computer science,test
Trading Agents for Roaming Users,"Some roaming users need services to manipulate autonomous processes. Trading agents running on agent trade servers are used as a case in point. We present a solution that provides the agent owners with means to upkeeping their desktop environment, and maintaining their agent trade server processes, via a briefcase service.","5 pages, 1 figure","Magnus Boman, Markus Bylund, Fredrik Espinoza, Mats Danielson, David Lyback",computer science,train
Computational Geometry Column 34,Problems presented at the open-problem session of the 14th Annual ACM Symposium on Computational Geometry are listed.,,"Pankaj K. Agarwal, Joseph O'Rourke",computer science,test
Incremental and Decremental Maintenance of Planar Width,"We present an algorithm for maintaining the width of a planar point set dynamically, as points are inserted or deleted. Our algorithm takes time O(kn^epsilon) per update, where k is the amount of change the update causes in the convex hull, n is the number of points in the set, and epsilon is any arbitrarily small constant. For incremental or decremental update sequences, the amortized time per update is O(n^epsilon).","7 pages; 2 figures. A preliminary version of this paper was presented
  at the 10th ACM/SIAM Symp. Discrete Algorithms (SODA '99); this is the
  journal version, and will appear in J. Algorithms",David Eppstein,computer science,train
Optimal Point Placement for Mesh Smoothing,"We study the problem of moving a vertex in an unstructured mesh of triangular, quadrilateral, or tetrahedral elements to optimize the shapes of adjacent elements. We show that many such problems can be solved in linear time using generalized linear programming. We also give efficient algorithms for some mesh smoothing problems that do not fit into the generalized linear programming paradigm.","12 pages, 3 figures. A preliminary version of this paper was
  presented at the 8th ACM/SIAM Symp. on Discrete Algorithms (SODA '97). This
  is the final version, and will appear in a special issue of J. Algorithms for
  papers from SODA '97","Nina Amenta, Marshall Bern, David Eppstein",computer science,val
Linear Complexity Hexahedral Mesh Generation,"We show that any polyhedron forming a topological ball with an even number of quadrilateral sides can be partitioned into O(n) topological cubes, meeting face to face. The result generalizes to non-simply-connected polyhedra satisfying an additional bipartiteness condition. The same techniques can also be used to reduce the geometric version of the hexahedral mesh generation problem to a finite case analysis amenable to machine solution.","12 pages, 17 figures. A preliminary version of this paper appeared at
  the 12th ACM Symp. on Computational Geometry. This is the final version, and
  will appear in a special issue of Computational Geometry: Theory and
  Applications for papers from SCG '96",David Eppstein,computer science,train
Randomization yields simple O(n log star n) algorithms for difficult Omega(n) problems,"We use here the results on the influence graph by Boissonnat et al. to adapt them for particular cases where additional information is available. In some cases, it is possible to improve the expected randomized complexity of algorithms from O(n log n) to O(n log star n). This technique applies in the following applications: triangulation of a simple polygon, skeleton of a simple polygon, Delaunay triangulation of points knowing the EMST (euclidean minimum spanning tree).","16 pages, 6 figures, Proc. 3rd Canad. Conf. Comput. Geom., 1991",Olivier Devillers,computer science,test
Analysis of approximate nearest neighbor searching with clustered point sets,"We present an empirical analysis of data structures for approximate nearest neighbor searching. We compare the well-known optimized kd-tree splitting method against two alternative splitting methods. The first, called the sliding-midpoint method, which attempts to balance the goals of producing subdivision cells of bounded aspect ratio, while not producing any empty cells. The second, called the minimum-ambiguity method is a query-based approach. In addition to the data points, it is also given a training set of query points for preprocessing. It employs a simple greedy algorithm to select the splitting plane that minimizes the average amount of ambiguity in the choice of the nearest neighbor for the training points. We provide an empirical analysis comparing these two methods against the optimized kd-tree construction for a number of synthetically generated data and query sets. We demonstrate that for clustered data and query sets, these algorithms can provide significant improvements over the standard kd-tree construction for approximate nearest neighbor searching.","20 pages, 8 figures. Presented at ALENEX '99, Baltimore, MD, Jan
  15-16, 1999","Songrit Maneewongvatana, David M. Mount",computer science,train
Computational Geometry Column 35,The subquadratic algorithm of Kapoor for finding shortest paths on a polyhedron is described.,,Joseph O'Rourke,computer science,train
On Deletion in Delaunay Triangulation,"This paper presents how the space of spheres and shelling may be used to delete a point from a $d$-dimensional triangulation efficiently. In dimension two, if k is the degree of the deleted vertex, the complexity is O(k log k), but we notice that this number only applies to low cost operations, while time consuming computations are only done a linear number of times. This algorithm may be viewed as a variation of Heller's algorithm, which is popular in the geographic information system community. Unfortunately, Heller algorithm is false, as explained in this paper.","15 pages 5 figures. in Proc. 15th Annu. ACM Sympos. Comput. Geom.,
  181--188, 1999",Olivier Devillers,computer science,train
Improved Incremental Randomized Delaunay Triangulation,"We propose a new data structure to compute the Delaunay triangulation of a set of points in the plane. It combines good worst case complexity, fast behavior on real data, and small memory occupation. The location structure is organized into several levels. The lowest level just consists of the triangulation, then each level contains the triangulation of a small sample of the levels below. Point location is done by marching in a triangulation to determine the nearest neighbor of the query at that level, then the march restarts from that neighbor at the level below. Using a small sample (3%) allows a small memory occupation; the march and the use of the nearest neighbor to change levels quickly locate the query.","19 pages, 7 figures Proc. 14th Annu. ACM Sympos. Comput. Geom.,
  106--115, 1998",Olivier Devillers,computer science,test
"The union of unit balls has quadratic complexity, even if they all contain the origin","We provide a lower bound construction showing that the union of unit balls in three-dimensional space has quadratic complexity, even if they all contain the origin. This settles a conjecture of Sharir.","5 pages, 5 figures","Herve Bronnimann, Olivier Devillers",computer science,train
Linear Segmentation and Segment Significance,"We present a new method for discovering a segmental discourse structure of a document while categorizing segment function. We demonstrate how retrieval of noun phrases and pronominal forms, along with a zero-sum weighting scheme, determines topicalized segmentation. Futhermore, we use term distribution to aid in identifying the role that the segment performs in the document. Finally, we present results of evaluation in terms of precision and recall which surpass earlier approaches.","9 pages, US Letter, 4 figures. Software License can be found at
  http://www.cs.columbia.edu/nlp/licenses/segmenterLicenseDownload.html","Min-Yen Kan, Judith L. Klavans, Kathleen R. McKeown",computer science,val
"Modelling Users, Intentions, and Structure in Spoken Dialog","We outline how utterances in dialogs can be interpreted using a partial first order logic. We exploit the capability of this logic to talk about the truth status of formulae to define a notion of coherence between utterances and explain how this coherence relation can serve for the construction of AND/OR trees that represent the segmentation of the dialog. In a BDI model we formalize basic assumptions about dialog and cooperative behaviour of participants. These assumptions provide a basis for inferring speech acts from coherence relations between utterances and attitudes of dialog participants. Speech acts prove to be useful for determining dialog segments defined on the notion of completing expectations of dialog participants. Finally, we sketch how explicit segmentation signalled by cue phrases and performatives is covered by our dialog model.",17 pages,"Bernd Ludwig, Guenther Goerz, Heinrich Niemann",computer science,train
A Lexicalized Tree Adjoining Grammar for English,"This document describes a sizable grammar of English written in the TAG formalism and implemented for use with the XTAG system. This report and the grammar described herein supersedes the TAG grammar described in an earlier 1995 XTAG technical report. The English grammar described in this report is based on the TAG formalism which has been extended to include lexicalization, and unification-based feature structures. The range of syntactic phenomena that can be handled is large and includes auxiliaries (including inversion), copula, raising and small clause constructions, topicalization, relative clauses, infinitives, gerunds, passives, adjuncts, it-clefts, wh-clefts, PRO constructions, noun-noun modifications, extraposition, determiner sequences, genitives, negation, noun-verb contractions, sentential adjuncts and imperatives. This technical report corresponds to the XTAG Release 8/31/98. The XTAG grammar is continuously updated with the addition of new analyses and modification of old ones, and an online version of this report can be found at the XTAG web page at http://www.cis.upenn.edu/~xtag/","310 pages, 181 Postscript figures, uses 11pt, psfig.tex",XTAG Research Group,computer science,train
Prefix Probabilities from Stochastic Tree Adjoining Grammars,"Language models for speech recognition typically use a probability model of the form Pr(a_n | a_1, a_2, ..., a_{n-1}). Stochastic grammars, on the other hand, are typically used to assign structure to utterances. A language model of the above form is constructed from such grammars by computing the prefix probability Sum_{w in Sigma*} Pr(a_1 ... a_n w), where w represents all possible terminations of the prefix a_1 ... a_n. The main result in this paper is an algorithm to compute such prefix probabilities given a stochastic Tree Adjoining Grammar (TAG). The algorithm achieves the required computation in O(n^6) time. The probability of subderivations that do not derive any words in the prefix, but contribute structurally to its derivation, are precomputed to achieve termination. This algorithm enables existing corpus-based estimation techniques for stochastic TAGs to be used for language modelling.","7 pages, 2 Postscript figures, uses colacl.sty, graphicx.sty,
  psfrag.sty","Mark-Jan Nederhof, Anoop Sarkar, Giorgio Satta",computer science,train
Conditions on Consistency of Probabilistic Tree Adjoining Grammars,"Much of the power of probabilistic methods in modelling language comes from their ability to compare several derivations for the same string in the language. An important starting point for the study of such cross-derivational properties is the notion of _consistency_. The probability model defined by a probabilistic grammar is said to be _consistent_ if the probabilities assigned to all the strings in the language sum to one. From the literature on probabilistic context-free grammars (CFGs), we know precisely the conditions which ensure that consistency is true for a given CFG. This paper derives the conditions under which a given probabilistic Tree Adjoining Grammar (TAG) can be shown to be consistent. It gives a simple algorithm for checking consistency and gives the formal justification for its correctness. The conditions derived here can be used to ensure that probability models that use TAGs can be checked for _deficiency_ (i.e. whether any probability mass is assigned to strings that cannot be generated).","7 pages, 4 Postscript figures, uses colacl.sty, graphicx.sty,
  psfrag.sty",Anoop Sarkar,computer science,train
Separating Dependency from Constituency in a Tree Rewriting System,In this paper we present a new tree-rewriting formalism called Link-Sharing Tree Adjoining Grammar (LSTAG) which is a variant of synchronous TAGs. Using LSTAG we define an approach towards coordination where linguistic dependency is distinguished from the notion of constituency. Such an approach towards coordination that explicitly distinguishes dependencies from constituency gives a better formal understanding of its representation when compared to previous approaches that use tree-rewriting systems which conflate the two issues.,"7 pages, 6 Postscript figures, uses fullname.sty",Anoop Sarkar,computer science,train
Incremental Parser Generation for Tree Adjoining Grammars,"This paper describes the incremental generation of parse tables for the LR-type parsing of Tree Adjoining Languages (TALs). The algorithm presented handles modifications to the input grammar by updating the parser generated so far. In this paper, a lazy generation of LR-type parsers for TALs is defined in which parse tables are created by need while parsing. We then describe an incremental parser generator for TALs which responds to modification of the input grammar by updating parse tables built so far.","12 pages, 12 Postscript figures, uses fullname.sty",Anoop Sarkar,computer science,val
"A Freely Available Morphological Analyzer, Disambiguator and Context Sensitive Lemmatizer for German","In this paper we present Morphy, an integrated tool for German morphology, part-of-speech tagging and context-sensitive lemmatization. Its large lexicon of more than 320,000 word forms plus its ability to process German compound nouns guarantee a wide morphological coverage. Syntactic ambiguities can be resolved with a standard statistical part-of-speech tagger. By using the output of the tagger, the lemmatizer can determine the correct root even for ambiguous word forms. The complete package is freely available and can be downloaded from the World Wide Web.","5 pages, Postscript only","Wolfgang Lezius, Reinhard Rapp, Manfred Wettler",computer science,train
Processing Unknown Words in HPSG,"The lexical acquisition system presented in this paper incrementally updates linguistic properties of unknown words inferred from their surrounding context by parsing sentences with an HPSG grammar for German. We employ a gradual, information-based concept of ``unknownness'' providing a uniform treatment for the range of completely known to maximally unknown lexical entries. ``Unknown'' information is viewed as revisable information, which is either generalizable or specializable. Updating takes place after parsing, which only requires a modified lexical lookup. Revisable pieces of information are identified by grammar-specified declarations which provide access paths into the parse feature structure. The updating mechanism revises the corresponding places in the lexical feature structures iff the context actually provides new information. For revising generalizable information, type union is required. A worked-out example demonstrates the inferential capacity of our implemented system.","5 pp., 1 PostScript figure","Petra Barg, Markus Walther",computer science,train
Computing Declarative Prosodic Morphology,"This paper describes a computational, declarative approach to prosodic morphology that uses inviolable constraints to denote small finite candidate sets which are filtered by a restrictive incremental optimization mechanism. The new approach is illustrated with an implemented fragment of Modern Hebrew verbs couched in MicroCUF, an expressive constraint logic formalism. For generation and parsing of word forms, I propose a novel off-line technique to eliminate run-time optimization. It produces a finite-state oracle that efficiently restricts the constraint interpreter's search space. As a byproduct, unknown words can be analyzed without special mechanisms. Unlike pure finite-state transducer approaches, this hybrid setup allows for more expressivity in constraints to specify e.g. token identity for reduplication or arithmetic constraints for phonetics.",10 pages,Markus Walther,computer science,train
"Security amplification by composition: The case of doubly-iterated, ideal ciphers","We investigate, in the Shannon model, the security of constructions corresponding to double and (two-key) triple DES. That is, we consider F_{k1}(F_{k2}(.)) and F_{k1}(F_{k2}^{-1}(F_{k1}(.))) with the component functions being ideal ciphers. This models the resistance of these constructions to ``generic'' attacks like meet in the middle attacks. We obtain the first proof that composition actually increases the security of these constructions in some meaningful sense. We compute a bound on the probability of breaking the double cipher as a function of the number of computations of the base cipher made, and the number of examples of the composed cipher seen, and show that the success probability is the square of that for a single key cipher. The same bound holds for the two-key triple cipher. The first bound is tight and shows that meet in the middle is the best possible generic attack against the double cipher.","An extended abstract of this paper appeared in the proceedings of
  Crypto 98 conference (Springer Verlag LNCS Vol 1462, 1998). This is the full
  version","William Aiello, Mihir Bellare, Giovanni Di Crescenzo, Ramarathnam Venkatesan",computer science,train
Security Policy Specification Using a Graphical Approach,"A security policy states the acceptable actions of an information system, as the actions bear on security. There is a pressing need for organizations to declare their security policies, even informal statements would be better than the current practice. But, formal policy statements are preferable to support (1) reasoning about policies, e.g., for consistency and completeness, (2) automated enforcement of the policy, e.g., using wrappers around legacy systems or after the fact with an intrusion detection system, and (3) other formal manipulation of policies, e.g., the composition of policies. We present LaSCO, the Language for Security Constraints on Objects, in which a policy consists of two parts: the domain (assumptions about the system) and the requirement (what is allowed assuming the domain is satisfied). Thus policies defined in LaSCO have the appearance of conditional access control statements. LaSCO policies are specified as expressions in logic and as directed graphs, giving a visual view of policy. LaSCO has a simple semantics in first order logic (which we provide), thus permitting policies we write, even for complex policies, to be very perspicuous. LaSCO has syntax to express many of the situations we have found to be useful on policies or, more interesting, the composition of policies. LaSCO has an object-oriented structure, permitting it to be useful to describe policies on the objects and methods of an application written in an object-oriented language, in addition to the traditional policies on operating system objects. A LaSCO specification can be automatically translated into executable code that checks an invocation of a program with respect to a policy. The implementation of LaSCO is in Java, and generates wrappers to check Java programs with respect to a policy.","28 pages, 22 figures, in color (but color is not essential for
  viewing); UC Davis CS department technical report (July 22, 1998)","James A. Hoagland, Raju Pandey, Karl N. Levitt",computer science,test
Multiparty computation unconditionally secure against Q^2 adversary structures,"We present here a generalization of the work done by Rabin and Ben-Or. We give a protocol for multiparty computation which tolerates any Q^2 active adversary structure based on the existence of a broadcast channel, secure communication between each pair of participants, and a monotone span program with multiplication tolerating the structure. The secrecy achieved is unconditional although we allow an exponentially small probability of error. This is possible due to a protocol for computing the product of two values already shared by means of a homomorphic commitment scheme which appeared originally in a paper of Chaum, Evertse and van de Graaf.",11 pages. McGill University School of Computer Science tech. report,"Adam Smith, Anton Stiglic",computer science,train
Introduction to the RSA algorithm and modular arithmetic,These notes are a brief introduction to the RSA algorithm and modular arithmetic. They are intended for an undergraduate audience.,Notes for the Dalhousie Integrated Science Program,R. Milson,computer science,train
Transport Level Security: a proof using the Gong-Needham-Yahalom Logic,This paper provides a proof of the proposed Internet standard Transport Level Security protocol using the Gong-Needham-Yahalom logic. It is intended as a teaching aid and hopes to show to students: the potency of a formal method for protocol design; some of the subtleties of authenticating parties on a network where all messages can be intercepted; the design of what should be a widely accepted standard.,"22 pages, 2 figures, 1 appendix",Walter Eaves,computer science,train
Certificate Revocation Paradigms,"Research in the field of electronic signature confirmation has been active for some 20 years now. Unfortunately present certificate-based solutions also come from that age when no-one knew about online data transmission. The official standardized X.509 framework also depends heavily on offline operations, one of the most complicated ones being certificate revocation handling. This is done via huge Certificate Revocation Lists which are both inconvenient and expencive. Several improvements to these lists are proposed and in this report we try to analyze them briefly. We conclude that although it is possible to do better than in the original X.509 setting, none of the solutions presented this far is good enough.","Tech report on 14 pages, 2 figures",Jan Willemson,computer science,train
Quantum Bit Commitment Expansion,The paper was retracted.,The paper was retracted,Dominic Mayers,computer science,val
"Specifying and Implementing Security Policies Using LaSCO, the Language for Security Constraints on Objects","In this dissertation, we present LaSCO, the Language for Security Constraints on Objects, a new approach to expressing security policies using policy graphs and present a method for enforcing policies so expressed. Other approaches for stating security policies fall short of what is desirable with respect to either policy clarity, executability, or the precision with which a policy may be expressed. However, LaSCO is designed to have those three desirable properties of a security policy language as well as: relevance for many different systems, statement of policies at an appropriate level of detail, user friendliness for both casual and expert users, and amenability to formal reasoning. In LaSCO, the constraints of a policy are stated as directed graphs annotated with expressions describing the situation under which the policy applies and what the requirement is. LaSCO may be used for such diverse applications as executing programs, file systems, operating systems, distributed systems, and networks. Formal operational semantics have been defined for LaSCO. An architecture for implementing LaSCO on any system, is presented along with an implementation of the system-independent portion in Perl. Using this, we have implemented LaSCO for Java programs, preventing Java programs from violating policy. A GUI to facilitate writing policies is provided. We have studied applying LaSCO to a network as viewed by GrIDS, a distributed intrusion detection system for large networks, and propose a design. We conclude that LaSCO has characteristics that enable its use on different types of systems throughout the process of precisely expressing a policy, understanding the implications of a policy, and implementing it on a system.","Ph.D. disseration, UC Davis, Computer Science, March 2000. In color
  but looks okay in black and white",James A. Hoagland,computer science,val
"The Random Oracle Methodology, Revisited","We take a critical look at the relationship between the security of cryptographic schemes in the Random Oracle Model, and the security of the schemes that result from implementing the random oracle by so called ""cryptographic hash functions"". The main result of this paper is a negative one: There exist signature and encryption schemes that are secure in the Random Oracle Model, but for which any implementation of the random oracle results in insecure schemes. In the process of devising the above schemes, we consider possible definitions for the notion of a ""good implementation"" of a random oracle, pointing out limitations and challenges.",31 pages,"Ran Canetti, Oded Goldreich, Shai Halevi",computer science,val
Anonymous Oblivious Transfer,In this short note we want to introduce {\em anonymous oblivious transfer} a new cryptographic primitive which can be proven to be strictly more powerful than oblivious transfer. We show that all functions can be robustly realized by multi party protocols with {\em anonymous oblivious transfer}. No assumption about possible collusions of cheaters or disruptors have to be made. Furthermore we shortly discuss how to realize anonymous oblivious transfer with oblivious broadcast or by quantum cryptography. The protocol of anonymous oblivious transfer was inspired by a quantum protocol: the anonymous quantum channel.,"6 pages, some things clearified, especially that a broadcast channel
  is not necessary","J. Mueller-Quade, H. Imai",computer science,train
A Linear Shift Invariant Multiscale Transform,"This paper presents a multiscale decomposition algorithm. Unlike standard wavelet transforms, the proposed operator is both linear and shift invariant. The central idea is to obtain shift invariance by averaging the aligned wavelet transform projections over all circular shifts of the signal. It is shown how the same transform can be obtained by a linear filter bank.","4 pages, 5 figures",Andreas Siebert,computer science,train
General Theory of Image Normalization,"We give a systematic, abstract formulation of the image normalization method as applied to a general group of image transformations, and then illustrate the abstract analysis by applying it to the hierarchy of viewing transformations of a planar object.","33 pages, plain tex, no figures",Stephen L. Adler,computer science,val
A Differential Invariant for Zooming,This paper presents an invariant under scaling and linear brightness change. The invariant is based on differentials and therefore is a local feature. Rotationally invariant 2-d differential Gaussian operators up to third order are proposed for the implementation of the invariant. The performance is analyzed by simulating a camera zoom-out.,"5 pages, 7 figures",Andreas Siebert,computer science,train
A Parallel Algorithm for Dilated Contour Extraction from Bilevel Images,"We describe a simple, but efficient algorithm for the generation of dilated contours from bilevel images. The initial part of the contour extraction is explained to be a good candidate for parallel computer code generation. The remainder of the algorithm is of linear nature.","5 pages, including 3 figures. For additional detail check
  http://www.nis.lanl.gov/~bschlei/labvis/index.html","B. R. Schlei, L. Prasad",computer science,train
"Image Compression with Iterated Function Systems, Finite Automata and Zerotrees: Grand Unification","Fractal image compression, Culik's image compression and zerotree prediction coding of wavelet image decomposition coefficients succeed only because typical images being compressed possess a significant degree of self-similarity. Besides the common concept, these methods turn out to be even more tightly related, to the point of algorithmical reducibility of one technique to another. The goal of the present paper is to demonstrate these relations. The paper offers a plain-term interpretation of Culik's image compression, in regular image processing terms, without resorting to finite state machines and similar lofty language. The interpretation is shown to be algorithmically related to an IFS fractal image compression method: an IFS can be exactly transformed into Culik's image code. Using this transformation, we will prove that in a self-similar (part of an) image any zero wavelet coefficient is the root of a zerotree, or its branch. The paper discusses the zerotree coding of (wavelet/projection) coefficients as a common predictor/corrector, applied vertically through different layers of a multiresolutional decomposition, rather than within the same view. This interpretation leads to an insight into the evolution of image compression techniques: from a causal single-layer prediction, to non-causal same-view predictions (wavelet decomposition among others) and to a causal cross-layer prediction (zero-trees, Culik's method).","This is a full paper submitted to Data Compression Conference '96; 10
  pages; The abstract of this paper was published in Proc. DCC'96: Data
  Compression Conference, March 31 - April 3, 1996, Snowbird, Utah, IEEE
  Computer Society Press, Los Alamitos, California, 1996, p.443","Oleg Kiselyov, Paul Fisher",computer science,train
Differential Invariants under Gamma Correction,This paper presents invariants under gamma correction and similarity transformations. The invariants are local features based on differentials which are implemented using derivatives of the Gaussian. The use of the proposed invariant representation is shown to yield improved correlation results in a template matching scenario.,"8 pages, 12 figures",Andreas Siebert,computer science,train
Assisted Video Sequences Indexing : Motion Analysis Based on Interest Points,"This work deals with content-based video indexing. Our viewpoint is semi-automatic analysis of compressed video. We consider the possible applications of motion analysis and moving object detection : assisting moving object indexing, summarising videos, and allowing image and motion queries. We propose an approach based on interest points. As first results, we test and compare the stability of different types of interest point detectors in compressed sequences.","HTML, 8 pages, 6 figures, http://rfv.insa-lyon.fr/~etievent/","Emmanuel Etievent, Frank Lebourgeois, Jean-Michel Jolion",computer science,val
Robustness of Regional Matching Scheme over Global Matching Scheme,"The paper has established and verified the theory prevailing widely among image and pattern recognition specialists that the bottom-up indirect regional matching process is the more stable and the more robust than the global matching process against concentrated types of noise represented by clutter, outlier or occlusion in the imagery. We have demonstrated this by analyzing the effect of concentrated noise on a typical decision making process of a simplified two candidate voting model where our theorem establishes the lower bounds to a critical breakdown point of election (or decision) result by the bottom-up matching process are greater than the exact bound of the global matching process implying that the former regional process is capable of accommodating a higher level of noise than the latter global process before the result of decision overturns. We present a convincing experimental verification supporting not only the theory by a white-black flag recognition problem in the presence of localized noise but also the validity of the conjecture by a facial recognition problem that the theorem remains valid for other decision making processes involving an important dimension-reducing transform such as principal component analysis or a Gabor transform.","16 pages, Latex, 7 EPS figures, using esub2acm.cls and epsf.tex","Liang Chen, Naoyuki Tokuda",computer science,test
Boosting the Differences: A fast Bayesian classifier neural network,"A Bayesian classifier that up-weights the differences in the attribute values is discussed. Using four popular datasets from the UCI repository, some interesting features of the network are illustrated. The network is suitable for classification problems.",latex 18pages no figures,"Ninan Sajeeth Philip, K. Babu Joseph",computer science,train
Distorted English Alphabet Identification : An application of Difference Boosting Algorithm,"The difference-boosting algorithm is used on letters dataset from the UCI repository to classify distorted raster images of English alphabets. In contrast to rather complex networks, the difference-boosting is found to produce comparable or better classification efficiency on this complex problem.",latex 14pages no figures,"Ninan Sajeeth Philip, K. Babu Joseph",computer science,val
Influencing Software Usage,"Technology designers often strive to design systems that are flexible enough to be used in a wide range of situations. Software engineers, in particular, are trained to seek general solutions to problems. General solutions can be used not only to address the problem at hand, but also to address a wide range of problems that the designers may not have even anticipated. Sometimes designers wish to provide general solutions, while encouraging certain uses of their technology and discouraging or precluding others. They may attempt to influence the use of technology by ``hard-wiring'' it so that it only can be used in certain ways, licensing it so that those who use it are legally obligated to use it in certain ways, issuing guidelines for how it should be used, or providing resources that make it easier to use the technology as the designers intended than to use it in any other way. This paper examines several cases where designers have attempted to influence the use of technology through one of these mechanisms. Such cases include key recovery encryption, Pegasus Mail, Platform for Internet Content Selection (PICS) Guidelines, Java, Platform for Privacy Preferences Project (P3P) Implementation Guide, Apple's style guidelines, and Microsoft Foundation Classes. In some of these cases, the designers sought to influence the use of technology for competitive reasons or in order to promote standardization or interoperability. However, in other cases designers were motivated by policy-related goals such as protecting privacy or free speech. As new technologies are introduced with the express purpose of advancing policy-related goals (for example, PICS and P3P), it is especially important to understand the roles designers might play in influencing the use of technology.","Prepared for the 26th Telecommunications Policy Research Conference,
  October 3-5, 1998, Alexandria, VA","Lorrie Faith Cranor, Rebecca N. Wright",computer science,train
The Impact of Net Culture on Mainstream Societies: a Global Analysis,"In this work the impact of the Internet culture on standard mainstream societies has been analyzed. After analytically establishing the fact that the Net can be viewed as a pan-societal superstructure which supports its own distinct culture, an ethnographic analysis is provided to find out the key aspects of this culture. The elements of this culture which have an empowering impacts on the standard mainstream societies, as well as the elements in it which can cause discouraging social effects are then discussed by a global investigation of the present status of various fundamental aspects (e,g, education, economics, politics, entertainment etc) of the mainstream societies as well as their links with the Net culture. Though immensely potential for providing various prominent positive impacts, the key findings of this work indicate that misuse of Internet can create tremendous harm to the members of the mainstream societies by generating a set of morally crippled people as well as a future generation completely void of principles and ethics. This structured diagnostic approach to the social problems caused by the manhandling of Internet leads to a concrete effort of providing the measures that can be taken to enhance or to overcome the supporting and limiting effects of the Net culture respectively with the intent to benefit our society and to protect the teratoidation of certain ethical values.","8 pages, no figure, Submitted to The Economic and Political Weekly",Tapas Kumar Das,computer science,train
Not Just a Matter of Time: Field Differences and the Shaping of Electronic Media in Supporting Scientific Communication,"The shift towards the use of electronic media in scholarly communication appears to be an inescapable imperative. However, these shifts are uneven, both with respect to field and with respect to the form of communication. Different scientific fields have developed and use distinctly different communicative forums, both in the paper and electronic arenas, and these forums play different communicative roles within the field. One common claim is that we are in the early stages of an electronic revolution, that it is only a matter of time before other fields catch up with the early adopters, and that all fields converge on a stable set of electronic forums. A social shaping of technology (SST) perspective helps us to identify important social forces centered around disciplinary constructions of trust and of legitimate communication that pull against convergence. This analysis concludes that communicative plurality and communicative heterogeneity are durable features of the scholarly landscape, and that we are likely to see field differences in the use of and meaning ascribed to communications forums persist, even as overall use of electronic communications technologies both in science and in society as a whole increases.","Accepted for publication in the Journal of the American Society for
  Information Science. Version was reformatted with several minor text changes","Rob Kling, Geoffrey McKim",computer science,train
Agents of Choice: Tools that Facilitate Notice and Choice about Web Site Data Practices,"A variety of tools have been introduced recently that are designed to help people protect their privacy on the Internet. These tools perform many different functions in-cluding encrypting and/or anonymizing communications, preventing the use of persistent identifiers such as cookies, automatically fetching and analyzing web site privacy policies, and displaying privacy-related information to users. This paper discusses the set of privacy tools that aim specifically at facilitating notice and choice about Web site data practices. While these tools may also have components that perform other functions such as encryption, or they may be able to work in conjunction with other privacy tools, the primary pur-pose of these tools is to help make users aware of web site privacy practices and to make it easier for users to make informed choices about when to provide data to web sites. Examples of such tools include the Platform for Privacy Preferences (P3P) and various infomediary services.",8 pages,Lorrie Faith Cranor,computer science,train
Scientific Collaboratories as Socio-Technical Interaction Networks: A Theoretical Approach,"Collaboratories refer to laboratories where scientists can work together while they are in distant locations from each other and from key equipment. They have captured the interest both of CSCW researchers and of science funders who wish to optimize the use of rare scientific equipment and expertise. We examine the kind of CSCW conceptions that help us best understand the character of working relationships in these scientific collaboratories. Our model, inspired by actor-network theory, considers technologies as Socio-technical Interaction Networks (STINs). This model provides a rich understanding of the scientific collaboratories, and also a more complete understanding of the conditions and activities that support collaborative work in them. We illustrate the significance of STIN models with several cases drawn from the fields of high energy physics and materials science.",,"Rob Kling, Geoffrey McKim, Joanna Fortuna, Adam King",computer science,val
What's Fit To Print: The Effect Of Ownership Concentration On Product Variety In Daily Newspaper Markets,"This paper examines the effect of ownership concentration on product position, product variety and readership in markets for daily newspapers. US antitrust policy presumes that mergers reduce the amount and diversity of content available to consumers. However, the effects of consolidation in differentiated product markets cannot be determined solely from theory. Because multi-product firms internalize business stealing, mergers may encourage firms to reposition products, leading to more, not less, variety. Using data on reporter assignments from 1993-1999, results show that differentiation and variety increase with concentration. Moreover, there is evidence that additional variety increases readership, suggesting that concentration benefits consumers.","29th TPRC Conference, 2001",Lisa M. George,computer science,train
"Spiders and Crawlers and Bots, Oh My: The Economic Efficiency and Public Policy of Contracts that Restrict Data Collection","Recent trends reveal the search by companies for a legal hook to prevent the undesired and unauthorized copying of information posted on websites. In the center of this controversy are metasites, websites that display prices for a variety of vendors. Metasites function by implementing shopbots, which extract pricing data from other vendors' websites. Technological mechanisms have proved unsuccessful in blocking shopbots, and in response, websites have asserted a variety of legal claims. Two recent cases, which rely on the troublesome trespass to chattels doctrine, suggest that contract law may provide a less demanding legal method of preventing the search of websites by data robots. If blocking collection of pricing data is as simple as posting an online contract, the question arises whether this end result is desirable and legally viable.","29th TPRC Conference, 2001",Jeffrey M. Rosenfeld,computer science,train
Voice vs Data: Estimates of Media Usage and Network Traffic,"The popular conception is that data traffic nearly, if not already, exceeds voice traffic on backbone networks. However, the results of research reported in this paper imply that voice traffic greatly exceeds data traffic when real users are asked to estimate their usage of a wide variety of media. Media usage was surveyed for students in New York City and in Los Angeles. Other than significant differences in radio listening, e-mails, and downloads, the usage was quite similar. Telephone usage (wired and wireless) was nearly an hour per day. When converted to bits, the telephone traffic was much greater than the data traffic over the Internet. This paper reports on the details of the two user studies. The traffic implications of the results are estimated. The finding that voice exceeds data will then be reconciled with the popular opposite conception.","29th TPRC Conference, 2001",A. Michael Noll,computer science,val
The Role of Incentives for Opening Monopoly Markets: Comparing GTE and BOC Cooperation with Local Entrants,"While the 1996 Telecommunications Act requires all incumbent local telephone companies to cooperate with local entrants, section 271 of the Act provides the Bell companies (but not GTE) additional incentives to cooperate. Using an original data set, I compare the negotiations of AT&T, as a local entrant, with GTE and with the Bell companies in states where both operate. My results suggest that the differential incentives matter: The Bells accommodate entry more than does GTE, as evidenced in quicker agreements, less litigation, and more favorable prices offered for network access. Consistent with this, there is more entry into Bell territories","29th TPRC Conference, 2001",Federico Mini,computer science,train
The Effect of Native Language on Internet Usage,"Our goal is to distinguish between the following two hypotheses: (A) The Internet will remain disproportionately in English and will, over time, cause more people to learn English as second language and thus solidify the role of English as a global language. This outcome will prevail even though there are more native Chinese and Spanish speakers than there are native English speakers. (B) As the Internet matures, it will more accurately reflect the native languages spoken around the world (perhaps weighted by purchasing power) and will not promote English as a global language. English's ""early lead"" on the web is more likely to persist if those who are not native English speakers frequently access the large number of English language web sites that are currently available. In that case, many existing web sites will have little incentive to develop non-English versions of their sites, and new sites will tend to gravitate towards English. The key empirical question, therefore, is whether individuals whose native language is not English use the Web, or certain types of Web sites, less than do native English speakers. In order to examine this issue empirically, we employ a unique data set on Internet use at the individual level in Canada from Media Metrix. Canada provides an ideal setting to examine this issue because English is one of the two official languages. Our preliminary results suggest that English web sites are not a barrier to Internet use for French-speaking Quebecois. These preliminary results are consistent with the scenario in which the Internet will promote English as a global language.","29th TPRC Conference, 2001","Neil Gandal, Carl Shapiro",computer science,test
"The Five-Minute Rule Ten Years Later, and Other Computer Storage Rules of Thumb","Simple economic and performance arguments suggest appropriate lifetimes for main memory pages and suggest optimal page sizes. The fundamental tradeoffs are the prices and bandwidths of RAMs and disks. The analysis indicates that with today's technology, five minutes is a good lifetime for randomly accessed pages, one minute is a good lifetime for two-pass sequentially accessed pages, and 16 KB is a good size for index pages. These rules-of-thumb change in predictable ways as technology ratios change. They also motivate the importance of the new Kaps, Maps, Scans, and $/Kaps, $/Maps, $/TBscan metrics.","Original document at:
  http://research.microsoft.com/~gray/5_min_rule_SIGMOD.doc","Jim Gray, Goetz Graefe",computer science,train
Similarity-Based Queries for Time Series Data,"We study a set of linear transformations on the Fourier series representation of a sequence that can be used as the basis for similarity queries on time-series data. We show that our set of transformations is rich enough to formulate operations such as moving average and time warping. We present a query processing algorithm that uses the underlying R-tree index of a multidimensional data set to answer similarity queries efficiently. Our experiments show that the performance of this algorithm is competitive to that of processing ordinary (exact match) queries using the index, and much faster than sequential scanning. We relate our transformations to the general framework for similarity queries of Jagadish et al.",,"Davood Rafiei, Alberto Mendelzon",computer science,val
Efficient Retrieval of Similar Time Sequences Using DFT,"We propose an improvement of the known DFT-based indexing technique for fast retrieval of similar time sequences. We use the last few Fourier coefficients in the distance computation without storing them in the index since every coefficient at the end is the complex conjugate of a coefficient at the beginning and as strong as its counterpart. We show analytically that this observation can accelerate the search time of the index by more than a factor of two. This result was confirmed by our experiments, which were carried out on real stock prices and synthetic data.",,"Davood Rafiei, Alberto Mendelzon",computer science,test
Least expected cost query optimization: an exercise in utility,"We identify two unreasonable, though standard, assumptions made by database query optimizers that can adversely affect the quality of the chosen evaluation plans. One assumption is that it is enough to optimize for the expected case---that is, the case where various parameters (like available memory) take on their expected value. The other assumption is that the parameters are constant throughout the execution of the query. We present an algorithm based on the ``System R''-style query optimization algorithm that does not rely on these assumptions. The algorithm we present chooses the plan of the least expected cost instead of the plan of least cost given some fixed value of the parameters. In execution environments that exhibit a high degree of variability, our techniques should result in better performance.","This paper appears in Proceedings of the Eighteenth Annual ACM
  Symposium on Principles of Database Systems, 1999, pp. 138--147","Francis C. Chu, Joseph Y. Halpern, Praveen Seshadri",computer science,train
Efficient and Extensible Algorithms for Multi Query Optimization,"Complex queries are becoming commonplace, with the growing use of decision support systems. These complex queries often have a lot of common sub-expressions, either within a single query, or across multiple such queries run as a batch. Multi-query optimization aims at exploiting common sub-expressions to reduce evaluation cost. Multi-query optimization has hither-to been viewed as impractical, since earlier algorithms were exhaustive, and explore a doubly exponential search space. In this paper we demonstrate that multi-query optimization using heuristics is practical, and provides significant benefits. We propose three cost-based heuristic algorithms: Volcano-SH and Volcano-RU, which are based on simple modifications to the Volcano search strategy, and a greedy heuristic. Our greedy heuristic incorporates novel optimizations that improve efficiency greatly. Our algorithms are designed to be easily added to existing optimizers. We present a performance study comparing the algorithms, using workloads consisting of queries from the TPC-D benchmark. The study shows that our algorithms provide significant benefits over traditional optimization, at a very acceptable overhead in optimization time.",,"Prasan Roy, S. Seshadri, S. Sudarshan, Siddhesh Bhobe",computer science,val
Comparative Analysis of Five XML Query Languages,"XML is becoming the most relevant new standard for data representation and exchange on the WWW. Novel languages for extracting and restructuring the XML content have been proposed, some in the tradition of database query languages (i.e. SQL, OQL), others more closely inspired by XML. No standard for XML query language has yet been decided, but the discussion is ongoing within the World Wide Web Consortium and within many academic institutions and Internet-related major companies. We present a comparison of five, representative query languages for XML, highlighting their common features and differences.","TeX v3.1415, 17 pages, 6 figures, to be published in ACM Sigmod
  Record, March 2000","Angela Bonifati, Stefano Ceri",computer science,train
"Don't Trash your Intermediate Results, Cache 'em","In data warehouse and data mart systems, queries often take a long time to execute due to their complex nature. Query response times can be greatly improved by caching final/intermediate results of previous queries, and using them to answer later queries. In this paper we describe a caching system called Exchequer which incorporates several novel features including optimization aware cache maintenance and the use of a cache aware optimizer. In contrast, in existing work, the module that makes cost-benefit decisions is part of the cache manager and works independent of the optimizer which essentially reconsiders these decisions while finding the best plan for a query. In our work, the optimizer takes the decisions for the cache manager. Furthermore, existing approaches are either restricted to cube (slice/point) queries, or cache just the query results. On the other hand, our work is extens ible and in fact presents a data-model independent framework and algorithm. Our experimental results attest to the efficacy of our cache management techniques and show that over a wide range of parameters (a) Exchequer's query response times are lower by more than 30% compared to the best performing competitor, and (b) Exchequer can deliver the same response time as its competitor with just one tenth of the cache size.","22 pages, 4 figures","Prasan Roy, Krithi Ramamritham, S. Seshadri, Pradeep Shenoy, S. Sudarshan",computer science,test
Materialized View Selection and Maintenance Using Multi-Query Optimization,"Because the presence of views enhances query performance, materialized views are increasingly being supported by commercial database/data warehouse systems. Whenever the data warehouse is updated, the materialized views must also be updated. However, whereas the amount of data entering a warehouse, the query loads, and the need to obtain up-to-date responses are all increasing, the time window available for making the warehouse up-to-date is shrinking. These trends necessitate efficient techniques for the maintenance of materialized views. In this paper, we show how to find an efficient plan for maintenance of a {\em set} of views, by exploiting common subexpressions between different view maintenance expressions. These common subexpressions may be materialized temporarily during view maintenance. Our algorithms also choose subexpressions/indices to be materialized permanently (and maintained along with other materialized views), to speed up view maintenance. While there has been much work on view maintenance in the past, our novel contributions lie in exploiting a recently developed framework for multiquery optimization to efficiently find good view maintenance plans as above. In addition to faster view maintenance, our algorithms can also be used to efficiently select materialized views to speed up workloads containing queries.","22 pages, 7 figures","Hoshi Mistry, Prasan Roy, Krithi Ramamritham, S. Sudarshan",computer science,train
Managing Periodically Updated Data in Relational Databases: A Stochastic Modeling Approach,"Recent trends in information management involve the periodic transcription of data onto secondary devices in a networked environment, and the proper scheduling of these transcriptions is critical for efficient data management. To assist in the scheduling process, we are interested in modeling the reduction of consistency over time between a relation and its replica, termed obsolescence of data. The modeling is based on techniques from the field of stochastic processes, and provides several stochastic models for content evolution in the base relations of a database, taking referential integrity constraints into account. These models are general enough to accommodate most of the common scenarios in databases, including batch insertions and life spans both with and without memory. As an initial ""proof of concept"" of the applicability of our approach, we validate the insertion portion of our model framework via experiments with real data feeds. We also discuss a set of transcription protocols which make use of the proposed stochastic model.",,"Avigdor Gal, Jonathan Eckstein",computer science,train
Algorithms for Rewriting Aggregate Queries Using Views,"Queries involving aggregation are typical in database applications. One of the main ideas to optimize the execution of an aggregate query is to reuse results of previously answered queries. This leads to the problem of rewriting aggregate queries using views. Due to a lack of theory, algorithms for this problem were rather ad-hoc. They were sound, but were not proven to be complete. Recently we have given syntactic characterizations for the equivalence of aggregate queries and applied them to decide when there exist rewritings. However, these decision procedures do not lend themselves immediately to an implementation. In this paper, we present practical algorithms for rewriting queries with $\COUNT$ and $\SUM$. Our algorithms are sound. They are also complete for important cases. Our techniques can be used to improve well-known procedures for rewriting non-aggregate queries. These procedures can then be adapted to obtain algorithms for rewriting queries with $\MIN$ and $\MAX$. The algorithms presented are a basis for realizing optimizers that rewrite queries using views.","technical report CW 292 of Katholieke Universiteit Leuven (Short
  version in In Julius Stuller, Jaroslav Pokorn?, Bernhard Thalheim, Yoshifumi
  Masunaga (Eds.): Current Issues in Databases and Information Systems,
  East-European Conference on Advances in Databases and Information Systems
  Held Jointly with International Conference on Database Systems for Advanced
  Applications, ADBIS-DASFAA 2000, Prague, Czech Republic, September 5-8,
  2000.)","Sara Cohen, Werner Nutt, Alexander Serebrenik",computer science,train
"Distributed Computation, the Twisted Isomorphism, and Auto-Poiesis","This paper presents a synchronization-based, multi-process computational model of anticipatory systems called the Phase Web. It describes a self-organizing paradigm that explicitly recognizes and exploits the existence of a boundary between inside and outside, accepts and exploits intentionality, and uses explicit self-reference to describe eg. auto-poiesis. The model explicitly connects computation to a discrete Clifford algebraic formalization that is in turn extended into homology and co-homology, wherein the recursive nature of objects and boundaries becomes apparent and itself subject to hierarchical recursion. Topsy, a computer program embodying the Phase Web, is available at www.cs.auc.dk/topsy.","26 pages, 4 figures. Originally submitted to the neuro-sys archive
  which was never publicly announced (was 9809001)",Michael Manthey,computer science,train
Gryphon: An Information Flow Based Approach to Message Brokering,"Gryphon is a distributed computing paradigm for message brokering, which is the transferring of information in the form of streams of events from information providers to information consumers. This extended abstract outlines the major problems in message brokering and Gryphon's approach to solving them.",Two page extended abstract,"Robert Strom, Guruduth Banavar, Tushar Chandra, Marc Kaplan, Kevan Miller, Bodhi Mukherjee, Daniel Sturman, Michael Ward",computer science,val
"Self-stabilizing mutual exclusion on a ring, even if K=N","We show that, contrary to common belief, Dijkstra's self-stabilizing mutual exclusion algorithm on a ring [Dij74,Dij82] also stabilizes when the number of states per node is one less than the number of nodes on the ring.",2 pages,Jaap-Henk Hoepman,computer science,train
A decision-theoretic approach to reliable message delivery,"We argue that the tools of decision theory need to be taken more seriously in the specification and analysis of systems. We illustrate this by considering a simple problem involving reliable communication, showing how considerations of utility and probability can be used to decide when it is worth sending heartbeat messages and, if they are sent, how often they should be sent.","This is the full version of a paper that appears in the Proceedings
  of the 12th International Symposium on Distributed Computing, 1998, pp. 89-10","Francis C. Chu, Joseph Y. Halpern",computer science,val
On Automata with Boundary,"We present a theory of automata with boundary for designing, modelling and analysing distributed systems. Notions of behaviour, design and simulation appropriate to the theory are defined. The problem of model checking for deadlock detection is discussed, and an algorithm for state space reduction in exhaustive search, based on the theory presented here, is described. Three examples of the application of the theory are given, one in the course of the development of the ideas and two as illustrative examples of the use of the theory.","41 pages, 22 figures. Uses Paul Taylor's diagrams macros, see
  http://www.ctan.org/tex-archive/macros/generic/diagrams/taylor/","R. Gates, P. Katis, N. Sabadini, R. F. C. Walters",computer science,val
"A Problem-Specific Fault-Tolerance Mechanism for Asynchronous, Distributed Systems","The idle computers on a local area, campus area, or even wide area network represent a significant computational resource---one that is, however, also unreliable, heterogeneous, and opportunistic. This type of resource has been used effectively for embarrassingly parallel problems but not for more tightly coupled problems. We describe an algorithm that allows branch-and-bound problems to be solved in such environments. In designing this algorithm, we faced two challenges: (1) scalability, to effectively exploit the variably sized pools of resources available, and (2) fault tolerance, to ensure the reliability of services. We achieve scalability through a fully decentralized algorithm, by using a membership protocol for managing dynamically available resources. However, this fully decentralized design makes achieving reliability even more challenging. We guarantee fault tolerance in the sense that the loss of up to all but one resource will not affect the quality of the solution. For propagating information efficiently, we use epidemic communication for both the membership protocol and the fault-tolerance mechanism. We have developed a simulation framework that allows us to evaluate design alternatives. Results obtained in this framework suggest that our techniques can execute scalably and reliably.","17 pages, 6 figures","Adriana Iamnitchi, Ian Foster",computer science,train
Sorting Integers on the AP1000,"Sorting is one of the classic problems of computer science. Whilst well understood on sequential machines, the diversity of architectures amongst parallel systems means that algorithms do not perform uniformly on all platforms. This document describes the implementation of a radix based algorithm for sorting positive integers on a Fujitsu AP1000 Supercomputer, which was constructed as an entry in the Joint Symposium on Parallel Processing (JSPP) 1994 Parallel Software Contest (PSC94). Brief consideration is also given to a full radix sort conducted in parallel across the machine.","1994 Project Report, 23 pages","Lex Weaver, Andrew Lynes",computer science,train
"A Note on ""Optimal Static Load Balancing in Distributed Computer Systems""","The problem of minimizing mean response time of generic jobs submitted to a heterogenous distributed computer systems is considered in this paper. A static load balancing strategy, in which decision of redistribution of loads does not depend on the state of the system, is used for this purpose. The article is closely related to a previous article on the same topic. The present article points out number of inconsistencies in the previous article, provides a new formulation, and discusses the impact of new findings, based on the improved formulation, on the results of the previous article.",18 pages,S. A. Mondal,computer science,train
Performing work efficiently in the presence of faults,"We consider a system of t synchronous processes that communicate only by sending messages to one another, and that together must perform $n$ independent units of work. Processes may fail by crashing; we want to guarantee that in every execution of the protocol in which at least one process survives, all n units of work will be performed. We consider three parameters: the number of messages sent, the total number of units of work performed (including multiplicities), and time. We present three protocols for solving the problem. All three are work-optimal, doing O(n+t) work. The first has moderate costs in the remaining two parameters, sending O(t\sqrt{t}) messages, and taking O(n+t) time. This protocol can be easily modified to run in any completely asynchronous system equipped with a failure detection mechanism. The second sends only O(t log{t}) messages, but its running time is large (exponential in n and t). The third is essentially time-optimal in the (usual) case in which there are no failures, and its time complexity degrades gracefully as the number of failures increases.",,"Cynthia Dwork, Joseph Y. Halpern, O. Waarts",computer science,train
Phase Clocks for Transient Fault Repair,"Phase clocks are synchronization tools that implement a form of logical time in distributed systems. For systems tolerating transient faults by self-repair of damaged data, phase clocks can enable reasoning about the progress of distributed repair procedures. This paper presents a phase clock algorithm suited to the model of transient memory faults in asynchronous systems with read/write registers. The algorithm is self-stabilizing and guarantees accuracy of phase clocks within O(k) time following an initial state that is k-faulty. Composition theorems show how the algorithm can be used for the timing of distributed procedures that repair system outputs.","22 pages, LaTeX",Ted Herman,computer science,train
Digitizing Legacy Documents: A Knowledge-Base Preservation Project,"This paper addresses the issue of making legacy information (that material held in paper format only) electronically searchable and retrievable. We used proprietary software and commercial hardware to create a process for scanning, cataloging, archiving and electronically disseminating full-text documents. This process is relatively easy to implement and reasonably affordable.","21 pages, 5 figures","Elizabeth Anderson, Robert Atkinson, Cynthia Crego, Jean Slisz, Sara Tompson",computer science,val
Vocal Access to a Newspaper Archive: Design Issues and Preliminary Investigation,This paper presents the design and the current prototype implementation of an interactive vocal Information Retrieval system that can be used to access articles of a large newspaper archive using a telephone. The results of preliminary investigation into the feasibility of such a system are also presented.,,Fabio Crestani,computer science,test
Making the most of electronic journals,"As most electronic journals available today have been derived from print originals, print journals have become a vital element in the broad development of electronic journals publishing. Further dependence on the print publishing model, however, will be a constraint on the continuing development of e-journals, and a series of conflicts are likely to arise. Making the most of e-journals requires that a distinctive new publishing model is developed. We consider some of the issues that will be fundamental in this new model, starting with user motivations and some reported publisher experiences, both of which suggest a broadening desire for comprehensive linked archives. This leads in turn to questions about the impact of rights assignment by authors, in particular the common practice of giving exlusive rights to publishers for individual works. Some non-prescriptive solutions are suggested, and four steps towards optimum e-journals are proposed.",11 pages,"Steve Hitchcock, Les Carr, Wendy Hall",computer science,val
The Computing Research Repository: Promoting the Rapid Dissemination and Archiving of Computer Science Research,"We describe the Computing Research Repository (CoRR), a new electronic archive for rapid dissemination and archiving of computer science research results. CoRR was initiated in September 1998 through the cooperation of ACM, LANL (Los Alamos National Laboratory) e-Print archive, and NCSTRL (Networked Computer Science Technical Research Library. Through its implementation of the Dienst protocol, CoRR combines the open and extensible architecture of NCSTRL with the reliable access and well-established management practices of the LANL XXX e-Print repository. This architecture will allow integration with other e-Print archives and provides a foundation for a future broad-based scholarly digital library. We describe the decisions that were made in creating CoRR, the architecture of the CoRR/NCSTRL interoperation, and issues that have arisen during the operation of CoRR.",Submission to ACM DL99,"Joseph Y. Halpern, Carl Lagoze",computer science,train
Competition and cooperation: Libraries and publishers in the transition to electronic scholarly journals,"The conversion of scholarly journals to digital format is proceeding rapidly, especially for those from large commercial and learned society publishers. This conversion offers the best hope for survival for such publishers. The infamous ""journal crisis"" is more of a library cost crisis than a publisher pricing problem, with internal library costs much higher than the amount spent on purchasing books and journals. Therefore publishers may be able to retain or even increase their revenues and profits, while at the same time providing a superior service. To do this, they will have to take over many of the function of libraries, and they can do that only in the digital domain. This paper examines publishers' strategies, how they are likely to evolve, and how they will affect libraries.",,Andrew Odlyzko,computer science,train
"MyLibrary: A Model for Implementing a User-centered, Customizable Interface to a Library's Collection of Information Resources","The paper describes an extensible model for implementing a user-centered, customizable interface to a library's collection of information resources. This model, called MyLibrary, integrates the principles of librarianship (collection, organization, dissemination, and evaluation) with globally networked computing resources creating a dynamic, customer-driven front-end to any library's set of materials. The model supports a framework for libraries to provide enhanced access to local and remote sets of data, information, and knowledge. At the same, the model does not overwhelm its users with too much information because the users control exactly how much information is displayed to them at any given time. The model is active and not passive; direct human interaction, computer mediated guidance and communication technologies, as well as current awareness services all play indispensable roles in this system.","10 pages, 6 figures",Eric Lease Morgan,computer science,val
"The Alex Catalogue, A Collection of Digital Texts with Automatic Methods for Acquisition and Cataloging, User-Defined Typography, Cross-searching of Indexed Content, and a Sense of Community","This paper describes the Alex Catalogue of Electronic Texts, the only Internet-accessible collection of digital documents allowing the user to 1) dynamically create customized, typographically readable documents on demand, 2) search the content of one or more documents from the collection simultaneously, 3) create sets of documents from the collection for review and annotation, and 4) publish these sets of annotated documents in turn fostering a sense of community around the Catalogue. More than a just a collection of links that will break over time, Alex is an archive of electronic texts providing unprecedented access to its content and features allowing it to meet the needs of a wide variety of users and settings. Furthermore, the process of maintaining the Catalogue is streamlined with tools for automatic acquisition and cataloging making it possible to sustain the service with a minimum of personnel.","9 pages, 2 figures",Eric Lease Morgan,computer science,train
KEA: Practical Automatic Keyphrase Extraction,"Keyphrases provide semantic metadata that summarize and characterize documents. This paper describes Kea, an algorithm for automatically extracting keyphrases from text. Kea identifies candidate keyphrases using lexical methods, calculates feature values for each candidate, and uses a machine-learning algorithm to predict which candidates are good keyphrases. The machine learning scheme first builds a prediction model using training documents with known keyphrases, and then uses the model to find keyphrases in new documents. We use a large test corpus to evaluate Kea's effectiveness in terms of how many author-assigned keyphrases are correctly identified. The system is simple, robust, and publicly available.",9 pages,"Ian H. Witten, Gordon W. Paynter, Eibe Frank, Carl Gutwin, Craig G. Nevill-Manning",computer science,train
Quality of OCR for Degraded Text Images,"Commercial OCR packages work best with high-quality scanned images. They often produce poor results when the image is degraded, either because the original itself was poor quality, or because of excessive photocopying. The ability to predict the word failure rate of OCR from a statistical analysis of the image can help in making decisions in the trade-off between the success rate of OCR and the cost of human correction of errors. This paper describes an investigation of OCR of degraded text images using a standard OCR engine (Adobe Capture). The documents were selected from those in the archive at Los Alamos National Laboratory. By introducing noise in a controlled manner into perfect documents, we show how the quality of OCR can be predicted from the nature of the noise. The preliminary results show that a simple noise model can give good prediction of the number of OCR errors.",7 pages,"Roger T. Hartley, Kathleen Crumpton",computer science,val
Content-Based Book Recommending Using Learning for Text Categorization,"Recommender systems improve access to relevant products and information by making personalized suggestions based on previous examples of a user's likes and dislikes. Most existing recommender systems use social filtering methods that base recommendations on other users' preferences. By contrast, content-based methods use information about an item itself to make suggestions. This approach has the advantage of being able to recommended previously unrated items to users with unique interests and to provide explanations for its recommendations. We describe a content-based book recommending system that utilizes information extraction and a machine-learning algorithm for text categorization. Initial experimental results demonstrate that this approach can produce accurate recommendations.","8 pages, 3 figures, Submission to Fourth ACM Conference on Digital
  Libraries","Raymond J. Mooney, Loriene Roy",computer science,val
The Distribution of Cycle Lengths in Graphical Models for Iterative Decoding,"This paper analyzes the distribution of cycle lengths in turbo decoding and low-density parity check (LDPC) graphs. The properties of such cycles are of significant interest in the context of iterative decoding algorithms which are based on belief propagation or message passing. We estimate the probability that there exist no simple cycles of length less than or equal to k at a randomly chosen node in a turbo decoding graph using a combination of counting arguments and independence assumptions. For large block lengths n, this probability is approximately e^{-{2^{k-1}-4}/n}, k>=4. Simulation results validate the accuracy of the various approximations. For example, for turbo codes with a block length of 64000, a randomly chosen node has a less than 1% chance of being on a cycle of length less than or equal to 10, but has a greater than 99.9% chance of being on a cycle of length less than or equal to 20. The effect of the ""S-random"" permutation is also analyzed and it is shown that while it eliminates short cycles of length k<8, it does not significantly affect the overall distribution of cycle lengths. Similar analyses and simulations are also presented for graphs for LDPC codes. The paper concludes by commenting briefly on how these results may provide insight into the practical success of iterative decoding methods.","23 pages, 11 figures","Xian-ping Ge, David Eppstein, Padhraic Smyth",computer science,test
Combining Random Number Generators using Quasicrystals,"This paper has been withdrawn by the author(s),",,"Louis-Sebastien Guimond, Zuzana Masakova, Jiri Patera, Edita Pelantova",computer science,train
Statistics and implementation of APRNGs,"This paper has been temporarily withdrawn by the author(s),",This paper has been temporarily withdrawn by the author(s),"Louis-Sebastien Guimond, Jan Patera, Jiri Patera",computer science,train
Lattice Structure and Convergence of a Game of Cards,This paper is devoted to the study of the dynamics of a discrete system related to some self stabilizing protocol on a ring of processors.,"10 pages, 1 figures, submitted. See also:
  http://www.liafa.jussieu.fr/~phan/anglais/public.html","Eric Goles, Michel Morvan, Ha Duong Phan",computer science,train
"SimLab 1.1, Software for Sensitivity and Uncertainty Analysis, tool for sound modelling","The aim of this paper is to present and describe SimLab 1.1 (Simulation Laboratory for Uncertainty and Sensitivity Analysis) software designed for Monte Carlo analysis that is based on performing multiple model evaluations with probabilistically selected model input. The results of these evaluations are used to determine both the uncertainty in model predictions and the input variables that drive this uncertainty. This methodology is essential in situations where a decision has to be taken based on the model results; typical examples include risk and emergency management systems, financial analysis and many others. It is also highly recommended as part of model validation, even where the models are used for diagnostic purposes, as an element of sound model building. SimLab allows an exploration of the space of possible alternative model assumptions and structure on the prediction of the model, thereby testing both the quality of the model and the robustness of the model based inference.","11 pages, pdf format, to be submitted to JACM","N. Giglioli, A. Saltelli",computer science,val
Approximating the satisfiability threshold for random k-XOR-formulas,"In this paper we study random linear systems with $k$ variables per equation over the finite field GF(2), or equivalently $k$-XOR-CNF formulas. In a previous paper Creignou and Daud\'e proved that the phase transition for the consistency (satisfiability) of such systems (formulas) exhibits a sharp threshold. Here we prove that the phase transition occurs as the number of equations (clauses) is proportional to the number of variables. For any $k\ge 3$ we establish first estimates for the critical ratio. For $k=3$ we get 0.93 as an upper bound, 0.89 as a lower bound, whereas experiments suggest that the critical ratio is approximately 0.92.","15 pages, 1 figure","Nadia Creignou, Herve Daude, Olivier Dubois",computer science,train
Solving Assembly Line Balancing Problems by Combining IP and CP,"Assembly line balancing problems consist in partitioning the work necessary to assemble a number of products among different stations of an assembly line. We present a hybrid approach for solving such problems, which combines constraint programming and integer programming.","10 pages, Sixth Annual Workshop of the ERCIM Working Group on
  Constraints, Prague, June 2001","Alexander Bockmayr, Nicolai Pisaruk",computer science,train
On a Special Case of the Generalized Neighbourhood Problem,"For a given finite class of finite graphs H, a graph G is called a realization of H if the neighbourhood of its any vertex induces the subgraph isomorphic to a graph of H. We consider the following problem known as the Generalized Neighbourhood Problem (GNP): given a finite class of finite graphs H, does there exist a non-empty graph G that is a realization of H? In fact, there are two modifications of that problem, namely the finite (the existence of a finite realization is required) and infinite one (the realization is required to be infinite). In this paper we show that GNP and its modifications for all finite classes H of finite graphs are reduced to the same problems with an additional restriction on H. Namely, the orders of any two graphs of H are equal and every graph of H has exactly s dominating vertices.","13 pages, 3 figures, in Russian","V. Naidenko, Yu. Orlovich",computer science,train
Sampling from a couple of positively correlated binomial variables,"We know that the marginals in a multinomial distribution are binomial variates exhibiting a negative correlation. But we can construct two linear combinations of such marginals in such a way to obtain a positive correlation. We discuss the restrictions that are to be imposed on the parameters of the given marginals to accomplish such a result. Next we discuss the regression function, showing that it is a linear function but not homoscedastic.",,Mario Catalani,computer science,val
PHORMA: Perfectly Hashed Order Restricted Multidimensional Array,"In this paper we propose a simple and efficient strategy to obtain a data structure generator to accomplish a perfect hash of quite general order restricted multidimensional arrays named {\em phormas}. The constructor of such objects gets two parameters as input: an n-vector a of non negative integers and a boolean function B on the types of order restrictions on the coordinates of the valid n-vectors bounded by a. At compiler time, the phorma constructor builds, from the pair a,B, a digraph G(a,B) with a single source s and a single sink t such that the st-paths are in 1-1 correspondence with the members of the B-restricted a-bounded array A(a,B). Besides perfectly hashing A(a,B), G(a,B) is an instance of an NW-family. This permits other useful computational tasks on it.","12 pages, 4 figures","Lauro Lins, Sostenes Lins, Silvio Melo",computer science,val
Context-free multilanguages,"This article is a sketch of ideas that were once intended to appear in the author's famous series, ""The Art of Computer Programming"". He generalizes the notion of a context-free language from a set to a multiset of words over an alphabet. The idea is to keep track of the number of ways to parse a string. For example, ""fruit flies like a banana"" can famously be parsed in two ways; analogous examples in the setting of programming languages may yet be important in the future. The treatment is informal but essentially rigorous.",Abstract added by Greg Kuperberg,Donald E. Knuth,computer science,train
Shellsort with three increments,"A perturbation technique can be used to simplify and sharpen A. C. Yao's theorems about the behavior of shellsort with increments $(h,g,1)$. In particular, when $h=\Theta(n^{7/15})$ and $g=\Theta(h^{1/5})$, the average running time is $O(n^{23/15})$. The proof involves interesting properties of the inversions in random permutations that have been $h$-sorted and $g$-sorted.",,"Svante Janson, Donald E. Knuth",computer science,train
Linear probing and graphs,"Mallows and Riordan showed in 1968 that labeled trees with a small number of inversions are related to labeled graphs that are connected and sparse. Wright enumerated sparse connected graphs in 1977, and Kreweras related the inversions of trees to the so-called ``parking problem'' in 1980. A~combination of these three results leads to a surprisingly simple analysis of the behavior of hashing by linear probing, including higher moments of the cost of successful search.",,Donald E. Knuth,computer science,train
A Fully Polynomial Randomized Approximation Scheme for the All Terminal Network Reliability Problem,"The classic all-terminal network reliability problem posits a graph, each of whose edges fails independently with some given probability.",To appear in SICOMP,David R. Karger,computer science,val
Minimum Cuts in Near-Linear Time,"We significantly improve known time bounds for solving the minimum cut problem on undirected graphs. We use a ``semi-duality'' between minimum cuts and maximum spanning tree packings combined with our previously developed random sampling techniques. We give a randomized algorithm that finds a minimum cut in an m-edge, n-vertex graph with high probability in O(m log^3 n) time. We also give a simpler randomized algorithm that finds all minimum cuts with high probability in O(n^2 log n) time. This variant has an optimal RNC parallelization. Both variants improve on the previous best time bound of O(n^2 log^3 n). Other applications of the tree-packing approach are new, nearly tight bounds on the number of near minimum cuts a graph may have and a new data structure for representing them in a space-efficient manner.",,David R. Karger,computer science,train
Approximate Graph Coloring by Semidefinite Programming,"We consider the problem of coloring k-colorable graphs with the fewest possible colors. We present a randomized polynomial time algorithm that colors a 3-colorable graph on $n$ vertices with min O(Delta^{1/3} log^{1/2} Delta log n), O(n^{1/4} log^{1/2} n) colors where Delta is the maximum degree of any vertex. Besides giving the best known approximation ratio in terms of n, this marks the first non-trivial approximation result as a function of the maximum degree Delta. This result can be generalized to k-colorable graphs to obtain a coloring using min O(Delta^{1-2/k} log^{1/2} Delta log n), O(n^{1-3/(k+1)} log^{1/2} n) colors. Our results are inspired by the recent work of Goemans and Williamson who used an algorithm for semidefinite optimization problems, which generalize linear programs, to obtain improved approximations for the MAX CUT and MAX 2-SAT problems. An intriguing outcome of our work is a duality relationship established between the value of the optimum solution to our semidefinite program and the Lovasz theta-function. We show lower bounds on the gap between the optimum solution of our semidefinite program and the actual chromatic number; by duality this also demonstrates interesting new facts about the theta-function.",,"David Karger, Rajeev Motwani, Madhu Sudan",computer science,train
A class of problems of NP to be worth to search an efficient solving algorithm,"We examine possibility to design an efficient solving algorithm for problems of the class \np. It is introduced a classification of \np problems by the property that a partial solution of size $k$ can be extended into a partial solution of size $k+1$ in polynomial time. It is defined an unique class problems to be worth to search an efficient solving algorithm. The problems, which are outside of this class, are inherently exponential. We show that the Hamiltonian cycle problem is inherently exponential.","9 pages, 1 figures",Anatoly D. Plotnikov,computer science,train
Reconstructing hv-Convex Polyominoes from Orthogonal Projections,"Tomography is the area of reconstructing objects from projections. Here we wish to reconstruct a set of cells in a two dimensional grid, given the number of cells in every row and column. The set is required to be an hv-convex polyomino, that is all its cells must be connected and the cells in every row and column must be consecutive. A simple, polynomial algorithm for reconstructing hv-convex polyominoes is provided, which is several orders of magnitudes faster than the best previously known algorithm from Barcucci et al. In addition, the problem of reconstructing a special class of centered hv-convex polyominoes is addressed. (An object is centered if it contains a row whose length equals the total width of the object). It is shown that in this case the reconstruction problem can be solved in linear time.",,"Christoph Durr, Marek Chrobak",computer science,train
Subgraph Isomorphism in Planar Graphs and Related Problems,"We solve the subgraph isomorphism problem in planar graphs in linear time, for any pattern of constant size. Our results are based on a technique of partitioning the planar graph into pieces of small tree-width, and applying dynamic programming within each piece. The same methods can be used to solve other planar graph problems including connectivity, diameter, girth, induced subgraph isomorphism, and shortest paths.","27 pages, 6 figures. A preliminary version of this paper appeared at
  the 6th ACM-SIAM Symp. Discrete Algorithms, 1995",David Eppstein,computer science,train
Fast Hierarchical Clustering and Other Applications of Dynamic Closest Pairs,"We develop data structures for dynamic closest pair problems with arbitrary distance functions, that do not necessarily come from any geometric structure on the objects. Based on a technique previously used by the author for Euclidean closest pairs, we show how to insert and delete objects from an n-object set, maintaining the closest pair, in O(n log^2 n) time per update and O(n) space. With quadratic space, we can instead use a quadtree-like structure to achieve an optimal time bound, O(n) per update. We apply these data structures to hierarchical clustering, greedy matching, and TSP heuristics, and discuss other potential applications in machine learning, Groebner bases, and local improvement algorithms for partition and placement problems. Experiments show our new methods to be faster in practice than previously used heuristics.","20 pages, 9 figures. A preliminary version of this paper appeared at
  the 9th ACM-SIAM Symp. on Discrete Algorithms, San Francisco, 1998, pp.
  619-628. For source code and experimental results, see
  http://www.ics.uci.edu/~eppstein/projects/pairs/",David Eppstein,computer science,test
Noise-based information processing: Noise-based logic and computing: what do we have so far?,"We briefly introduce noise-based logic. After describing the main motivations we outline classical, instantaneous (squeezed and non-squeezed), continuum, spike and random-telegraph-signal based schemes with applications such as circuits that emulate the brain functioning and string verification via a slow communication channel.","Invited talk at the 21st International Conference on Noise and
  Fluctuations, Toronto, Canada, June 12-16, 2011","Laszlo B. Kish, Sunil Khatri, Sergey Bezrukov, Ferdinand Peper, Zoltan Gingl, Tamas Horvath",computer science,train
The Life and Death of Unwanted Bits: Towards Proactive Waste Data Management in Digital Ecosystems,"Our everyday data processing activities create massive amounts of data. Like physical waste and trash, unwanted and unused data also pollutes the digital environment by degrading the performance and capacity of storage systems and requiring costly disposal. In this paper, we propose using the lessons from real life waste management in handling waste data. We show the impact of waste data on the performance and operational costs of our computing systems. To allow better waste data management, we define a waste hierarchy for digital objects and provide insights into how to identify and categorize waste data. Finally, we introduce novel ways of reusing, reducing, and recycling data and software to minimize the impact of data wastage",Fixed references,"Ragib Hasan, Randal Burns",computer science,test
Power aware physical model for 3d IC's,"In this work we have proposed a geometric model that is employed to devise a scheme for identifying the hotspots and zones in a chip. These spots or zone need to be guarded thermally to ensure performance and reliability of the chip. The model namely continuous unit sphere model has been presented taking into account that the 3D region of the chip is uniform, thereby reflecting on the possible locations of heat sources and the target observation points. The experimental results for the - continuous domain establish that a region which does not contain any heat sources may become hotter than the regions containing the thermal sources. Thus a hotspot may appear away from the active sources, and placing heat sinks on the active thermal sources alone may not suffice to tackle thermal imbalance. Power management techniques aid in obtaining a uniform power profile throughout the chip, but we propose an algorithm using minimum bipartite matching where we try to move the sources minimally (with minimum perturbation in the chip floor plan) near cooler points (blocks) to obtain a uniform power profile due to diffusion of heat from hotter point to cooler ones.","10 pages, publised in International Journal of VLSI design &
  Communication Systems (VLSICS) Vol.2, No.3, September 2011",Yasmeen Hasan,computer science,train
Parallel Algorithms for DNA Probe Placement on Small Oligonucleotide Arrays,"Oligonucleotide arrays are used in a wide range of genomic analyses, such as gene expression profiling, comparative genomic hybridization, chromatin immunoprecipitation, SNP detection, etc. During fabrication, the sites of an oligonucleotide array are selectively exposed to light in order to activate oligonucleotides for further synthesis. Optical effects can cause unwanted illumination at masked sites that are adjacent to the sites intentionally exposed to light. This results in synthesis of unforeseen sequences in masked sites and compromises interpretation of experimental data. To reduce such uncertainty, one can exploit freedom in how probes are assigned to array sites. The border length minimization problem (BLMP) seeks a placement of probes that minimizes the sum of border lengths in all masks. In this paper, we propose two parallel algorithms for the BLMP. The proposed parallel algorithms have the local-search paradigm at their core, and are especially developed for the BLMP. The results reported show that, for small microarrays with at most 1156 probes, the proposed parallel algorithms perform better than the best previous algorithms.",,"Dragos Trinca, Sanguthevar Rajasekaran",computer science,train
Optimal Inverter VAR Control in Distribution Systems with High PV Penetration,"The intent of the study detailed in this paper is to demonstrate the benefits of inverter var control on a fast timescale to mitigate rapid and large voltage fluctuations due to the high penetration of photovoltaic generation and the resulting reverse power flow. Our approach is to formulate the volt/var control as a radial optimal power flow (OPF) problem to minimize line losses and energy consumption, subject to constraints on voltage magnitudes. An efficient solution to the radial OPF problem is presented and used to study the structure of optimal inverter var injection and the net benefits, taking into account the additional cost of inverter losses when operating at non-unity power factor. This paper will illustrate how, depending on the circuit topology and its loading condition, the inverter's optimal reactive power injection is not necessarily monotone with respect to their real power output. The results are demonstrated on a distribution feeder on the Southern California Edison system that has a very light load and a 5 MW photovoltaic (PV) system installed away from the substation.",,"Masoud Farivar, Russell Neal, Christopher Clarke, Steven Low",computer science,train
Temporal Psychovisual Modulation: a new paradigm of information display,"We report on a new paradigm of information display that greatly extends the utility and versatility of current optoelectronic displays. The main innovation is to let a display of high refresh rate optically broadcast so-called atom frames, which are designed through non-negative matrix factorization to form bases for a class of images, and different viewers perceive selfintended images by using display-synchronized viewing devices and their own human visual systems to fuse appropriately weighted atom frames. This work is essentially a scheme of temporal psychovisual modulation in visible spectrum, using an optoelectronic modulator coupled with a biological demodulator.",,"Xiaolin Wu, Guangtao Zhai",computer science,train
A New Full Adder Cell for Molecular Electronics,"Due to high power consumption and difficulties with minimizing the CMOS transistor size, molecular electronics has been introduced as an emerging technology. Further, there have been noticeable advances in fabrication of molecular wires and switches and also molecular diodes can be used for designing different logic circuits. Considering this novel technology, we use molecules as the active components of the circuit, for transporting electric charge. In this paper, a full adder cell based on molecular electronics is presented. This full adder is consisted of resonant tunneling diodes and transistors which are implemented via molecular electronics. The area occupied by this kind of full adder would be much times smaller than the conventional designs and it can be used as the building block of more complex molecular arithmetic circuits.","13 pages, 14 figures","Mehdi Ghasemi, Mohammad Hossein Moaiyeri, Keivan Navi",computer science,val
Thermal analysis & optimization of a 3 dimensional heterogeneous structure,"Besides the lot of advantages offered by the 3D stacking of devices in an integrated circuit there is a chance of device damage due to rise in peak temperature value. Hence, in order to make use of all the potential benefits of the vertical stacking a thermal aware design is very essential. The first step for designing a thermal aware architecture is to analyze the hotspot temperature generated by the devices. In this paper we are presenting the results of our thermal analysis experiments of a 3D heterogeneous structure with three layers. The bottom layer had eight identical processors at 2.4 GHz and the top layer was with four memory units. The intermediate layer was a thermal interface material (TIM). The 2D thermal analysis of the top and bottom layers was also done separately. In the next step simulations were carried out by varying TIM thickness and conductivity to study its affect on hotspot temperature so as to optimize the temperature distribution.","Computer Science & Engineering: An International Journal (CSEIJ),
  Vol.2, No.1, February 2012","Ramya Menon C., Vinod Pangracious",computer science,train
Design and modelling of different SRAM's based on CNTFET 32nm technology,"Carbon nanotube field-effect transistor (CNTFET) refers to a field-effect transistor that utilizes a single carbon nanotube or an array of carbon nanotubes as the channel material instead of bulk silicon in the traditional MOSFET structure. Since it was first demonstrated in 1998, there have been tremendous developments in CNTFETs, which promise for an alternative material to replace silicon in future electronics. Carbon nanotubes are promising materials for the nano-scale electron devices such as nanotube FETs for ultra-high density integrated circuits and quantum-effect devices for novel intelligent circuits, which are expected to bring a breakthrough in the present silicon technology. A Static Random Access Memory (SRAM) is designed to plug two needs: i) The SRAM provides as cache memory, communicating between central processing unit and Dynamic Random Access Memory (DRAM). ii) The SRAM technology act as driving force for low power application since SRAM is portable compared to DRAM, and SRAM doesn't require any refresh current. On the basis of acquired knowledge, we present different SRAM's designed for the conventional CNTFET. HSPICE simulations of this circuit using Stanford CNTFET model shows a great improvement in power saving.",15 Pages,Naagesh S. Bhat,computer science,train
Intra-bodyhybrid communication scheme for healthcare systems,"Intra-body communication (IBC) is a type of Body Area Network (BAN)that utilizes human body as the medium for data transmission. Thelow power requirements of intra-body communication (IBC) as compared to near field electromagnetic waves showed that it can be a suitable solution for Medical Body Area Networks (MBANs) in a mobile health care system.In this paper, we investigate the transmission characteristics of the human body as a conductor of signals by considering different data transmission rates of multi-point to point network in order to reduce overall power consumption of the BAN.Furthermore, we utilize IBC and propose a new scheme to combines Slotted ALOHA, TDMA, and Reservation ALOHA together to increase the throughput and decrease the delay. By using our new hybrid scheme with the movable boundary designed for health status monitoring, we are able to increase the efficiency of data transmission by prioritizing the more critical data from the sensors.","International Journal on Bioinformatics & Biosciences (IJBB) Vol.2,
  No.1, March 2012","Abdullah Alshehab, Chiu Tung Wu, Nao Kobayashi, Sikieng Sok, Shigeru Shimamoto",computer science,train
Bottom-up rewriting for words and terms,"For the whole class of linear term rewriting systems, we define \emph{bottom-up rewriting} which is a restriction of the usual notion of rewriting. We show that bottom-up rewriting effectively inverse-preserves recognizability and analyze the complexity of the underlying construction. The Bottom-Up class (BU) is, by definition, the set of linear systems for which every derivation can be replaced by a bottom-up derivation. Membership to BU turns out to be undecidable, we are thus lead to define more restricted classes: the classes SBU(k), k in N of Strongly Bottom-Up(k) systems for which we show that membership is decidable. We define the class of Strongly Bottom-Up systems by SBU = U_{k in \} SBU(k). We give a polynomial sufficient condition for a system to be in $\SBU$. The class SBU contains (strictly) several classes of systems which were already known to inverse preserve recognizability: the inverse left-basic semi-Thue systems (viewed as unary term rewriting systems), the linear growing term rewriting systems, the inverse Linear-Finite-Path-Ordering systems.",86 pages; long version to be cut into pieces for publication,"Irene Durand, Geraud Senizergues",computer science,test
Fuzzy Chemical Abstract Machines,"Fuzzy set theory opens new vistas in computability theory and here I show this by defining a new computational metaphor--the fuzzy chemical metaphor. This metaphor is an extension of the chemical metaphor. In particular, I introduce the idea of a state of a system as a solution of fuzzy molecules, that is molecules that are not just different but rather similar, that react according to a set of fuzzy reaction rules. These notions become precise by introducing fuzzy labeled transition systems. Solutions of fuzzy molecules and fuzzy reaction rules are used to define the general notion of a fuzzy chemical abstract machine, which is a {\em realization} of the fuzzy chemical metaphor. Based on the idea that these machines can be used to describe the operational semantics of process calculi and algebras that include fuzziness as a fundamental property, I present a toy calculus that is a fuzzy equivalent of the $\pi$-calculus.",,Apostolos Syropoulos,computer science,train
The equality problem for infinite words generated by primitive morphisms,"We study the equality problem for infinite words obtained by iterating morphisms. In particular, we give a practical algorithm to decide whether or not two words generated by primitive morphisms are equal.","Preliminary version of a paper to appear in Information and
  Computation",Juha Honkala,computer science,train
State complexity of orthogonal catenation,A language $L$ is the orthogonal catenation of languages $L_1$ and $L_2$ if every word of $L$ can be written in a unique way as a catenation of a word in $L_1$ and a word in $L_2$. We establish a tight bound for the state complexity of orthogonal catenation of regular languages. The bound is smaller than the bound for arbitrary catenation.,DCFS 2008,"Mark Daley, Michael Domaratzki, Kai Salomaa",computer science,train
Linear-Space Computation of the Edit-Distance between a String and a Finite Automaton,"The problem of computing the edit-distance between a string and a finite automaton arises in a variety of applications in computational biology, text processing, and speech recognition. This paper presents linear-space algorithms for computing the edit-distance between a string and an arbitrary weighted automaton over the tropical semiring, or an unambiguous weighted automaton over an arbitrary semiring. It also gives an efficient linear-space algorithm for finding an optimal alignment of a string and such a weighted automaton.",,"Cyril Allauzen, Mehryar Mohri",computer science,val
Descriptional complexity of bounded context-free languages,"Finite-turn pushdown automata (PDA) are investigated concerning their descriptional complexity. It is known that they accept exactly the class of ultralinear context-free languages. Furthermore, the increase in size when converting arbitrary PDAs accepting ultralinear languages to finite-turn PDAs cannot be bounded by any recursive function. The latter phenomenon is known as non-recursive trade-off. In this paper, finite-turn PDAs accepting bounded languages are considered. First, letter-bounded languages are studied. We prove that in this case the non-recursive trade-off is reduced to a recursive trade-off, more precisely, to an exponential trade-off. A conversion algorithm is presented and the optimality of the construction is shown by proving tight lower bounds. Furthermore, the question of reducing the number of turns of a given finite-turn PDA is studied. Again, a conversion algorithm is provided which shows that in this case the trade-off is at most polynomial. Finally, the more general case of word-bounded languages is investigated. We show how the results obtained for letter-bounded languages can be extended to word-bounded languages.","31 pages, 1 figure. A preliminary version was presented at DLT 2007.
  The full version is submitted to a journal","Andreas Malcher, Giovanni Pighizzini",computer science,train
Deterministic pushdown automata and unary languages,"The simulation of deterministic pushdown automata defined over a one-letter alphabet by finite state automata is investigated from a descriptional complexity point of view. We show that each unary deterministic pushdown automaton of size s can be simulated by a deterministic finite automaton with a number of states that is exponential in s. We prove that this simulation is tight. Furthermore, its cost cannot be reduced even if it is performed by a two-way nondeterministic automaton. We also prove that there are unary languages for which deterministic pushdown automata cannot be exponentially more succinct than finite automata. In order to state this result, we investigate the conversion of deterministic pushdown automata into context-free grammars. We prove that in the unary case the number of variables in the resulting grammar is strictly smaller than the number of variables needed in the case of nonunary alphabets.","17 pages. Preprint of an article submitted for consideration in the
  International Journal of Foundations of Computer Science (World Scientific
  Publishing Company). A preliminary version was presented at the conference
  CIAA 2008",Giovanni Pighizzini,computer science,train
"Answers to Questions Formulated in the Paper ""On States Observability in Deterministic Finite Automata""","This paper gives answers to questions formulated as open in the paper ""On State Observability in Deterministic Finite Automata"" by A. Mateescu and Gh. Paun. Specifically, it demonstrates that for all k >= 2, the families of regular languages acceptable by deterministic finite automata with no more than k semi-observable states, denoted by Tk, are anti-AFL's, and that the family T1 differs in the closure property under Kleene +.",,Tomas Masopust,computer science,val
The cost of being co-Buchi is nonlinear,"It is well known, and easy to see, that not each nondeterministic Buchi automaton on infinite words can be simulated by a nondeterministic co-Buchi automaton. We show that in the cases when such a simulation is possible, the number of states needed for it can grow nonlinearly. More precisely, we show a sequence of - as we believe, simple and elegant - languages which witness the existence of a nondeterministic Buchi automaton with n states, which can be simulated by a nondeterministic co-Buchi automaton, but cannot be simulated by any nondeterministic co-Buchi automaton with less than c*n^{7/6} states for some constant c. This improves on the best previously known lower bound of 3(n-1)/2.","12 pages, 4 figures; added information about grand","Jerzy Marcinkowski, Jakub Michaliszyn",computer science,val
2D cellular automata: dynamics and undecidability,"In this paper we introduce the notion of quasi-expansivity for 2D CA and we show that it shares many properties with expansivity (that holds only for 1D CA). Similarly, we introduce the notions of quasi-sensitivity and prove that the classical dichotomy theorem holds in this new setting. Moreover, we show a tight relation between closingness and openness for 2D CA. Finally, the undecidability of closingness property for 2D CA is proved.","24 pages, 12 figures. paper submitted to an international conference","Enrico Formenti, Alberto Dennunzio, Michael Weiss",computer science,test
Theory and practice,"The author argues to Silicon Valley that the most important and powerful part of computer science is work that is simultaneously theoretical and practical. He particularly considers the intersection of the theory of algorithms and practical software development. He combines examples from the development of the TeX typesetting system with clever jokes, criticisms, and encouragements.",Abstract added by Greg Kuperberg,Donald E. Knuth,computer science,val
The Revolution Yet to Happen,"All information about physical objects including humans, buildings, processes, and organizations will be online. This trend is both desirable and inevitable. Cyberspace will provide the basis for wonderful new ways to inform, entertain, and educate people. The information and the corresponding systems will streamline commerce, but will also provide new levels of personal service, health care, and automation. The most significant benefit will be a breakthrough in our ability to remotely communicate with one another using all our senses. The ACM and the transistor were born in 1947. At that time the stored program computer was a revolutionary idea and the transistor was just a curiosity. Both ideas evolved rapidly. By the mid 1960s integrated circuits appeared -- allowing mass fabrication of transistors on silicon substrates. This allowed low-cost mass-produced computers. These technologies enabled extraordinary increases in processing speed and memory coupled with extraordinary price declines. The only form of processing and memory more easily, cheaply, and rapidly fabricated is the human brain. Peter Cohrane (1996) estimates the brain to have a processing power of around 1000 million-million operations per second, (one Petaops) and a memory of 10 Terabytes. If current trends continue, computers could have these capabilities by 2047. Such computers could be 'on body' personal assistants able to recall everything one reads, hears, and sees.","Original document at:
  http://research.microsoft.com/~gray/Revolution.doc","C. Gordon Bell, Jim Gray",computer science,train
What Next? A Dozen Information-Technology Research Goals,"Charles Babbage's vision of computing has largely been realized. We are on the verge of realizing Vannevar Bush's Memex. But, we are some distance from passing the Turing Test. These three visions and their associated problems have provided long-range research goals for many of us. For example, the scalability problem has motivated me for several decades. This talk defines a set of fundamental research problems that broaden the Babbage, Bush, and Turing visions. They extend Babbage's computational goal to include highly-secure, highly-available, self-programming, self-managing, and self-replicating systems. They extend Bush's Memex vision to include a system that automatically organizes, indexes, digests, evaluates, and summarizes information (as well as a human might). Another group of problems extends Turing's vision of intelligent machines to include prosthetic vision, speech, hearing, and other senses. Each problem is simply stated and each is orthogonal from the others, though they share some common core technologies","MS word original:
  http://research.microsoft.com/~gray/papers/MS_TR_99_50_TuringTalk.doc",Jim Gray,computer science,val
Questions for a Materialist Philosophy Implying the Equivalence of Computers and Human Cognition,"Issues related to a materialist philosophy are explored as concerns the implied equivalence of computers running software and human observers. One issue explored concerns the measurement process in quantum mechanics. Another issue explored concerns the nature of experience as revealed by the existence of dreams. Some difficulties stemming from a materialist philosophy as regards these issues are pointed out. For example, a gedankenexperiment involving what has been called ""negative"" observation is discussed that illustrates the difficulty with a materialist assumption in quantum mechanics. Based on an exploration of these difficulties, specifications are outlined briefly that would provide a means to demonstrate the equivalence of of computers running software and human experience given a materialist assumption.",20 pages,Douglas M. Snyder,computer science,train
One More Revolution to Make: Free Scientific Publishing,"Computer scientists are in the position to create new, free high-quality journals. So what would it take?","Taken from
  http://www.acm.org/pubs/citations/journals/cacm/2001-44-5/p25-apt/ Posted
  with permission of the ACM",Krzysztof R. Apt,computer science,test
ENUM: The Collision of Telephony and DNS Policy,"ENUM marks either the convergence or collision of the public telephone network with the Internet. ENUM is an innovation in the domain name system (DNS). It starts with numerical domain names that are used to query DNS name servers. The servers respond with address information found in DNS records. This can be telephone numbers, email addresses, fax numbers, SIP addresses, or other information. The concept is to use a single number in order to obtain a plethora of contact information. By convention, the Internet Engineering Task Force (IETF) ENUM Working Group determined that an ENUM number would be the same numerical string as a telephone number. In addition, the assignee of an ENUM number would be the assignee of that telephone number. But ENUM could work with any numerical string or, in fact, any domain name. The IETF is already working on using E.212 numbers with ENUM. [Abridged]","29th TPRC Conference, 2001",Robert Cannon,computer science,train
Edsger Wybe Dijkstra (1930 -- 2002): A Portrait of a Genius,"We discuss the scientific contributions of Edsger Wybe Dijkstra, his opinions and his legacy.",10 pages. To appear in Formal Aspects of Computing,Krzysztof R. Apt,computer science,val
Classical and Nonextensive Information Theory,"In this work we firstly review some results in Classical Information Theory. Next, we try to generalize these results by using the Tsallis entropy. We present a preliminary result and discuss our aims in this field.",6 pages without figures,Gilson Antonio Giraldi,computer science,val
The pre-history of quantum computation,The main ideas behind developments in the theory and technology of quantum computation were formulated in the late 1970s and early 1980s by two physicists in the West and a mathematician in the former Soviet Union. It is not generally known in the West that the subject has roots in the Russian technical literature. The author hopes to present as impartial a synthesis as possible of the early history of thought on this subject. The role of reversible and irreversible computational processes is examined briefly as it relates to the origins of quantum computing and the so-called Information Paradox in physics.,"11 pages, in Afrikaans (title: Die voorgeskiedenis van
  kwantumberekening) with English abstract",P. H. Potgieter,computer science,train
Some first thoughts on the stability of the asynchronous systems,"The (non-initialized, non-deterministic) asynchronous systems (in the input-output sense) are multi-valued functions from m-dimensional signals to sets of n-dimensional signals, the concept being inspired by the modeling of the asynchronous circuits. Our purpose is to state the problem of the their stability.","12 pages, conference",Serban E. Vlad,computer science,train
A note on digitized angles,We study the configurations of pixels that occur when two digitized straight lines meet each other.,,Donald E. Knuth,computer science,val
Computer-Generated Photorealistic Hair,"This paper presents an efficient method for generating and rendering photorealistic hair in two dimensional pictures. The method consists of three major steps. Simulating an artist drawing is used to design the rough hair shape. A convolution based filter is then used to generate photorealistic hair patches. A refine procedure is finally used to blend the boundaries of the patches with surrounding areas. This method can be used to create all types of photorealistic human hair (head hair, facial hair and body hair). It is also suitable for fur and grass generation. Applications of this method include: hairstyle designing/editing, damaged hair image restoration, human hair animation, virtual makeover of a human, and landscape creation.","7 pages, 7 figures",Alice J. Lin,computer science,train
Embedded Reflection Mapping,"Environment maps are used to simulate reflections off curved objects. We present a technique to reflect a user, or a group of users, in a real environment, onto a virtual object, in a virtual reality application, using the live video feeds from a set of cameras, in real-time. Our setup can be used in a variety of environments ranging from outdoor or indoor scenes.",,"Paul Anderson, Goncalo Carvalho",computer science,train
The Persint visualization program for the ATLAS experiment,"The Persint program is designed for the three-dimensional representation of objects and for the interfacing and access to a variety of independent applications, in a fully interactive way. Facilities are provided for the spatial navigation and the definition of the visualization properties, in order to interactively set the viewing and viewed points, and to obtain the desired perspective. In parallel, applications may be launched through the use of dedicated interfaces, such as the interactive reconstruction and display of physics events. Recent developments have focalized on the interfacing to the XML ATLAS General Detector Description AGDD, making it a widely used tool for XML developers. The graphics capabilities of this program were exploited in the context of the ATLAS 2002 Muon Testbeam where it was used as an online event display, integrated in the online software framework and participating in the commissioning and debug of the detector system.","9 pages, 10 figures, proceedings of CHEP2003","D. Pomarede, M. Virchaux",computer science,train
GraXML - Modular Geometric Modeler,"Many entities managed by HEP Software Frameworks represent spatial (3-dimensional) real objects. Effective definition, manipulation and visualization of such objects is an indispensable functionality. GraXML is a modular Geometric Modeling toolkit capable of processing geometric data of various kinds (detector geometry, event geometry) from different sources and delivering them in ways suitable for further use. Geometric data are first modeled in one of the Generic Models. Those Models are then used to populate powerful Geometric Model based on the Java3D technology. While Java3D has been originally created just to provide visualization of 3D objects, its light weight and high functionality allow an effective reuse as a general geometric component. This is possible also thanks to a large overlap between graphical and general geometric functionality and modular design of Java3D itself. Its graphical functionalities also allow a natural visualization of all manipulated elements. All these techniques have been developed primarily (or only) for the Java environment. It is, however, possible to interface them transparently to Frameworks built in other languages, like for example C++. The GraXML toolkit has been tested with data from several sources, as for example ATLAS and ALICE detector description and ATLAS event data. Prototypes for other sources, like Geometry Description Markup Language (GDML) exist too and interface to any other source is easy to add.","Talk from the 2003 Computing in High Energy and Nuclear Physics
  (CHEP03), La Jolla, Ca, USA, March 2003. PSN THJT009",Julius Hrivnac,computer science,train
The FRED Event Display: an Extensible HepRep Client for GLAST,"A new graphics client prototype for the HepRep protocol is presented. Based on modern toolkits and high level languages (C++ and Ruby), Fred is an experiment to test applicability of scripting facilities to the high energy physics event display domain. Its flexible structure, extensibility and the use of the HepRep protocol are key features for its use in the astroparticle experiment GLAST.","Talk from the 2003 Computing in High Energy and Nuclear Physics
  (CHEP03), La Jolla, Ca, USA, March 2003, 5 pages, LaTeX, 3 eps figures. PSN
  MOLT010","Marco Frailis, Riccardo Giannitrapani",computer science,val
The Use of HepRep in GLAST,"HepRep is a generic, hierarchical format for description of graphics representables that can be augmented by physics information and relational properties. It was developed for high energy physics event display applications and is especially suited to client/server or component frameworks. The GLAST experiment, an international effort led by NASA for a gamma-ray telescope to launch in 2006, chose HepRep to provide a flexible, extensible and maintainable framework for their event display without tying their users to any one graphics application. To support HepRep in their GUADI infrastructure, GLAST developed a HepRep filler and builder architecture. The architecture hides the details of XML and CORBA in a set of base and helper classes allowing physics experts to focus on what data they want to represent. GLAST has two GAUDI services: HepRepSvc, which registers HepRep fillers in a global registry and allows the HepRep to be exported to XML, and CorbaSvc, which allows the HepRep to be published through a CORBA interface and which allows the client application to feed commands back to GAUDI (such as start next event, or run some GAUDI algorithm). GLAST's HepRep solution gives users a choice of client applications, WIRED (written in Java) or FRED (written in C++ and Ruby), and leaves them free to move to any future HepRep-compliant event display.","Talk from the 2003 Computing in High Energy and Nuclear Physics
  (CHEP03), La Jolla, Ca, USA, March 2003, 9 pages pdf, 15 figures. PSN THLT009","J. Perl, R. Giannitrapani, M. Frailis",computer science,val
Application of interactive parallel visualization for commodity-based clusters using visualization APIs,"We present an efficient and inexpensive to develop application for interactive high-performance parallel visualization. We extend popular APIs such as Open Inventor and VTK to support commodity-based cluster visualization. Our implementation follows a standard master/slave concept: the general idea is to have a ``Master'' node, which will intercept a sequential graphical user interface (GUI) and broadcast it to the ``Slave'' nodes. The interactions between the nodes are implemented using MPI. The parallel remote rendering uses Chromium. This paper is mainly the report of our implementation experiences. We present in detail the proposed model and key aspects of its implementation. Also, we present performance measurements, we benchmark and quantitatively demonstrate the dependence of the visualization speed on the data size and the network bandwidth, and we identify the singularities and draw conclusions on Chromium's sort-first rendering architecture. The most original part of this work is the combined use of Open Inventor and Chromium.","12 pages, 4 figures","Stanimire Tomov, Robert Bennett, Michael McGuigan, Arnold Peskin, Gordon Smith, John Spiletic",computer science,test
Visualization of variations in human brain morphology using differentiating reflection functions,"Conventional visualization media such as MRI prints and computer screens are inherently two dimensional, making them incapable of displaying true 3D volume data sets. By applying only transparency or intensity projection, and ignoring light-matter interaction, results will likely fail to give optimal results. Little research has been done on using reflectance functions to visually separate the various segments of a MRI volume. We will explore if applying specific reflectance functions to individual anatomical structures can help in building an intuitive 2D image from a 3D dataset. We will test our hypothesis by visualizing a statistical analysis of the genetic influences on variations in human brain morphology because it inherently contains complex and many different types of data making it a good candidate for our approach","10 pages, keywords: MRI, Medical Visualization, Volume rendering,
  BRDF, Specular reflection overlap",Gibby Koldenhof,computer science,test
An Algorithm for Transforming Color Images into Tactile Graphics,"This paper presents an algorithm that transforms color visual images, like photographs or paintings, into tactile graphics. In the algorithm, the edges of objects are detected and colors of the objects are estimated. Then, the edges and the colors are encoded into lines and textures in the output tactile image. Design of the method is substantiated by various qualities of haptic recognizing of images. Also, means of presentation of the tactile images in printouts are discussed. Example translated images are shown.","9 pages, 7 figures",Artur Rataj,computer science,test
Bundling Equilibrium in Combinatorial auctions,"This paper analyzes individually-rational ex post equilibrium in the VC (Vickrey-Clarke) combinatorial auctions. If $\Sigma$ is a family of bundles of goods, the organizer may restrict the participants by requiring them to submit their bids only for bundles in $\Sigma$. The $\Sigma$-VC combinatorial auctions (multi-good auctions) obtained in this way are known to be individually-rational truth-telling mechanisms. In contrast, this paper deals with non-restricted VC auctions, in which the buyers restrict themselves to bids on bundles in $\Sigma$, because it is rational for them to do so. That is, it may be that when the buyers report their valuation of the bundles in $\Sigma$, they are in an equilibrium. We fully characterize those $\Sigma$ that induce individually rational equilibrium in every VC auction, and we refer to the associated equilibrium as a bundling equilibrium. The number of bundles in $\Sigma$ represents the communication complexity of the equilibrium. A special case of bundling equilibrium is partition-based equilibrium, in which $\Sigma$ is a field, that is, it is generated by a partition. We analyze the tradeoff between communication complexity and economic efficiency of bundling equilibrium, focusing in particular on partition-based equilibrium.",,"Ron Holzman, Noa Kfir-Dahav, Dov Monderer, Moshe Tennenholtz",computer science,train
Combinatorial Auctions with Decreasing Marginal Utilities,"In most of microeconomic theory, consumers are assumed to exhibit decreasing marginal utilities. This paper considers combinatorial auctions among such submodular buyers. The valuations of such buyers are placed within a hierarchy of valuations that exhibit no complementarities, a hierarchy that includes also OR and XOR combinations of singleton valuations, and valuations satisfying the gross substitutes property. Those last valuations are shown to form a zero-measure subset of the submodular valuations that have positive measure. While we show that the allocation problem among submodular valuations is NP-hard, we present an efficient greedy 2-approximation algorithm for this case and generalize it to the case of limited complementarities. No such approximation algorithm exists in a setting allowing for arbitrary complementarities. Some results about strategic aspects of combinatorial auctions among players with decreasing marginal utilities are also presented.",To appear in GEB. Preliminary version appeared in EC'01,"Benny Lehmann, Daniel Lehmann, Noam Nisan",computer science,test
Truth Revelation in Approximately Efficient Combinatorial Auctions,"Some important classical mechanisms considered in Microeconomics and Game Theory require the solution of a difficult optimization problem. This is true of mechanisms for combinatorial auctions, which have in recent years assumed practical importance, and in particular of the gold standard for combinatorial auctions, the Generalized Vickrey Auction (GVA). Traditional analysis of these mechanisms - in particular, their truth revelation properties - assumes that the optimization problems are solved precisely. In reality, these optimization problems can usually be solved only in an approximate fashion. We investigate the impact on such mechanisms of replacing exact solutions by approximate ones. Specifically, we look at a particular greedy optimization method. We show that the GVA payment scheme does not provide for a truth revealing mechanism. We introduce another scheme that does guarantee truthfulness for a restricted class of players. We demonstrate the latter property by identifying natural properties for combinatorial auctions and showing that, for our restricted class of players, they imply that truthful strategies are dominant. Those properties have applicability beyond the specific auction studied.",Submitted to a Journal. A preliminary version appeared in EC'99,"Daniel Lehmann, Liadan Ita O'Callaghan, Yoav Shoham",computer science,train
Expected Qualitative Utility Maximization,"A model for decision making that generalizes Expected Utility Maximization is presented. This model, Expected Qualitative Utility Maximization, encompasses the Maximin criterion. It relaxes both the Independence and the Continuity postulates. Its main ingredient is the definition of a qualitative order on nonstandard models of the real numbers and the consideration of nonstandard utilities. Expected Qualitative Utility Maximization is characterized by an original weakening of von Neumann-Morgenstern's postulates. Subjective probabilities may be defined from those weakened postulates, as Anscombe and Aumann did from the original postulates. Subjective probabilities are numbers, not matrices as in the Subjective Expected Lexicographic Utility approach. JEL no.: D81 Keywords: Utility Theory, Non-Standard Utilities, Qualitative Decision Theory",Small correction in Section 4,Daniel Lehmann,computer science,train
Classes of service under perfect competition and technological change: a model for the dynamics of the Internet?,"Certain services may be provided in a continuous, one-dimensional, ordered range of different qualities and a customer requiring a service of quality q can only be offered a quality superior or equal to q. Only a discrete set of different qualities will be offered, and a service provider will provide the same service (of fixed quality b) to all customers requesting qualities of service inferior or equal to b. Assuming all services (of quality b) are priced identically, a monopolist will choose the qualities of service and the prices that maximize profit but, under perfect competition, a service provider will choose the (inferior) quality of service that can be priced at the lowest price. Assuming significant economies of scale, two fundamentally different regimes are possible: either a number of different classes of service are offered (DC regime), or a unique class of service offers an unbounded quality of service (UC regime). The DC regime appears in one of two sub-regimes: one, BDC, in which a finite number of classes is offered, the qualities of service offered are bounded and requests for high-quality services are not met, or UDC in which an infinite number of classes of service are offered and every request is met. The types of the demand curve and of the economies of scale, not the pace of technological change, determine the regime and the class boundaries. The price structure in the DC regime obeys very general laws.",Extended abstract in Proceedings of EC'01,Daniel Lehmann,computer science,val
Nonstandard numbers for qualitative decision making,The consideration of nonstandard models of the real numbers and the definition of a qualitative ordering on those models provides a generalization of the principle of maximization of expected utility. It enables the decider to assign probabilities of different orders of magnitude to different events or to assign utilities of different orders of magnitude to different outcomes. The properties of this generalized notion of rationality are studied in the frameworks proposed by von Neumann and Morgenstern and later by Anscombe and Aumann. It is characterized by an original weakening of their postulates in two different situations: nonstandard probabilities and standard utilities on one hand and standard probabilities and nonstandard utilities on the other hand. This weakening concerns both Independence and Continuity. It is orthogonal with the weakening proposed by lexicographic orderings.,14 pages. Presented at TARK'98,Daniel Lehmann,computer science,train
Complexity of Manipulating Elections with Few Candidates,"In multiagent settings where the agents have different preferences, preference aggregation is a central issue. Voting is a general method for preference aggregation, but seminal results have shown that all general voting protocols are manipulable. One could try to avoid manipulation by using voting protocols where determining a beneficial manipulation is hard. Especially among computational agents, it is reasonable to measure this hardness by computational complexity. Some earlier work has been done in this area, but it was assumed that the number of voters and candidates is unbounded. We derive hardness results for practical multiagent settings where the number of candidates is small but the number of voters can be large. We show that with complete information about the others' votes, individual manipulation is easy, and coalitional manipulation is easy with unweighted voters. However, constructive coalitional manipulation with weighted voters is intractable for all of the voting protocols under study, except for the nonrandomized Cup. Destructive manipulation tends to be easier. Randomizing over instantiations of the protocols (such as schedules of the Cup protocol) can be used to make manipulation hard. Finally, we show that under weak assumptions, if weighted coalitional manipulation with complete information about the others' votes is hard in some voting protocol, then individual and unweighted manipulation is hard when there is uncertainty about the others' votes.",In AAAI-02 plenary session,"Vincent Conitzer, Tuomas Sandholm",computer science,val
On the suitability of the 2 x 2 games for studying reciprocal cooperation and kin selection,"The 2 x 2 games, in particular the Prisoner's Dilemma, have been extensively used in studies into reciprocal cooperation and, to a lesser extent, kin selection. This paper examines the suitability of the 2 x 2 games for modelling the evolution of cooperation through reciprocation and kin selection. This examination is not restricted to the Prisoner's Dilemma, but includes the other non-trivial symmetric 2 x 2 games. We show that the popularity of the Prisoner's Dilemma for modelling social and biotic interaction is justified by its superiority according to these criteria. Indeed, the Prisoner's Dilemma is unique in providing the simplest support for reciprocal cooperation, and additive kin-selected altruism. However, care is still required in choosing the particular Prisoner's Dilemma payoff matrix to use. This paper reviews the impact of non-linear payoffs for the application of Hamilton's rule to typical altruistic interactions, and derives new results for cases in which the roles of potential altruist and beneficiary are separated. In doing so we find the same equilibrium condition holds in continuous games between relatives, and in discrete games with roles.","20 pages, 10 tables, 5 figures",James A. R. Marshall,computer science,val
A Game Theoretic Framework for Incentives in P2P Systems,"Peer-To-Peer (P2P) networks are self-organizing, distributed systems, with no centralized authority or infrastructure. Because of the voluntary participation, the availability of resources in a P2P system can be highly variable and unpredictable. In this paper, we use ideas from Game Theory to study the interaction of strategic and rational peers, and propose a differential service-based incentive scheme to improve the system's performance.",,"Chiranjeeb Buragohain, Divyakant Agrawal, Subhash Suri",computer science,train
A Cartography for 2x2 Symmetric Games,"A bidimensional representation of the space of 2x2 Symmetric Games in the strategic representation is proposed. This representation provides a tool for the classification of 2x2 symmetric games, quantification of the fraction of them having a certain feature, and predictions of changes in the characteristics of a game when a change in done on the payoff matrix that defines it.","13 pages, 7 figures This is a new version of the work, adapted to be
  presented in the III Colombian Congress and I Andean International Conference
  of Operational Research (Cartagena, Colombia, March 2004)",Alvaro Francisco Huertas-Rosero,computer science,train
Designing an interface to optimize reading with small display windows,"The electronic presentation of text in small display windows is mushrooming. In the present paper, four ways of presenting text in a small display window were examined and compared to a Normal Page condition: rapid serial visual presentation (RSVP), RSVP with a Completion Meter, Sentence-by-Sentence presentation, and Sentence-by-Sentence presentation with a Completion Meter. Dependent measures were reading efficiency - speed and comprehension - and preference. For designers of hardware or software with small display windows, the results suggest the following: (1) Though RSVP is disliked by readers, the present methods of allowing self-pacing and regressions in RSVP, unlike earlier tested methods, are efficient and feasible. (2) Slower reading in RSVP should be achieved by increasing pauses between sentences or by repeating sentences, not by decreasing the within-sentence rate. (3) Completion meters do not interfere with performance, and are usually preferred. (4) The space-saving Sentence-by-Sentence format is as efficient and as preferred as the Normal Page format.",,"Tarjin Rahman, Paul Muter",computer science,train
Virtual Kathakali : Gesture Driven Metamorphosis,"Training in motor skills such as athletics, dance, or gymnastics is not possible today except in the direct presence of the coach/instructor. This paper describes a computer vision based gesture recognition system which is used to metamorphose the user into a Virtual person, e.g. as a Kathakali dancer, which is graphically recreated at a near or diatant location. Thus this can be seen by an off-site coach using low-bandwidth joint-motion data which permits real time animation. The metamorphosis involves altering the appearance and identity of the user and also creating a specific environment possibly in interaction with other virtual creatures. A robust vision module is used to identify the user, based on very simple binary image processing in real time which also manages to resolve self-occlusion, correct for clothing/colour and other variations among users. Gestures are identified by locating key points at the shoulder, elbow and wrist joint, which are then recreated in an articulated humanoid model, which in this instance, representes a Kathakali dancer in elaborate traditional dress. Unlike glove based or other and movement tracking systems, this application requires the user to wear no hardwire devices and is aimed at making gesture tracking simpler, cheaper, and more user friendly.","Proceedings of International Conference on Knowledge Based Computer
  Systems, Mumbai, India, Dec '98. 12 pages, 19 figures","Soumyadeep Paul, Sudipta N. Sinha, Amitabha Mukerjee",computer science,train
Workflow Automation with Lotus Notes for the Governmental Administrative Information System,"The paper presents an introductory overview of the workflow automation area, outlining the main types, basic technologies, the essential features of workflow applications. Two sorts of process models for the definition of workflows (according to the conversation-based and activity-based methodologies) are sketched. Later on, the nature of Lotus Notes and its capabilities (as an environment for workflow management systems development) are indicated. Concluding, the experience of automating administrative workflows (developing a Subsystem of Inter-institutional Document Management of the VADIS project) is briefly outlined.","8 pages, 7 figures",Saulius Maskeliunas,computer science,train
Tap Tips: Lightweight Discovery of Touchscreen Targets,"We describe tap tips, a technique for providing touch-screen target location hints. Tap tips are lightweight in that they are non-modal, appear only when needed, require a minimal number of user gestures, and do not add to the standard touchscreen gesture vocabulary. We discuss our implementation of tap tips in an electronic guidebook system and some usability test results.",,"Paul M. Aoki, Amy Hurst, Allison Woodruff",computer science,val
"The Guidebook, the Friend, and the Room: Visitor Experience in a Historic House","In this paper, we describe an electronic guidebook prototype and report on a study of its use in a historic house. Supported by mechanisms in the guidebook, visitors constructed experiences that had a high degree of interaction with three entities: the guidebook, their companions, and the house and its contents. For example, we found that most visitors played audio descriptions played through speakers (rather than using headphones or reading textual descriptions) to facilitate communication with their companions.",,"Allison Woodruff, Paul M. Aoki, Amy Hurst, Margaret H. Szymanski",computer science,val
"Electronic Commerce, Consumer Search and Retailing Cost Reduction","This paper explains four things in a unified way. First, how e-commerce can generate price equilibria where physical shops either compete with virtual shops for consumers with Internet access, or alternatively, sell only to consumers with no Internet access. Second, how these price equilibria might involve price dispersion on-line. Third, why prices may be higher on-line. Fourth, why established firms can, but need not, be more reluctant than newly created firm to adopt e-commerce. For this purpose we develop a model where e-commerce reduces consumers' search costs, involves trade-offs for consumers, and reduces retailing costs.","29th TPRC Conference, 2001","Pedro Pereira, Cristina Mazón",computer science,train
Building Multi-Platform User Interfaces with UIML,"There has been a widespread emergence of computing devices in the past few years that go beyond the capabilities of traditional desktop computers. However, users want to use the same kinds of applications and access the same data and information on these appliances that they can access on their desktop computers. The user interfaces for these platforms go beyond the traditional interaction metaphors. It is a challenge to build User Interfaces (UIs) for these devices of differing capabilities that allow the end users to perform the same kinds of tasks. The User Interface Markup Language (UIML) is an XML-based language that allows the canonical description of UIs for different platforms. We describe the language features of UIML that facilitate the development of multi-platform UIs. We also describe the key aspects of our approach that makes UIML succeed where previous approaches failed, namely the division in the representation of a UI, the use of a generic vocabulary, and an integrated development environment specifically designed for transformation-based UI development. Finally we describe the initial details of a multi-step usability engineering process for building multi-platform UI using UIML.",12 pages,"Mir Farooq Ali, Manuel A. Perez-Quinones, Eric Shell, Marc Abrams",computer science,train
A Multi-Step Process for Generating Multi-Platform User Interfaces using UIML,"There has been a widespread emergence of computing devices in the past few years that go beyond the capabilities of traditional desktop computers. These devices have varying input/output characteristics, modalities and interaction mechanisms. However, users want to use the same kinds of applications and access the same data and information on these appliances that they can access on their desktop computers. The user interfaces for these devices and platforms go beyond the traditional interaction metaphors. It is a challenge to build User Interfaces (UIs) for these devices of differing capabilities that allow the end users to perform the same kinds of tasks. The User Interface Markup Language (UIML) is an XML-based language that allows the canonical description of UIs for different platforms. We present a multi-step transformation-based framework for building Multi-Platform User Interfaces using UIML. We describe the language features of UIML that facilitate the development of multi-platform UIs, the multi-step process involved in our framework and the transformations needed to build the UIs.",11 pages,"Mir Farooq Ali, Manuel A. Perez-Quinones, Marc Abrams",computer science,train
Eavesdropping on Electronic Guidebooks: Observing Learning Resources in Shared Listening Environments,"We describe an electronic guidebook, Sotto Voce, that enables visitors to share audio information by eavesdropping on each other's guidebook activity. We have conducted three studies of visitors using electronic guidebooks in a historic house: one study with open air audio played through speakers and two studies with eavesdropped audio. An analysis of visitor interaction in these studies suggests that eavesdropped audio provides more social and interactive learning resources than open air audio played through speakers.",8 pages,"Allison Woodruff, Paul M. Aoki, Rebecca E. Grinter, Amy Hurst, Margaret H. Szymanski, James D. Thornton",computer science,train
Practical Strategies for Integrating a Conversation Analyst in an Iterative Design Process,"We present a case study of an iterative design process that includes a conversation analyst. We discuss potential benefits of conversation analysis for design, and we describe our strategies for integrating the conversation analyst in the design process. Since the analyst on our team had no previous exposure to design or engineering, and none of the other members of our team had any experience with conversation analysis, we needed to build a foundation for our interaction. One of our key strategies was to pair the conversation analyst with a designer in a highly interactive collaboration. Our tactics have been effective on our project, leading to valuable results that we believe we could not have obtained using another method. We hope that this paper can serve as a practical guide to those interested in establishing a productive and efficient working relationship between a conversation analyst and the other members of a design team.",11 pages,"Allison Woodruff, Margaret H. Szymanski, Rebecca E. Grinter, Paul M. Aoki",computer science,train
Biologically Motivated Distributed Designs for Adaptive Knowledge Management,"We discuss how distributed designs that draw from biological network metaphors can largely improve the current state of information retrieval and knowledge management of distributed information systems. In particular, two adaptive recommendation systems named TalkMine and @ApWeb are discussed in more detail. TalkMine operates at the semantic level of keywords. It leads different databases to learn new and adapt existing keywords to the categories recognized by its communities of users using distributed algorithms. @ApWeb operates at the structural level of information resources, namely citation or hyperlink structure. It relies on collective behavior to adapt such structure to the expectations of users. TalkMine and @ApWeb are currently being implemented for the research library of the Los Alamos National Laboratory under the Active Recommendation Project. Together they define a biologically motivated information retrieval system, recommending simultaneously at the level of user knowledge categories expressed in keywords, and at the level of individual documents and their associations to other documents. Rather than passive information retrieval, with this system, users obtain an active, evolving interaction with information resources.","To appear in Design Principles for the Immune System and Other
  Distributed Autonomous Systems. i. Cohen and L. Segel (Eds.). Oxford
  University Press","Luis M. Rocha, Johan Bollen",computer science,val
Making news understandable to computers,Computers and devices are largely unaware of events taking place in the world. This could be changed if news were made available in a computer-understandable form. In this paper we present XML documents called NewsForms that represent the key points of 17 types of news events. We discuss the benefits of computer-understandable news and present the NewsExtract program for converting text news stories into NewsForms.,,Erik T. Mueller,computer science,train
Fuzzy data: XML may handle it,"Data modeling is one of the most difficult tasks in application engineering. The engineer must be aware of the use cases and the required application services and at a certain point of time he has to fix the data model which forms the base for the application services. However, once the data model has been fixed it is difficult to consider changing needs. This might be a problem in specific domains, which are as dynamic as the healthcare domain. With fuzzy data we address all those data that are difficult to organize in a single database. In this paper we discuss a gradual and pragmatic approach that uses the XML technology to conquer more model flexibility. XML may provide the clue between unstructured text data and structured database solutions and shift the paradigm from ""organizing the data along a given model"" towards ""organizing the data along user requirements"".","15 pages, 6 figures","R. Schweiger, S. Hoelzer, J. Dudeck",computer science,train
On the Automated Classification of Web Sites,"In this paper we discuss several issues related to automated text classification of web sites. We analyze the nature of web content and metadata in relation to requirements for text features. We find that HTML metatags are a good source of text features, but are not in wide use despite their role in search engine rankings. We present an approach for targeted spidering including metadata extraction and opportunistic crawling of specific semantic hyperlinks. We describe a system for automatically classifying web sites into industry categories and present performance results based on different combinations of text features and training data. This system can serve as the basis for a generalized framework for automated metadata creation.","12 pages, etendu.sty",John M. Pierre,computer science,train
"Activities, Context and Ubiquitous Computing","Context and context-awareness provides computing environments with the ability to usefully adapt the services or information they provide. It is the ability to implicitly sense and automatically derive the user needs that separates context-aware applications from traditionally designed applications, and this makes them more attentive, responsive, and aware of their user's identity, and their user's environment. This paper argues that context-aware applications capable of supporting complex, cognitive activities can be built from a model of context called Activity-Centric Context. A conceptual model of Activity-Centric context is presented. The model is illustrated via a detailed example.",,"Paul Prekop, Mark Burnett",computer science,test
Visualization for Periodic Population Movement between Distinct Localities,"We present a new visualization method to summarize and present periodic population movement between distinct locations, such as floors, buildings, cities, or the like. In the specific case of this paper, we have chosen to focus on student movement between college dormitories on the Columbia University campus. The visual information is presented to the information analyst in the form of an interactive geographical map, in which specific temporal periods as well as individual buildings can be singled out for detailed data exploration. The navigational interface has been designed to specifically meet a geographical setting.","Poster Summary: 2 pages, 4 figures, InfoVis 2003 Symposium",Alexander Haubold,computer science,train
BdbServer++: A User Driven Data Location and Retrieval Tool,"The adoption of Grid technology has the potential to greatly aid the BaBar experiment. BdbServer was originally designed to extract copies of data from the Objectivity/DB database at SLAC and IN2P3. With data now stored in multiple locations in a variety of data formats, we are enhancing this tool. This will enable users to extract selected deep copies of event collections and ship them to the requested site using the facilities offered by the existing Grid infrastructure. By building on the work done by various groups in BaBar, and the European DataGrid, we have successfully expanded the capabilities of the BdbServer software. This should provide a framework for future work in data distribution.","Paper based on the poster from the 2003 Computing in High Energy and
  Nuclear Physics (CHEP03), La Jolla, Ca, USA, March 2003, 4 pages, LaTeX, 0
  figures. PSN TUCP011","A. D. Earl, A. Hasan, D. Boutigany",computer science,train
BaBar - A Community Web Site in an Organizational Setting,"The BABAR Web site was established in 1993 at the Stanford Linear Accelerator Center (SLAC) to support the BABAR experiment, to report its results, and to facilitate communication among its scientific and engineering collaborators, currently numbering about 600 individuals from 75 collaborating institutions in 10 countries. The BABAR Web site is, therefore, a community Web site. At the same time it is hosted at SLAC and funded by agencies that demand adherence to policies decided under different priorities. Additionally, the BABAR Web administrators deal with the problems that arise during the course of managing users, content, policies, standards, and changing technologies. Desired solutions to some of these problems may be incompatible with the overall administration of the SLAC Web sites and/or the SLAC policies and concerns. There are thus different perspectives of the same Web site and differing expectations in segments of the SLAC population which act as constraints and challenges in any review or re-engineering activities. Web Engineering, which post-dates the BABAR Web, has aimed to provide a comprehensive understanding of all aspects of Web development. This paper reports on the first part of a recent review of application of Web Engineering methods to the BABAR Web site, which has led to explicit user and information models of the BABAR community and how SLAC and the BABAR community relate and react to each other. The paper identifies the issues of a community Web site in a hierarchical, semi-governmental sector and formulates a strategy for periodic reviews of BABAR and similar sites.","Talk from the 2003 Computing in High Energy and Nuclear Physics
  (CHEP03), La Jolla, Ca, USA, March 2003, 8 pages, PDF, PSN MONT006","Ray Cowan, Yogesh Deshpande, Bebo White",computer science,train
Centralized reward system gives rise to fast and efficient work sharing for intelligent Internet agents lacking direct communication,"WWW has a scale-free structure where novel information is often difficult to locate. Moreover, Intelligent agents easily get trapped in this structure. Here a novel method is put forth, which turns these traps into information repositories, supplies: We populated an Internet environment with intelligent news foragers. Foraging has its associated cost whereas foragers are rewarded if they detect not yet discovered novel information. The intelligent news foragers crawl by using the estimated long-term cumulated reward, and also have a finite sized memory: the list of most promising supplies. Foragers form an artificial life community: the most successful ones are allowed to multiply, while unsuccessful ones die out. The specific property of this community is that there is no direct communication amongst foragers but the centralized rewarding system. Still, fast division of work is achieved.",,"Zsolt Palotai, Sandor Mandusitz, Andras Lorincz",computer science,train
A Correlation-Based Distance,"In this short technical report, we define on the sample space R^D a distance between data points which depends on their correlation. We also derive an expression for the center of mass of a set of points with respect to this distance.",,"Jean-Luc Falcone, Paul Albuquerque",computer science,train
Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition,"This paper presents the MAXQ approach to hierarchical reinforcement learning based on decomposing the target Markov decision process (MDP) into a hierarchy of smaller MDPs and decomposing the value function of the target MDP into an additive combination of the value functions of the smaller MDPs. The paper defines the MAXQ hierarchy, proves formal results on its representational power, and establishes five conditions for the safe use of state abstractions. The paper presents an online model-free learning algorithm, MAXQ-Q, and proves that it converges wih probability 1 to a kind of locally-optimal policy known as a recursively optimal policy, even in the presence of the five kinds of state abstraction. The paper evaluates the MAXQ representation and MAXQ-Q through a series of experiments in three domains and shows experimentally that MAXQ-Q (with state abstractions) converges to a recursively optimal policy much faster than flat Q learning. The fact that MAXQ learns a representation of the value function has an important benefit: it makes it possible to compute and execute an improved, non-hierarchical policy via a procedure similar to the policy improvement step of policy iteration. The paper demonstrates the effectiveness of this non-hierarchical execution experimentally. Finally, the paper concludes with a comparison to related work and a discussion of the design tradeoffs in hierarchical reinforcement learning.","63 pages, 15 figures",Thomas G. Dietterich,computer science,val
State Abstraction in MAXQ Hierarchical Reinforcement Learning,"Many researchers have explored methods for hierarchical reinforcement learning (RL) with temporal abstractions, in which abstract actions are defined that can perform many primitive actions before terminating. However, little is known about learning with state abstractions, in which aspects of the state space are ignored. In previous work, we developed the MAXQ method for hierarchical RL. In this paper, we define five conditions under which state abstraction can be combined with the MAXQ value function decomposition. We prove that the MAXQ-Q learning algorithm converges under these conditions and show experimentally that state abstraction is important for the successful application of MAXQ-Q learning.","7 pages, 2 figures",Thomas G. Dietterich,computer science,train
Multiplicative Algorithm for Orthgonal Groups and Independent Component Analysis,"The multiplicative Newton-like method developed by the author et al. is extended to the situation where the dynamics is restricted to the orthogonal group. A general framework is constructed without specifying the cost function. Though the restriction to the orthogonal groups makes the problem somewhat complicated, an explicit expression for the amount of individual jumps is obtained. This algorithm is exactly second-order-convergent. The global instability inherent in the Newton method is remedied by a Levenberg-Marquardt-type variation. The method thus constructed can readily be applied to the independent component analysis. Its remarkable performance is illustrated by a numerical simulation.","11 pages, 2 figures",Toshinao Akuzawa,computer science,val
Multiplicative Nonholonomic/Newton -like Algorithm,"We construct new algorithms from scratch, which use the fourth order cumulant of stochastic variables for the cost function. The multiplicative updating rule here constructed is natural from the homogeneous nature of the Lie group and has numerous merits for the rigorous treatment of the dynamics. As one consequence, the second order convergence is shown. For the cost function, functions invariant under the componentwise scaling are choosen. By identifying points which can be transformed to each other by the scaling, we assume that the dynamics is in a coset space. In our method, a point can move toward any direction in this coset. Thus, no prewhitening is required.",12 pages,"Toshinao Akuzawa, Noboru Murata",computer science,val
Complexity analysis for algorithmically simple strings,"Given a reference computer, Kolmogorov complexity is a well defined function on all binary strings. In the standard approach, however, only the asymptotic properties of such functions are considered because they do not depend on the reference computer. We argue that this approach can be more useful if it is refined to include an important practical case of simple binary strings. Kolmogorov complexity calculus may be developed for this case if we restrict the class of available reference computers. The interesting problem is to define a class of computers which is restricted in a {\it natural} way modeling the real-life situation where only a limited class of computers is physically available to us. We give an example of what such a natural restriction might look like mathematically, and show that under such restrictions some error terms, even logarithmic in complexity, can disappear from the standard complexity calculus. Keywords: Kolmogorov complexity; Algorithmic information theory.",10 pages,Andrei N. Soklakov,computer science,train
Robust Classification for Imprecise Environments,"In real-world environments it usually is difficult to specify target operating conditions precisely, for example, target misclassification costs. This uncertainty makes building robust classification systems problematic. We show that it is possible to build a hybrid classifier that will perform at least as well as the best available classifier for any target conditions. In some cases, the performance of the hybrid actually can surpass that of the best known classifier. This robust performance extends across a wide variety of comparison frameworks, including the optimization of metrics such as accuracy, expected cost, lift, precision, recall, and workforce utilization. The hybrid also is efficient to build, to store, and to update. The hybrid is based on a method for the comparison of classifier performance that is robust to imprecise class distributions and misclassification costs. The ROC convex hull (ROCCH) method combines techniques from ROC analysis, decision analysis and computational geometry, and adapts them to the particulars of analyzing learned classifiers. The method is efficient and incremental, minimizes the management of classifier performance data, and allows for clear visual comparisons and sensitivity analyses. Finally, we point to empirical evidence that a robust hybrid classifier indeed is needed for many real-world problems.","24 pages, 12 figures. To be published in Machine Learning Journal.
  For related papers, see http://www.hpl.hp.com/personal/Tom_Fawcett/ROCCH/","Foster Provost, Tom Fawcett",computer science,train
Top-down induction of clustering trees,"An approach to clustering is presented that adapts the basic top-down induction of decision trees method towards clustering. To this aim, it employs the principles of instance based learning. The resulting methodology is implemented in the TIC (Top down Induction of Clustering trees) system for first order clustering. The TIC system employs the first order logical decision tree representation of the inductive logic programming system Tilde. Various experiments with TIC are presented, in both propositional and relational domains.","9 pages, 3 figures","Hendrik Blockeel, Luc De Raedt, Jan Ramon",computer science,train
Scaling Up Inductive Logic Programming by Learning from Interpretations,"When comparing inductive logic programming (ILP) and attribute-value learning techniques, there is a trade-off between expressive power and efficiency. Inductive logic programming techniques are typically more expressive but also less efficient. Therefore, the data sets handled by current inductive logic programming systems are small according to general standards within the data mining community. The main source of inefficiency lies in the assumption that several examples may be related to each other, so they cannot be handled independently. Within the learning from interpretations framework for inductive logic programming this assumption is unnecessary, which allows to scale up existing ILP algorithms. In this paper we explain this learning setting in the context of relational databases. We relate the setting to propositional data mining and to the classical ILP setting, and show that learning from interpretations corresponds to learning from multiple relations and thus extends the expressiveness of propositional learning, while maintaining its efficiency to a large extent (which is not the case in the classical ILP setting). As a case study, we present two alternative implementations of the ILP system Tilde (Top-down Induction of Logical DEcision trees): Tilde-classic, which loads all data in main memory, and Tilde-LDS, which loads the examples one by one. We experimentally compare the implementations, showing Tilde-LDS can handle large data sets (in the order of 100,000 examples or 100 MB) and indeed scales up linearly in the number of examples.",37 pages,"Hendrik Blockeel, Luc De Raedt, Nico Jacobs, Bart Demoen",computer science,train
Learning Policies with External Memory,"In order for an agent to perform well in partially observable domains, it is usually necessary for actions to depend on the history of observations. In this paper, we explore a {\it stigmergic} approach, in which the agent's actions include the ability to set and clear bits in an external memory, and the external memory is included as part of the input to the agent. In this case, we need to learn a reactive policy in a highly non-Markovian domain. We explore two algorithms: SARSA(\lambda), which has had empirical success in partially observable domains, and VAPS, a new algorithm due to Baird and Moore, with convergence guarantees in partially observable domains. We compare the performance of these two algorithms on benchmark problems.",8 pages,"Leonid Peshkin, Nicolas Meuleau, Leslie Kaelbling",computer science,train
Efficient algorithms for decision tree cross-validation,"Cross-validation is a useful and generally applicable technique often employed in machine learning, including decision tree induction. An important disadvantage of straightforward implementation of the technique is its computational overhead. In this paper we show that, for decision trees, the computational overhead of cross-validation can be reduced significantly by integrating the cross-validation with the normal decision tree induction process. We discuss how existing decision tree algorithms can be adapted to this aim, and provide an analysis of the speedups these adaptations may yield. The analysis is supported by experimental results.","9 pages, 6 figures.
  http://www.cs.kuleuven.ac.be/cgi-bin-dtai/publ_info.pl?id=34784","Hendrik Blockeel, Jan Struyf",computer science,train
Verifying the Unification Algorithm in LCF,"Manna and Waldinger's theory of substitutions and unification has been verified using the Cambridge LCF theorem prover. A proof of the monotonicity of substitution is presented in detail, as an example of interaction with LCF. Translating the theory into LCF's domain-theoretic logic is largely straightforward. Well-founded induction on a complex ordering is translated into nested structural inductions. Correctness of unification is expressed using predicates for such properties as idempotence and most-generality. The verification is presented as a series of lemmas. The LCF proofs are compared with the original ones, and with other approaches. It appears difficult to find a logic that is both simple and flexible, especially for proving termination.",,Lawrence C. Paulson,computer science,train
Constructing Recursion Operators in Intuitionistic Type Theory,"Martin-L\""of's Intuitionistic Theory of Types is becoming popular for formal reasoning about computer programs. To handle recursion schemes other than primitive recursion, a theory of well-founded relations is presented. Using primitive recursion over higher types, induction and recursion are formally derived for a large class of well-founded relations. Included are < on natural numbers, and relations formed by inverse images, addition, multiplication, and exponentiation of other relations. The constructions are given in full detail to allow their use in theorem provers for Type Theory, such as Nuprl. The theory is compared with work in the field of ordinal recursion over higher types.",,Lawrence C. Paulson,computer science,train
Proving Termination of Normalization Functions for Conditional Expressions,"Boyer and Moore have discussed a recursive function that puts conditional expressions into normal form [1]. It is difficult to prove that this function terminates on all inputs. Three termination proofs are compared: (1) using a measure function, (2) in domain theory using LCF, (3) showing that its recursion relation, defined by the pattern of recursive calls, is well-founded. The last two proofs are essentially the same though conducted in markedly different logical frameworks. An obviously total variant of the normalize function is presented as the `computational meaning' of those two proofs. A related function makes nested recursive calls. The three termination proofs become more complex: termination and correctness must be proved simultaneously. The recursion relation approach seems flexible enough to handle subtle termination proofs where previously domain theory seemed essential.",,Lawrence C. Paulson,computer science,train
Natural Deduction as Higher-Order Resolution,"An interactive theorem prover, Isabelle, is under development. In LCF, each inference rule is represented by one function for forwards proof and another (a tactic) for backwards proof. In Isabelle, each inference rule is represented by a Horn clause. Resolution gives both forwards and backwards proof, supporting a large class of logics. Isabelle has been used to prove theorems in Martin-L\""of's Constructive Type Theory. Quantifiers pose several difficulties: substitution, bound variables, Skolemization. Isabelle's representation of logical syntax is the typed lambda-calculus, requiring higher- order unification. It may have potential for logic programming. Depth-first subgoaling along inference rules constitutes a higher-order Prolog.",,Lawrence C. Paulson,computer science,train
The Foundation of a Generic Theorem Prover,"Isabelle is an interactive theorem prover that supports a variety of logics. It represents rules as propositions (not as functions) and builds proofs by combining rules. These operations constitute a meta-logic (or `logical framework') in which the object-logics are formalized. Isabelle is now based on higher-order logic -- a precise and well-understood foundation. Examples illustrate use of this meta-logic to formalize logics and proofs. Axioms for first-order logic are shown sound and complete. Backwards proof is formalized by meta-reasoning about object-level entailment. Higher-order logic has several practical advantages over other meta-logics. Many proof techniques are known, such as Huet's higher-order unification procedure.",,Lawrence C. Paulson,computer science,val
Isabelle: The Next 700 Theorem Provers,"Isabelle is a generic theorem prover, designed for interactive reasoning in a variety of formal theories. At present it provides useful proof procedures for Constructive Type Theory, various first-order logics, Zermelo-Fraenkel set theory, and higher-order logic. This survey of Isabelle serves as an introduction to the literature. It explains why generic theorem proving is beneficial. It gives a thorough history of Isabelle, beginning with its origins in the LCF system. It presents an account of how logics are represented, illustrated using classical logic. The approach is compared with the Edinburgh Logical Framework. Several of the Isabelle object-logics are presented.",,Lawrence C. Paulson,computer science,test
A Formulation of the Simple Theory of Types (for Isabelle),"Simple type theory is formulated for use with the generic theorem prover Isabelle. This requires explicit type inference rules. There are function, product, and subset types, which may be empty. Descriptions (the eta-operator) introduce the Axiom of Choice. Higher-order logic is obtained through reflection between formulae and terms of type bool. Recursive types and functions can be formally constructed. Isabelle proof procedures are described. The logic appears suitable for general mathematics as well as computational problems.",,Lawrence C. Paulson,computer science,train
A Higher-Order Implementation of Rewriting,"Many automatic theorem-provers rely on rewriting. Using theorems as rewrite rules helps to simplify the subgoals that arise during a proof. LCF is an interactive theorem-prover intended for reasoning about computation. Its implementation of rewriting is presented in detail. LCF provides a family of rewriting functions, and operators to combine them. A succession of functions is described, from pattern matching primitives to the rewriting tool that performs most inferences in LCF proofs. The design is highly modular. Each function performs a basic, specific task, such as recognizing a certain form of tautology. Each operator implements one method of building a rewriting function from simpler ones. These pieces can be put together in numerous ways, yielding a variety of rewrit- ing strategies. The approach involves programming with higher-order functions. Rewriting functions are data values, produced by computation on other rewriting functions. The code is in daily use at Cambridge, demonstrating the practical use of functional programming.",,Lawrence C. Paulson,computer science,train
"Logic Programming, Functional Programming, and Inductive Definitions","An attempt at unifying logic and functional programming is reported. As a starting point, we take the view that ""logic programs"" are not about logic but constitute inductive definitions of sets and relations. A skeletal language design based on these considerations is sketched and a prototype implementation discussed.",,"Lawrence C. Paulson, Andrew W. Smith",computer science,val
Designing a Theorem Prover,"A step-by-step presentation of the code for a small theorem prover introduces theorem-proving techniques. The programming language used is Standard ML. The prover operates on a sequent calculus formulation of first-order logic, which is briefly explained. The implementation of unification and logical inference is shown. The prover is demonstrated on several small examples, including one that shows its limitations. The final part of the paper is a survey of contemporary research on interactive theorem proving.",,Lawrence C. Paulson,computer science,val
A Method for Solving Distributed Service Allocation Problems,"We present a method for solving service allocation problems in which a set of services must be allocated to a set of agents so as to maximize a global utility. The method is completely distributed so it can scale to any number of services without degradation. We first formalize the service allocation problem and then present a simple hill-climbing, a global hill-climbing, and a bidding-protocol algorithm for solving it. We analyze the expected performance of these algorithms as a function of various problem parameters such as the branching factor and the number of agents. Finally, we use the sensor allocation problem, an instance of a service allocation problem, to show the bidding protocol at work. The simulations also show that phase transition on the expected quality of the solution exists as the amount of communication between agents increases.",,Jose M Vidal,computer science,train
Running C++ models undet the Swarm environment,"Objective-C is still the language of choice if users want to run their simulation efficiently under the Swarm environment since the Swarm environment itself was written in Objective-C. The language is a fast, object-oriented and easy to learn. However, the language is less well known than, less expressive than, and lacks support for many important features of C++ (eg. OpenMP for high performance computing application). In this paper, we present a methodology and software tools that we have developed for auto generating an Objective-C object template (and all the necessary interfacing functions) from a given C++ model, utilising the Classdesc's object description technology, so that the C++ model can both be run and accessed under the Objective-C and C++ environments. We also present a methodology for modifying an existing Swarm application to make part of the model (eg. the heatbug's step method) run under the C++ environment.",,"Richard Leow, Russell K. Standish",computer science,train
EcoLab: Agent Based Modeling for C++ programmers,"\EcoLab{} is an agent based modeling system for C++ programmers, strongly influenced by the design of Swarm. This paper is just a brief outline of \EcoLab's features, more details can be found in other published articles, documentation and source code from the \EcoLab{} website.",,"Russell K. Standish, Richard Leow",computer science,train
An agent framework for dynamic agent retraining: Agent academy,"Agent Academy (AA) aims to develop a multi-agent society that can train new agents for specific or general tasks, while constantly retraining existing agents in a recursive mode. The system is based on collecting information both from the environment and the behaviors of the acting agents and their related successes/failures to generate a body of data, stored in the Agent Use Repository, which is mined by the Data Miner module, in order to generate useful knowledge about the application domain. Knowledge extracted by the Data Miner is used by the Agent Training Module as to train new agents or to enhance the behavior of agents already running. In this paper the Agent Academy framework is introduced, and its overall architecture and functionality are presented. Training issues as well as agent ontologies are discussed. Finally, a scenario, which aims to provide environmental alerts to both individuals and public authorities, is described an AA-based use case.",,"P. Mitkas, A. Symeonidis, D. Kechagias, I. N. Athanasiadis, G. Laleci, G. Kurt, Y. Kabak, A. Acar, A. Dogac",computer science,train
"Coalition Formation: Concessions, Task Relationships and Complexity Reduction","Solutions to the coalition formation problem commonly assume agent rationality and, correspondingly, utility maximization. This in turn may prevent agents from making compromises. As shown in recent studies, compromise may facilitate coalition formation and increase agent utilities. In this study we leverage on those new results. We devise a novel coalition formation mechanism that enhances compromise. Our mechanism can utilize information on task dependencies to reduce formation complexity. Further, it works well with both cardinal and ordinal task values. Via experiments we show that the use of the suggested compromise-based coalition formation mechanism provides significant savings in the computation and communication complexity of coalition formation. Our results also show that when information on task dependencies is used, the complexity of coalition formation is further reduced. We demonstrate successful use of the mechanism for collaborative information filtering, where agents combine linguistic rules to analyze documents' contents.",,"Samir Aknine, Onn Shehory",computer science,train
Emergent Statistical Wealth Distributions in Simple Monetary Exchange Models: A Critical Review,"This paper reviews recent attempts at modelling inequality of wealth as an emergent phenomenon of interacting-agent processes. We point out that recent models of wealth condensation which draw their inspiration from molecular dynamics have, in fact, reinvented a process introduced quite some time ago by Angle (1986) in the sociological literature. We emphasize some problematic aspects of simple wealth exchange models and contrast them with a monetary model based on economic principles of market mediated exchange. The paper also reports new results on the influence of market power on the wealth distribution in statistical equilibrium. As it turns out, inequality increases but market power alone is not sufficient for changing the exponential tails of simple exchange models into Pareto tails.",,Thomas Lux,computer science,train
Friends for Free: Self-Organizing Artificial Social Networks for Trust and Cooperation,"By harvesting friendship networks from e-mail contacts or instant message ""buddy lists"" Peer-to-Peer (P2P) applications can improve performance in low trust environments such as the Internet. However, natural social networks are not always suitable, reliable or available. We propose an algorithm (SLACER) that allows peer nodes to create and manage their own friendship networks. We evaluate performance using a canonical test application, requiring cooperation between peers for socially optimal outcomes. The Artificial Social Networks (ASN) produced are connected, cooperative and robust - possessing many of the disable properties of human friendship networks such as trust between friends (directly linked peers) and short paths linking everyone via a chain of friends. In addition to new application possibilities, SLACER could supply ASN to P2P applications that currently depend on human social networks thus transforming them into fully autonomous, self-managing systems.",,"David Hales, Stefano Arteconi",computer science,val
Effect of door delay on aircraft evacuation time,"The recent commercial launch of twin-deck Very Large Transport Aircraft (VLTA) such as the Airbus A380 has raised questions concerning the speed at which they may be evacuated. The abnormal height of emergency exits on the upper deck has led to speculation that emotional factors such as fear may lead to door delay, and thus play a significant role in increasing overall evacuation time. Full-scale evacuation tests are financially expensive and potentially hazardous, and systematic studies of the evacuation of VLTA are rare. Here we present a computationally cheap agent-based framework for the general simulation of aircraft evacuation, and apply it to the particular case of the Airbus A380. In particular, we investigate the effect of door delay, and conclude that even a moderate average delay can lead to evacuation times that exceed the maximum for safety certification. The model suggests practical ways to minimise evacuation time, as well as providing a general framework for the simulation of evacuation.","8 pages, 2 figures","Martyn Amos, Andrew Wood",computer science,train
Building Scenarios for Environmental Management and Planning: An IT-Based Approach,"Oftentimes, the need to build multidiscipline knowledge bases, oriented to policy scenarios, entails the involvement of stakeholders in manifold domains, with a juxtaposition of different languages whose semantics can hardly allow inter-domain transfers. A useful support for planning is the building up of durable IT based interactive platforms, where it is possible to modify initial positions toward a semantic convergence. The present paper shows an area-based application of these tools, for the integrated distance-management of different forms of knowledge expressed by selected stakeholders about environmental planning issues, in order to build alternative development scenarios. Keywords: Environmental planning, Scenario building, Multi-source knowledge, IT-based",,"Dino Borri, Domenico Camarda",computer science,train
Open at the Top; Open at the Bottom; and Continually (but Slowly) Evolving,"Systems of systems differ from traditional systems in that they are open at the top, open at the bottom, and continually (but slowly) evolving. ""Open at the top"" means that there is no pre-defined top level application. New applications may be created at any time. ""Open at the bottom"" means that the system primitives are defined functionally rather than concretely. This allows the implementation of these primitives to be modified as technology changes. ""Continually (but slowly) evolving"" means that the system's functionality is stable enough to be useful but is understood to be subject to modification. Systems with these properties tend to be environments within which other systems operate--and hence are systems of systems. It is also important to understand the larger environment within which a system of systems exists.","6 pages. To be presented at the IEEE Conference on Systems of Systems
  Engineering, April, 2006",Russ Abbott,computer science,val
Open Access beyond cable: The case of Interactive TV,"In this paper we analyze the development of interactive TV in the U.S. and Western Europe. We argue that despite the nascent character of the market there are important regulatory issues at stake, as exemplified by the AOL/TW merger and the British Interactive Broadcasting case. Absent rules that provide for non-discriminatory access to network components (including terminal equipment specifications), dominant platform operators are likely to leverage ownership of delivery infrastructure into market power over interactive TV services. While integration between platform operator, service provider and terminal vendor may facilitate the introduction of services in the short-term, the lasting result will be a collection of fragmented ""walled gardens"" offering limited content and applications. Would interactive TV develop under such model, the exciting opportunities for broad-based innovation and extended access to multiple information, entertainment and educational services opened by the new generation of broadcasting technologies will be foregone","typos corrected, content changed section 3(a), new abstract","Hernan Galperin, Francois Bar",computer science,train
Data Visualization on Shared Usage Multi-Screen Environment,"The modern multimedia technologies based on the whole palette of hardware and software facilities of real-time high-speed information processing, in a combination with effective facilities of the remote access to information resources, allow us to visualize diverse types of information. Data visualization facilities &#8211; is the face of the Automated Control System on whom often judge about their efficiency. They take a special place, providing visualization of the diverse information necessary for decision-making by a final control link - the person allocated by certain powers.","4 pages, 1 figure",Ph. D. Yuriy A. Chashkov,computer science,train
Digital watermarking in the singular vector domain,"Many current watermarking algorithms insert data in the spatial or transform domains like the discrete cosine, the discrete Fourier, and the discrete wavelet transforms. In this paper, we present a data-hiding algorithm that exploits the singular value decomposition (SVD) representation of the data. We compute the SVD of the host image and the watermark and embed the watermark in the singular vectors of the host image. The proposed method leads to an imperceptible scheme for digital images, both in grey scale and color and is quite robust against attacks like noise and JPEG compression.","11 pages, 21 figures, Elsevier class","Rashmi Agarwal, M. S. Santhanam",computer science,test
Un filtre temporel crédibiliste pour la reconnaissance d'actions humaines dans les vidéos,"In the context of human action recognition in video sequences, a temporal belief filter is presented. It allows to cope with human action disparity and low quality videos. The whole system of action recognition is based on the Transferable Belief Model (TBM) proposed by P. Smets. The TBM allows to explicitly model the doubt between actions. Furthermore, the TBM emphasizes the conflict which is exploited for action recognition. The filtering performance is assessed on real video sequences acquired by a moving camera and under several unknown view angles.",8 pages,"Emmanuel Ramasso, Michèle Rombaut, Denis Pellerin",computer science,val
A Fast Block Matching Algorithm for Video Motion Estimation Based on Particle Swarm Optimization and Motion Prejudgment,"In this paper, we propose a fast 2-D block-based motion estimation algorithm called Particle Swarm Optimization - Zero-motion Prejudgment(PSO-ZMP) which consists of three sequential routines: 1)Zero-motion prejudgment. The routine aims at finding static macroblocks(MB) which do not need to perform remaining search thus reduces the computational cost; 2)Predictive image coding and 3)PSO matching routine. Simulation results obtained show that the proposed PSO-ZMP algorithm achieves over 10 times of computation less than Diamond Search(DS) and 5 times less than the recent proposed Adaptive Rood Pattern Searching(ARPS). Meanwhile the PSNR performances using PSO-ZMP are very close to that using DS and ARPS in some less-motioned sequences. While in some sequences containing dense and complex motion contents, the PSNR performances of PSO-ZMP are several dB lower than that using DS and ARPS but in an acceptable degree.","10 pages, 12 figures, submitted to ACM Symposium of Applied
  Computing(SAC)","Ran Ren, Madan mohan Manokar, Yaogang Shi, Baoyu Zheng",computer science,train
A High Quality/Low Computational Cost Technique for Block Matching Motion Estimation,"Motion estimation is the most critical process in video coding systems. First of all, it has a definitive impact on the rate-distortion performance given by the video encoder. Secondly, it is the most computationally intensive process within the encoding loop. For these reasons, the design of high-performance low-cost motion estimators is a crucial task in the video compression field. An adaptive cost block matching (ACBM) motion estimation technique is presented in this paper, featuring an excellent tradeoff between the quality of the reconstructed video sequences and the computational effort. Simulation results demonstrate that the ACBM algorithm achieves a slight better rate-distortion performance than the one given by the well-known full search algorithm block matching algorithm with reductions of up to 95% in the computational load.",Submitted on behalf of EDAA (http://www.edaa.com/),"S. Lopez, G. M. Callico, J. F. Lopez, R. Sarmiento",computer science,train
Multimedia Applications of Multiprocessor Systems-on-Chips,"This paper surveys the characteristics of multimedia systems. Multimedia applications today are dominated by compression and decompression, but multimedia devices must also implement many other functions such as security and file management. We introduce some basic concepts of multimedia algorithms and the larger set of functions that multimedia systems-on-chips must implement.",Submitted on behalf of EDAA (http://www.edaa.com/),Wayne Wolf,computer science,val
A Coprocessor for Accelerating Visual Information Processing,"Visual information processing will play an increasingly important role in future electronics systems. In many applications, e.g. video surveillance cameras, data throughput of microprocessors is not sufficient and power consumption is too high. Instruction profiling on a typical test algorithm has shown that pixel address calculations are the dominant operations to be optimized. Therefore AddressLib, a structured scheme for pixel addressing was developed, that can be accelerated by AddressEngine, a coprocessor for visual information processing. In this paper, the architectural design of AddressEngine is described, which in the first step supports a subset of the AddressLib. Dataflow and memory organization are optimized during architectural design. AddressEngine was implemented in a FPGA and was tested with MPEG-7 Global Motion Estimation algorithm. Results on processing speed and circuit complexity are given and compared to a pure software implementation. The next step will be the support for the full AddressLib, including segment addressing. An outlook on further investigations on dynamic reconfiguration capabilities is given.",Submitted on behalf of EDAA (http://www.edaa.com/),"W. Stechele, L. Alvado Carcel, S. Herrmann, J. Lidon Simon",computer science,test
SecMon: End-to-End Quality and Security Monitoring System,"The Voice over Internet Protocol (VoIP) is becoming a more available and popular way of communicating for Internet users. This also applies to Peer-to-Peer (P2P) systems and merging these two have already proven to be successful (e.g. Skype). Even the existing standards of VoIP provide an assurance of security and Quality of Service (QoS), however, these features are usually optional and supported by limited number of implementations. As a result, the lack of mandatory and widely applicable QoS and security guaranties makes the contemporary VoIP systems vulnerable to attacks and network disturbances. In this paper we are facing these issues and propose the SecMon system, which simultaneously provides a lightweight security mechanism and improves quality parameters of the call. SecMon is intended specially for VoIP service over P2P networks and its main advantage is that it provides authentication, data integrity services, adaptive QoS and (D)DoS attack detection. Moreover, the SecMon approach represents a low-bandwidth consumption solution that is transparent to the users and possesses a self-organizing capability. The above-mentioned features are accomplished mainly by utilizing two information hiding techniques: digital audio watermarking and network steganography. These techniques are used to create covert channels that serve as transport channels for lightweight QoS measurement's results. Furthermore, these metrics are aggregated in a reputation system that enables best route path selection in the P2P network. The reputation system helps also to mitigate (D)DoS attacks, maximize performance and increase transmission efficiency in the network.","Paper was presented at 7th international conference IBIZA 2008: On
  Computer Science - Research And Applications, Poland, Kazimierz Dolny
  31.01-2.02 2008; 14 pages, 5 figures","Tomasz Ciszkowski, Charlott Eliasson, Markus Fiedler, Zbigniew Kotulski, Radu Lupu, Wojciech Mazurczyk",computer science,train
A Reliable SVD based Watermarking Schem,"We propose a novel scheme for watermarking of digital images based on singular value decomposition (SVD), which makes use of the fact that the SVD subspace preserves significant amount of information of an image, as compared to its singular value matrix, Zhang and Li (2005). The principal components of the watermark are embedded in the original image, leaving the detector with a complimentary set of singular vectors for watermark extraction. The above step invariably ensures that watermark extraction from the embedded watermark image, using a modified matrix, is not possible, thereby removing a major drawback of an earlier proposed algorithm by Liu and Tan (2002).","8 Pages, 7 Figures","Chirag Jain, Siddharth Arora, Prasanta K. Panigrahi",computer science,val
Developing numerical libraries in Java,"The rapid and widespread adoption of Java has created a demand for reliable and reusable mathematical software components to support the growing number of compute-intensive applications now under development, particularly in science and engineering. In this paper we address practical issues of the Java language and environment which have an effect on numerical library design and development. Benchmarks which illustrate the current levels of performance of key numerical kernels on a variety of Java platforms are presented. Finally, a strategy for the development of a fundamental numerical toolkit for Java is proposed and its current status is described.","11 pages. Revised version of paper presented to the 1998 ACM
  Conference on Java for High Performance Network Computing. To appear in
  Concurrency: Practice and Experience","Ronald F. Boisvert, Jack J. Dongarra, Roldan Pozo, Karin Remington, G. W. Stewart",computer science,val
Hyper-Systolic Matrix Multiplication,A novel parallel algorithm for matrix multiplication is presented. The hyper-systolic algorithm makes use of a one-dimensional processor abstraction. The procedure can be implemented on all types of parallel systems. It can handle matrix-vector multiplications as well as transposed matrix products.,"29 pages, 13 figures","Thomas Lippert, Nikolay Petkov, Paolo Palazzari, Klaus Schilling",computer science,train
"Mathematical Software: Past, Present, and Future","This paper provides some reflections on the field of mathematical software on the occasion of John Rice's 65th birthday. I describe some of the common themes of research in this field and recall some significant events in its evolution. Finally, I raise a number of issues that are of concern to future developments.","To appear in the Proceedings of the International Symposium on
  Computational Sciences, Purdue University, May 21-22, 1999. 20 pages",Ronald F. Boisvert,computer science,train
Automatic Differentiation Tools in Optimization Software,We discuss the role of automatic differentiation tools in optimization software. We emphasize issues that are important to large-scale optimization and that have proved useful in the installation of nonlinear solvers in the NEOS Server. Our discussion centers on the computation of the gradient and Hessian matrix for partially separable functions and shows that the gradient and Hessian matrix can be computed with guaranteed bounds in time and memory requirements,11 pages,Jorge J. Moré,computer science,train
GPCG: A Case Study in the Performance and Scalability of Optimization Algorithms,"GPCG is an algorithm within the Toolkit for Advanced Optimization (TAO) for solving bound constrained, convex quadratic problems. Originally developed by More' and Toraldo, this algorithm was designed for large-scale problems but had been implemented only for a single processor. The TAO implementation is available for a wide range of high-performance architecture, and has been tested on up to 64 processors to solve problems with over 2.5 million variables.",title + 16 pages,"Steven J. Benson, Lois Curfman McInnes, Jorge J. Moré",computer science,val
Benchmarking Optimization Software with Performance Profiles,We propose performance profiles-distribution functions for a performance metric-as a tool for benchmarking and comparing optimization software. We show that performance profiles combine the best features of other tools for performance evaluation.,13 pages plus title and toc pages,"Elizabeth D. Dolan, Jorge J. Moré",computer science,train
Users Guide for SnadiOpt: A Package Adding Automatic Differentiation to Snopt,"SnadiOpt is a package that supports the use of the automatic differentiation package ADIFOR with the optimization package Snopt. Snopt is a general-purpose system for solving optimization problems with many variables and constraints. It minimizes a linear or nonlinear function subject to bounds on the variables and sparse linear or nonlinear constraints. It is suitable for large-scale linear and quadratic programming and for linearly constrained optimization, as well as for general nonlinear programs. The method used by Snopt requires the first derivatives of the objective and constraint functions to be available. The SnadiOpt package allows users to avoid the time-consuming and error-prone process of evaluating and coding these derivatives. Given Fortran code for evaluating only the values of the objective and constraints, SnadiOpt automatically generates the code for evaluating the derivatives and builds the relevant Snopt input files and sparse data structures.","pages i-iv, 1-23","E. Michael Gertz, Philip E. Gill, Julia Muetherig",computer science,val
Computer validated proofs of a toolset for adaptable arithmetic,"Most existing implementations of multiple precision arithmetic demand that the user sets the precision {\em a priori}. Some libraries are said adaptable in the sense that they dynamically change the precision of each intermediate operation individually to deliver the target accuracy according to the actual inputs. We present in this text a new adaptable numeric core inspired both from floating point expansions and from on-line arithmetic. The numeric core is cut down to four tools. The tool that contains arithmetic operations is proved to be correct. The proofs have been formally checked by the Coq assistant. Developing the proofs, we have formally proved many results published in the literature and we have extended a few of them. This work may let users (i) develop application specific adaptable libraries based on the toolset and / or (ii) write new formal proofs based on the set of validated facts.","21 pages, web links","Sylvie Boldo, Marc Daumas, Claire Moreau-Finot, Laurent Thery",computer science,train
Development of a Java Package for Matrix Programming,"We had assembled a Java package, known as MatrixPak, of four classes for the purpose of numerical matrix computation. The classes are matrix, matrix_operations, StrToMatrix, and MatrixToStr; all of which are inherited from java.lang.Object class. Class matrix defines a matrix as a two-dimensional array of float types, and contains the following mathematical methods: transpose, adjoint, determinant, inverse, minor and cofactor. Class matrix_operations contains the following mathematical methods: matrix addition, matrix subtraction, matrix multiplication, and matrix exponential. Class StrToMatrix contains methods necessary to parse a string representation (for example, [[2 3 4]-[5 6 7]]) of a matrix into a matrix definition, whereas class MatrixToStr does the reverse.","Secondary school (high school) student project report. Foundation for
  JMaths project","Ngee-Peng Lim, Maurice HT Ling, Shawn YC Lim, Ji-Hee Choi, Henry BK Teo",computer science,val
"Finding the ""truncated"" polynomial that is closest to a function","When implementing regular enough functions (e.g., elementary or special functions) on a computing system, we frequently use polynomial approximations. In most cases, the polynomial that best approximates (for a given distance and in a given interval) a function has coefficients that are not exactly representable with a finite number of bits. And yet, the polynomial approximations that are actually implemented do have coefficients that are represented with a finite - and sometimes small - number of bits: this is due to the finiteness of the floating-point representations (for software implementations), and to the need to have small, hence fast and/or inexpensive, multipliers (for hardware implementations). We then have to consider polynomial approximations for which the degree-$i$ coefficient has at most $m_i$ fractional bits (in other words, it is a rational number with denominator $2^{m_i}$). We provide a general method for finding the best polynomial approximation under this constraint. Then, we suggest refinements than can be used to accelerate our method.","14 pages, 1 figure","Nicolas Brisebarre, Jean-Michel Muller",computer science,val
Alternative Local Discriminant Bases Using Empirical Expectation and Variance Estimation,We propose alternative discriminant measures for selecting the best basis among a large collection of orthonormal bases for classification purposes. A generalization of the Local Discriminant Basis Algorithm of Saito and Coifman is constructed. The success of these new methods is evaluated and compared to earlier methods in experiments.,11 pages,Eirik Fossgaard,computer science,test
On the Significance of Digits in Interval Notation,"To analyse the significance of the digits used for interval bounds, we clarify the philosophical presuppositions of various interval notations. We use information theory to determine the information content of the last digit of the numeral used to denote the interval's bounds. This leads to the notion of efficiency of a decimal digit: the actual value as percentage of the maximal value of its information content. By taking this efficiency into account, many presentations of intervals can be made more readable at the expense of negligible loss of information.","11 pages, LaTeX",M. H. van Emden,computer science,val
A sufficient condition for global invertibility of Lipschitz mapping,"We show that S.Vavasis' sufficient condition for global invertibility of a polynomial mapping can be easily generalized to the case of a general Lipschitz mapping. Keywords: Invertibility conditions, generalized Jacobian, nonsmooth analysis.","LATeX2e, 3 pages, MSC-class: 26B10",S. Tarasov,computer science,train
New Developments in Interval Arithmetic and Their Implications for Floating-Point Standardization,"We consider the prospect of a processor that can perform interval arithmetic at the same speed as conventional floating-point arithmetic. This makes it possible for all arithmetic to be performed with the superior security of interval methods without any penalty in speed. In such a situation the IEEE floating-point standard needs to be compared with a version of floating-point arithmetic that is ideal for the purpose of interval arithmetic. Such a comparison requires a succinct and complete exposition of interval arithmetic according to its recent developments. We present such an exposition in this paper. We conclude that the directed roundings toward the infinities and the definition of division by the signed zeros are valuable features of the standard. Because the operations of interval arithmetic are always defined, exceptions do not arise. As a result neither Nans nor exceptions are needed. Of the status flags, only the inexact flag may be useful. Denormalized numbers seem to have no use for interval arithmetic; in the use of interval constraints, they are a handicap.",12 pages; 3 tables,M. H. van Emden,computer science,train
Computing sharp and scalable bounds on errors in approximate zeros of univariate polynomials,"There are several numerical methods for computing approximate zeros of a given univariate polynomial. In this paper, we develop a simple and novel method for determining sharp upper bounds on errors in approximate zeros of a given polynomial using Rouche's theorem from complex analysis. We compute the error bounds using non-linear optimization. Our bounds are scalable in the sense that we compute sharper error bounds for better approximations of zeros. We use high precision computations using the LEDA/real floating-point filter for computing our bounds robustly.","13 pages, no figures","P. H. D. Ramakrishna, Sudebkumar Prasant Pal, Samir Bhalla, Hironmay Basu, Sudhir Kumar Singh",computer science,train
Propagation by Selective Initialization and Its Application to Numerical Constraint Satisfaction Problems,"Numerical analysis has no satisfactory method for the more realistic optimization models. However, with constraint programming one can compute a cover for the solution set to arbitrarily close approximation. Because the use of constraint propagation for composite arithmetic expressions is computationally expensive, consistency is computed with interval arithmetic. In this paper we present theorems that support, selective initialization, a simple modification of constraint propagation that allows composite arithmetic expressions to be handled efficiently.",,"M. H. van Emden, B. Moa",computer science,train
Solving Elliptic Finite Element Systems in Near-Linear Time with Support Preconditioners,"We consider linear systems arising from the use of the finite element method for solving scalar linear elliptic problems. Our main result is that these linear systems, which are symmetric and positive semidefinite, are well approximated by symmetric diagonally dominant matrices. Our framework for defining matrix approximation is support theory. Significant graph theoretic work has already been developed in the support framework for preconditioners in the diagonally dominant case, and in particular it is known that such systems can be solved with iterative methods in nearly linear time. Thus, our approximation result implies that these graph theoretic techniques can also solve a class of finite element problems in nearly linear time. We show that the support number bounds, which control the number of iterations in the preconditioned iterative solver, depend on mesh quality measures but not on the problem size or shape of the domain.","Added ref to Chen & Toledo in Section 9 Added description of how to
  form RHS; added ref to Wang and Sarin","Erik Boman, Bruce Hendrickson, Stephen Vavasis",computer science,test
Analysis of and workarounds for element reversal for a finite element-based algorithm for warping triangular and tetrahedral meshes,"We consider an algorithm called FEMWARP for warping triangular and tetrahedral finite element meshes that computes the warping using the finite element method itself. The algorithm takes as input a two- or three-dimensional domain defined by a boundary mesh (segments in one dimension or triangles in two dimensions) that has a volume mesh (triangles in two dimensions or tetrahedra in three dimensions) in its interior. It also takes as input a prescribed movement of the boundary mesh. It computes as output updated positions of the vertices of the volume mesh. The first step of the algorithm is to determine from the initial mesh a set of local weights for each interior vertex that describes each interior vertex in terms of the positions of its neighbors. These weights are computed using a finite element stiffness matrix. After a boundary transformation is applied, a linear system of equations based upon the weights is solved to determine the final positions of the interior vertices. The FEMWARP algorithm has been considered in the previous literature (e.g., in a 2001 paper by Baker). FEMWARP has been succesful in computing deformed meshes for certain applications. However, sometimes FEMWARP reverses elements; this is our main concern in this paper. We analyze the causes for this undesirable behavior and propose several techniques to make the method more robust against reversals. The most successful of the proposed methods includes combining FEMWARP with an optimization-based untangler.","Revision of earlier version of paper. Submitted for publication in
  BIT Numerical Mathematics on 27 April 2010. Accepted for publication on 7
  September 2010. Published online on 9 October 2010. The final publication is
  available at http://www.springerlink.com","Suzanne M. Shontz, Stephen A. Vavasis",computer science,train
A Fully Sparse Implementation of a Primal-Dual Interior-Point Potential Reduction Method for Semidefinite Programming,"In this paper, we show a way to exploit sparsity in the problem data in a primal-dual potential reduction method for solving a class of semidefinite programs. When the problem data is sparse, the dual variable is also sparse, but the primal one is not. To avoid working with the dense primal variable, we apply Fukuda et al.'s theory of partial matrix completion and work with partial matrices instead. The other place in the algorithm where sparsity should be exploited is in the computation of the search direction, where the gradient and the Hessian-matrix product of the primal and dual barrier functions must be computed in every iteration. By using an idea from automatic differentiation in backward mode, both the gradient and the Hessian-matrix product can be computed in time proportional to the time needed to compute the barrier functions of sparse variables itself. Moreover, the high space complexity that is normally associated with the use of automatic differentiation in backward mode can be avoided in this case. In addition, we suggest a technique to efficiently compute the determinant of the positive definite matrix completion that is required to compute primal search directions. The method of obtaining one of the primal search directions that minimizes the number of the evaluations of the determinant of the positive definite completion is also proposed. We then implement the algorithm and test it on the problem of finding the maximum cut of a graph.",,"Gun Srijuntongsiri, Stephen A. Vavasis",computer science,val
Two Iterative Algorithms for Solving Systems of Simultaneous Linear Algebraic Equations with Real Matrices of Coefficients,"The paper describes two iterative algorithms for solving general systems of M simultaneous linear algebraic equations (SLAE) with real matrices of coefficients. The system can be determined, underdetermined, and overdetermined. Linearly dependent equations are also allowed. Both algorithms use the method of Lagrange multipliers to transform the original SLAE into a positively determined function F of real original variables X(i) (i=1,...,N) and Lagrange multipliers Lambda(i) (i=1,...,M). Function F is differentiated with respect to variables X(i) and the obtained relationships are used to express F in terms of Lagrange multipliers Lambda(i). The obtained function is minimized with respect to variables Lambda(i) with the help of one of two the following minimization techniques: (1) relaxation method or (2) method of conjugate gradients by Fletcher and Reeves. Numerical examples are given.",5 pages; 0 figures; 4 references,"A. S. Kondratiev, N. P. Polishchuk",computer science,val
Aspects of Evolutionary Design by Computers,"This paper examines the four main types of Evolutionary Design by computers: Evolutionary Design Optimisation, Evolutionary Art, Evolutionary Artificial Life Forms and Creative Evolutionary Design. Definitions for all four areas are provided. A review of current work in each of these areas is given, with examples of the types of applications that have been tackled. The different properties and requirements of each are examined. Descriptions of typical representations and evolutionary algorithms are provided and examples of designs evolved using these techniques are shown. The paper then discusses how the boundaries of these areas are beginning to merge, resulting in four new 'overlapping' types of Evolutionary Design: Integral Evolutionary Design, Artificial Life Based Evolutionary Design, Aesthetic Evolutionary AL and Aesthetic Evolutionary Design. Finally, the last part of the paper discusses some common problems faced by creators of Evolutionary Design systems, including: interdependent elements in designs, epistasis, and constraint handling.","In Proceedings of the 3rd On-line World Conference on Soft Computing
  in Engineering Design and Manufacturing (WSC3)",Peter J Bentley,computer science,train
Training Reinforcement Neurocontrollers Using the Polytope Algorithm,A new training algorithm is presented for delayed reinforcement learning problems that does not assume the existence of a critic model and employs the polytope optimization algorithm to adjust the weights of the action network so that a simple direct measure of the training performance is maximized. Experimental results from the application of the method to the pole balancing problem indicate improved training performance compared with critic-based and genetic reinforcement approaches.,,"A. Likas, I. E. Lagaris",computer science,val
An Efficient Mean Field Approach to the Set Covering Problem,"A mean field feedback artificial neural network algorithm is developed and explored for the set covering problem. A convenient encoding of the inequality constraints is achieved by means of a multilinear penalty function. An approximate energy minimum is obtained by iterating a set of mean field equations, in combination with annealing. The approach is numerically tested against a set of publicly available test problems with sizes ranging up to 5x10^3 rows and 10^6 columns. When comparing the performance with exact results for sizes where these are available, the approach yields results within a few percent from the optimal solutions. Comparisons with other approximate methods also come out well, in particular given the very low CPU consumption required -- typically a few seconds. Arbitrary problems can be processed using the algorithm via a public domain server.","17 pages, 2 figures","Mattias Ohlsson, Carsten Peterson, Bo Söderberg",computer science,train
Alife Model of Evolutionary Emergence of Purposeful Adaptive Behavior,"The process of evolutionary emergence of purposeful adaptive behavior is investigated by means of computer simulations. The model proposed implies that there is an evolving population of simple agents, which have two natural needs: energy and reproduction. Any need is characterized quantitatively by a corresponding motivation. Motivations determine goal-directed behavior of agents. The model demonstrates that purposeful behavior does emerge in the simulated evolutionary processes. Emergence of purposefulness is accompanied by origin of a simple hierarchy in the control system of agents.","9 pages, 5 figures. Full version of poster presentation on ECAL 2001
  (see ""Advances in Artificial Life."" J. Kelemen, P. Sosik (Eds.), 6th European
  Conference, ECAL 2001, Prague, Czech Republic, September 10-14, 2001,
  Proceedings, p. 413.)","Mikhail S. Burtsev, Vladimir G. Redko, Roman V. Gusarev",computer science,train
Design of statistical quality control procedures using genetic algorithms,"In general, we can not use algebraic or enumerative methods to optimize a quality control (QC) procedure so as to detect the critical random and systematic analytical errors with stated probabilities, while the probability for false rejection is minimum. Genetic algorithms (GAs) offer an alternative, as they do not require knowledge of the objective function to be optimized and search through large parameter spaces quickly. To explore the application of GAs in statistical QC, we have developed an interactive GAs based computer program that designs a novel near optimal QC procedure, given an analytical process. The program uses the deterministic crowding algorithm. An illustrative application of the program suggests that it has the potential to design QC procedures that are significantly better than 45 alternative ones that are used in the clinical laboratories.","11 pages, 1 figure","Aristides T. Hatjimihail, Theophanes T. Hatjimihail",computer science,train
Selection of future events from a time series in relation to estimations of forecasting uncertainty,"A new general procedure for a priori selection of more predictable events from a time series of observed variable is proposed. The procedure is applicable to time series which contains different types of events that feature significantly different predictability, or, in other words, to heteroskedastic time series. A priori selection of future events in accordance to expected uncertainty of their forecasts may be helpful for making practical decisions. The procedure first implies creation of two neural network based forecasting models, one of which is aimed at prediction of conditional mean and other - conditional dispersion, and then elaboration of the rule for future event selection into groups of more and less predictable events. The method is demonstrated and tested by the example of the computer generated time series, and then applied to the real world time series, Dow Jones Industrial Average index.",,Igor B. Konovalov,computer science,val
"Thinking, Learning, and Autonomous Problem Solving","Ever increasing computational power will require methods for automatic programming. We present an alternative to genetic programming, based on a general model of thinking and learning. The advantage is that evolution takes place in the space of constructs and can thus exploit the mathematical structures of this space. The model is formalized, and a macro language is presented which allows for a formal yet intuitive description of the problem under consideration. A prototype has been developed to implement the scheme in PERL. This method will lead to a concentration on the analysis of problems, to a more rapid prototyping, to the treatment of new problem classes, and to the investigation of philosophical problems. We see fields of application in nonlinear differential equations, pattern recognition, robotics, model building, and animated pictures.","9 pages, 4 figures",Joerg D. Becker,computer science,train
Optimizing GoTools' Search Heuristics using Genetic Algorithms,"GoTools is a program which solves life & death problems in the game of Go. This paper describes experiments using a Genetic Algorithm to optimize heuristic weights used by GoTools' tree-search. The complete set of heuristic weights is composed of different subgroups, each of which can be optimized with a suitable fitness function. As a useful side product, an MPI interface for FreePascal was implemented to allow the use of a parallelized fitness function running on a Beowulf cluster. The aim of this exercise is to optimize the current version of GoTools, and to make tools available in preparation of an extension of GoTools for solving open boundary life & death problems, which will introduce more heuristic parameters to be fine tuned.","23 pages, to appear in Journal of ICGA","Matthew Pratola, Thomas Wolf",computer science,train
Predicting Response-Function Results of Electrical/Mechanical Systems Through Artificial Neural Network,"In the present paper a newer application of Artificial Neural Network (ANN) has been developed i.e., predicting response-function results of electrical-mechanical system through ANN. This method is specially useful to complex systems for which it is not possible to find the response-function because of complexity of the system. The proposed approach suggests that how even without knowing the response-function, the response-function results can be predicted with the use of ANN to the system. The steps used are: (i) Depending on the system, the ANN-architecture and the input & output parameters are decided, (ii) Training & test data are generated from simplified circuits and through tactic-superposition of it for complex circuits, (iii) Training the ANN with training data through many cycles and (iv) Test-data are used for predicting the response-function results. It is found that the proposed novel method for response prediction works satisfactorily. Thus this method could be used specially for complex systems where other methods are unable to tackle it. In this paper the application of ANN is particularly demonstrated to electrical-circuit system but can be applied to other systems too.",8 pages including 3 figures,"R. C. Gupta, Ankur Agarwal, Ruchi Gupta, Sanjay Gupta",computer science,val
A novel evolutionary formulation of the maximum independent set problem,"We introduce a novel evolutionary formulation of the problem of finding a maximum independent set of a graph. The new formulation is based on the relationship that exists between a graph's independence number and its acyclic orientations. It views such orientations as individuals and evolves them with the aid of evolutionary operators that are very heavily based on the structure of the graph and its acyclic orientations. The resulting heuristic has been tested on some of the Second DIMACS Implementation Challenge benchmark graphs, and has been found to be competitive when compared to several of the other heuristics that have also been tested on those graphs.",,"V. C. Barbosa, L. C. D. Campos",computer science,val
"Fast, Approximate Synthesis of Fractional Gaussian Noise for Generating Self-Similar Network Traffic","Recent network traffic studies argue that network arrival processes are much more faithfully modeled using statistically self-similar processes instead of traditional Poisson processes [LTWW94,PF95]. One difficulty in dealing with self-similar models is how to efficiently synthesize traces (sample paths) corresponding to self-similar traffic. We present a fast Fourier transform method for synthesizing approximate self-similar sample paths for one type of self-similar process, Fractional Gaussian Noise, and assess its performance and validity. We find that the method is as fast or faster than existing methods and appears to generate close approximations to true self-similar sample paths. We also discuss issues in using such synthesized sample paths for simulating network traffic, and how an approximation used by our method can dramatically speed up evaluation of Whittle's estimator for H, the Hurst parameter giving the strength of long-range dependence present in a self-similar time series.",14 pages,Vern Paxson,computer science,train
ABR Flow Control for Multipoint Connections,"Multipoint capabilities are essential for ATM networks to efficiently support many applications, including IP multicasting and overlay applications. The current signaling and routing specifications for ATM define point-to-multipoint capabilities. Multipoint-to-point connection support is also being discussed by the signaling and PNNI groups, and will be defined in the near future for the unspecified bit rate (UBR) service. We examine point-to-multipoint and multipoint-to-point flow control for the available bit rate (ABR) service, as discussed in the traffic management working group.","5 pages, 2 figures submitted to IEEE Network Magazine, ATM Forum
  Perspectives column","Sonia Fahmy, Raj Jain",computer science,val
Overload Based Explicit Rate Switch Schemes with MCR Guarantees,"An explicit rate switch scheme monitors the load at each link and gives feedback to the sources. We define the overload factor as the ratio of the input rate to the available capacity. In this paper, we present four overload based ABR switch schemes which provide MCR guarantees. The switch schemes proposed use the overload factor and other quantities to calculate feedback rates. A dynamic queue control mechanism is used to achieve efficient usage of the link, control queues and, achieve constant queuing delay at steady state. The proposed algorithms are studied and compared using several configurations. The configurations were chosen to test the performance of the algorithms in presence of link bottlenecks, source bottlenecks and transient sources. A comparison of the proposed algorithms based on the simulation results is presented.",Submitted to the INFOCOM '99,"Bobby Vandalore, Sonia Fahmy, Raj Jain, Rohit Goyal, Mukul Goyal",computer science,train
Design and Analysis of Queue Control Functions for Explicit Rate Switch Schemes,"The main goals of a switch scheme are high utilization, low queuing delay and fairness. To achieve high utilization the switch scheme can maintain non-zero (small) queues in steady state which can be used if the sources do not have data to send. Queue length (delay) can be controlled if part of the link capacity is used for draining queues in the event of queue build up. In most schemes a simple threshold function is used for queue control. Better control of the queue and hence delay can be achieved by using sophisticated queue control functions. It is very important to design and analyze such queue control functions. We study step, linear, hyperbolic and inverse hyperbolic queue control functions. Analytical explanation and simulation results consistent with analysis are presented. From the study, we conclude that inverse hyperbolic is the best control function and to reduce complexity the linear control function can be used since it performs satisfactorily in most cases.","Proceedings of IC3N'98, October 1998","Bobby Vandalore, Raj Jain, Rohit Goyal, Sonia Fahmy",computer science,test
A Definition of General Weighted Fairness and its Support in Explicit Rate Switch Algorithms,"In this paper we give a general definition of weighted fairness and show how this can achieve various fairness definitions, such as those mentioned in the ATM Forum TM 4.0 Specifications. We discuss how a pricing policy can be mapped to general weighted (GW) fairness. The GW fairness can be achieved by calculating the $ExcessFairshare$ (weighted fairshare of the left over bandwidth) for each VC. We show how a switch algorithm can be modified to support the GW fairness by using the $ExcessFairshare$. We use ERICA+ as an example switch algorithm and show how it can be modified to achieve the general fairness. Simulations results are presented to demonstrate that the modified switch algorithm achieves GW fairness. An analytical proof for convergence of the modified ERICA+ algorithm is given in the appendix.","Proceedings of ICNP'98, October1998","Bobby Vandalore, Sonia Fahmy, Raj Jain, Rohit Goyal, Mukul Goyal",computer science,train
Worst Case Buffer Requirements For Tcp Over ABR,"ATM (asynchronous transfer mode) is the technology chosen for the Broadband Integrated Services Digital Network (B-ISDN). The ATM ABR (available bit rate) service can be used to transport ``best-effort'' traffic. In this paper, we extend our earlier work on the buffer requirements problem for TCP over ABR. Here, a worst case scenario is generated such that TCP sources send a burst of data at the time when the sources have large congestion windows and the ACRs (allowed cell rates) for ABR are high. We find that ABR using the ERICA+ switch algorithm can control the maximum queue lengths (hence the buffer requirements) even for the worst case. We present analytical arguments for the expected queue length and simulation results for different number of sources values and parameter values.","SICON'98, June 98","Bobby Vandalore, Shivkumar Kalyanaraman, Raj Jain, Rohit Goyal, Sonia Fahmy",computer science,train
Performance of TCP over ABR with Long-Range Dependent VBR Background Traffic over Terrestrial and Satellite ATM networks,"Compressed video is well known to be self-similar in nature. We model VBR carrying Long-Range Dependent (LRD), multiplexed MPEG-2 video sources. The actual traffic for the model is generated using fast-fourier transform of generate the fractional gaussian noise (FGN) sequence. Our model of compressed video sources bears similarity to an MPEG-2 Transport Stream carrying video, i.e., it is long-range dependent and generates traffic in a piecewise-CBR fashion. We study the effect of such VBR traffic on ABR carrying TCP traffic. The effect of such VBR traffic is that the ABR capacity is highly variant. We find that a switch algorithm like ERICA+ can tolerate this variance in ABR capacity while maintaining high throughput and low delay. We present simulation results for terrestrial and satellite configurations.",Proceedings of LCN `98,"Shivkumar Kalyanaraman, Bobby Vandalore, Raj Jain, Rohit Goyal, Sonia Fahmy, Seong-Cheol Kim, Sastri Kota",computer science,val
Fairness for ABR multipoint-to-point connections,"In multipoint-to-point connections, the traffic at the root (destination) is the combination of all traffic originating at the leaves. A crucial concern in the case of multiple senders is how to define fairness within a multicast group and among groups and point-to-point connections. Fairness definition can be complicated since the multipoint connection can have the same identifier (VPI/VCI) on each link, and senders might not be distinguishable in this case. Many rate allocation algorithms implicitly assume that there is only one sender in each VC, which does not hold for multipoint-to-point cases. We give various possibilities for defining fairness for multipoint connections, and show the tradeoffs involved. In addition, we show that ATM bandwidth allocation algorithms need to be adapted to give fair allocations for multipoint-to-point connections.","Proceedings of SPIE 98, November 1998","Sonia Fahmy, Raj Jain, Rohit Goyal, Bobby Vandalore",computer science,val
Modeling Traffic Management in ATM Networks with OPNET,"Asynchronous transfer mode (ATM) is the new generation of computer and communication networks that are being deployed throughout the telecommunication industry as well as in campus backbones. ATM technology distinguishes itself from the previous networking protocols in that it has the latest traffic management technology and thus allows guaranteeing delay, throughput, and other performance measures. This in turn, allows users to integrate voice, video, and data on the same network. Available bit rate (ABR) service in ATM has been designed to fairly distribute all unused capacity to data traffic and is specified in the ATM Forum's Traffic Management (TM4.0) standard. This paper will describe the OPNET models that have been developed for ATM and ABR design and analysis.","Proc. of OPNETWORK'98, Washington DC., May 1998","Rohit Goyal, Raj Jain, Sonia Fahmy, Shobana Narayanaswamy",computer science,val
laboratories for Data Communications and Computer Networks,"In this paper we describe a hands-on laboratory oriented instructional package that we have developed for data communications and networking. The package consists of a software tool, together with instructional material for a laboratory based networking curriculum. The software is based on a simulation environment that enables the student to experiment with various networking protocols, on an easy to use graphical user interface (GUI). Data message flows, packet losses, control/routing message flows, virtual circuit setups, link failures, bit errors etc., are some of the features that can be visualized in this environment. The student can also modify the networking components provided, as well as add new components using the C programming language. The instructional material consists of a set of laboratory exercises for flow and error control (HDLC), IEEE 802.3 CSMA/CD protocol, the token ring protocol, interconnecting LANs via bridges, TCP congestion avoidance and control, IP fragmentation and reassembly, ATM PNNI routing and ATM policing. The laboratory exercises have facilitated the development of a networking curriculum based on both the traditional computer networking principles, as well as the new technologies in telecommunication networking. The laboratory environment has been used in the networking curriculum at The Ohio State University, and is being piloted at other universities. The entire package is freely available over the Internet.","Proc. of Frontiers in Education (FIE98), Tempe, November 1998","Rohit Goyal, Steve Lai, Raj Jain, Arian Durresi",computer science,train
Numeration systems on a regular language,"Generalizations of linear numeration systems in which the set of natural numbers is recognizable by finite automata are obtained by describing an arbitrary infinite regular language following the lexicographic ordering. For these systems of numeration, we show that ultimately periodic sets are recognizable. We also study the translation and the multiplication by constants as well as the order dependence of the recognizability.",15 pages,"Pierre B. A. Lecomte, Michel Rigo",computer science,val
The Sources of Certainty in Computation and Formal Systems,"In his Discourse on the Method of Rightly Conducting the Reason, and Seeking Truth in the Sciences, Rene Descartes sought ``clear and certain knowledge of all that is useful in life.'' Almost three centuries later, in ``The foundations of mathematics,'' David Hilbert tried to ``recast mathematical definitions and inferences in such a way that they are unshakable.'' Hilbert's program relied explicitly on formal systems (equivalently, computational systems) to provide certainty in mathematics. The concepts of computation and formal system were not defined in his time, but Descartes' method may be understood as seeking certainty in essentially the same way. In this article, I explain formal systems as concrete artifacts, and investigate the way in which they provide a high level of certainty---arguably the highest level achievable by rational discourse. The rich understanding of formal systems achieved by mathematical logic and computer science in this century illuminates the nature of programs, such as Descartes' and Hilbert's, that seek certainty through rigorous analysis.","33 pages, 8 figures, presented at the conference, Computer Science as
  a Human Science, the 1999-2000 Sawyer Seminar at the University of Chicago",Michael J. O'Donnell,computer science,val
Efficient generation of rotating workforce schedules,"Generating high-quality schedules for a rotating workforce is a critical task in all settings where a certain staffing level must be guaranteed beyond the capacity of single employees, such as for instance in industrial plants, hospitals, or airline companies. Results from ergonomics \cite{BEST91} indicate that rotating workforce schedules have a profound impact on the health and social life of employees as well as on their performance at work. Moreover, rotating workforce schedules must satisfy legal requirements and should also meet the objectives of the employing organization. We describe our solution to this problem. A basic design decision was to aim at quickly obtaining high-quality schedules for realistically sized problems while maintaining human control. The interaction between the decision maker and the algorithm therefore consists in four steps: (1) choosing a set of lengths of work blocks (a work block is a sequence of consecutive days of work shifts), (2) choosing a particular sequence of work and days-off blocks among those that have optimal weekend characteristics, (3) enumerating possible shift sequences for the chosen work blocks subject to shift change constraints and bounds on sequences of shifts, and (4) assignment of shift sequences to work blocks while fulfilling the staffing requirements. The combination of constraint satisfaction and problem-oriented intelligent backtracking algorithms in each of the four steps allows to find good solutions for real-world problems in acceptable time. Computational results from real-world problems and from benchmark examples found in the literature confirm the viability of our approach. The algorithms are now part of a commercial shift scheduling software package.","24 pages, uses dbairep.sty","Nysret Musliu, Johannes Gaertner, Wolfgang Slany",computer science,train
On the theory of system administration,"This paper describes necessary elements for constructing theoretical models of network and system administration. Armed with a theoretical model it becomes possible to determine best practices and optimal strategies in a way which objectively relates policies and assumptions to results obtained. It is concluded that a mixture of automation and human, or other intelligent incursion is required to fully implement system policy with current technology. Some aspects of the author's immunity model for automated system administration are explained, as an example. A theoretical framework makes the prediction that the optimal balance between resource availability and garbage collection strategies is encompassed by the immunity model.","About 38 pages american size, 4 figures",Mark Burgess,computer science,val
The Competitiveness of On-Line vis-a-vis Conventional Retailing: A Preliminary Study,"Previous research has directly studied whether on-line retailing is more competitive than conventional retail markets. The evidence from books and music CDs is mixed. Here, I use an indirect approach to compare the competitiveness of on-line with conventional markets. Focusing on the retail market for books, I identify a peculiarity in the pricing of bestsellers relative to other titles. Supposing that competitive barriers are lower in on-line retailing, I analyze how the lower barriers would affect the relative pricing of bestsellers. The empirical data indicates that on-line retailing is more competitive than conventional retailing.",11th NEC Research Symposium,Ivan Png,computer science,train
A Virtual Java Simulation Lab for Computer Science Students,"The VJ-Lab is a project oriented to improve the students learning process of Computer Science degree at the National University of La Plata. The VJ-Lab is a Web application with Java based simulations. Java can be used to provide simulation environments with simple pictorial interfaces that can help students to understand the subject. There are many fields in which it is difficult to give students a feel for the subject that they are learning. Computer based simulations offer a fun and effective way to enable students to learn by doing. Both, practicing skills and applying knowledge are both allowed in simulated worlds. We will focus on the VJ-Lab project overview, the work in progress and some Java based simulations running. They imitate the behavior of data network protocol and data structure algorithms. These applets are produced by the students of the 'Software Development Laboratory' course.","3 pages, WebNet 2000 (World Conference on the WWW and Internet) -
  AACE (Association for the Advancement of Computing Education)","Javier Diaz, Claudia Queiruga, Villar Claudia, Laura Fava",computer science,val
A polynomial axles-detection algorithm for a four-contacts treadle,This submission was removed because it contained proprietary information that was distributed without permission.,Removed by arXiv admin,Giancarlo Crocetti,computer science,train
"How to Commission, Operate and Maintain a Large Future Accelerator Complex from Far Remote","A study on future large accelerators [1] has considered a facility, which is designed, built and operated by a worldwide collaboration of equal partner institutions, and which is remote from most of these institutions. The full range of operation was considered including commi-ssioning, machine development, maintenance, trouble shooting and repair. Experience from existing accele-rators confirms that most of these activities are already performed 'remotely'. The large high-energy physics ex-periments and astronomy projects, already involve inter-national collaborations of distant institutions. Based on this experience, the prospects for a machine operated remotely from far sites are encouraging. Experts from each laboratory would remain at their home institution but continue to participate in the operation of the machine after construction. Experts are required to be on site only during initial commissioning and for par-ticularly difficult problems. Repairs require an on-site non-expert maintenance crew. Most of the interventions can be made without an expert and many of the rest resolved with remote assistance. There appears to be no technical obstacle to controlling an accelerator from a distance. The major challenge is to solve the complex management and communication problems.","ICALEPCS 2001 abstract ID No. FRBI001 invited talk submitting author
  F. Willeke 5 pages, 1 figure","P. Czarapata, D. Hartill, S. Myers, S. Peggs, N. Phinney, M. Serio, N. Toge, F. Willeke, C. Zhang",computer science,train
Overview of the Experimental Physics and Industrial Control System (EPICS) Channel Archiver,"The Channel Archiver has been operational for more than two years at Los Alamos National Laboratory and other sites. This paper introduces the available components (data sampling engine, viewers, scripting interface, HTTP/CGI integration and data management), presents updated performance measurements and reviews operational experience with the Channel Archiver.","3 pages, 1 figure, 8th International Conference on Accelerator and
  Large Experimental Physics Control Systems (PSN THAP019), San Jose, CA, USA,
  November 27-30","K. U. Kasemir, L. R. Dalesio",computer science,test
Integrating LabVIEW into a Distributed Computing Environment,"Being easy to learn and well suited for a self-contained desktop laboratory setup, many casual programmers prefer to use the National Instruments LabVIEW environment to develop their logic. An ActiveX interface is presented that allows integration into a plant-wide distributed environment based on the Experimental Physics and Industrial Control System (EPICS). This paper discusses the design decisions and provides performance information, especially considering requirements for the Spallation Neutron Source (SNS) diagnostics system.","3 pages, 2 figures, 8th International Conference on Accelerator and
  Large Experimental Physics Control Systems (PSN THAP032), San Jose, CA, USA,
  November 27-30","K. U. Kasemir, M. Pieck, L. R. Dalesio",computer science,train
Open Source Real Time Operating Systems Overview,"Modern control systems applications are often built on top of a real time operating system (RTOS) which provides the necessary hardware abstraction as well as scheduling, networking and other services. Several open source RTOS solutions are publicly available, which is very attractive, both from an economic (no licensing fees) as well as from a technical (control over the source code) point of view. This contribution gives an overview of the RTLinux and RTEMS systems (architecture, development environment, API etc.). Both systems feature most popular CPUs, several APIs (including Posix), networking, portability and optional commercial support. Some performance figures are presented, focusing on interrupt latency and context switching delay.","Talk at ICALEPCS 2001 Conference, Nov 2001, San Jose, USA, (WEBT001),
  3 pages, LaTex",Till Straumann,computer science,val
Modeling the input history of programs for improved instruction-memory performance,"When a program is loaded into memory for execution, the relative position of its basic blocks is crucial, since loading basic blocks that are unlikely to be executed first places them high in the instruction-memory hierarchy only to be dislodged as the execution goes on. In this paper we study the use of Bayesian networks as models of the input history of a program. The main point is the creation of a probabilistic model that persists as the program is run on different inputs and at each new input refines its own parameters in order to reflect the program's input history more accurately. As the model is thus tuned, it causes basic blocks to be reordered so that, upon arrival of the next input for execution, loading the basic blocks into memory automatically takes into account the input history of the program. We report on extensive experiments, whose results demonstrate the efficacy of the overall approach in progressively lowering the execution times of a program on identical inputs placed randomly in a sequence of varied inputs. We provide results on selected SPEC CINT2000 programs and also evaluate our approach as compared to the gcc level-3 optimization and to Pettis-Hansen reordering.",,"C. A. G. Assis, E. S. T. Fernandes, V. C. Barbosa",computer science,train
"Markets are Dead, Long Live Markets","Researchers have long proposed using economic approaches to resource allocation in computer systems. However, few of these proposals became operational, let alone commercial. Questions persist about the economic approach regarding its assumptions, value, applicability, and relevance to system design. The goal of this paper is to answer these questions. We find that market-based resource allocation is useful, and more importantly, that mechanism design and system design should be integrated to produce systems that are both economically and computationally efficient.",Fix rotation of figures,Kevin Lai,computer science,train
A Survey of Virtualization Techniques Focusing on Secure On-Demand Cluster Computing,"Virtualization, a technique once used to multiplex the resources of high-priced mainframe hardware, is seeing a resurgence in applicability with the increasing computing power of commodity computers. By inserting a layer of software between the machine and traditional operating systems, this technology allows access to a shared computing medium in a manner that is secure, resource-controlled, and efficient. These properties are attractive in the field of on-demand computing, where the fine-grained subdivision of resources provided by virtualized systems allows potentially higher utilization of computing resources. It this work, we survey a number of virtual machine systems with the goal of finding an appropriate candidate to serve as the basis for the On-Demand Secure Cluster Computing project at the National Center for Supercomputing Applications. Contenders are reviewed on a number of desirable properties including portability and security. We conclude with a comparison and justification of our choice.",,Nadir Kiyanclar,computer science,test
A Low-Footprint Class Loading Mechanism for Embedded Java Virtual Machines,This paper shows that it is possible to dramatically reduce the memory consumption of classes loaded in an embedded Java virtual machine without reducing its functionalities. We describe how to pack the constant pool by deleting entries which are only used during the class loading process. We present some benchmarks which demonstrate the efficiency of this mechanism. We finally suggest some additional optimizations which can be applied if some restrictions to the functionalities of the virtual machine can be tolerated.,,"Christophe Rippert, Alexandre Courbot, Gilles Grimaud",computer science,train
Executing the same binary on several operating systems,We notice a way to execute a binary file on Windows and ELF-based systems. It can be used to create software installers and other applications not exceeding 64 kilo bytes.,The technique is outdated,Steffen Grønneberg,computer science,val
A Survey of Unix Init Schemes,"In most modern operating systems, init (as in ""initialization"") is the program launched by the kernel at boot time. It runs as a daemon and typically has PID 1. Init is responsible for spawning all other processes and scavenging zombies. It is also responsible for reboot and shutdown operations. This document describes existing solutions that implement the init process and/or init scripts in Unix-like systems. These solutions range from the legacy and still-in-use BSD and SystemV schemes, to recent and promising schemes from Ubuntu, Apple, Sun and independent developers. Our goal is to highlight their focus and compare their sets of features.",,"Yvan Royon, Stéphane Frénot",computer science,val
OS Debugging Method Using a Lightweight Virtual Machine Monitor,"Demands for implementing original OSs that can achieve high I/O performance on PC/AT compatible hardware have recently been increasing, but conventional OS debugging environments have not been able to simultaneously assure their stability, be easily customized to new OSs and new I/O devices, and assure efficient execution of I/O operations. We therefore developed a novel OS debugging method using a lightweight virtual machine. We evaluated this debugging method experimentally and confirmed that it can transfer data about 5.4 times as fast as the conventional virtual machine monitor.",Submitted on behalf of EDAA (http://www.edaa.com/),Tadashi Takeuchi,computer science,train
RTK-Spec TRON: A Simulation Model of an ITRON Based RTOS Kernel in SystemC,This paper presents the methodology and the modeling constructs we have developed to capture the real time aspects of RTOS simulation models in a System Level Design Language (SLDL) like SystemC. We describe these constructs and show how they are used to build a simulation model of an RTOS kernel targeting the $\mu$-ITRON OS specification standard.,Submitted on behalf of EDAA (http://www.edaa.com/),"M. Abdelsalam Hassan, Keishi Sakanushi, Yoshinori Takeuchi, Masaharu Imai",computer science,val
Power-Aware Real-Time Scheduling upon Identical Multiprocessor Platforms,"In this paper, we address the power-aware scheduling of sporadic constrained-deadline hard real-time tasks using dynamic voltage scaling upon multiprocessor platforms. We propose two distinct algorithms. Our first algorithm is an off-line speed determination mechanism which provides an identical speed for each processor. That speed guarantees that all deadlines are met if the jobs are scheduled using EDF. The second algorithm is an on-line and adaptive speed adjustment mechanism which reduces the energy consumption while the system is running.","The manuscript corresponds to the final version of SUTC 2008
  conference","Vincent Nélis, Joël Goossens, Nicolas Navet, Raymond Devillers, Dragomir Milojevic",computer science,train
"Faster-than-light effects and negative group delays in optics and electronics, and their applications","Recent manifestations of apparently faster-than-light effects confirmed our predictions that the group velocity in transparent optical media can exceed c. Special relativity is not violated by these phenomena. Moreover, in the electronic domain, the causality principle does not forbid negative group delays of analytic signals in electronic circuits, in which the peak of an output pulse leaves the exit port of a circuit before the peak of the input pulse enters the input port. Furthermore, pulse distortion for these superluminal analytic signals can be negligible in both the optical and electronic domains. Here we suggest an extension of these ideas to the microelectronic domain. The underlying principle is that negative feedback can be used to produce negative group delays. Such negative group delays can be used to cancel out the positive group delays due to transistor latency (e.g., the finite RC rise time of MOSFETS caused by their intrinsic gate capacitance), as well as the propagation delays due to the interconnects between transistors. Using this principle, it is possible to speed up computer systems.","13 pages, 5 figures, 2001 Photonic West Plenary Talk","Raymond Y. Chiao, Jandir M. Hickmann, Daniel Solli",computer science,train
Experiences with advanced CORBA services,"The Common Object Request Broker Architecture (CORBA) is successfully used in many control systems (CS) for data transfer and device modeling. Communication rates below 1 millisecond, high reliability, scalability, language independence and other features make it very attractive. For common types of applications like error logging, alarm messaging or slow monitoring, one can benefit from standard CORBA services that are implemented by third parties and save tremendous amount of developing time. We have started using few CORBA services on our previous CORBA-based control system for the light source ANKA [1] and use now several CORBA services for the ALMA Common Software (ACS) [2], the core of the control system of the Atacama Large Millimeter Array. Our experiences with the interface repository (IFR), the implementation repository, the naming service, the property service, telecom log service and the notify service from different vendors are presented. Performance and scalability benchmarks have been performed.","Poster THAP005, ICALEPS 2001, 3 pages (ZIP and WORD file)","G. Milcinski, M. Plesko, M. Sekoranja",computer science,val
Minimizing Cache Misses in Scientific Computing Using Isoperimetric Bodies,"A number of known techniques for improving cache performance in scientific computations involve the reordering of the iteration space. Some of these reorderings can be considered coverings of the iteration space with sets having small surface-to-volume ratios. Use of such sets may reduce the number of cache misses in computations of local operators having the iteration space as their domain. First, we derive lower bounds on cache misses that any algorithm must suffer while computing a local operator on a grid. Then, we explore coverings of iteration spaces of structured and unstructured discretization grid operators which allow us to approach these lower bounds. For structured grids we introduce a covering by successive minima tiles based on the interference lattice of the grid. We show that the covering has a small surface-to-volume ratio and present a computer experiment showing actual reduction of the cache misses achieved by using these tiles. For planar unstructured grids we show existence of a covering which reduces the number of cache misses to the level of that of structured grids. Next, we introduce a class of multidimensional grids, called starry grids in this paper. These grids represent an abstraction of unstructured grids used in, for example, molecular simulations and the solution of partial differential equations. We show that starry grids can be covered by sets having a low surface-to-volume ratio and, hence have the same cache efficiency as structured grids. Finally, we present a triangulation of a three-dimensional cube that has the property that any local operator on the corresponding grid must incur a significantly larger number of cache misses than a similar operator on a structured grid of the same size.","27 pages, 10 figures","Michael Frumkin, Rob F. Van der Wijngaart",computer science,val
Modelling Delay Jitter in Voice over IP,"It has been suggested in voice over IP that an appropriate choice of the distribution used in modeling the delay jitters, can improve the play-out algorithm. In this paper, we propose a tool using which, one can determine, at a given instance, which distribution model best explains the jitter distribution. This is done using Expectation Maximization, to choose amongst possible distribution models which include, the i.i.d exponential distribution, the gamma distribution etc.",,"R. Ganesh, B. Kaushik, R. Sadhu",computer science,train
A Performance Study of Monitoring and Information Services for Distributed Systems,"Monitoring and information services form a key component of a distributed system, or Grid. A quantitative study of such services can aid in understanding the performance limitations, advise in the deployment of the systems, and help evaluate future development work. To this end, we study the performance of three monitoring and information services for distributed systems: the Globus Toolkit's Monitoring and Discovery Service (MDS), the European Data Grid Relational Grid Monitoring Architecture (R-GMA), and Hawkeye, part of the Condor project. We perform experiments to test their scalability with respect to number of users, number of resources, and amount of data collected. Our study shows that each approach has different behaviors, often due to their different design goals. In the four sets of experiments we conducted to evaluate the performance of the service components under different circumstances, we found a strong advantage to caching or prefetching the data, as well as the need to have primary components at well connected sites due to high load seen by all systems.","12 pages, 20 figures","Xuehai Zhang, Jeffrey Freschl, Jennifer M. Schopf",computer science,val
A Monitoring System for the BaBar INFN Computing Cluster,"Monitoring large clusters is a challenging problem. It is necessary to observe a large quantity of devices with a reasonably short delay between consecutive observations. The set of monitored devices may include PCs, network switches, tape libraries and other equipments. The monitoring activity should not impact the performances of the system. In this paper we present PerfMC, a monitoring system for large clusters. PerfMC is driven by an XML configuration file, and uses the Simple Network Management Protocol (SNMP) for data collection. SNMP is a standard protocol implemented by many networked equipments, so the tool can be used to monitor a wide range of devices. System administrators can display informations on the status of each device by connecting to a WEB server embedded in PerfMC. The WEB server can produce graphs showing the value of different monitored quantities as a function of time; it can also produce arbitrary XML pages by applying XSL Transformations to an internal XML representation of the cluster's status. XSL Transformations may be used to produce HTML pages which can be displayed by ordinary WEB browsers. PerfMC aims at being relatively easy to configure and operate, and highly efficient. It is currently being used to monitor the Italian Reprocessing farm for the BaBar experiment, which is made of about 200 dual-CPU Linux machines.","Talk from the 2003 Computing in High Energy and Nuclear Physics
  (CHEP03), La Jolla, Ca, USA, March 2003, 10 pages, LaTeX, 4 eps figures. PSN
  MOET006","M. Marzolla, V. Melloni",computer science,val
Performance comparison between iSCSI and other hardware and software solutions,"We report on our investigations on some technologies that can be used to build disk servers and networks of disk servers using commodity hardware and software solutions. It focuses on the performance that can be achieved by these systems and gives measured figures for different configurations. It is divided into two parts : iSCSI and other technologies and hardware and software RAID solutions. The first part studies different technologies that can be used by clients to access disk servers using a gigabit ethernet network. It covers block access technologies (iSCSI, hyperSCSI, ENBD). Experimental figures are given for different numbers of clients and servers. The second part compares a system based on 3ware hardware RAID controllers, a system using linux software RAID and IDE cards and a system mixing both hardware RAID and software RAID. Performance measurements for reading and writing are given for different RAID levels.","Paper associated to a poster from the 2003 Computing in High Energy
  and Nuclear Physics (CHEP03), La Jolla, Ca, USA, March 2003, 4 pages, LaTeX.
  PSN TUDP001",Mathias Gug,computer science,val
Elements for Response Time Statistics in ERP Transaction Systems,"We present some measurements and ideas for response time statistics in ERP systems. It is shown that the response time distribution of a given transaction in a given system is generically a log-normal distribution or, in some situations, a sum of two or more log-normal distributions. We present some arguments for this form of the distribution based on heuristic rules for response times, and we show data from performance measurements in actual systems to support the log-normal form. Deviations of the log-normal form can often be traced back to performance problems in the system. Consequences for the interpretation of response time data and for service level agreements are discussed.","revtex, twocolumn, 8 pages, 13 figures. figures replaced by coloured
  versions",Andreas Mielke,computer science,train
Analysis of a Reputation System for Mobile Ad-Hoc Networks with Liars,"The application of decentralized reputation systems is a promising approach to ensure cooperation and fairness, as well as to address random failures and malicious attacks in Mobile Ad-Hoc Networks. However, they are potentially vulnerable to liars. With our work, we provide a first step to analyzing robustness of a reputation system based on a deviation test. Using a mean-field approach to our stochastic process model, we show that liars have no impact unless their number exceeds a certain threshold (phase transition). We give precise formulae for the critical values and thus provide guidelines for an optimal choice of parameters.","17 pages, 6 figures","Jochen Mundinger, Jean-Yves Le Boudec",computer science,train
On Degree-Based Decentralized Search in Complex Networks,"Decentralized search aims to find the target node in a large network by using only local information. The applications of it include peer-to-peer file sharing, web search and anything else that requires locating a specific target in a complex system. In this paper, we examine the degree-based decentralized search method. Specifically, we evaluate the efficiency of the method in different cases with different amounts of available local information. In addition, we propose a simple refinement algorithm for significantly shortening the length of the route that has been found. Some insights useful for the future developments of efficient decentralized search schemes have been achieved.","6 pages, 3 figs, shortly published by ECCS'06","Shi Xiao, Gaoxi Xiao",computer science,val
Mini-indexes for literate programs,"This paper describes how to implement a documentation technique that helps readers to understand large programs or collections of programs, by providing local indexes to all identifiers that are visible on every two-page spread. A detailed example is given for a program that finds all Hamiltonian circuits in an undirected graph.",,Donald E. Knuth,computer science,test
Scoping Constructs in Logic Programming: Implementation Problems and their Solution,"The inclusion of universal quantification and a form of implication in goals in logic programming is considered. These additions provide a logical basis for scoping but they also raise new implementation problems. When universal and existential quantifiers are permitted to appear in mixed order in goals, the devices of logic variables and unification that are employed in solving existential goals must be modified to ensure that constraints arising out of the order of quantification are respected. Suitable modifications that are based on attaching numerical tags to constants and variables and on using these tags in unification are described. The resulting devices are amenable to an efficient implementation and can, in fact, be assimilated easily into the usual machinery of the Warren Abstract Machine (WAM). The provision of implications in goals results in the possibility of program clauses being added to the program for the purpose of solving specific subgoals. A naive scheme based on asserting and retracting program clauses does not suffice for implementing such additions for two reasons. First, it is necessary to also support the resurrection of an earlier existing program in the face of backtracking. Second, the possibility for implication goals to be surrounded by quantifiers requires a consideration of the parameterization of program clauses by bindings for their free variables. Devices for supporting these additional requirements are described as also is the integration of these devices into the WAM. Further extensions to the machine are outlined for handling higher-order additions to the language. The ideas presented here are relevant to the implementation of the higher-order logic programming language lambda Prolog.",46 pages,"Gopalan Nadathur, Bharat Jayaraman, Keehang Kwon",computer science,train
Linguistic Reflection in Java,"Reflective systems allow their own structures to be altered from within. Here we are concerned with a style of reflection, called linguistic reflection, which is the ability of a running program to generate new program fragments and to integrate these into its own execution. In particular we describe how this kind of reflection may be provided in the compiler-based, strongly typed object-oriented programming language Java. The advantages of the programming technique include attaining high levels of genericity and accommodating system evolution. These advantages are illustrated by an example taken from persistent programming which shows how linguistic reflection allows functionality (program code) to be generated on demand (Just-In-Time) from a generic specification and integrated into the evolving running program. The technique is evaluated against alternative implementation approaches with respect to efficiency, safety and ease of use.","25 pages. Source code for examples at
  http://www-ppg.dcs.st-and.ac.uk/Java/ReflectionExample/ Dynamic compilation
  package at http://www-ppg.dcs.st-and.ac.uk/Java/DynamicCompilation/","G. N. C. Kirby, R. Morrison, D. W. Stemple",computer science,val
A Polymorphic Groundness Analysis of Logic Programs,"A polymorphic analysis is an analysis whose input and output contain parameters which serve as placeholders for information that is unknown before analysis but provided after analysis. In this paper, we present a polymorphic groundness analysis that infers parameterised groundness descriptions of the variables of interest at a program point. The polymorphic groundness analysis is designed by replacing two primitive operators used in a monomorphic groundness analysis and is shown to be as precise as the monomorphic groundness analysis for any possible values for mode parameters. Experimental results of a prototype implementation of the polymorphic groundness analysis are given.",30 pages,Lunjin Lu,computer science,train
Universal Object Oriented Languages and Computer Algebra,"The universal object oriented languages made programming more simple and efficient. In the article is considered possibilities of using similar methods in computer algebra. A clear and powerful universal language is useful if particular problem was not implemented in standard software packages like REDUCE, MATHEMATICA, etc. and if the using of internal programming languages of the packages looks not very efficient. Functional languages like LISP had some advantages and traditions for algebraic and symbolic manipulations. Functional and object oriented programming are not incompatible ones. An extension of the model of an object for manipulation with pure functions and algebraic expressions is considered.","5 pages LaTeX, (3 pages extended abstract of talk at International
  Conference: Computer Algebra in Scientific Computing, CASC'98, 20-24 Apr
  1998, St.-Petersburg, Russia; + 2 pages of comments to 3 slides included as 3
  separate ps files)",Alexander Yu. Vlasov,computer science,val
Semantics of Programming Languages: A Tool-Oriented Approach,"By paying more attention to semantics-based tool generation, programming language semantics can significantly increase its impact. Ultimately, this may lead to ``Language Design Assistants'' incorporating substantial amounts of semantic knowledge.","12 pages, 2 figures. Submitted to ACM SIGPLAN Notices","Jan Heering, Paul Klint",computer science,train
Why C++ is not very fit for GUI programming,"With no intent of starting a holy war, this paper lists several annoying C++ birthmarks that the author has come across developing GUI class libraries. C++'s view of classes, instances and hierarchies appears tantalizingly close to GUI concepts of controls, widgets, window classes and subwindows. OO models of C++ and of a window system are however different. C++ was designed to be a ""static"" language with a lexical name scoping, static type checking and hierarchies defined at compile time. Screen objects on the other hand are inherently dynamic; they usually live well beyond the procedure/block that created them; the hierarchy of widgets is defined to a large extent by layout, visibility and event flow. Many GUI fundamentals such as dynamic and geometric hierarchies of windows and controls, broadcasting and percolation of events are not supported directly by C++ syntax or execution semantics (or supported as ""exceptions"" -- pun intended). Therefore these features have to be emulated in C++ GUI code. This leads to duplication of a graphical toolkit or a window manager functionality, code bloat, engaging in unsafe practices and forgoing of many strong C++ features (like scoping rules and compile-time type checking). This paper enumerates a few major C++/GUI sores and illustrates them on simple examples.",Previous version of this paper appeared in Proc. MacHack'95,Oleg Kiselyov,computer science,train
Fractal Symbolic Analysis,"Restructuring compilers use dependence analysis to prove that the meaning of a program is not changed by a transformation. A well-known limitation of dependence analysis is that it examines only the memory locations read and written by a statement, and does not assume any particular interpretation for the operations in that statement. Exploiting the semantics of these operations enables a wider set of transformations to be used, and is critical for optimizing important codes such as LU factorization with pivoting. Symbolic execution of programs enables the exploitation of such semantic properties, but it is intractable for all but the simplest programs. In this paper, we propose a new form of symbolic analysis for use in restructuring compilers. Fractal symbolic analysis compares a program and its transformed version by repeatedly simplifying these programs until symbolic analysis becomes tractable, ensuring that equality of simplified programs is sufficient to guarantee equality of the original programs. We present a prototype implementation of fractal symbolic analysis, and show how it can be used to optimize the cache performance of LU factorization with pivoting.","13 pages, 19 figures","Nikolay Mateev, Vijay Menon, Keshav Pingali",computer science,train
TSIA: A Dataflow Model,"The Task System and Item Architecture (TSIA) is a model for transparent application execution. In many real-world projects, a TSIA provides a simple application with a transparent reliable, distributed, heterogeneous, adaptive, dynamic, real-time, parallel, secure or other execution. TSIA is suitable for many applications, not just for the simple applications served to date. This presentation shows that TSIA is a dataflow model - a long-standing model for transparent parallel execution. The advances to the dataflow model include a simple semantics, as well as support for input/output, for modifiable items and for other such effects.",,Burkhard D. Steinmacher-Burow,computer science,val
On Redundancy Elimination Tolerant Scheduling Rules,"In (Ferrucci, Pacini and Sessa, 1995) an extended form of resolution, called Reduced SLD resolution (RSLD), is introduced. In essence, an RSLD derivation is an SLD derivation such that redundancy elimination from resolvents is performed after each rewriting step. It is intuitive that redundancy elimination may have positive effects on derivation process. However, undesiderable effects are also possible. In particular, as shown in this paper, program termination as well as completeness of loop checking mechanisms via a given selection rule may be lost. The study of such effects has led us to an analysis of selection rule basic concepts, so that we have found convenient to move the attention from rules of atom selection to rules of atom scheduling. A priority mechanism for atom scheduling is built, where a priority is assigned to each atom in a resolvent, and primary importance is given to the event of arrival of new atoms from the body of the applied clause at rewriting time. This new computational model proves able to address the study of redundancy elimination effects, giving at the same time interesting insights into general properties of selection rules. As a matter of fact, a class of scheduling rules, namely the specialisation independent ones, is defined in the paper by using not trivial semantic arguments. As a quite surprising result, specialisation independent scheduling rules turn out to coincide with a class of rules which have an immediate structural characterisation (named stack-queue rules). Then we prove that such scheduling rules are tolerant to redundancy elimination, in the sense that neither program termination nor completeness of equality loop check is lost passing from SLD to RSLD.","53 pages, to appear on TPLP","F. Ferrucci, G. Pacini, M. I. Sessa",computer science,train
Algorithms for Rapidly Dispersing Robot Swarms in Unknown Environments,"We develop and analyze algorithms for dispersing a swarm of primitive robots in an unknown environment, R. The primary objective is to minimize the makespan, that is, the time to fill the entire region. An environment is composed of pixels that form a connected subset of the integer grid. There is at most one robot per pixel and robots move horizontally or vertically at unit speed. Robots enter R by means of k>=1 door pixels Robots are primitive finite automata, only having local communication, local sensors, and a constant-sized memory. We first give algorithms for the single-door case (i.e., k=1), analyzing the algorithms both theoretically and experimentally. We prove that our algorithms have optimal makespan 2A-1, where A is the area of R. We next give an algorithm for the multi-door case (k>1), based on a wall-following version of the leader-follower strategy. We prove that our strategy is O(log(k+1))-competitive, and that this bound is tight for our strategy and other related strategies.","17 pages, 4 figures, Latex, to appear in Workshop on Algorithmic
  Foundations of Robotics, 2002","Tien-Ruey Hsiang, Esther M. Arkin, Michael Bender, Sandor P. Fekete, Joseph S. B. Mitchell",computer science,val
Qualitative Study of a Robot Arm as a Hamiltonian System,"A double pendulum subject to external torques is used as a model to study the stability of a planar manipulator with two links and two rotational driven joints. The hamiltonian equations of motion and the fixed points (stationary solutions) in phase space are determined. Under suitable conditions, the presence of constant torques does not change the number of fixed points, and preserves the topology of orbits in their linear neighborhoods; two equivalent invariant manifolds are observed, each corresponding to a saddle-center fixed point.","15 pages, 5 figures","G. A. Monerat, E. V. Correa Silva, A. G. Cyrino",computer science,train
Replay Debugging of Complex Real-Time Systems: Experiences from Two Industrial Case Studies,"Deterministic replay is a method for allowing complex multitasking real-time systems to be debugged using standard interactive debuggers. Even though several replay techniques have been proposed for parallel, multi-tasking and real-time systems, the solutions have so far lingered on a prototype academic level, with very little results to show from actual state-of-the-practice commercial applications. This paper describes a major deterministic replay debugging case study performed on a full-scale industrial robot control system, as well as a minor replay instrumentation case study performed on a military aircraft radar system. In this article, we will show that replay debugging is feasible in complex multi-million lines of code software projects running on top of off-the-shelf real-time operating systems. Furthermore, we will discuss how replay debugging can be introduced in existing systems without impracticable analysis efforts. In addition, we will present benchmarking results from both studies, indicating that the instrumentation overhead is acceptable and affordable.","In M. Ronsse, K. De Bosschere (eds), proceedings of the Fifth
  International Workshop on Automated Debugging (AADEBUG 2003), September 2003,
  Ghent. cs.SE/0309027","Daniel Sundmark, Henrik Thane, Joel Huselius, Anders Pettersson, Roger Mellander, Ingemar Reiyer, Mattias Kallvi",computer science,train
Dynamic Modelling and Adaptive Traction Control for Mobile Robots,"Mobile robots have received a great deal of research in recent years. A significant amount of research has been published in many aspects related to mobile robots. Most of the research is devoted to design and develop some control techniques for robot motion and path planning. A large number of researchers have used kinematic models to develop motion control strategy for mobile robots. Their argument and assumption that these models are valid if the robot has low speed, low acceleration and light load. However, dynamic modelling of mobile robots is very important as they are designed to travel at higher speed and perform heavy duty work. This paper presents and discusses a new approach to develop a dynamic model and control strategy for wheeled mobile robot which I modelled as a rigid body that roles on two wheels and a castor. The motion control strategy consists of two levels. The first level is dealing with the dynamic of the system and denoted as Low level controller. The second level is developed to take care of path planning and trajectory generation.",,"A. Albagul, Wahyudi",computer science,test
Coevolution Based Adaptive Monte Carlo Localization (CEAMCL),"An adaptive Monte Carlo localization algorithm based on coevolution mechanism of ecological species is proposed. Samples are clustered into species, each of which represents a hypothesis of the robots pose. Since the coevolution between the species ensures that the multiple distinct hypotheses can be tracked stably, the problem of premature convergence when using MCL in highly symmetric environments can be solved. And the sample size can be adjusted adaptively over time according to the uncertainty of the robots pose by using the population growth model. In addition, by using the crossover and mutation operators in evolutionary computation, intra-species evolution can drive the samples move towards the regions where the desired posterior density is large. So a small size of samples can represent the desired density well enough to make precise localization. The new algorithm is termed coevolution based adaptive Monte Carlo localization (CEAMCL). Experiments have been carried out to prove the efficiency of the new localization algorithm.",,"Luo Ronghua, Hong Bingrong",computer science,test
Design and Implementation of a General Decision-making Model in RoboCup Simulation,"The study of the collaboration, coordination and negotiation among different agents in a multi-agent system (MAS) has always been the most challenging yet popular in the research of distributed artificial intelligence. In this paper, we will suggest for RoboCup simulation, a typical MAS, a general decision-making model, rather than define a different algorithm for each tactic (e.g. ball handling, pass, shoot and interception, etc.) in soccer games as most RoboCup simulation teams did. The general decision-making model is based on two critical factors in soccer games: the vertical distance to the goal line and the visual angle for the goalpost. We have used these two parameters to formalize the defensive and offensive decisions in RoboCup simulation and the results mentioned above had been applied in NOVAURO, original name is UJDB, a RoboCup simulation team of Jiangsu University, whose decision-making model, compared with that of Tsinghua University, the world champion team in 2001, is a universal model and easier to be implemented.",,"Changda Wang, Xianyi Chen, Xibin Zhao, Shiguang Ju",computer science,val
Space Robotics Part 2: Space-based Manipulators,"In this second of three short papers, I introduce some of the basic concepts of space robotics with an emphasis on some specific challenging areas of research that are peculiar to the application of robotics to space infrastructure development. The style of these short papers is pedagogical and the concepts in this paper are developed from fundamental manipulator robotics. This second paper considers the application of space manipulators to on-orbit servicing (OOS), an application which has considerable commercial application. I provide some background to the notion of robotic on-orbit servicing and explore how manipulator control algorithms may be modified to accommodate space manipulators which operate in the micro-gravity of space.",,Alex Ellery,computer science,train
Gyroscopically Stabilized Robot: Balance and Tracking,"The single wheel, gyroscopically stabilized robot - Gyrover, is a dynamically stable but statically unstable, underactuated system. In this paper, based on the dynamic model of the robot, we investigate two classes of nonholonomic constraints associated with the system. Then, based on the backstepping technology, we propose a control law for balance control of Gyrover. Next, through transferring the systems states from Cartesian coordinate to polar coordinate, control laws for point-to-point control and line tracking in Cartesian space are provided.",,"Yongsheng Ou, Yangsheng Xu",computer science,train
Dynamic replanning in uncertain environments for a sewer inspection robot,"The sewer inspection robot MAKRO is an autonomous multi-segment robot with worm-like shape driven by wheels. It is currently under development in the project MAKRO-PLUS. The robot has to navigate autonomously within sewer systems. Its first tasks will be to take water probes, analyze it onboard, and measure positions of manholes and pipes to detect polluted-loaded sewage and to improve current maps of sewer systems. One of the challenging problems is the controller software, which should enable the robot to navigate in the sewer system and perform the inspection tasks autonomously, not inflicting any self-damage. This paper focuses on the route planning and replanning aspect of the robot. The robots software has four different levels, of which the planning system is the highest level, and the remaining three are controller levels each with a different degree of abstraction. The planner coordinates the sequence of actions that are to be successively executed by the robot.",,"Oliver Adria, Hermann Streich, Joachim Hertzberg",computer science,test
WebotsTM: Professional Mobile Robot Simulation,"Cyberbotics Ltd. develops WebotsTM, a mobile robotics simulation software that provides you with a rapid prototyping environment for modelling, programming and simulating mobile robots. The provided robot libraries enable you to transfer your control programs to several commercially available real mobile robots. WebotsTM lets you define and modify a complete mobile robotics setup, even several different robots sharing the same environment. For each object, you can define a number of properties, such as shape, color, texture, mass, friction, etc. You can equip each robot with a large number of available sensors and actuators. You can program these robots using your favorite development environment, simulate them and optionally transfer the resulting programs onto your real robots. WebotsTM has been developed in collaboration with the Swiss Federal Institute of Technology in Lausanne, thoroughly tested, well documented and continuously maintained for over 7 years. It is now the main commercial product available from Cyberbotics Ltd.",,Olivier Michel,computer science,train
A correct proof of the heuristic GCD algorithm,"In this note, we fill a gap in the proof of the heuristic GCD in the multivariate case made by Char, Geddes and Gonnet (JSC 1989) and give some additionnal information on this method.",,Bernard Parisse,computer science,val
Orthonormal RBF wavelet and ridgelet-like series and transforms for high-dimensional problems,"This paper developed a systematic strategy establishing RBF on the wavelet analysis, which includes continuous and discrete RBF orthonormal wavelet transforms respectively in terms of singular fundamental solutions and nonsingular general solutions of differential operators. In particular, the harmonic Bessel RBF transforms were presented for high-dimensional data processing. It was also found that the kernel functions of convection-diffusion operator are feasible to construct some stable ridgelet-like RBF transforms. We presented time-space RBF transforms based on non-singular solution and fundamental solution of time-dependent differential operators. The present methodology was further extended to analysis of some known RBFs such as the MQ, Gaussian and pre-wavelet kernel RBFs.",,W. Chen,computer science,train
A Note on the DQ Analysis of Anisotropic Plates,"Recently, Bert, Wang and Striz [1, 2] applied the differential quadrature (DQ) and harmonic differential quadrature (HDQ) methods to analyze static and dynamic behaviors of anisotropic plates. Their studies showed that the methods were conceptually simple and computationally efficient in comparison to other numerical techniques. Based on some recent work by the present author [3, 4], the purpose of this note is to further simplify the formulation effort and improve computing efficiency in applying the DQ and HDQ methods for these cases.",,"W Chen, Weixing He, Tingxiu Zhong",computer science,val
Parameterized Type Definitions in Mathematica: Methods and Advantages,"The theme of symbolic computation in algebraic categories has become of utmost importance in the last decade since it enables the automatic modeling of modern algebra theories. On this theoretical background, the present paper reveals the utility of the parameterized categorical approach by deriving a multivariate polynomial category (over various coefficient domains), which is used by our Mathematica implementation of Buchberger's algorithms for determining the Groebner basis. These implementations are designed according to domain and category parameterization principles underlining their advantages: operation protection, inheritance, generality, easy extendibility. In particular, such an extension of Mathematica, a widely used symbolic computation system, with a new type system has a certain practical importance. The approach we propose for Mathematica is inspired from D. Gruntz and M. Monagan's work in Gauss, for Maple.",14 pages,Alina Andreica,computer science,train
Size reduction and partial decoupling of systems of equations,"A method is presented that reduces the number of terms of systems of linear equations (algebraic, ordinary and partial differential equations). As a byproduct these systems have a tendency to become partially decoupled and are more likely to be factorizable or integrable. A variation of this method is applicable to non-linear systems. Modifications to improve efficiency are given and examples are shown. This procedure can be used in connection with the computation of the radical of a differential ideal (differential Groebner basis).",,Thomas Wolf,computer science,train
TCTL Inevitability Analysis of Dense-time Systems,"Inevitability properties in branching temporal logics are of the syntax forall eventually \phi, where \phi is an arbitrary (timed) CTL formula. In the sense that ""good things will happen"", they are parallel to the ""liveness"" properties in linear temporal logics. Such inevitability properties in dense-time logics can be analyzed with greatest fixpoint calculation. We present algorithms to model-check inevitability properties both with and without requirement of non-Zeno computations. We discuss a technique for early decision on greatest fixpoints in the temporal logics, and experiment with the effect of non-Zeno computations on the evaluation of greatest fixpoints. We also discuss the TCTL subclass with only universal path quantifiers which allows for the safe abstraction analysis of inevitability properties. Finally, we report our implementation and experiments to show the plausibility of our ideas.",22 pages,"Farn Wang, Geng-Dian Hwang, Fang Yu",computer science,train
Quasi-Optimal Arithmetic for Quaternion Polynomials,"Fast algorithms for arithmetic on real or complex polynomials are well-known and have proven to be not only asymptotically efficient but also very practical. Based on Fast Fourier Transform (FFT), they for instance multiply two polynomials of degree up to N or multi-evaluate one at N points simultaneously within quasi-linear time O(N.polylog N). An extension to (and in fact the mere definition of) polynomials over the skew-field H of quaternions is promising but still missing. The present work proposes three such definitions which in the commutative case coincide but for H turn out to differ, each one satisfying some desirable properties while lacking others. For each notion we devise algorithms for according arithmetic; these are quasi-optimal in that their running times match lower complexity bounds up to polylogarithmic factors.",published version (11 pages) plus appendix (2 pages),Martin Ziegler,computer science,train
Digital Version of Green`s Theorem and its Application to The Coverage Problem in Formal Verification,"We present a novel scheme to the coverage problem, introducing a quantitative way to estimate the interaction between a block and its enviroment.This is achieved by setting a discrete version of Green`s theorem, specially adapted for Model Checking based verification of integrated circuits.This method is best suited for the coverage problem since it enables one to quantify the incompleteness or, on the other hand, the redundancy of a set of rules, describing the model under verification.Moreover this can be done continuously throughout the verification process, thus enabling the user to pinpoint the stages at which incompleteness/redundancy occurs. Although the method is presented locally on a small hardware example, we additionally show its possibility to provide precise coverage estimation also for large scale systems. We compare this method to others by checking it on the same test-cases.","13 Pages, 6 figures. Submitted to the IEEE Transactions on
  Computer-Aided Design of Integrated Circuits and Systems","Eli Appleboim, Emil Saucan",computer science,train
Efficient dot product over word-size finite fields,"We want to achieve efficiency for the exact computation of the dot product of two vectors over word-size finite fields. We therefore compare the practical behaviors of a wide range of implementation techniques using different representations. The techniques used include oating point representations, discrete logarithms, tabulations, Montgomery reduction, delayed modulus.",,Jean-Guillaume Dumas,computer science,train
An unexpected application of minimization theory to module decompositions,The aim of this work is to show how we can decompose a module (if decomposable) into an indecomposable module with the help of the minimization process.,15-02-2004,"Gerard Duchamp, Hatem Hadj Kacem, Eric Laugerotte",computer science,test
Fractionally-addressed delay lines,"While traditional implementations of variable-length digital delay lines are based on a circular buffer accessed by two pointers, we propose an implementation where a single fractional pointer is used both for read and write operations. On modern general-purpose architectures, the proposed method is nearly as efficient as the popularinterpolated circular buffer, and it behaves well for delay-length modulations commonly found in digital audio effects. The physical interpretation of the new implementation shows that it is suitable for simulating tension or density modulations in wave-propagating media.","11 pages, 19 figures, to be published in IEEE Transactions on Speech
  and Audio Processing Corrected ACM-class",Davide Rocchesso,computer science,train
The Sound Manifesto,"Computing practice today depends on visual output to drive almost all user interaction. Other senses, such as audition, may be totally neglected, or used tangentially, or used in highly restricted specialized ways. We have excellent audio rendering through D-A conversion, but we lack rich general facilities for modeling and manipulating sound comparable in quality and flexibility to graphics. We need co-ordinated research in several disciplines to improve the use of sound as an interactive information channel. Incremental and separate improvements in synthesis, analysis, speech processing, audiology, acoustics, music, etc. will not alone produce the radical progress that we seek in sonic practice. We also need to create a new central topic of study in digital audio research. The new topic will assimilate the contributions of different disciplines on a common foundation. The key central concept that we lack is sound as a general-purpose information channel. We must investigate the structure of this information channel, which is driven by the co-operative development of auditory perception and physical sound production. Particular audible encodings, such as speech and music, illuminate sonic information by example, but they are no more sufficient for a characterization than typography is sufficient for a characterization of visual information.","To appear in the conference on Critical Technologies for the Future
  of Computing, part of SPIE's International Symposium on Optical Science and
  Technology, 30 July to 4 August 2000, San Diego, CA","Michael J. O'Donnell, Ilia Bisnovatyi",computer science,train
Generalization of a 3-D resonator model for the simulation of spherical enclosures,"A rectangular enclosure has such an even distribution of resonances that it can be accurately and efficiently modelled using a feedback delay network. Conversely, a non rectangular shape such as a sphere has a distribution of resonances that challenges the construction of an efficient model. This work proposes an extension of the already known feedback delay network structure to model the resonant properties of a sphere. A specific frequency distribution of resonances can be approximated, up to a certain frequency, by inserting an allpass filter of moderate order after each delay line of a feedback delay network. The structure used for rectangular boxes is therefore augmented with a set of allpass filters allowing parametric control over the enclosure size and the boundary properties. This work was motivated by informal listening tests which have shown that it is possible to identify a basic shape just from the distribution of its audible resonances.","39 pages, 16 figures, 6 tables. Accepted for publication in Applied
  Signal Processing","Davide Rocchesso, Pierre Dutilleux",computer science,train
Source-Filter Decomposition of Harmonic Sounds,"This paper describes a method for decomposing steady-state instrument data into excitation and formant filter components. The input data, taken from several series of recordings of acoustical instruments is analyzed in the frequency domain, and for each series a model is built, which most accurately represents the data as a source-filter system. The source part is taken to be a harmonic excitation system with frequency-invariant magnitudes, and the filter part is considered to be responsible for all spectral inhomogenieties. This method has been applied to the SHARC database of steady state instrument data to create source-filter models for a large number of acoustical instruments. Subsequent use of such models can have a wide variety of applications, including improvements to wavetable and physical modeling synthesis, high quality pitch shifting, and creation of ""hybrid"" instrument timbres.","Preliminary results reported at DAFx-99, in ""Decomposition of Steady
  State Instrument Data into Excitation System and Formant Filter Components"",
  http://www.tele.ntnu.no/akustikk/meetings/DAFx99/bisnovatyi.pdf 5 pages + 2
  appendices (6 graphs, 1 table)","Ilia Bisnovatyi, Michael J. O'Donnell",computer science,test
Flexible Software Framework for Modal Synthesis,"Modal synthesis is an important area of physical modeling whose exploration in the past has been held back by a large number of control parameters, the scarcity of general-purpose design tools and the difficulty of obtaining the computational power required for real-time synthesis. This paper presents an overview of a flexible software framework facilitating the design and control of instruments based on modal synthesis. The framework is designed as a hierarchy of polymorphic synthesis objects, representing modal structures of various complexity. As a method of generalizing all interactions among the elements of a modal system, an abstract notion of {\it energy} is introduced, and a set of energy transfer functions is provided. Such abstraction leads to a design where the dynamics of interactions can be largely separated from the specifics of particular modal structures, yielding an easily configurable and expandable system. A real-time version of the framework has been implemented as a set of C++ classes along with an integrating shell and a GUI, and is currently being used to design and play modal instruments, as well as to survey fundamental properties of various modal algorithms.","Presented at DAFx00,
  http://profs.sci.univr.it/~dafx/DAFx-final-papers.html",Ilia Bisnovatyi,computer science,train
Pitch Tracking of Acoustic Signals based on Average Squared Mean Difference Function,"In this paper, a method of pitch tracking based on variance minimization of locally periodic subsamples of an acoustic signal is presented. Replicates along the length of the periodically sampled data of the signal vector are taken and locally averaged sample variances are minimized to estimate the fundamental frequency. Using this method, pitch tracking of any text independent voiced signal is possible for different speakers.",,"Roudra Chakraborty, Debapriya Sengupta, Sagnik Sinha",computer science,train
DSP Based System for Real time Voice Synthesis Applications Development,"This paper describes an experimental system designed for development of real time voice synthesis applications. The system is composed from a DSP coprocessor card, equipped with an TMS320C25 or TMS320C50 chip, voice acquisition module (ADDA2),host computer (IBM-PC compatible), software specific tools.","4 pages, 3 figures, SPECOM' 96 Conference","Radu Arsinte, Attila Ferencz, Costin Miron",computer science,train
TR01: Time-continuous Sparse Imputation,"An effective way to increase the noise robustness of automatic speech recognition is to label noisy speech features as either reliable or unreliable (missing) prior to decoding, and to replace the missing ones by clean speech estimates. We present a novel method to obtain such clean speech estimates. Unlike previous imputation frameworks which work on a frame-by-frame basis, our method focuses on exploiting information from a large time-context. Using a sliding window approach, denoised speech representations are constructed using a sparse representation of the reliable features in an overcomplete basis of fixed-length exemplar fragments. We demonstrate the potential of our approach with experiments on the AURORA-2 connected digit database.","9 pages, 5 figures, Technical Report","J. F. Gemmeke, B. Cranen",computer science,val
iKlax: a New Musical Audio Format for Active Listening,"In this paper, we are presenting a new model for interactive music. Unlike most interactive systems, our model is based on file organization, but does not require digital audio treatments. This model includes a definition of a constraints system and its solver. The products of this project are intended for the general public, inexperienced users, as well as professional musicians, and will be distributed commercially. We are here presenting three products of this project. The difficulty of this project is to design a technology and software products for interactive music which must be easy to use by the general public and by professional composers.",,"Fabien Gallot, Owen Lagadec, Myriam Desainte-Catherine, Sylvain Marchand",computer science,train
New Ica-Beamforming Method to Under-Determined BSS,This paper has been withdrawn by the author ali pourmohammad.,This paper has been withdrawn,"Ali Pourmohammad, Seyed Mohammad Ahadi",computer science,train
Broy-Lamport Specification Problem: A Gurevich Abstract State Machine Solution,We apply the Gurevich Abstract State Machine methodology to a benchmark specification problem of Broy and Lamport.,,James K. Huggins,computer science,train
Equivalence is in the Eye of the Beholder,"In a recent provocative paper, Lamport points out ""the insubstantiality of processes"" by proving the equivalence of two different decompositions of the same intuitive algorithm by means of temporal formulas. We point out that the correct equivalence of algorithms is itself in the eye of the beholder. We discuss a number of related issues and, in particular, whether algorithms can be proved equivalent directly.",See also the ASM web site at http://www.eecs.umich.edu/gasm/,"Yuri Gurevich, James K. Huggins",computer science,train
Evolving Algebras and Partial Evaluation,We describe an automated partial evaluator for evolving algebras implemented at the University of Michigan.,See also the web site at http://www.eecs.umich.edu/gasm/,"Yuri Gurevich, James K. Huggins",computer science,test
An Offline Partial Evaluator for Evolving Algebras,"We describe the architecture of an evolving algebra partial evaluator, a program which specializes an evolving algebra with respect to a portion of its input. We discuss the particular analysis, specialization, and optimization techniques used and show an example of its use.",See also the web site at http://www.eecs.umich.edu/gasm/,James K. Huggins,computer science,train
The Railroad Crossing Problem: An Experiment with Instantaneous Actions and Immediate Reactions,We give an evolving algebra solution for the well-known railroad crossing problem and use the occasion to experiment with agents that perform instantaneous actions in continuous time and in particular with agents that fire at the moment they are enabled.,See also the web site at http://www.eecs.umich.edu/gasm/,"Yuri Gurevich, James K. Huggins",computer science,train
Second Product Line Practice Workshop Report,"The second Software Engineering Institute Product Line Practice Workshop was a hands-on meeting held in November 1997 to share industry practices in software product lines and to explore the technical and non-technical issues involved. This report synthesizes the workshop presentations and discussions, which identified factors involved in product line practices and analyzed issues in the areas of software engineering, technical management, and enterprise management.",,"L. Bass, G. Chastek, P. Clements, L. Northrop, D. Smith, J. Withey",computer science,val
Case Study in Survivable Network System Analysis,This paper presents a method for analyzing the survivability of distributed network systems and an example of its application.,,"Robert Ellison, Rick Linger, Thomas Longstaff, Nancy Mead",computer science,val
Abstract State Machines 1988-1998: Commented ASM Bibliography,"An annotated bibliography of papers which deal with or use Abstract State Machines (ASMs), as of January 1998.",Also maintained as a BibTeX file at http://www.eecs.umich.edu/gasm/,"Egon Boerger, James K. Huggins",computer science,train
Managing Object-Oriented Integration and Regression Testing,"Systematic testing of object-oriented software turned out to be much more complex than testing conventional software. Especially the highly incremental and iterative development cycle demands both many more changes and partially implemented resp. re-implemented classes. Much more integration and regression testing has to be done to reach stable stages during the development. In this presentation we propose a diagram capturing all possible dependencies and interactions in an object-oriented program. Then we give algorithms and coverage criteria to identify integration resp. regression test strategys and all test cases to be executed after some implementation resp. modification activities. Finally, we summarize some practical experiences and heuristics.","Proc. 6th euroSTAR, Munich, 30 November-4 December 1998",Mario Winter,computer science,train
LuaJava - A Scripting Tool for Java,"Scripting languages are becoming more and more important as a tool for software development, as they provide great flexibility for rapid prototyping and for configuring componentware applications. In this paper we present LuaJava, a scripting tool for Java. LuaJava adopts Lua, a dynamically typed interpreted language, as its script language. Great emphasis is given to the transparency of the integration between the two languages, so that objects from one language can be used inside the other like native objects. The final result of this integration is a tool that allows the construction of configurable Java applications, using off-the-shelf components, in a high abstraction level.","10 pages, LaTeX, 1 figure. Available at
  http://www.tecgraf.puc-rio.br/~cassino/luajava","Carlos Cassino, Roberto Ierusalimschy, Noemi Rodriguez",computer science,val
Analyzing the Social Structure and Dynamics of E-mail and Spam in Massive Backbone Internet Traffic,"E-mail is probably the most popular application on the Internet, with everyday business and personal communications dependent on it. Spam or unsolicited e-mail has been estimated to cost businesses significant amounts of money. However, our understanding of the network-level behavior of legitimate e-mail traffic and how it differs from spam traffic is limited. In this study, we have passively captured SMTP packets from a 10 Gbit/s Internet backbone link to construct a social network of e-mail users based on their exchanged e-mails. The focus of this paper is on the graph metrics indicating various structural properties of e-mail networks and how they evolve over time. This study also looks into the differences in the structural and temporal characteristics of spam and non-spam networks. Our analysis on the collected data allows us to show several differences between the behavior of spam and legitimate e-mail traffic, which can help us to understand the behavior of spammers and give us the knowledge to statistically model spam traffic on the network-level in order to complement current spam detection techniques.","15 pages, 20 figures, technical report","Farnaz Moradi, Tomas Olovsson, Philippas Tsigas",computer science,train
An Applied Study on Educational Use of Facebook as a Web 2.0 Tool: The Sample Lesson of Computer Networks and Communication,"The main aim of the research was to examine educational use of Facebook. The Computer Networks and Communication lesson was taken as the sample and the attitudes of the students included in the study group towards Facebook were measured in a semi-experimental setup. The students on Facebook platform were examined for about three months and they continued their education interactively in that virtual environment. After the-three-month-education period, observations for the students were reported and the attitudes of the students towards Facebook were measured by three different measurement tools. As a result, the attitudes of the students towards educational use of Facebook and their views were heterogeneous. When the average values of the group were examined, it was reported that the attitudes towards educational use of Facebook was above a moderate level. Therefore, it might be suggested that social networks in virtual environments provide continuity in life long learning.",11 pages,"Murat Kayri, Ozlem Cakir",computer science,val
A Distributed Method for Trust-Aware Recommendation in Social Networks,"This paper contains the details of a distributed trust-aware recommendation system. Trust-base recommenders have received a lot of attention recently. The main aim of trust-based recommendation is to deal the problems in traditional Collaborative Filtering recommenders. These problems include cold start users, vulnerability to attacks, etc.. Our proposed method is a distributed approach and can be easily deployed on social networks or real life networks such as sensor networks or peer to peer networks.",,Mohsen Jamali,computer science,train
Characterizing the speed and paths of shared bicycles in Lyon,"Thanks to numerical data gathered by Lyon's shared bicycling system V\'elo'v, we are able to analyze 11.6 millions bicycle trips, leading to the first robust characterization of urban bikers' behaviors. We show that bicycles outstrip cars in downtown Lyon, by combining high speed and short paths.These data also allows us to calculate V\'elo'v fluxes on all streets, pointing to interesting locations for bike paths.",,"Pablo Jensen, Jean-Baptiste Rouquier, Nicolas Ovtracht, Céline Robardet",computer science,train
Prognostic Watch of the Electric Power System,"A prognostic watch of the electric power system (EPS)is framed up, which detects the threat to EPS for a day ahead according to the characteristic times for a day ahead and according to the droop for a day ahead. Therefore, a prognostic analysis of the EPS development for a day ahead is carried out. Also the power grid, the electricity marker state, the grid state and the level of threat for a power grid are found for a day ahead. The accuracy of the built up prognostic watch is evaluated.",11 pages,Stefan Z. Stefanov,computer science,train
Toward Emerging Topic Detection for Business Intelligence: Predictive Analysis of `Meme' Dynamics,"Detecting and characterizing emerging topics of discussion and consumer trends through analysis of Internet data is of great interest to businesses. This paper considers the problem of monitoring the Web to spot emerging memes - distinctive phrases which act as ""tracers"" for topics - as a means of early detection of new topics and trends. We present a novel methodology for predicting which memes will propagate widely, appearing in hundreds or thousands of blog posts, and which will not, thereby enabling discovery of significant topics. We begin by identifying measurables which should be predictive of meme success. Interestingly, these metrics are not those traditionally used for such prediction but instead are subtle measures of meme dynamics. These metrics form the basis for learning a classifier which predicts, for a given meme, whether or not it will propagate widely. The utility of the prediction methodology is demonstrated through analysis of memes that emerged online during the second half of 2008.","AAAI 2011 Spring Symposium, Stanford University, CA. 21-23 March 2011","Kristin Glass, Richard Colbaugh",computer science,train
On Sharing Viral Video over an Ad Hoc Wireless Network,"We consider the problem of broadcasting a viral video (a large file) over an ad hoc wireless network (e.g., students in a campus). Many smartphones are GPS enabled, and equipped with peer-to-peer (ad hoc) transmission mode, allowing them to wirelessly exchange files over short distances rather than use the carrier's WAN. The demand for the file however is transmitted through the social network (e.g., a YouTube link posted on Facebook). To address this coupled-network problem (demand on the social network; bandwidth on the wireless network) where the two networks have different topologies, we propose a file dissemination algorithm. In our scheme, users query their social network to find geographically nearby friends that have the desired file, and utilize the underlying ad hoc network to route the data via multi-hop transmissions. We show that for many popular models for social networks, the file dissemination time scales sublinearly with n; the number of users, compared to the linear scaling required if each user who wants the file must download it from the carrier's WAN.",,"Yi-Ting Chen, Constantine Caramanis, Sanjay Shakkottai",computer science,train
On Social-Temporal Group Query with Acquaintance Constraint,"Three essential criteria are important for activity planning, including: (1) finding a group of attendees familiar with the initiator, (2) ensuring each attendee in the group to have tight social relations with most of the members in the group, and (3) selecting an activity period available for all attendees. Therefore, this paper proposes Social-Temporal Group Query to find the activity time and attendees with the minimum total social distance to the initiator. Moreover, this query incorporates an acquaintance constraint to avoid finding a group with mutually unfamiliar attendees. Efficient processing of the social-temporal group query is very challenging. We show that the problem is NP-hard via a proof and formulate the problem with Integer Programming. We then propose two efficient algorithms, SGSelect and STGSelect, which include effective pruning techniques and employ the idea of pivot time slots to substantially reduce the running time, for finding the optimal solutions. Experimental results indicate that the proposed algorithms are much more efficient and scalable. In the comparison of solution quality, we show that STGSelect outperforms the algorithm that represents manual coordination by the initiator.",VLDB2011,"De-Nian Yang, Yi-Ling Chen, Wang-Chien Lee, Ming-Syan Chen",computer science,train
Business Mode Selection in Digital Content Markets,"In this paper, we consider a two-sided digital content market, and study which of the two business modes, i.e., Business-to-Customer (B2C) and Customer-to-Customer (C2C), should be selected and when it should be selected. The considered market is managed by an intermediary, through which content producers can sell their contents to consumers. The intermediary can select B2C or C2C as its business mode, while the content producers and consumers are rational agents that maximize their own utilities. The content producers are differentiated by their content qualities. First, given the intermediary's business mode, we show that there always exists a unique equilibrium at which neither the content producers nor the consumers change their decisions. Moreover, if there are a sufficiently large number of consumers, then the decision process based on the content producers' naive expectation can reach the unique equilibrium. Next, we show that in a market with only one intermediary, C2C should be selected if the intermediary aims at maximizing its profit. Then, by considering a particular scenario where the contents are not highly substitutable, we prove that when the intermediary chooses to maximize the social welfare, C2C should be selected if the content producers can receive sufficient compensation for content sales, and B2C should be selected otherwise.",This paper has been withdrawn,"Shaolei Ren, Jaeok Park, Mihaela van der Schaar",computer science,val
A Month in the Life of Groupon,"Groupon has become the latest Internet sensation, providing daily deals to customers in the form of discount offers for restaurants, ticketed events, appliances, services, and other items. We undertake a study of the economics of daily deals on the web, based on a dataset we compiled by monitoring Groupon over several weeks. We use our dataset to characterize Groupon deal purchases, and to glean insights about Groupon's operational strategy. Our focus is on purchase incentives. For the primary purchase incentive, price, our regression model indicates that demand for coupons is relatively inelastic, allowing room for price-based revenue optimization. More interestingly, mining our dataset, we find evidence that Groupon customers are sensitive to other, ""soft"", incentives, e.g., deal scheduling and duration, deal featuring, and limited inventory. Our analysis points to the importance of considering incentives other than price in optimizing deal sites and similar systems.",6 pages,"John W. Byers, Michael Mitzenmacher, Michalis Potamias, Georgios Zervas",computer science,train
Proofs for an Abstraction of Continuous Dynamical Systems Utilizing Lyapunov Functions,"In this report proofs are presented for a method for abstracting continuous dynamical systems by timed automata. The method is based on partitioning the state space of dynamical systems with invariant sets, which form cells representing locations of the timed automata. To enable verification of the dynamical system based on the abstraction, conditions for obtaining sound, complete, and refinable abstractions are set up. It is proposed to partition the state space utilizing sub-level sets of Lyapunov functions, since they are positive invariant sets. The existence of sound abstractions for Morse-Smale systems and complete and refinable abstractions for linear systems are proved.",,"Christoffer Sloth, Rafael Wisniewski",computer science,train
A control-theoretical methodology for the scheduling problem,"This paper presents a novel methodology to develop scheduling algorithms. The scheduling problem is phrased as a control problem, and control-theoretical techniques are used to design a scheduling algorithm that meets specific requirements. Unlike most approaches to feedback scheduling, where a controller integrates a ""basic"" scheduling algorithm and dynamically tunes its parameters and hence its performances, our methodology essentially reduces the design of a scheduling algorithm to the synthesis of a controller that closes the feedback loop. This approach allows the re-use of control-theoretical techniques to design efficient scheduling algorithms; it frames and solves the scheduling problem in a general setting; and it can naturally tackle certain peculiar requirements such as robustness and dynamic performance tuning. A few experiments demonstrate the feasibility of the approach on a real-time benchmark.",,"Carlo A. Furia, Alberto Leva, Martina Maggio, Paola Spoletini",computer science,train
A General Proof of Convergence for Adaptive Distributed Beamforming Schemes,"This work focuses on the convergence analysis of adaptive distributed beamforming schemes that can be reformulated as local random search algorithms via a random search framework. Once reformulated as local random search algorithms, it is proved that under two sufficient conditions: a) the objective function of the algorithm is continuous and all its local maxima are global maxima, and b) the origin is an interior point within the range of the considered transformation of the random perturbation, the corresponding adaptive distributed beamforming schemes converge both in probability and in mean. This proof of convergence is general since it can be applied to analyze randomized adaptive distributed beamforming schemes with any type of objective functions and probability measures as long as both the sufficient conditions are satisfied. Further, this framework can be generalized to analyze an asynchronous scheme where distributed transmitters can only update their beamforming coefficients asynchronously. Simulation results are also provided to validate our analyses.",,"Chang-Ching Chen, Chia-Shiang Tseng, Che Lin",computer science,train
Fuzzy Controller for Matrix Converter System to Improve its Quality of Output,"In this paper, Fuzzy Logic controller is developed for ac/ac Matrix Converter. Furthermore, Total Harmonic Distortion is reduced significantly. Space Vector Algorithm is a method to improve power quality of the converter output. But its quality is limited to 86.7%.We are introduced a Cross coupled DQ axis controller to improve power quality. The Matrix Converter is an attractive topology for High voltage transformation ratio. A Matlab / Simulink simulation analysis of the Matrix Converter system is provided. The design and implementation of fuzzy controlled Matrix Converter is described. This AC-AC system is proposed as an effective replacement for the conventional AC-DC-AC system which employs a two-step power conversion.",11 pages,"Nagalingam Mahendran, G. Gurusamy",computer science,train
Regulating Response Time in an Autonomic Computing System: A Comparision of Proportional Control and Fuzzy Control Approaches,"Ecommerce is an area where an Autonomic Computing system could be very effectively deployed. Ecommerce has created demand for high quality information technology services and businesses are seeking quality of service guarantees from their service providers. These guarantees are expressed as part of service level agreements. Properly adjusting tuning parameters for enforcement of the service level agreement is time-consuming and skills-intensive. Moreover, in case of changes to the workload, the setting of the parameters may no longer be optimum. In an ecommerce system, where the workload changes frequently, there is a need to update the parameters at regular intervals. This paper describes two approaches, one, using a proportional controller and two, using a fuzzy controller, to automate the tuning of MaxClients parameter of Apache web server based on the required response time and the current workload. This is an illustration of the self-optimizing characteristic of an autonomic computing system.","9 pages, 7 figures, 1 table","Harish Sheeranalli Venkatarama, Kandasamy Chandra Sekaran",computer science,train
Directed factor graph based fault diagnosis model construction for mode switching satellite power system,"Satellite power system is a complex, highly interconnected hybrid system that exhibit nonlinear and mode switching behaviors. Directed factor graph is an inference model for fault diagnosis using probabilistic reasoning techniques. A novel approach for constructing the directed factor graph structure based on hybrid bond graph model is proposed. The system components status and their fault symptoms are treated as hypothesis and evidences respectively. The cause-effect relations between hypothesis and evidences are identified and concluded though qualitative equations and causal path analysis on hybrid bond graph model. A power supply module of a satellite power system is provided as case study to show the feasibility and validity of the proposed method.",,"Xiaolei Zhang, Yi Shen, Zhenhua Wang",computer science,val
Timed Game Abstraction of Control Systems,"This paper proposes a method for abstracting control systems by timed game automata, and is aimed at obtaining automatic controller synthesis. The proposed abstraction is based on partitioning the state space of a control system using positive and negative invariant sets, generated by Lyapunov functions. This partitioning ensures that the vector field of the control system is transversal to the facets of the cells, which induces some desirable properties of the abstraction. To allow a rich class of control systems to be abstracted, the update maps of the timed game automaton are extended. Conditions on the partitioning of the state space and the control are set up to obtain sound abstractions. Finally, an example is provided to demonstrate the method applied to a control problem related to navigation.",,"Christoffer Sloth, Rafael Wisniewski",computer science,train
Computation for Supremal Simulation-Based Controllable and Strong Observable Subautomata,"Bisimulation relation has been successfully applied to computer science and control theory. In our previous work, simulation-based controllability and simulation-based observability are proposed, under which the existence of bisimilarity supervisor is guaranteed. However, a given specification automaton may not satisfy these conditions, and a natural question is how to compute a maximum permissive subspecification. This paper aims to answer this question and investigate the computation of the supremal simulation-based controllable and strong observable subautomata with respect to given specifications by the lattice theory. In order to achieve the supremal solution, three monotone operators, namely simulation operator, controllable operator and strong observable operator, are proposed upon the established complete lattice. Then, inequalities based on these operators are formulated, whose solution is the simulation-based controllable and strong observable set. In particular, a sufficient condition is presented to guarantee the existence of the supremal simulation-based controllable and strong observable subautomata. Furthermore, an algorithm is proposed to compute such subautomata.","22 pages, 1 figure","Yajuan Sun, Hai Lin, Fuchun Liu",computer science,val
Control of Multi-Agent Formations with Only Shape Constraints,"This paper considers a novel problem of how to choose an appropriate geometry for a group of agents with only shape constraints but with a flexible scale. Instead of assigning the formation system with a specific geometry, here the only requirement on the desired geometry is a shape without any location, rotation and, most importantly, scale constraints. Optimal rigid transformation between two different geometries is discussed with especial focus on the scaling operation, and the cooperative performance of the system is evaluated by what we call the geometries degrees of similarity (DOS) with respect to the desired shape during the entire convergence process. The design of the scale when measuring the DOS is discussed from constant value and time-varying function perspectives respectively. Fixed structured nonlinear control laws that are functions on the scale are developed to guarantee the exponential convergence of the system to the assigned shape. Our research is originated from a three-agent formation system and is further extended to multiple (n > 3) agents by defining a triangular complement graph. Simulations demonstrate that formation system with the time-varying scale function outperforms the one with an arbitrary constant scale, and the relationship between underlying topology and the system performance is further discussed based on the simulation observations. Moveover, the control scheme is applied to bearing-only sensor-target localization to show its application potentials.",Submitted,"Huang Huang, Changbin Yu, Qinghe Wu",computer science,train
On the Statistics and Predictability of Go-Arounds,"This paper takes an empirical approach to identify operational factors at busy airports that may predate go-around maneuvers. Using four years of data from San Francisco International Airport, we begin our investigation with a statistical approach to investigate which features of airborne, ground operations (e.g., number of inbound aircraft, number of aircraft taxiing from gate, etc.) or weather are most likely to fluctuate, relative to nominal operations, in the minutes immediately preceding a missed approach. We analyze these findings both in terms of their implication on current airport operations and discuss how the antecedent factors may affect NextGen. Finally, as a means to assist air traffic controllers, we draw upon techniques from the machine learning community to develop a preliminary alert system for go-around prediction.","10 pages, 14 figures, Submitted to USA/Europe ATM Seminar 2011","Maxime Gariel, Kevin Spieser, Emilio Frazzoli",computer science,train
Prediction of Peptide Conformation by the Multicanonical Algorithm,We test the effectiveness of the multicanonical algorithm for the tertiary structure prediction of peptides and proteins. As a simple example we study Met-enkephalin. The lowest-energy conformation obtained agrees with that determined by other methods such as Monte Carlo simulated annealing. But unlike to simulated annealing the relationship to the canonical ensemble remains exactly controlled. Thermodynamic quantities at various temperature can be calculated from one run.,"5 pages, Latex file with attached postscript files, FSU-SCRI-93C-34","Ulrich H. E. Hansmann, Yuko Okamoto",physics,train
Solitons and 1/f Noise in Molecular Chains,"Davydov's model of solitons in alpha-helix protein chains is shown to display features of self-organized criticality (SOC), i.e., power law behaviour of correlations in space and 1/f-noise, as a consequence of considering random peptide group displacements from their (periodic) equilibrium positions along a chain. This may shed light on a basic mechanism leading to obtain flicker noise in alpha-helix protein chains and to predict a SOC regime in biomolecular structures from first principles. We believe our treatment of 1/f noise to be of some relevance to recent findings due to Voss on DNA [Phys. Rev. Lett. 68, 3805 (1992)].",IC/93/22,"H. Rosu, E. Canessa",physics,train
Statistical Mechanics and Visual Signal Processing,"The nervous system solves a wide variety of problems in signal processing. In many cases the performance of the nervous system is so good that it apporaches fundamental physical limits, such as the limits imposed by diffraction and photon shot noise in vision. In this paper we show how to use the language of statistical field theory to address and solve problems in signal processing, that is problems in which one must estimate some aspect of the environment from the data in an array of sensors. In the field theory formulation the optimal estimator can be written as an expectation value in an ensemble where the input data act as external field. Problems at low signal-to-noise ratio can be solved in perturbation theory, while high signal-to-noise ratios are treated with a saddle-point approximation. These ideas are illustrated in detail by an example of visual motion estimation which is chosen to model a problem solved by the fly's brain. In this problem the optimal estimator has a rich structure, adapting to various parameters of the environment such as the mean-square contrast and the correlation time of contrast fluctuations. This structure is in qualitative accord with existing measurements on motion sensitive neurons in the fly's brain, and we argue that the adaptive properties of the optimal estimator may help resolve conlficts among different interpretations of these data. Finally we propose some crucial direct tests of the adaptive behavior.","34pp, LaTeX, PUPT-1435","Marc Potters, William Bialek",physics,train
Response Functions Improving Performance in Analog Attractor Neural Networks,"In the context of attractor neural networks, we study how the equilibrium analog neural activities, reached by the network dynamics during memory retrieval, may improve storage performance by reducing the interferences between the recalled pattern and the other stored ones. We determine a simple dynamics that stabilizes network states which are highly correlated with the retrieved pattern, for a number of stored memories that does not exceed $\alpha_{\star} N$, where $\alpha_{\star}\in[0,0.41]$ depends on the global activity level in the network and $N$ is the number of neurons.","13 pages (with figures), LaTex (RevTex), to appear on Phys.Rev.E (RC)","Nicolas Brunel, Riccardo Zecchina",physics,train
Nonlinear Localized Excitations and the Dynamics of H-Bonds in DNA,"We analyze typical models which intend to describe (parts of) the dynamics of H-Bonds in DNA. We show that these models generically allow for nonlinear localized excitatons (NLEs) (discrete breathers). We especially study the scattering of phonons by NLEs and observe strong reflection of phonons by the NLE. We relate our results to the problem of functioning of a complex biomolecule, e.g. the DNA.","Talk presented at workshop NONLINEAR EXCITATIONS IN BIOMOLECULES Les
  Houches 1994, to appear in Springer/Editions de Physique; 11 pages, uuencoded
  compressed ps-file (first uudecode, then uncompress the file lh.ps.Z) size
  170KByte","S. Flach, C. R. Willis",physics,train
Protein-Machine model of a single enzymatic reaction,"The theory of biochemical processes needs simple but realistic models of phenomena underlying microscopic dynamics of proteins. Many experiments performed in the 1980s have demonstrated that within the protein native state, apart from usual vibrational dynamics, a rich interconformational (activated) dynamics exists. The slowness of this dynamics makes any conventional theory of chemical reactions inapplicable for description of enzymatic reactions. It is presumably a rule that it is the process of conformational relaxation, and not the details of chemical mechanism, that affects their rate. In a simple model of Protein-Machine type, applied in constructing a novel theory of enzymatic reaction, conformational dynamics is treated as a realative quasi-continuous motion of solid-like structural elements of protein. Simple and tractable formulas for the chemical relaxation time and the enzyme turnover number in the steady state conditions are found. The important result obtained is that the kinetic mechanisms close to and far from the equilibrium can differ.","10 pages, Latex (4 figures available on request by post)",Michal Kurzynski,physics,train
Criticality in Simple Models of Evolution,"We consider two, apparently similar, models of biological evolution which have been claimed to exhibit self-organized critical behaviour. A careful reanalysis of these models, including several new analytic results for one of them, suggests that they are qualitatively different. We demonstrate the limitations of the mean field description of these systems. We argue that a more precise definition of self-organized criticality is desirable and establish several criteria in this connection.","RevTeX, 21 pages + 4 postscript figures (appended as .tar.gz.uu file)
  preprint numbers SUNY-NTG-94-45, ITP-SB-94-32","Jan de Boer, A. D. Jackson, Tilo Wettig",physics,val
Self-organized Critical Model Of Biological Evolution,"A punctuated equilibrium model of biological evolution with relative fitness between different species being the fundamental driving force of evolution is introduced. Mutation is modeled as a fitness updating cellular automaton process where the change in fitness after mutation follows a Gaussian distribution with mean $x>0$ and standard deviation $\sigma$. Scaling behaviors are observed in our numerical simulation, indicating that the model is self-organized critical. Besides, the numerical experiment suggests that models with different $x$ and $\sigma$ belong to the same universality class. PACS numbers: 87.10.+e, 05.40.+j","8 pages in REVTEX 3.0 with 4 figures (Figures available on request by
  sending e-mail to chau@guinness.ias.edu)","H. F. Chau, L. Mak, P. K. Kwok",physics,train
A Bit-String Model for Biological Aging,We present a simple model for biological aging. We studied it through computer simulations and we have found this model to reflect some features of real populations.,"LaTeX file, 4 PS figures included",Thadeu J. P. Penna,physics,train
Efficient Monte Carlo Simulation of Biological Aging,"A bit-string model of biological life-histories is parallelized, with hundreds of millions of individuals. It gives the desired drastic decay of survival probabilities with increasing age for 32 age intervals.",PostScript file to appear in Int.J.Mod.Phys.C,"T. J. P. Penna, D. Stauffer",physics,test
The Inter-Strand Modes of the DNA as a Probe into MW-Radiation,"We consider the regime in which the bands of the torsional acoustic (TA) and the hydrogen-bond-stretch (HBS) modes of the DNA interpenetrate each other. Within the framework of a model that accommodates the structure of the double helix, we find the three-wave interaction between the TA- and the HBS-modes, and show that microwave radiation could bring about torsional vibrations that could serve as a pump mode for maintaining the HBS-one. Rayleigh's threshold condition for the parametric resonance provides an estimate for the power density of the mw-field necessary for generating the HBS-mode.",13 pages,Voislav Golo,quantitative biology,val
Differential hydrophobicity drives self-assembly in Huntington's disease,"Identifying the driving forces and the mechanism of association of huntingtin-exon1, a close marker for the progress of Huntington's disease, is an important prerequisite towards finding potential drug targets, and ultimately a cure. We introduce here a modelling framework based on a key analogy of the physico-chemical properties of the exon1 fragment to block copolymers. We use a systematic mesoscale methodology, based on Dissipative Particle Dynamics, which is capable of overcoming kinetic barriers, thus capturing the dynamics of significantly larger systems over longer times than considered before. Our results reveal that the relative hydrophobicity of the poly-glutamine block as compared to the rest of the (proline-based) exon1 fragment, ignored to date, constitutes a major factor in the initiation of the self-assembly process. We find that the assembly is governed by both the concentration of exon1 and the length of the poly-glutamine stretch, with a low length threshold for association even at the lowest volume fractions we considered. Moreover, this self-association occurs irrespective of whether the glutamine stretch is in random coil or hairpin configuration, leading to spherical or cylindrical assemblies, respectively. We discuss the implications of these results for reinterpretation of existing research within this context, including that the routes towards aggregation of exon1 may be distinct to those of the widely studied homopolymeric poly-glutamine peptides.",,"Martin G. Burke, Rudiger Woscholski, Sophia N. Yaliraki",quantitative biology,train
Hydration Water Dynamics and Instigation of Protein Structural Relaxation,"The molecular mechanism of the solvent motion that is required to instigate the protein structural relaxation above a critical hydration level or transition temperature has yet to be determined. In this work we use quasi-elastic neutron scattering (QENS) and molecular dynamics simulation to investigate hydration water dynamics near a greatly simplified protein surface. We consider the hydration water dynamics near the completely deuterated N-acetyl-leucine-methylamide (NALMA) solute, a hydrophobic amino acid side chain attached to a polar blocked polypeptide backbone, as a function of concentration between 0.5M-2.0M, under ambient conditions. In this Communication, we focus our results of hydration dynamics near a model protein surface on the issue of how enzymatic activity is restored once a critical hydration level is reached, and provide a hypothesis for the molecular mechanism of the solvent motion that is required to trigger protein structural relaxation when above the hydration transition.","2 pages, 2 figures, Communication","Daniela Russo, Greg Hura, Teresa Head-Gordon",quantitative biology,train
Thermal denaturation and folding rates of single domain proteins: size matters,"We analyze the dependence of thermal denaturation transition and folding rates of globular proteins on the number of amino acid residues, N. Using lattice Go models we show that DeltaT/T_F ~ N^-1, where T_F is the folding transition temperature and DeltaT is the folding transition width. This finding is consistent with finite size effects expected for the systems undergoing a phase transition from a disordered to an ordered phase. The dependence of the folding rates k_F on N for lattice models and the dataset of 57 proteins and peptides shows that k_F = k_F^0 exp(-CN^beta) provides a good fit, if 0 < beta <= 2/3 and C is a constant. We find that k_F = k_F^0 exp(-1.1N^0.5) with k_F^0 =(0.4x10^-6 s)^-1 can estimate optimal protein folding rates to within an order of magnitude in most cases. By using this fit for a set of proteins with beta-sheet topology we find that k_F^0 is approximately equal to k_U^0, the prefactor for unfolding rates. The maximum ratio of k_U^0/k_F^0 is 10 for this class of proteins.","11 pages, 3 figures","Mai Suan Li, D. K. Klimov, D. Thirumalai",quantitative biology,train
Asymmetry in the shapes of folded and denatured states of proteins,"The asymmetry in the shapes of folded and unfolded states are probed using two parameters, one being a measure of the sphericity and the other that describes the shape. For the folded states, whose interiors are densely packed, the radii of gyration (Rg) and these two parameters are calculated using the coordinates of the experimentally determined structures. Although Rg scales as expected for maximally compact structures, the distributions of the shape parameters show that there is considerable asymmetry in the shapes of folded structures. The degree of asymmetry is greater for proteins that form oligomers. Analysis of the two- and three-body contacts in the native structures shows that the presence of near equal number of contacts between backbone and side-chains and between side-chains gives rise to dense packing. We suggest that proteins with relatively large values of shape parameters can tolerate volume mutations without greatly affecting the network of contacts or their stability. To probe shape characteristics of denatured states we have developed a model of a WW-like domain. The shape parameters, which are calculated using Langevin simulations, change dramatically in the course of coil to globule transition. Comparison of the values of shape parameters between the globular state and the folded state of WW domain shows that both energetic (especially dispersion in the hydrophobic interactions) and steric effects are important in determining packing in proteins.","22 pages, 7 figures","Ruxandra I. Dima, D. Thirumalai",quantitative biology,train
Protein secondary structure prediction by combining hidden Markov models and sliding window scores,"Instead of conformation states of single residues, refined conformation states of quintuplets are proposed to reflect conformation correlation. Simple hidden Markov models combining with sliding window scores are used for predicting secondary structure of a protein from its amino acid sequence. Since the length of protein conformation segments varies in a narrow range, we ignore the duration effect of the length distribution. The window scores for residues are a window version of the Chou-Fasman propensities estimated under an approximation of conditional independency. Different window widths are examined, and the optimal width is found to be 17. A high accuracy about 70% is achieved.","8 pages, 1 figure, 2 tables",Wei-Mou Zheng,quantitative biology,test
"Protein secondary structure: Entropy, correlations and prediction","Is protein secondary structure primarily determined by local interactions between residues closely spaced along the amino acid backbone, or by non-local tertiary interactions? To answer this question we have measured the entropy densities of primary structure and secondary structure sequences, and the local inter-sequence mutual information density. We find that the important inter-sequence interactions are short ranged, that correlations between neighboring amino acids are essentially uninformative, and that only 1/4 of the total information needed to determine the secondary structure is available from local inter-sequence correlations. Since the remaining information must come from non-local interactions, this observation supports the view that the majority of most proteins fold via a cooperative process where secondary and tertiary structure form concurrently. To provide a more direct comparison to existing secondary structure prediction methods, we construct a simple hidden Markov model (HMM) of the sequences. This HMM achieves a prediction accuracy comparable to other single sequence secondary structure prediction algorithms, and can extract almost all of the inter-sequence mutual information. This suggests that these algorithms are almost optimal, and that we should not expect a dramatic improvement in prediction accuracy. However, local correlations between secondary and primary structure are probably of under-appreciated importance in many tertiary structure prediction methods, such as threading.","8 pages, 5 figures","Gavin E. Crooks, Steven E. Brenner",quantitative biology,val
Complex folding pathways in a simple beta-hairpin,"The determination of the folding mechanisms of proteins is critical to understand the topological change that can propagate Alzheimer and Creutzfeld-Jakobs diseases, among others. The computational community has paid considerable attention to this problem; however, the associated time scale, typically on the order of milliseconds or more, represents a formidable challenge. Ab initio protein folding from long molecular dynamics (MD) simulations or ensemble dynamics is not feasible with ordinary computing facilities and new techniques must be introduced. Here we present a detailed study of the folding of a 16-residue beta-hairpin, described by a generic energy model and using the activation-relaxation technique. From a total of 90 trajectories at 300 K, three folding pathways emerge. All involve a simultaneous optimization of the complete hydrophobic and hydrogen bonding interactions. The first two follow closely those observed by previous theoretical studies. The third pathway, never observed by previous all-atom folding, unfolding and equilibrium simulations, can be described as a reptation move of one strand of the beta-sheet with respect to the other. This reptation move indicates that non-native interactions can play a dominant role in the folding of secondary structures. These results point to a more complex folding picture than expected for a simple beta-hairpin.","14 pages, 10 figures","Guanghong Wei, Normand Mousseau, Philippe Derreumaux",quantitative biology,train
Analytic models for mechanotransduction: gating a mechanosensitive channel,Analytic estimates for the forces and free energy generated by bilayer deformation reveal a compelling and intuitive model for MscL channel gating analogous to the nucleation of a second phase. We argue that the competition between hydrophobic mismatch and tension results in a surprisingly rich story which can provide both a quantitative comparison to measurements of opening tension for MscL when reconstituted in bilayers of different thickness and qualitative insights into the function of the MscL channel and other transmembrane proteins.,,"Paul Wiggins, Rob Phillips",quantitative biology,train
Are residues in a protein folding nucleus evolutionarily conserved?,"It is important to understand how protein folding and evolution influences each other. Several studies based on entropy calculation correlating experimental measurement of residue participation in folding nucleus and sequence conservation have reached different conclusions. Here we report analysis of conservation of folding nucleus using an evolutionary model alternative to entropy based approaches. We employ a continuous time Markov model of codon substitution to distinguish mutation fixed by evolution and mutation fixed by chance. This model takes into account bias in codon frequency, bias favoring transition over transversion, as well as explicit phylogenetic information. We measure selection pressure using the ratio $\omega$ of synonymous vs. non-synonymous substitution at individual residue site. The $\omega$-values are estimated using the {\sc Paml} method, a maximum-likelihood estimator. Our results show that there is little correlation between the extent of kinetic participation in protein folding nucleus as measured by experimental $\phi$-value and selection pressure as measured by $\omega$-value. In addition, two randomization tests failed to show that folding nucleus residues are significantly more conserved than the whole protein. These results suggest that at the level of codon substitution, there is no indication that folding nucleus residues are significantly more conserved than other residues. We further reconstruct candidate ancestral residues of the folding nucleus and suggest possible test tube mutation studies of ancient folding nucleus.","15 pages, 4 figures, and 1 table. Accepted by J. Mol. Biol","Yan Yuan Tseng, Jie Liang",quantitative biology,val
Probing subtle fluorescence dynamics in cellular proteins by streak camera based Fluorescence Lifetime Imaging Microscopy,We report the cell biological applications of a recently developed multiphoton fluorescence lifetime imaging microscopy system using a streak camera (StreakFLIM). The system was calibrated with standard fluorophore specimens and was shown to have high accuracy and reproducibility. We demonstrate the applicability of this instrument in living cells for measuring the effects of protein targeting and point mutations in the protein sequence which are not obtainable in conventional intensity based fluorescence microscopy methods. We discuss the relevance of such time resolved information in quantitative energy transfer microscopy and in measurement of the parameters characterizing intracellular physiology.,,"R. V. Krishnan, Eva Biener, Jian-Hua Zhang, Robert Heckel, Brian Herman",quantitative biology,train
Auto-reverse nuclear migration in bipolar mammalian cells on micropatterned surfaces,"A novel assay based on micropatterning and time-lapse microscopy has been developed for the study of nuclear migration dynamics in cultured mammalian cells. When cultured on 10-20 um wide adhesive stripes, the motility of C6 glioma and primary mouse fibroblast cells is diminished. Nevertheless, nuclei perform an unexpected auto-reverse motion: when a migrating nucleus approaches the leading edge, it decelerates, changes the direction of motion and accelerates to move toward the other end of the elongated cell. During this process cells show signs of polarization closely following the direction of nuclear movement. The observed nuclear movement requires a functioning microtubular system, as revealed by experiments disrupting the main cytoskeletal components with specific drugs. On the basis of our results we argue that auto-reverse nuclear migration is due to forces determined by the interplay of microtubule dynamics and the changing position of the microtubule organizing center as the nucleus reaches the leading edge. Our assay recapitulates specific features of nuclear migration (cell polarization, oscillatory nuclear movement), while allows the systematic study of a large number of individual cells. In particular, our experiments yielded the first direct evidence of reversive nuclear motion in mammalian cells, induced by attachment constraints.",Figures and supplemental videos: http://esr.elte.hu/nuclearmotility,"B. Szabo, Zs. Kornyei, J. Zach, D. Selmeczi, G. Csucs, A. Czirok, T. Vicsek",quantitative biology,test
Cytokinesis: the initial linear phase crosses over to a multiplicity of non-linear endings,"We investigate the final stage of cytokinesis in two types of amoeba, pointing out the existence of biphasic furrow contraction. The first phase is characterized by a constant contraction rate, is better studied, and seems universal to a large extent. The second phase is more diverse. In Dictyostelium discoideum the transition involves a change in the rate of contraction, and occurs when the width of the cleavage furrow is comparable to the height of the cell. In Entamoeba invadens the contractile ring carries the cell through the first phase, but cannot complete the second stage of cytokinesis. As a result, a cooperative mechanism has evolved in that organism, where a neighboring amoeba performs directed motion towards the dividing cell, and physically causes separation by means of extending a pseudopod. We expand here on a previous report of this novel chemotactic signaling mechanism.",,"D. Biron, P. Libros, D. Sagi, D. Mirelman, E. Moses",quantitative biology,val
A graph model for the evolution of specificity in humoral immunity,"The immune system protects the body against health-threatening entities, known as antigens, through very complex interactions involving the antigens and the system's own entities. One remarkable feature resulting from such interactions is the immune system's ability to improve its capability to fight antigens commonly found in the individual's environment. This adaptation process is called the evolution of specificity. In this paper, we introduce a new mathematical model for the evolution of specificity in humoral immunity, based on Jerne's functional, or idiotypic, network. The evolution of specificity is modeled as the dynamic updating of connection weights in a graph whose nodes are related to the network's idiotypes. At the core of this weight-updating mechanism are the increase in specificity caused by clonal selection and the decrease in specificity due to the insertion of uncorrelated idiotypes by the bone marrow. As we demonstrate through numerous computer experiments, for appropriate choices of parameters the new model correctly reproduces, in qualitative terms, several immune functions.",,"L. E. Flores, E. J. Aguilar, V. C. Barbosa, L. A. V. de Carvalho",quantitative biology,train
Mathematical model of solid tumor formation,"The problem of the onset and growth of solid tumour in homogeneous tissue is regarded using an approach based on local interaction between the tumoral and the sane tissue cells. The characteristic sizes and growth rates of spherical tumours, the points of the beginning and the end of spherical growth, and the further development of complex structures (elongated outgrowths, dendritic structures, and metastases) are derived from the assumption that the reproduction rate of a population of cancer cells is a non-monotone function of their local concentration. The predicted statistical distribution of the characteristic tumour sizes, when compared to the clinical data, will make a basis for checking the validity of the theory.","7 pages, 5 figures, key words:tumour growth, mathematical model,
  local interaction","R. G. Khlebopros, V. A. Slepkov, V. G. Sukhovolsky, Y. V. Mironov, V. E. Fedorov, S. P. Gabuda",quantitative biology,val
Aggregation of foraging swarms,"In this paper we consider a continuous-time anisotropic swarm model with an attraction/repulsion function and study its aggregation properties. It is shown that the swarm members will aggregate and eventually form a cohesive cluster of finite size around the swarm center. We also study the swarm cohesiveness when the motion of each agent is a combination of the inter-individual interactions and the interaction of the agent with external environment. Moreover, we extend our results to more general attraction/repulsion functions. The model in this paper is more general than isotropic swarms and our results provide further insight into the effect of the interaction pattern on individual motion in a swarm system.",,Long Wang,quantitative biology,val
Simulating the Impact of a Molecular 'Decision-Process' on Cellular Phenotype and Multicellular Patterns in Brain Tumors,"Experimental evidence indicates that human brain cancer cells proliferate or migrate, yet do not display both phenotypes at the same time. Here, we present a novel computational model simulating this cellular decision-process leading up to either phenotype based on a molecular interaction network of genes and proteins. The model's regulatory network consists of the epidermal growth factor receptor (EGFR), its ligand transforming growth factor-a (TGFa), the downstream enzyme phospholipaseC-gamma (PLCg) and a mitosis-associated response pathway. This network is activated by autocrine TGFa secretion, and the EGFR-dependent downstream signaling this step triggers, as well as modulated by an extrinsic nutritive glucose gradient. Employing a framework of mass action kinetics within a multiscale agent-based environment, we analyze both the emergent multicellular behavior of tumor growth and the single-cell molecular profiles that change over time and space. Our results show that one can indeed simulate the dichotomy between cell migration and proliferation based solely on an EGFR decision network. It turns out that these behavioral decisions on the single cell level impact the spatial dynamics of the entire cancerous system. Furthermore, the simulation results yield intriguing experimentally testable hypotheses also on the sub-cellular level such as spatial cytosolic polarization of PLCg towards an extrinsic chemotactic gradient. Implications of these results for future works, both on the modeling and experimental side are discussed.",,"Chaitanya Athale, Yuri Mansury, Thomas S. Deisboeck",quantitative biology,train
"Physical Schemata Underlying Biological Pattern Formation - Examples, Issues and Strategies","Biological systems excel at building spatial structures on scales ranging from nanometers to kilometers and exhibit temporal patterning from milliseconds to years. One approach that nature has taken to accomplish this relies on the harnessing of pattern-forming processes of non-equilibrium physics and chemistry. For these systems, the study of biological pattern formation starts with placing a biological phenomenon of interest within the context of the proper pattern-formation schema and then focusing on the ways in which control is exerted to adapt the pattern to the needs of the organism. This approach is illustrated by several examples, notably bacterial colonies (diffusive-growth schema) and intracellular calcium waves (excitable-media schema).",,"Herbert Levine, Eshel Ben-Jacob",quantitative biology,train
Model for the robust establishment of precise proportions in the early Drosophila embryo,"During embryonic development, a spatial pattern is formed in which proportions are established precisely. As an early pattern formation step in Drosophila embryos, an anterior-posterior gradient of Bicoid (Bcd) induces hunchback (hb) expression (Driever et al. 1989; Tautz et al. 1988). In contrast to the Bcd gradient, the Hb profile includes information about the scale of the embryo. Furthermore, the resulting hb expression pattern shows a much lower embryo-to-embryo variability than the Bcd gradient (Houchmandzadeh et al. 2002). An additional graded posterior repressing activity could theoretically account for the observed scaling. However, we show that such a model cannot produce the observed precision in the Hb boundary, such that a fundamentally different mechanism must be at work. We describe and simulate a model that can account for the observed precise generation of the scaled Hb profile in a highly robust manner. The proposed mechanism includes Staufen (Stau), an RNA binding protein that appears essential to precision scaling (Houchmandzadeh et al. 2002). In the model, Stau is released from both ends of the embryo and relocalises hb RNA by increasing its mobility. This leads to an effective transport of hb away from the respective Stau sources. The balance between these opposing effects then gives rise to scaling and precision. Considering the biological importance of robust precision scaling and the simplicity of the model, the same principle may be employed more often during development.","20 pages, 2 figures, accepted for publication in J. theor. Biol","Tinri Aegerter-Wilmsen, Christof M. Aegerter, Ton Bisseling",quantitative biology,train
Pattern formation in a stochastic model of cancer growth,"We investigate noise-induced pattern formation in a model of cancer growth based on Michaelis-Menten kinetics, subject to additive and multiplicative noises. We analyse stability properties of the system and discuss the role of diffusion and noises in the system's dynamics. We find that random dichotomous fluctuations in the immune response intensity along with Gaussian environmental noise lead to emergence of a spatial pattern of two phases, in which cancer cells, or, respectively, immune cells predominate.","17 pages, 15 figures",Anna Ochab-Marcinek,quantitative biology,train
Human housekeeping genes are compact,"We identify a set of 575 human genes that are expressed in all conditions tested in a publicly available database of microarray results. Based on this common occurrence, the set is expected to be rich in ""housekeeping"" genes, showing constitutive expression in all tissues. We compare selected aspects of their genomic structure with a set of background genes. We find that the introns, untranslated regions and coding sequences of the housekeeping genes are shorter, indicating a selection for compactness in these genes.",,"Eli Eisenberg, Erez Y. Levanon",quantitative biology,train
A covariance kernel for proteins,"We propose a new kernel for biological sequences which borrows ideas and techniques from information theory and data compression. This kernel can be used in combination with any kernel method, in particular Support Vector Machines for protein classification. By incorporating prior biological assumptions on the properties of amino-acid sequences and using a Bayesian averaging framework, we compute the value of this kernel in linear time and space, benefiting from previous achievements proposed in the field of universal coding. Encouraging classification results are reported on a standard protein homology detection experiment.","12 pages, 1 figure","Marco Cuturi, Jean-Philippe Vert",quantitative biology,train
Random model for RNA interference yields scale free network,"We introduce a random bit-string model of post-transcriptional genetic regulation based on sequence matching. The model spontaneously yields a scale free network with power law scaling with $ \gamma=-1$ and also exhibits log-periodic behaviour. The in-degree distribution is much narrower, and exhibits a pronounced peak followed by a Gaussian distribution. The network is of the smallest world type, with the average minimum path length independent of the size of the network, as long as the network consists of one giant cluster. The percolation threshold depends on the system size.","9 pages, 13 figures, submitted to Midterm Conference COSIN on
  ``Growing Networks and Graphs in Statistical Physics, Finance, Biology and
  Social Systems'', Rome, 1-5 September 2003","Duygu Balcan, Ayse Erzan",quantitative biology,train
Computational identification of transcription factor binding sites by functional analysis of sets of genes sharing overrepresented upstream motifs,"BACKGROUND: Transcriptional regulation is a key mechanism in the functioning of the cell, and is mostly effected through transcription factors binding to specific recognition motifs located upstream of the coding region of the regulated gene. The computational identification of such motifs is made easier by the fact that they often appear several times in the upstream region of the regulated genes, so that the number of occurrences of relevant motifs is often significantly larger than expected by pure chance. RESULTS: To exploit this fact, we construct sets of genes characterized by the statistical overrepresentation of a certain motif in their upstream regions. Then we study the functional characterization of these sets by analyzing their annotation to Gene Ontology terms. For the sets showing a statistically significant specific functional characterization, we conjecture that the upstream motif characterizing the set is a binding site for a transcription factor involved in the regulation of the genes in the set. CONCLUSIONS: The method we propose is able to identify many known binding sites in S. cerevisiae and new candidate targets of regulation by known transcription factors. Its application to less well studied organisms is likely to be valuable in the exploration of their regulatory interaction network.","19 pages, 1 figure. Published version with several improvements.
  Supplementary material available from the authors","Davide Cora', Ferdinando Di Cunto, Paolo Provero, Lorenzo Silengo, Michele Caselle",quantitative biology,val
MAVID: Constrained ancestral alignment of multiple sequences,"We describe a new global multiple alignment program capable of aligning a large number of genomic regions. Our progressive alignment approach incorporates the following ideas: maximum-likelihood inference of ancestral sequences, automatic guide-tree construction, protein based anchoring of ab-initio gene predictions, and constraints derived from a global homology map of the sequences. We have implemented these ideas in the MAVID program, which is able to accurately align multiple genomic regions up to megabases long. MAVID is able to effectively align divergent sequences, as well as incomplete unfinished sequences. We demonstrate the capabilities of the program on the benchmark CFTR region which consists of 1.8Mb of human sequence and 20 orthologous regions in marsupials, birds, fish, and mammals. Finally, we describe two large MAVID alignments: an alignment of all the available HIV genomes and a multiple alignment of the entire human, mouse and rat genomes.",,"Nicolas Bray, Lior Pachter",quantitative biology,train
Relevance Vector Machines for classifying points and regions in biological sequences,"The Relevance Vector Machine (RVM) is a recently developed machine learning framework capable of building simple models from large sets of candidate features. Here, we describe a protocol for using the RVM to explore very large numbers of candidate features, and a family of models which apply the power of the RVM to classifying and detecting interesting points and regions in biological sequence data. The models described here have been used successfully for predicting transcription start sites and other features in genome sequences.","16 pages, 3 figures","Thomas A. Down, Tim J. P. Hubbard",quantitative biology,train
What can we learn from noncoding regions of similarity between genomes?,"Background: In addition to known protein-coding genes, large amount of apparently non-coding sequence are conserved between the human and mouse genomes. It seems reasonable to assume that these conserved regions are more likely to contain functional elements than less-conserved portions of the genome. Here we used a motif-oriented machine learning method to extract the strongest signal from a set of non-coding conserved sequences. Results: We successfully fitted models to reflect the non-coding sequences, and showed that the results were quite consistent for repeated training runs. Using the learned model to scan genomic sequence, we found that it often made predictions close to the start of annotated genes. We compared this method with other published promoter-prediction systems, and show that the set of promoters which are detected by this method seems to be substantially similar to that detected by existing methods. Conclusions: The results presented here indicate that the promoter signal is the strongest single motif-based signal in the non-coding functional fraction of the genome. They also lend support to the belief that there exists a substantial subset of promoter regions which share common features and are detectable by a variety of computational methods.","10 pages, 5 figures","Thomas A. Down, Tim J. P. Hubbard",quantitative biology,test
Clone-array pooled shotgun mapping and sequencing: design and analysis of experiments,"This paper studies sequencing and mapping methods that rely solely on pooling and shotgun sequencing of clones. First, we scrutinize and improve the recently proposed Clone-Array Pooled Shotgun Sequencing (CAPSS) method, which delivers a BAC-linked assembly of a whole genome sequence. Secondly, we introduce a novel physical mapping method, called Clone-Array Pooled Shotgun Mapping (CAPS-MAP), which computes the physical ordering of BACs in a random library. Both CAPSS and CAPS-MAP construct subclone libraries from pooled genomic BAC clones. We propose algorithmic and experimental improvements that make CAPSS a viable option for sequencing a set of BACs. We provide the first probabilistic model of CAPSS sequencing progress. The model leads to theoretical results supporting previous, less formal arguments on the practicality of CAPSS. We demonstrate the usefulness of CAPS-MAP for clone overlap detection with a probabilistic analysis, and a simulated assembly of the Drosophila melanogaster genome. Our analysis indicates that CAPS-MAP is well-suited for detecting BAC overlaps in a highly redundant library, relying on a low amount of shotgun sequence information. Consequently, it is a practical method for computing the physical ordering of clones in a random library, without requiring additional clone fingerprinting. Since CAPS-MAP requires only shotgun sequence reads, it can be seamlessly incorporated into a sequencing project with almost no experimental overhead.","An extended abstract is to be published at the 14th International
  Conference on Genome Informatics (GIW), December 14-17, 2003, Yokohama, Japan","Miklós Csürös, Bingshan Li, Aleksandar Milosavljevic",quantitative biology,train
Genetic Paralog Analysis and Simulations,"Using Monte Carlo methods, we simulated the effects of bias in generation and elimination of paralogs on the size distribution of paralog groups. It was found that the function describing the decay of the number of paralog groups with their size depends on the ratio between the probability of duplications of genes and their deletions, which corresponds to different selection pressures on the genome size. Slightly different slopes of curves describing the decay of the number of paralog groups with their size were also observed when the threshold of homology between paralogous sequences was changed.","10 pages including figs, for ICCS 2004 Cracow","Stanislaw Cebrat, Jan P. Radomski, Dietrich Stauffer",quantitative biology,train
RNA Binding Density on X-chromosome Differing from that on 22 Autosomes in Human,"To test whether X-chromosome has unique genomic characteristics, X-chromosome and 22 autosomes were compared for RNA binding density. Nucleotide sequences on the chromosomes were divided into 50kb per segment that was recoded as a set of frequency values of 7-nucleotide (7nt) strings using all possible 7nt strings (47=16384). 120 genes highly expressed in tonsil germinal center B cells were selected for calculating 7nt string frequency values of all introns (RNAs). The binding density of DNA segments and RNAs was determined by the amount of complement sequences. It was shown for the first time that gene-poor and low gene expression X-chromosome had the lowest percentage of the DNA segments that can highly bind RNAs, whereas gene-rich and high gene expression chromosome 19 had the highest percentage of the segments. On the basis of these results, it is proposed that the nonrandom properties of distribution of RNA highly binding DNA segments on the chromosomes provide strong evidence that lack of RNA highly binding segments may be a cause of X-chromosome inactivation",,"Zhanjun Lu, Ying Lu, Shuxia Song, Zhai Yu, Xiufang Wang",quantitative biology,train
Fold-Hopf Bursting in a Model for Calcium Signal Transduction,"We study a recent model for calcium signal transduction. This model displays spiking, bursting and chaotic oscillations in accordance with experimental results. We calculate bifurcation diagrams and study the bursting behaviour in detail. This behaviour is classified according to the dynamics of separated slow and fast subsystems. It is shown to be of the Fold-Hopf type, a type which was previously only described in the context of neuronal systems, but not in the context of signal transduction in the cell.","13 pages, 5 figures","Lutz Brusch, Wolfram Lorenz, Michal Or-Guil, Markus Bär, Ursula Kummer",quantitative biology,test
"Communication on the letter: ""Evolutionary Conservation of Motif Constituents in the Yeast Protein Interaction Network.""",Former work on an application of order-disorder theory is recalled as a vehicle to add further development and significance to the recent paper on motifs in protein interactions.,2 pages,Stan Bumble,quantitative biology,val
Enhancement of the stability of genetic switches by overlapping upstream regulatory domains,"We study genetic switches formed from pairs of mutually repressing operons. The switch stability is characterised by a well defined lifetime which grows sub-exponentially with the number of copies of the most-expressed transcription factor, in the regime accessible by our numerical simulations. The stability can be markedly enhanced by a suitable choice of overlap between the upstream regulatory domains. Our results suggest that robustness against biochemical noise can provide a selection pressure that drives operons, that regulate each other, together in the course of evolution.","4 pages, 5 figures, RevTeX4","Patrick B. Warren, Pieter Rein ten Wolde",quantitative biology,train
The topology of the regulatory interactions predics the expression pattern of the segment polarity genes in Drosophila melanogaster,"Expression of the Drosophila segment polarity genes is initiated by a prepattern of pair-rule gene products and maintained by a network of regulatory interactions throughout several stages of embryonic development. Analysis of a model of gene interactions based on differential equations showed that wild-type expression patterns of these genes can be obtained for a wide range of kinetic parameters, which suggests that the steady states are determined by the topology of the network and the type of regulatory interactions between components, not the detailed form of the rate laws. To investigate this, we propose and analyze a Boolean model of this network which is based on a binary ON/OFF representation of transcription and protein levels, and in which the interactions are formulated as logical functions. In this model the spatial and temporal patterns of gene expression are determined by the topology of the network and whether components are present or absent, rather than the absolute levels of the mRNAs and proteins and the functional details of their interactions. The model is able to reproduce the wild type gene expression patterns, as well as the ectopic expression patterns observed in over-expression experiments and various mutants. Furthermore, we compute explicitly all steady states of the network and identify the basin of attraction of each steady state. The model gives important insights into the functioning of the segment polarity gene network, such as the crucial role of the wingless and sloppy paired genes, and the network's ability to correct errors in the prepattern.","24 pages, 9 figures","Reka Albert, Hans G. Othmer",quantitative biology,train
Homogeneous and Scalable Gene Expression Regulatory Networks with Random Layouts of Switching Parameters,"We consider a model of large regulatory gene expression networks where the thresholds activating the sigmoidal interactions between genes and the signs of these interactions are shuffled randomly. Such an approach allows for a qualitative understanding of network dynamics in a lack of empirical data concerning the large genomes of living organisms. Local dynamics of network nodes exhibits the multistationarity and oscillations and depends crucially upon the global topology of a ""maximal"" graph (comprising of all possible interactions between genes in the network). The long time behavior observed in the network defined on the homogeneous ""maximal"" graphs is featured by the fraction of positive interactions ($0\leq \eta\leq 1$) allowed between genes. There exists a critical value $\eta_c<1$ such that if $\eta<\eta_c$, the oscillations persist in the system, otherwise, when $\eta>\eta_c,$ it tends to a fixed point (which position in the phase space is determined by the initial conditions and the certain layout of switching parameters). In networks defined on the inhomogeneous directed graphs depleted in cycles, no oscillations arise in the system even if the negative interactions in between genes present therein in abundance ($\eta_c=0$). For such networks, the bidirectional edges (if occur) influence on the dynamics essentially. In particular, if a number of edges in the ""maximal"" graph is bidirectional, oscillations can arise and persist in the system at any low rate of negative interactions between genes ($\eta_c=1$). Local dynamics observed in the inhomogeneous scalable regulatory networks is less sensitive to the choice of initial conditions. The scale free networks demonstrate their high error tolerance.","LaTeX, 30 pages, 20 pictures","D. Volchenkov, R. Lima",quantitative biology,val
Toy Models and Statistical Mechanics of Subgraphs and Motifs of Genetic and Protein Networks,Theoretical physics is used for a toy model of molecular biology to assess conditions that lead to the edge of chaos (EOC) in a network of biomolecules. Results can enhance our ability to understand complex diseases and their treatment or cure.,"7 pages, 2 figures",S. Bumble,quantitative biology,train
Discriminative Topological Features Reveal Biological Network Mechanisms,"Recent genomic and bioinformatic advances have motivated the development of numerous random network models purporting to describe graphs of biological, technological, and sociological origin. The success of a model has been evaluated by how well it reproduces a few key features of the real-world data, such as degree distributions, mean geodesic lengths, and clustering coefficients. Often pairs of models can reproduce these features with indistinguishable fidelity despite being generated by vastly different mechanisms. In such cases, these few target features are insufficient to distinguish which of the different models best describes real world networks of interest; moreover, it is not clear a priori that any of the presently-existing algorithms for network generation offers a predictive description of the networks inspiring them. To derive discriminative classifiers, we construct a mapping from the set of all graphs to a high-dimensional (in principle infinite-dimensional) ``word space.'' This map defines an input space for classification schemes which allow us for the first time to state unambiguously which models are most descriptive of the networks they purport to describe. Our training sets include networks generated from 17 models either drawn from the literature or introduced in this work, source code for which is freely available. We anticipate that this new approach to network analysis will be of broad impact to a number of communities.","supplemental website:
  http://www.columbia.edu/itc/applied/wiggins/netclass/","Manuel Middendorf, Etay Ziv, Carter Adams, Jen Hom, Robin Koytcheff, Chaya Levovitz, Gregory Woods, Linda Chen, Chris Wiggins",quantitative biology,val
Global Topological Study of the Protein-protein Interaction Networks,"We employed the random graph theory approach to analyze the protein-protein interaction database DIP (Feb. 2004), for seven species (S. cerevisiae, H. pylori, E. coli, C. elegans, H. sapiens, M. musculus and D. melanogaster). Several global topological parameters (such as node connectivity, average diameter, node connectivity correlation) were used to characterize these protein-protein interaction networks (PINs). The logarithm of the connectivity distribution vs. the logarithm of connectivity study indicated that PINs follow a power law (P(k) ~ k-\gamma) behavior. Using the regression analysis method we determined that \gamma lies between 1.5 and 2.4, for the seven species. Correlation analysis provides good evidence supporting the fact that the seven PINs form a scale-free network. The average diameters of the networks and their randomized version are found to have large difference. We also demonstrated that the interaction networks are quite robust when subject to random perturbation. Average node connectivity correlation study supports the earlier results that nodes of low connectivity are correlated, whereas nodes of high connectivity are not directly linked. These results provided some evidence suggesting such correlation relations might be a general feature of the PINs across different species.","13 pages, 9 figures, 4 tables","Ka-Lok Ng, Chien-Hung Huang",quantitative biology,train
Large-scale reverse engineering by the Lasso,"We perform a reverse engineering from the ``extended Spellman data'', consisting of 6178 mRNA levels measured by microarrays at 73 instances in four time series during the cell cycle of the yeast Saccharomyces cerevisae. By assuming a linear model of the genetic regulatory network, and imposing an extra constraint (the Lasso), we obtain a unique inference of coupling parameters. These parameters are transfered into an adjacent matrix, which is analyzed with respect to topological properties and biological relevance. We find a very broad distribution of outdegrees in the network, compatible with earlier findings for biological systems and totally incompatible with a random graph, and also indications of modules in the network. Finally, we show there is an excess of genes coding for transcription factors among the genes of highest outdegrees, a fact which indicates that our approach has biological relevance.","4 pages, submitted for publication","Mika Gustafsson, Michael Hornquist, Anna Lombardi",quantitative biology,val
On the stability of Murray's testosterone model,"We prove the global asymptotic stability of a well-known delayed negative-feedback model of testosterone dynamics, which has been proposed as a model of oscillatory behavior. We establish stability (and hence the impossibility of oscillations) even in the presence of delays of arbitrary length.","10 pages, no figures. Submitted to the Journal of Theoretical Biology","G. A. Enciso, E. D. Sontag",quantitative biology,test
Synchronization and oscillatory dynamics in heterogeneous mutually inhibited neurons,"We study some mechanisms responsible for synchronous oscillations and loss of synchrony at physiologically relevant frequencies (10-200 Hz) in a network of heterogeneous inhibitory neurons. We focus on the factors that determine the level of synchrony and frequency of the network response, as well as the effects of mild heterogeneity on network dynamics. With mild heterogeneity, synchrony is never perfect and is relatively fragile. In addition, the effects of inhibition are more complex in mildly heterogeneous networks than in homogeneous ones. In the former, synchrony is broken in two distinct ways, depending on the ratio of the synaptic decay time to the period of repetitive action potentials ($\tau_s/T$), where $T$ can be determined either from the network or from a single, self-inhibiting neuron. With $\tau_s/T > 2$, corresponding to large applied current, small synaptic strength or large synaptic decay time, the effects of inhibition are largely tonic and heterogeneous neurons spike relatively independently. With $\tau_s/T < 1$, synchrony breaks when faster cells begin to suppress their less excitable neighbors; cells that fire remain nearly synchronous. We show numerically that the behavior of mildly heterogeneous networks can be related to the behavior of single, self-inhibiting cells, which can be studied analytically.","17 pages, 6 figures, Kluwer.sty. Journal of Compuational Neuroscience
  (in press). Originally submitted to the neuro-sys archive which was never
  publicly announced (was 9802001)","J. A. White, C. C. Chow, J. Ritt, C. Soto-Trevino, N. Kopell",quantitative biology,val
Frequency control in synchronized networks of inhibitory neurons,"We analyze the control of frequency for a synchronized inhibitory neuronal network. The analysis is done for a reduced membrane model with a biophysically-based synaptic influence. We argue that such a reduced model can quantitatively capture the frequency behavior of a larger class of neuronal models. We show that in different parameter regimes, the network frequency depends in different ways on the intrinsic and synaptic time constants. Only in one portion of the parameter space, called `phasic', is the network period proportional to the synaptic decay time. These results are discussed in connection with previous work of the authors, which showed that for mildly heterogeneous networks, the synchrony breaks down, but coherence is preserved much more for systems in the phasic regime than in the other regimes. These results imply that for mildly heterogeneous networks, the existence of a coherent rhythm implies a linear dependence of the network period on synaptic decay time, and a much weaker dependence on the drive to the cells. We give experimental evidence for this conclusion.","18 pages, 3 figures, Kluwer.sty. J. Comp. Neurosci. (in press).
  Originally submitted to the neuro-sys archive which was never publicly
  announced (was 9803001)","Carson C. Chow, John A. White, Jason Ritt, Nancy Kopell",quantitative biology,train
Coding Strategies in Monkey V1 and Inferior Temporal Cortices,"We would like to know whether the statistics of neuronal responses vary across cortical areas. We examined stimulus-elicited spike count response distributions in V1 and IT cortices of awake monkeys. In both areas the distribution of spike counts for each stimulus was well-described by a Gaussian, with the log of the variance in the spike count linearly related to the log of the mean spike count. Two significant differences in response characteristics were found: both the range of spike counts and the slope of the log(variance) vs. log(mean) regression were larger in V1 than in IT. However, neurons in the two areas transmitted approximately the same amount of information about the stimuli, and had about the same channel capacity (the maximum possible transmitted information given noise in the responses). These results suggest that neurons in V1 use more variable signals over a larger dynamic range than neurons in IT, which use less variable signals over a smaller dynamic range. The two coding strategies are approximately as effective in transmitting information.","25 pages, 8 figures. Originally submitted to the neuro-sys archive
  which was never publicly announced (was 9804001)","Ethan D. Gershon, Matthew C. Wiener, Peter E. Latham, Barry J. Richmond",quantitative biology,train
Measuring the dynamics of neural responses in primary auditory cortex,"We review recent developments in the measurement of the dynamics of the response properties of auditory cortical neurons to broadband sounds, which is closely related to the perception of timbre. The emphasis is on a method that characterizes the spectro-temporal properties of single neurons to dynamic, broadband sounds, akin to the drifting gratings used in vision. The method treats the spectral and temporal aspects of the response on an equal footing.","27 pages, 17 figures, straight LaTeX +psfig. Originally submitted to
  the neuro-sys archive which was never publicly announced (was 9804002)","Didier A. Depireux, Jonathan Z. Simon, Shihab A. Shamma",quantitative biology,train
Synaptic Transmission: An Information-Theoretic Perspective,"Here we analyze synaptic transmission from an information-theoretic perspective. We derive closed-form expressions for the lower-bounds on the capacity of a simple model of a cortical synapse under two explicit coding paradigms. Under the ``signal estimation'' paradigm, we assume the signal to be encoded in the mean firing rate of a Poisson neuron. The performance of an optimal linear estimator of the signal then provides a lower bound on the capacity for signal estimation. Under the ``signal detection'' paradigm, the presence or absence of the signal has to be detected. Performance of the optimal spike detector allows us to compute a lower bound on the capacity for signal detection. We find that single synapses (for empirically measured parameter values) transmit information poorly but significant improvement can be achieved with a small amount of redundancy.","7 pages, 4 figures, NIPS97 proceedings: neuroscience. Originally
  submitted to the neuro-sys archive which was never publicly announced (was
  9809002)","A. Manwani, C. Koch",quantitative biology,train
Sensory Coding with Dynamically Competitive Networks,"Studies of insect olfactory processing indicate that odors are represented by rich spatio-temporal patterns of neural activity. These patterns are very difficult to predict a priori, yet they are stimulus specific and reliable upon repeated stimulation with the same input. We formulate here a theoretical framework in which we can interpret these experimental results. We propose a paradigm of ``dynamic competition'' in which inputs (odors) are represented by internally competing neural assemblies. Each pattern is the result of dynamical motion within the network and does not involve a ``winner'' among competing possibilities. The model produces spatio-temporal patterns with strong resemblance to those observed experimentally and possesses many of the general features one desires for pattern classifiers: large information capacity, reliability, specific responses to specific inputs, and reduced sensitivity to initial conditions or influence of noise. This form of neural processing may thus describe the organizational principles of neural information processing in sensory systems and go well beyond the observations on insect olfactory processing which motivated its development.","19 pages, 16 figures. Originally submitted to the neuro-sys archive
  which was never publicly announced (was 9905002)","M. I. Rabinovich, R. Huerta, A. Volkovskii, Henry D. I. Abarbanel, G. Laurent",quantitative biology,train
Temporal structure in neuronal activity during working memory in Macaque parietal cortex,"A number of cortical structures are reported to have elevated single unit firing rates sustained throughout the memory period of a working memory task. How the nervous system forms and maintains these memories is unknown but reverberating neuronal network activity is thought to be important. We studied the temporal structure of single unit (SU) activity and simultaneously recorded local field potential (LFP) activity from area LIP in the inferior parietal lobe of two awake macaques during a memory-saccade task. Using multitaper techniques for spectral analysis, which play an important role in obtaining the present results, we find elevations in spectral power in a 50--90 Hz (gamma) frequency band during the memory period in both SU and LFP activity. The activity is tuned to the direction of the saccade providing evidence for temporal structure that codes for movement plans during working memory. We also find SU and LFP activity are coherent during the memory period in the 50--90 Hz gamma band and no consistent relation is present during simple fixation. Finally, we find organized LFP activity in a 15--25 Hz frequency band that may be related to movement execution and preparatory aspects of the task. Neuronal activity could be used to control a neural prosthesis but SU activity can be hard to isolate with cortical implants. As the LFP is easier to acquire than SU activity, our finding of rich temporal structure in LFP activity related to movement planning and execution may accelerate the development of this medical application.","Originally submitted to the neuro-sys archive which was never
  publicly announced (was 0005002)","B. Pesaran, J. S. Pezaris, M. Sahani, P. P. Mitra, R. A. Andersen",quantitative biology,val
Structured psychosocial stress and therapeutic failure,"Generalized language-of-thought arguments appropriate to interacting cognitive modules permit exploration of how disease states interact with medical treatment. The interpenetrating feedback between treatment and response to it creates a kind of idiotypic hall-of-mirrors generating a synergistic pattern of efficacy, treatment failure, adverse reactions, and patient noncompliance which, from a Rate Distortion perspective, embodies a distorted image of externally-imposed structured psychosocial stress. For the US, accelerating spatial and social diffusion of such stress enmeshes both dominant and subordinate populations in a linked system which will express itself, not only in an increasingly unhealthy society, but in the diffusion of therapeutic failure, including, but not limited to, drug-based treatments.","18 pages, 4 figures","Rodrick Wallace, Deborah Wallace",quantitative biology,train
Different ocular dominance map formation by influence of orientation columns in visual cortices,"In animal experiments, the observed orientation preference (OP) and ocular dominance (OD) columns in the visual cortex of the brain show various pattern types. Here, we show that the different visual map formations in various species are due to the crossover behavior in anisotropic systems composed of orientational and scalar components such as easy-plane Heisenberg models. We predict the transition boundary between different pattern types with the anisotropy as a main bifurcation parameter, which is consistent with experimental observations.","4 pages, 4 figure","Myoung Won Cho, Seunghwan Kim",quantitative biology,val
What do neural nets and quantum theory tell us about mind and reality?,"This paper proposes an approach to framing and answering fundamental questions about consciousness. It argues that many of the more theoretical debates about consciousness, such as debates about ""when does it begin?"", are misplaced and meaningless, in part because ""consciousness"" as a word has many valid and interesting definitions, and in part because consciousness qua mind or intelligence (the main focus here)is a matter of degree or level, not a binary variable. It proposes that new mathematical work related to functional neural network designs -- designs so functional that they can be used in engineering -- is essential to a functional understanding of intelligence as such, and outlines some key mathematics as of 1999, citing earlier work for more details. Quantum theory is relevant, but not in the simple ways proposed in more popular philosophies.","17p.Transcript of plenary talk at international conference ""Towards a
  Science of Consciousness,"" hosted by United Nations University. Tokyo, 1999",Paul J. Werbos,quantitative biology,train
Results and Limitations of the Soliton Theory of DNA Transcription,"It has been suggested by several authors that nonlinear excitations, in particular solitary waves, could play a fundamental functional role in the process of DNA transcription, effecting the opening of the double chain needed for RNA Polymerase to be able to copy the genetic code. Some models have been proposed to model the relevant DNA dynamics in terms of a reduced number of effective degrees of freedom. Here I discuss advantages and disadvantages of such an approach, and discuss in more detail one of the models, i.e. the one proposed by Yakushevich.","An older review paper (NOT UPDATED), posted here for archival
  purposes",G. Gaeta,quantitative biology,train
"Galilean Satellites as Sites for Incipient Life, and the Earth as its Shelter","Numerous problems connected with an assumption of the life origin on the Earth do not arise on Galilean satellites. Here, in presence of a practically non-salt water and of a great deal (~5-10%) of abiogenic organics, a great diversity of conditions, which are unthinkable for the Earth, were realized more than once. They were caused by global electrochemical processes in the magnetic field presence what could entail an absolute enantiomeric synthesis. The subsequent explosions of the satellites' icy envelopes saturated by the electrolysis products resulted in appearance of hot massive atmospheres and warm deep oceans and ejection of the dirty ice fragments (=comet nuclei), what led to the material exchange with other bodies, etc.",19 pages,E. M. Drobyshevski,quantitative biology,val
Phase synchronization in cerebral hemodynamics,"A healthy human brain is perfused with blood flowing laminarly through cerebral vessels, providing brain tissue with substrates such as oxygen and glucose. Under normal conditions, cerebral blood flow is controlled by autoregulation as well as metabolic, chemical and neurogenic regulation. Physiological complexity of these mechanisms invariably leads to a question as to what are the relations between the statistical properties of arterial and intracranial pressure fluctuations. To shed new light on cerebral hemodynamics, we employ a complex continuous wavelet transform to determine the instantaneous phase difference between the arterial blood pressure (ABP) and intracranial pressure (ICP) in patients with traumatic brain injuries or spontaneous cerebral hemorrhage. For patients with mild to moderate injury, the phase difference slowly evolves in time. However, severe neurological injury with elevated ICP are herein associated with synchronization of arterial and intracranial pressure. We use Shannon entropy to quantify the stability of ABP-ICP phase difference and discuss the clinical applicability of such measure to assessment of cerebrovascular reactivity and autoregulation integrity.","4 pages, 4 figures","Miroslaw Latka, Malgorzata Turalska, Waldemar Kolodziej, Dariusz Latka, Brahm Goldstein, Bruce J. West",quantitative biology,test
Complex Systems Analysis of Cell Cycling Models in Carcinogenesis,"Carcinogenesis is a complex process that involves dynamically inter-connected modular sub-networks that evolve under the influence of micro-environmentally induced perturbations, in non-random, pseudo-Markov chain processes. An appropriate n-stage model of carcinogenesis involves therefore n-valued Logic treatments of nonlinear dynamic transformations of complex functional genomes and cell interactomes. Lukasiewicz Algebraic Logic models of genetic networks and signaling pathways in cells are formulated in terms of nonlinear dynamic systems with n-state components that allow for the generalization of previous, Boolean or ""fuzzy"", logic models of genetic activities in vivo. Such models are then applied to cell transformations during carcinogenesis based on very extensive genomic transcription and translation data from the CGAP databases supported by NCI. Such models are represented in a Lukasiewicz-Topos with an n-valued Lukasiewicz Algebraic Logics subobject classifier description that represents non-random and nonlinear network activities as well as their transformations in carcinogeness. Specific models for different types of cancer are then derived from representations of the dynamic state-space of LT non-random, pseudo-Markov chain process, network models in terms of cDNA and proteomic, high throughput analyses by ultra-sensitive techniques. This novel theoretical analysis is based on extensive CGAP genomic data for human tumors, as well as recently published studies of cyclin signaling. Several such specific models suggest novel clinical trials and rational therapies of cancer through re-establishment of cell cycling inhibition in stage III cancers.","23 pages, 1 Figure",I. C. Baianu,quantitative biology,val
"Applications of Novel Techniques to Health Foods, Medical and Agricultural Biotechnology","Selected applications of novel techniques in Agricultural Biotechnology, Health Food formulations and Medical Biotechnology are being reviewed with the aim of unraveling future developments and policy changes that are likely to open new niches for Biotechnology and prevent the shrinking or closing the existing ones. Amongst the selected novel techniques with applications to both Agricultural and Medical Biotechnology are: immobilized bacterial cells and enzymes, microencapsulation and liposome production, genetic manipulation of microorganisms, development of novel vaccines from plants, epigenomics of mammalian cells and organisms, as well as biocomputational tools for molecular modeling related to disease and Bioinformatics. Both fundamental and applied aspects of the emerging new techniques are being discussed in relation to their anticipated impact on future biotechnology applications together with policy changes that are needed for continued success in both Agricultural and Medical Biotechnology. Several novel techniques are illustrated in an attempt to convey the most representative and powerful tools that are currently being developed for both immediate and long term applications in Agriculture, Health Food formulation and production, pharmaceuticals and Medicine. The research aspects are naturally emphasized in our review as they are key to further developments in Medical and Agricultural Biotechnology.",39 pages and 9 figures,"I. C. Baianu, P. R. Lozano, V. I. Prisecaru, H. C. Lin",quantitative biology,train
Vaccination pattern affects immunological response,The response of the immune system to different vaccination patterns is studied with a simple model. It is argued that the history and characteristics of the pattern defines very different secondary immune responses in the case of infection. The memory function of the immune response can be set to work in very different modes depending on the pattern followed during immunizations. It is argued that the history and pattern of immunizations can be a decisive (and experimentally accessible) factor to tailor the effectiveness of a specific vaccine.,"4 pages, five figures",P. Etchegoin,quantitative biology,train
"Mathematics, Biology, and Physics: Interactions and Interdependence","This paper traces the seminal roles that physicists and mathematicians have played in the conceptual development of the biological sciences in the past, and especially in the 19th and 20th centuries.",12 pages,"Michael C. Mackey, Moises Santillan",quantitative biology,test
1/f Scaling in Heart Rate Requires Antagonistic Autonomic Control,"We present the first systematic evidence for the origins of 1/f-type temporal scaling in human heart rate. The heart rate is regulated by the activity of two branches of the autonomic nervous system: the parasympathetic (PNS) and the sympathetic (SNS) nervous systems. We examine alterations in the scaling property when the balance between PNS and SNS activity is modified, and find that the relative PNS suppression by congestive heart failure results in a substantial increase in the Hurst exponent H towards random walk scaling $1/f^{2}$ and a similar breakdown is observed with relative SNS suppression by primary autonomic failure. These results suggest that 1/f scaling in heart rate requires the intricate balance between the antagonistic activity of PNS and SNS.","4 pages, 3 figures, to appear in Phys. Rev. E (2004)","Zbigniew R. Struzik, Junichiro Hayano, Seiichiro Sakata, Shin Kwak, Yoshiharu Yamamoto",quantitative biology,train
"SARS oubreaks in Ontario, Hong Kong and Singapore: the role of diagnosis and isolation as a control mechanism","In this article we use global and regional data from the SARS epidemic in conjunction with a model of susceptible, exposed, infective, diagnosed, and recovered classes of people (``SEIJR'') to extract average properties and rate constants for those populations. The model is fitted to data from the Ontario (Toronto) in Canada, Hong Kong in China and Singapore outbreaks and predictions are made based on various assumptions and observations, including the current effect of isolating individuals diagnosed with SARS. The epidemic dynamics for Hong Kong and Singapore appear to be different from the dynamics in Toronto, Ontario. Toronto shows a very rapid increase in the number of cases between March 31st and April 6th, followed by a {\it significant} slowing in the number of new cases. We explain this as the result of an increase in the diagnostic rate and in the effectiveness of patient isolation after March 26th. Our best estimates are consistent with SARS eventually being contained in Toronto, although the time of containment is sensitive to the parameters in our model. It is shown that despite the empirically modeled heterogeneity in transmission, SARS' average reproductive number is 1.2, a value quite similar to that computed for some strains of influenza \cite{CC2}. Although it would not be surprising to see levels of SARS infection higher than ten per cent in some regions of the world (if unchecked), lack of data and the observed heterogeneity and sensitivity of parameters prevent us from predicting the long-term impact of SARS.","16 pages, 3 tables, 4 figures","Gerardo Chowell, Paul W. Fenimore, Melissa A. Castillo-Garsow, Carlos Castillo-Chavez",quantitative biology,train
The Basic Reproductive Number of Ebola and the Effects of Public Health Measures: The Cases of Congo and Uganda,"Despite improved control measures, Ebola remains a serious public health risk in African regions where recurrent outbreaks have been observed since the initial epidemic in 1976. Using epidemic modeling and data from two well-documented Ebola outbreaks (Congo 1995 and Uganda 2000), we estimate the number of secondary cases generated by an index case in the absence of control interventions ($R_0$). Our estimate of $R_0$ is 1.83 (SD 0.06) for Congo (1995) and 1.34 (SD 0.03) for Uganda (2000). We model the course of the outbreaks via an SEIR (susceptible-exposed-infectious-removed) epidemic model that includes a smooth transition in the transmission rate after control interventions are put in place. We perform an uncertainty analysis of the basic reproductive number $R_0$ to quantify its sensitivity to other disease-related parameters. We also analyze the sensitivity of the final epidemic size to the time interventions begin and provide a distribution for the final epidemic size. The control measures implemented during these two outbreaks (including education and contact tracing followed by quarantine) reduce the final epidemic size by a factor of 2 relative the final size with a two-week delay in their implementation.","27 pages, 7 figures","Gerardo Chowell, Nick W. Hengartner, Carlos Castillo-Chavez, Paul W. Fenimore, J. M. Hyman",quantitative biology,train
Plant defense multigene families: I. Divergence of Fusarium solani-induced expression in Pisum and Lathyrus,"The defense response in plants challenged with pathogens is characterized by the activation of a diverse set of genes. Many of the same genes are induced in the defense responses of a wide range of plant species. How plant defense gene families evolve may therefore provide an important clue to our understanding of how disease resistance evolves. Because studies usually focus on a single host species, little data are available regarding changes in defense gene expression patterns as species diverge. The expression of defense-induced genes PR10, chitinase and chalcone synthase was assayed in four pea species (Pisum sativum, P. humile, P. elatius and P. fulvum) and two Lathyrus species (L. sativus and L. tingitanus) which exhibited a range of infection phenotypes with Fusarium solani . In P. sativum, resistance was accompanied by a strong induction of defense genes at 8 hr. post-inoculation. Weaker induction was seen in susceptible interactions in wild species. Divergence in the timing of PR10 expression was most striking between P. sativum and its closest realtive, P. humile. Two members of this multigene family, designated PR10.1 and PR10.2, are strongly-expressed in response to Fusarium, while the PR10.3 gene is more weakly expressed, among Pisum species. The rapidity with which PR10 expression evolves raises the question, is divergence of defense gene expression a part of the phenotypic diversity underlying plant/pathogen coevolution?","13 pages, 6 figures arXiv reference added to first page; minor
  formatting changes","Sandhya Tewari, Stuart M. Brown, Brian Fristensky",quantitative biology,train
Complexity and hierarchical game of life,"Hierarchical structure is an essential part of complexity, important notion relevant for a wide range of applications ranging from biological population dynamics through robotics to social sciences. In this paper we propose a simple cellular-automata tool for study of hierarchical population dynamics.",,"Ivan Gotz, Isaak Rubinstein, Eugene Tsvetkov, Boris Zaltzman",quantitative biology,train
Dynamics of Fixation of Advantageous Mutations,"We investigate the process of fixation of advantageous mutations in an asexual population. We assume that the effect of each beneficial mutation is exponentially distributed with mean value $\omega_{med}=1/\beta$. The model also considers that the effect of each new deleterious mutation reduces the fitness of the organism independent on the previous number of mutations. We use the branching process formulation and also extensive simulations to study the model. The agreement between the analytical predictions and the simulational data is quite satisfactory. Surprisingly, we observe that the dependence of the probability of fixation $P_{fix}$ on the parameter $\omega_{med}$ is precisely described by a power-law relation, $P_{fix} \sim \omega_{med}^{\gamma}$. The exponent $\gamma$ is an increase function of the rate of deleterious mutations $U$, whereas the probability $P_{fix}$ is a decreasing function of $U$. The mean value $\omega_{fix}$ of the beneficial mutations which reach ultimate fixation depends on $U$ and $\omega_{med}$. The ratio $\omega_{fix}/\omega_{med}$ increases as we consider higher values of mutation value $U$ in the region of intermediate to large values of $\omega_{med}$, whereas for low $\omega_{med}$ we observe the opposite behavior.",13 pages,"Viviane M. de Oliveira, Paulo R. A. Campos",quantitative biology,val
Phase transition and selection in a four-species cyclic Lotka-Volterra model,"We study a four species ecological system with cyclic dominance whose individuals are distributed on a square lattice. Randomly chosen individuals migrate to one of the neighboring sites if it is empty or invade this site if occupied by their prey. The cyclic dominance maintains the coexistence of all the four species if the concentration of vacant sites is lower than a threshold value. Above the treshold, a symmetry breaking ordering occurs via growing domains containing only two neutral species inside. These two neutral species can protect each other from the external invaders (predators) and extend their common territory. According to our Monte Carlo simulations the observed phase transition is equivalent to those found in spreading models with two equivalent absorbing states although the present model has continuous sets of absorbing states with different portions of the two neutral species. The selection mechanism yielding symmetric phases is related to the domain growth process whith wide boundaries where the four species coexist.","4 pages, 5 figures","Gyorgy Szabo, Gustavo Arial Sznaider",quantitative biology,train
The Evolution of tRNA-Leu Genes in Animal Mitochondrial Genomes,"Animal mitochondrial genomes usually have two transfer RNAs for Leucine: one, with anticodon UAG, translates the four-codon family CUN, whilst the other, with anticodon UAA, translates the two-codon family UUR. These two genes must differ at the third anticodon position, but in some species the genes differ at many additional sites, indicating that these genes have been independent for a long time. Duplication and deletion of genes in mitochondrial genomes occurs frequently during the evolution of the Metazoa. If a tRNA-Leu gene were duplicated and a substitution occurred in the anticodon, this would effectively turn one type of tRNA into the other. The original copy of the second tRNA type might then be lost by a deletion elsewhere in the genome. There are several groups of species in which the two tRNA-Leu genes occur next to one another (or very close) on the genome, which suggests that tandem duplication has occurred. Here we use RNA-specific phylogenetic methods to determine evolutionary trees for both genes. We present evidence that the process of duplication, anticodon mutation and deletion of tRNA-Leu genes has occurred at least five times during the evolution of the Metazoa - once in the common ancestor of all Protostomes, once in the common ancestor of Echinoderms and Hemichordates, once in the hermit crab, and twice independently in Molluscs.","20 pages, 6 figures. J. Mol. Evol. (in press)","P. G. Higgs, D. Jameson, H. Jow, M. Rattray",quantitative biology,val
"Computer simulations of history of life: speciation, emergence of complex species from simpler organisms, and extinctions","We propose a generic model of eco-systems, with a {\it hierarchical} food web structure. In our computer simulations we let the eco-system evolve continuously for so long that that we can monitor extinctions as well as speciations over geological time scales. {\it Speciation} leads not only to horizontal diversification of species at any given trophic level but also to vertical bio-diversity that accounts for the emergence of complex species from simpler forms of life. We find that five or six trophic levels appear as the eco-system evolves for sufficiently long time, starting initially from just one single level. Moreover, the time intervals between the successive collections of ecological data is so short that we could also study ``micro''-evolution of the eco-system, i.e., the birth, ageing and death of individual organisms.","7 pages, including 4 EPS figures, REVTEX","Debashish Chowdhury, Dietrich Stauffer",quantitative biology,train
An asymptotic maximum principle for essentially linear evolution models,"Recent work on mutation-selection models has revealed that, under specific assumptions on the fitness function and the mutation rates, asymptotic estimates for the leading eigenvalue of the mutation-reproduction matrix may be obtained through a low-dimensional maximum principle in the limit N to infinity (where N is the number of types). In order to extend this variational principle to a larger class of models, we consider here a family of reversible N by N matrices and identify conditions under which the high-dimensional Rayleigh-Ritz variational problem may be reduced to a low-dimensional one that yields the leading eigenvalue up to an error term of order 1/N. For a large class of mutation-selection models, this implies estimates for the mean fitness, as well as a concentration result for the ancestral distribution of types.","31 pages, 2 figures. Thorough revision, additional material included.
  J. Math. Biol., in press","E. Baake, M. Baake, A. Bovier, M. Klein",quantitative biology,train
Cellular automaton for bacterial towers,"A simulation approach to the stochastic growth of bacterial towers is presented, in which a non-uniform and finite nutrient supply essentially determines the emerging structure through elementary chemotaxis. The method is based on cellular automata and we use simple, microscopic, local rules for bacterial division in nutrient-rich surroundings. Stochastic nutrient diffusion, while not crucial to the dynamics of the total population, is influential in determining the porosity of the bacterial tower and the roughness of its surface. As the bacteria run out of food, we observe an exponentially rapid saturation to a carrying capacity distribution, similar in many respects to that found in a recently proposed phenomenological hierarchical population model, which uses heuristic parameters and macroscopic rules. Complementary to that phenomenological model, the simulation aims at giving more microscopic insight into the possible mechanisms for one of the recently much studied bacterial morphotypes, known as ""towering biofilm"", observed experimentally using confocal laser microscopy. A simulation suggesting a mechanism for biofilm resistance to antibiotics is also shown.",,"J. O. Indekeu, C. V. Giuraniuc",quantitative biology,train
Adaptation and enslavement in endosymbiont-host associations,"The evolutionary persistence of symbiotic associations is a puzzle. Adaptation should eliminate cooperative traits if it is possible to enjoy the advantages of cooperation without reciprocating - a facet of cooperation known in game theory as the Prisoner's Dilemma. Despite this barrier, symbioses are widespread, and may have been necessary for the evolution of complex life. The discovery of strategies such as tit-for-tat has been presented as a general solution to the problem of cooperation. However, this only holds for within-species cooperation, where a single strategy will come to dominate the population. In a symbiotic association each species may have a different strategy, and the theoretical analysis of the single species problem is no guide to the outcome. We present basic analysis of two-species cooperation and show that a species with a fast adaptation rate is enslaved by a slowly evolving one. Paradoxically, the rapidly evolving species becomes highly cooperative, whereas the slowly evolving one gives little in return. This helps understand the occurrence of endosymbioses where the host benefits, but the symbionts appear to gain little from the association.","v2: Correction made to equations 5 & 6 v3: Revised version accepted
  in Phys. Rev. E; New figure added","Marcus R. Frean, Edward R. Abraham",quantitative biology,train
Modelling of SARS for Hong Kong,"A simplified susceptible-infected-recovered (SIR) epidemic model and a small-world model are applied to analyse the spread and control of Severe Acute Respiratory Syndrome (SARS) for Hong Kong in early 2003. From data available in mid April 2003, we predict that SARS would be controlled by June and nearly 1700 persons would be infected based on the SIR model. This is consistent with the known data. A simple way to evaluate the development and efficacy of control is described and shown to provide a useful measure for the future evolution of an epidemic. This may contribute to improve strategic response from the government. The evaluation process here is universal and therefore applicable to many similar homogeneous epidemic diseases within a fixed population. A novel model consisting of map systems involving the Small-World network principle is also described. We find that this model reproduces qualitative features of the random disease propagation observed in the true data. Unlike traditional deterministic models, scale-free phenomena are observed in the epidemic network. The numerical simulations provide theoretical support for current strategies and achieve more efficient control of some epidemic diseases, including SARS.","6 pages, 8 figures","Pengliang Shi, Michael Small",quantitative biology,train
Probabilistic estimation of microarray data reliability and underlying gene expression,"Background: The availability of high throughput methods for measurement of mRNA concentrations makes the reliability of conclusions drawn from the data and global quality control of samples and hybridization important issues. We address these issues by an information theoretic approach, applied to discretized expression values in replicated gene expression data. Results: Our approach yields a quantitative measure of two important parameter classes: First, the probability $P(\sigma | S)$ that a gene is in the biological state $\sigma$ in a certain variety, given its observed expression $S$ in the samples of that variety. Second, sample specific error probabilities which serve as consistency indicators of the measured samples of each variety. The method and its limitations are tested on gene expression data for developing murine B-cells and a $t$-test is used as reference. On a set of known genes it performs better than the $t$-test despite the crude discretization into only two expression levels. The consistency indicators, i.e. the error probabilities, correlate well with variations in the biological material and thus prove efficient. Conclusions: The proposed method is effective in determining differential gene expression and sample reliability in replicated microarray data. Already at two discrete expression levels in each sample, it gives a good explanation of the data and is comparable to standard techniques.","11 pages, 4 figures","S. Bilke, T. Breslin, M. Sigvardsson",quantitative biology,val
Development of a Multiphoton Fluorescence Lifetime Imaging Microscopy (FLIM) system using a Streak Camera,We report the development and detailed calibration of a multiphoton fluorescence lifetime imaging system (FLIM) using a streak camera. The present system is versatile with high spatial (0.2 micron) and temporal (50 psec) resolution and allows rapid data acquisition and reliable and reproducible lifetime determinations. The system was calibrated with standard fluorescent dyes and the lifetime values obtained were in very good agreement with values reported in literature for these dyes. We also demonstrate the applicability of the system to FLIM studies in cellular specimens including stained pollen grains and fibroblast cells expressing green fluorescent protein. The lifetime values obtained matched well with those reported earlier by other groups for these same specimens. Potential applications of the present system include the measurement of intracellular physiology and Fluorescence Resonance Energy Transfer (FRET) imaging which are discussed in the context of live cell imaging.,,"R. V. Krishnan, H. Saitoh, H. Terada, V. E. Centonze, B. Herman",quantitative biology,train
Idl Signal Processing Library 1.0,"We make available a library of documented IDL .pro files as well as a shareable object library that allows IDL to call routines from LAPACK. The routines are for use in the spectral analysis of time series data. The primary focus of these routines are David Thomson's multitaper methods but a whole range of functions will be made available in future revisions of the submission. At present routines are provided to carry out the following operations: calculate prolate spheroidal sequences and eigenvalues, project time-series into frequency bands, calculate spectral estimates with or without moving windows, and calculate the cross-coherence between two time series as a function of frequency as well as the coherence between frequencies for a single time series.","13 IDL .pro files, 1 .html file, 1 .ps file, 1 license file. Download
  the source for the IDL files (save as .tar.gz) Read idl_lib.ps for
  instructions on use. Originally submitted to the neuro-sys archive which was
  never publicly announced (was 9801001)","B. Pesaran, P. P. Mitra",quantitative biology,train
Response kinetics of tethered bacteria to stepwise changes in nutrient concentration,"We examined the changes in swimming behaviour of the bacterium Rhodobacter sphaeroides in response to stepwise changes in a nutrient (propionate), following the prestimulus motion, the initial response and the adaptation to the sustained concentration of the chemical. This was carried out by tethering motile cells by their flagella to glass slides and following the rotational behaviour of their cell bodies in response to the nutrient change. Computerised motion analysis was used to analyse the behaviour. Distributions of run and stop times were obtained from rotation data for tethered cells. Exponential and Weibull fits for these distributions, and variability in individual responses are discussed. In terms of parameters derived from the run and stop time distributions, we compare the responses to stepwise changes in the nutrient concentration and the long-term behaviour of 84 cells under twelve propionate concentration levels from 1 nM to 25 mM. We discuss traditional assumptions for the random walk approximation to bacterial swimming and compare them with the observed R. sphaeroides motile behaviour.","11 pages, 7 figures, in press in BioSystems","Anna A. Chernova, Judith P. Armitage, Helen L. Packer, Philip K. Maini",quantitative biology,val
Solvent content of protein crystals from diffraction intensities by Independent Component Analysis,"An analysis of the protein content of several crystal forms of proteins has been performed. We apply a new numerical technique, the Independent Component Analysis (ICA), to determine the volume fraction of the asymmetric unit occupied by the protein. This technique requires only the crystallographic data of structure factors as input.","9 pages, 2 figures, 1 table","Antonio Lamura, Massimo Ladisa, Giovanni Nico, Dritan Siliqi",quantitative biology,train
Identification in models of biochemical reactions,"We introduce, analyze, and implement a new method for parameter identification for system of ordinary differential equations that are used to model sets of biochemical reactions. Our method relies on the integral formulation of the ODE system and a method of linear least squares applied to the integral equations. Certain variants of this method are also introduced in this paper.","39 pages, 8 figures","S. A. Belbas, Suhnghee Kim",quantitative biology,train
Microelectromagnets for the manipulation of biological systems,"Microelectromagnet devices, a ring trap and a matrix, were developed for the microscopic control of biological systems. The ring trap is a circular Au wire with an insulator on top. The matrix has two arrays of straight Au wires, one array perpendicular to the other, that are separated and topped by insulating layers. Microelectromagnets can produce strong magnetic fields to stably manipulate magnetically tagged biological systems in a fluid. Moreover, by controlling the currents flowing through the wires, a microelectromagnet matrix can move a peak in the magnetic field magnitude continuously over the surface of the device, generate multiple peaks simultaneously and control them independently. These capabilities of a matrix can be used to trap, continuously transport, assemble, separate and sort biological samples on micrometer length scales. Combining microelectromagnets with microfluidic systems, chip-based experimental systems can be realized for novel applications in biological and biomedical studies.","20 pages, 6 figures","H. Lee, A. M. Purdon, R. M. Westervelt",quantitative biology,train
A Barrier Penetration Model for DNA Double Strand Separation,A barrier penetration model has been proposed to explain the spontaneous melting of the DNA oligomers into two separate single strands whereas the partially melted intermediate states are shown to be the bound state solution of the same effective potential that generates the barrier.,"32 pages, 8 figures",Ajit Kumar Mohanty,quantitative biology,train
Open Mass Spectrometry Search Algorithm,"Large numbers of MS/MS peptide spectra generated in proteomics experiments require efficient, sensitive and specific algorithms for peptide identification. In the Open Mass Spectrometry Search Algorithm [OMSSA], specificity is calculated by a classic probability score using an explicit model for matching experimental spectra to sequences. At default thresholds, OMSSA matches more spectra from a standard protein cocktail than a comparable algorithm. OMSSA is designed to be faster than published algorithms in searching large MS/MS datasets.",,"Lewis Y. Geer, Sanford P. Markey, Jeffrey A. Kowalak, Lukas Wagner, Ming Xu, Dawn M. Maynard, Xiaoyu Yang, Wenyao Shi, Stephen H. Bryant",quantitative biology,train
Finite Width Model Sequence Comparison,"Sequence comparison is a widely used computational technique in modern molecular biology. In spite of the frequent use of sequence comparisons the important problem of assigning statistical significance to a given degree of similarity is still outstanding. Analytical approaches to filling this gap usually make use of an approximation that neglects certain correlations in the disorder underlying the sequence comparison algorithm. Here, we use the longest common subsequence problem, a prototype sequence comparison problem, to analytically establish that this approximation does make a difference to certain sequence comparison statistics. In the course of establishing this difference we develop a method that can systematically deal with these disorder correlations.",,"Ralf Bundschuh, Nicholas Chia",quantitative biology,train
Bi-Phasic Vesicles: instability induced by adsorption of proteins,"The recent discovery of a lateral organization in cell membranes due to small structures called 'rafts' has motivated a lot of biological and physico-chemical studies. A new experiment on a model system has shown a spectacular budding process with the expulsion of one or two rafts when one introduces proteins on the membrane. In this paper, we give a physical interpretation of the budding of the raft phase. An approach based on the energy of the system including the presence of proteins is used to derive a shape equation and to study possible instabilities. This model shows two different situations which are strongly dependent on the nature of the proteins: a regime of easy budding when the proteins are strongly coupled to the membrane and a regime of difficult budding.",19 avr. 2004,"Jean-Marc Allain, Martine Ben Amar",quantitative biology,train
Turbulence near cyclic fold bifurcations in birhythmic media,"We show that at the onset of a cyclic fold bifurcation, a birhythmic medium composed of glycolytic oscillators displays turbulent dynamics. By computing the largest Lyapunov exponent, the spatial correlation function, and the average transient lifetime, we classify it as a weak turbulence with transient nature. Virtual heterogeneities generating unstable fast oscillations are the mechanism of the transient turbulence. In the presence of wavenumber instability, unstable oscillations can be reinjected leading to stationary turbulence. We also find similar turbulence in a cell cycle model. These findings suggest that weak turbulence may be universal in biochemical birhythmic media exhibiting cyclic fold bifurcations.",14 pages 10 figures,"Dorjsuren Battogtokh, John J. Tyson",quantitative biology,train
Modeling stochastic Ca$^{2+}$ release from a cluster of IP$_3$-sensitive receptors,"We focused our attention on Ca$^{2+}$ release from the endoplasmic reticulum through a cluster of inositol 1,4,5-trisphosphate (IP$_3$) receptor channels. The random opening and closing of these receptors introduce stochastic effects that have been observed experimentally. Here, we present a stochastic version of Othmer-Tang model for IP$_3$ receptor clusters. We address the average behavior of the channels in response to IP$_3$ stimuli. We found, by stochastic simulation, that the shape of the receptor response to IP$_3$ (fraction of open channels versus [IP$_3$]), is affected by the cytosolic Ca$^{2+}$ level. We also study several aspects of the stochastic properties of Ca${2+}$ release and we compare with experimental observations.","25 pages 10 figures, revised version",Luis Diambra,quantitative biology,val
Phase Transition in Reconstituted Chromatin,"By observing reconstituted chromatin by fluorescence microscopy (FM) and atomic force microscopy (AFM), we found that the density of nucleosomes exhibits a bimodal profile, i.e., there is a large transition between the dense and dispersed states in reconstituted chromatin. Based on an analysis of the spatial distribution of nucleosome cores, we deduced an effective thermodynamic potential as a function of the nucleosome-nucleosome distance. This enabled us to interpret the folding transition of chromatin in terms of a first-order phase transition. This mechanism for the condensation of chromatin is discussed in terms of its biological significance.","16 pages, 3 figures","Tonau Nakai, Kohji Hizume, Shige. H. Yoshimura, Kunio Takeyasu, Kenichi Yoshikawa",quantitative biology,train
"Pattern formation within Escherichia coli: diffusion, membrane attachment, and self-interaction of MinD molecules","In E. coli, accurate cell division depends upon the oscillation of Min proteins from pole to pole. We provide a model for the polar localization of MinD based only on diffusion, a delay for nucleotide exchange, and different rates of attachment to the bare membrane and the occupied membrane. We derive analytically the probability density, and correspondingly the length scale, for MinD attachment zones. Our simple analytical model illustrates the processes giving rise to the observed localization of cellular MinD zones.","4 pages, 3 figures, submitted to PRL","Rahul V. Kulkarni, Kerwyn Casey Huang, Morten Kloster, Ned S. Wingreen",quantitative biology,test
Observations of magnetic field induced contraction of fission yeast cells using optical projection microscopy,"The charges in live cells interact with or produce electric fields, which results in enormous dielectric responses, flexoelectricity, and related phenomena. Here we report on a contraction of schizosacchraoymces pombe (fission yeast) cells induced by magnetic fields, as observed using a phase sensitive projection image technique. Unlike electric fields, magnetic fields only act on moving charges. The observed behavior is quite remarkable, and may result from a contractile Lorentz force acting on diamagnetic screening currents. This would indicate extremely high intracellular charge mobilities. Besides, we observed a large electro - optical response from fission yeast cells.","13 pages, four sets of figures, accepted for publication in CEJP,
  October 2004","Xi Yang, Andrew Beckwith",quantitative biology,test
Collective charge excitations along cell membranes,"A significant part of the thin layers of counter-ions adjacent to the exterior and interior surfaces of a cell membrane form quasi-two-dimensional (2D) layers of mobile charge. Collective charge density oscillations, known as plasmon modes, in these 2D charged systems of counter-ions are predicted in the present paper. This is based on a calculation of the self-consistent response of this system to a fast electric field fluctuation. The possibility that the membrane channels might be using these excitations to carry out fast communication is suggested and experiments are proposed to reveal the existence of such excitations.","4 two-column pages, 3 figures",Efstratios Manousakis,quantitative biology,train
The dynamics of the min proteins of Escherichia coli under the constant external fields,"In E. coli the determination of the middle of the cell and the proper placement of the septum is essential to the division of the cell. This step depends on the proteins MinC, MinD, and MinE. Exposure to a constant external field e.g., an electric field or magnetic field may cause the bacteria cell division mechanism to change resulting in an abnormal cytokinesis. To have insight into the effects of an external field on this process, we model the process using a set of the deterministic reaction diffusion equations, which incorporate the influence of an external field, min protein reactions, and diffusion of all species. Using the numerical method, we have found some changes in the dynamics of the oscillations of the min proteins from pole to pole when compared that of without the external field. The results show some interesting effects, which are qualitatively in good agreement with some experimental results.","25 pages, 11 figures","Paisan Kanthang, Waipot Ngamsaad, Charin Modchang, Wannapong Triampo, Narin Nuttawut, I-Ming Tang, Yongwimol Lenbury",quantitative biology,val
Competing Polymerization of Actin Skeleton explains Relation between Network Polarity and Cell Movements,"Based on experimental observations it is known that various biological cells exhibit a persistent random walk during migration on flat substrates. The persistent random walk is characterized by `stop-and-go' movements : unidirectional motions over distances of the order of several cell diameter are separated by localized short time erratic movements. Using computer simulations the reasons for this phenomena had been unveiled and shown to be attributed to two antagonistic nucleation processes during the polymerization of the cell's actin cytoskeleton : the (ordinary) spontaneous nucleation and the dendritic nucleation processes. Whereas spontaneous nucleations generate actin filaments growing in different directions and hence create motions in random directions, dendritic nucleations provide a unidirectional growth. Since dendritic growth exhibits stochastic fluctuations, spontaneous nucleation may eventually compete or even dominate, which results in a reorientation of filament growth and hence a new direction of cell motion. The event of reorientation takes place at instants of vanishing polarity of the actin skeleton.","13 pages, 5 figures","B. Nandy, A. Baumgaertner",quantitative biology,val
Uncorrelated two-state single molecule trajectories from reducible kinetic schemes,"Trajectories of on-off events are the output of many single molecule experiments. Usually, one describes the underlying mechanism that generates the trajectory using a kinetic scheme, and by analyzing the trajectory aims at deducing this scheme. In a previous work [O. Flomenbom, J. Klafter, and A. Szabo, submitted (2004)], we showed that when successive events along a trajectory are uncorrelated, all the information in the trajectory is contained in two basic functions, which are the waiting time probability functions (PDFs) of the on state and of the off state. The kinetic schemes that lead to such uncorrelated trajectories were termed reducible. Here we discuss the reasons that lead to reducible schemes. In particular, the topology of reducible schemes is characterized and proven.",,"Ophir Flomenbom, Joseph Klafter",quantitative biology,val
Control of spiral waves and turbulent states in a cardiac model by travelling-wave perturbations,We propose a travelling-wave perturbation method to control the spatiotemporal dynamics in a cardiac model. It is numerically demonstrated that the method can successfully suppress the wave instability (alternans in action potential duration) in the one-dimensional case and convert spiral waves and turbulent states to the normal travelling wave states in the two-dimensional case. An experimental scheme is suggested which may provide a new design for a cardiac defibrillator.,"9 pages, 5 figures","Peng-Ye Wang, Ping Xie, Hua-Wei Yin",quantitative biology,test
To a Problem of Not Increasing Dynamic Compliance at Asthma Patients with Ventilating Disorders after Berotec Inhalation,"The purpose of research was to check up the influence of decrease of nonequality of ventilating (after bronchodilator (berotec) inhalation (BI)) on the magnitude of dynamic compliance of lungs (Cdyn) at asthma patients with ventilating infringements. Methods and materials: 20 patients (with 2 and 3 degrees of ventilating infringements (VC<73%, FEV1<51%, MVV<56%), without restrictive disease of lungs, suffering from bronchial asthma were studied before and after BI by plotting volume, rate flow, against the transpulmonare pressure. About the change of nonequality of ventilating we consider by the change after BI of Cdyn, Cdyn at once after flow interruption (Cdyn1), tissue resistance at inhalation (Rti in) and exhalation (Rti ex), parameters of ventilating and general parameters of respiratory mechanics. Results: the parameters of ventilating were improved (P < 0,05). General parameters of respiratory mechanics also improved. Rti in and Rti ex are made 0,48+0,16; 1,05+0,25 kPa/l/s before BI and decreased 0,09+0,04; 0,28+0,09 kPa/l/s after BI (P < 0,05; P < 0,05). But Cdyn and Cdyn1 are not changed after BI. Conclusions: 1. The decrease of ventilation nonequality and tissue friction after BI do not influence on the initially reduced dynamic compliance of lungs at asthma patients without any restrictive diseases of lungs. 2. The cause of not increasing of dynamic compliance after BI probably due by changes in elastic component of parenchyma of lungs, insensitive to berotec.","9 pages, 1 figure, 2 tables. Submitted ERJ-00766-2002",Konstantin F. Tetenev,quantitative biology,train
Dynamics of Acute Inflammation,"When the body is infected, it mounts an acute inflammatory response to rid itself of the pathogens and restore health. Uncontrolled acute inflammation due to infection is defined clinically as Sepsis and can culminate in organ failure and death. We consider a three dimensional ordinary differential equation model of inflammation consisting of a pathogen, and two inflammatory mediators. The model reproduces the healthy outcome and diverse negative outcomes, depending on initial conditions and parameters.when key parameters are changed and suggest various therapeutic strategies. We suggest that the clinical condition of sepsis can arise from several distinct physiological states, each of which requires a different treatment approach. We analyze the various bifurcations between the different outcomes","27 pages, 9 figures, Accepted by the Journal of Theoretical Biology","Rukmini Kumar, Gilles Clermont, Yoram Vodovotz, Carson Chow",quantitative biology,train
On tumor development: fractional transport approach,"A growth of malignant neoplasm is considered as a fractional transport approach. We suggested that the main process of the tumor development through a lymphatic net is fractional transport of cells. In the framework of this fractional kinetics we were able to show that the mean size of main growth is due to subdiffusion, while the appearance of metaphases is determined by superdiffusion.",,"A. Iomin, S. Dorfman, L. Dorfman",quantitative biology,train
Periodic Oscillations of Blood Cell Populations in Chronic Myelogenous Leukemia,"We develop some techniques to prove analytically the existence and stability of long period oscillations of stem cell populations in the case of periodic chronic myelogenous leukemia. Such a periodic oscillation $p_\infty $ can be analytically constructed when the hill coefficient involved in the nonlinear feedback is infinite, and we show it is possible to obtain a contractive returning map (for the semiflow defined by the modeling functional differential equation) in a closed and convex cone containing $p_\infty $ when the hill coefficient is large, and the fixed point of such a contractive map gives the long period oscillation previously observed both numerically and experimentally.",23 pages,"Michael C. Mackey, Chunhua Ou, Laurent Pujo-Menjouet, Jianhong Wu",quantitative biology,val
Oscillations in a maturation model of blood cell production,"In this paper we use a continuous model to describe the development of a single cell lineage following the committal of stem cells. Three separate controls are implemented in the model, namely the proliferative control of stem cells, the proliferative control of developing blast cells, and the peripheral control of stem cell committal by circulating blood cell density. We show that variation of parameters in all three control systems can cause oscillations, and that the characters of these oscillations are very different. This allows us some potential insight into the mechanisms that may be operative in some of the dynamic blood diseases like cyclical neutropenia and periodic chronic myelogenous leukemia.","24 pages, 11 figures","Ivana Drobnjak, A. C. Fowler, Michael C. Mackey",quantitative biology,val
Critical Scale-invariance in Healthy Human Heart Rate,"We demonstrate the robust scale-invariance in the probability density function (PDF) of detrended healthy human heart rate increments, which is preserved not only in a quiescent condition, but also in a dynamic state where the mean level of heart rate is dramatically changing. This scale-independent and fractal structure is markedly different from the scale-dependent PDF evolution observed in a turbulent-like, cascade heart rate model. These results strongly support the view that healthy human heart rate is controlled to converge continually to a critical state.","9 pages, 3 figures. Phys. Rev. Lett., to appear (2004)","Ken Kiyono, Zbigniew R. Struzik, Naoko Aoyagi, Seiichiro Sakata, Junichiro Hayano, Yoshiharu Yamamoto",quantitative biology,train
In vivo Cancer Marker in Mice,"This work introduces an in vivo marker in mice from the altitude of the well, determined by this cancer.The duration of development and the altitude of the cancer well are obtained from the synchronization of the mechanics and the kinetics of the processes of normal and anomalous transport under tumor mass growth.The mechanics and the kinetics of these two transports are found from the cancer fugacity.The cancer fugacity is defined as a photograph of the rate of the scaling exponent under tumor mass growth.",5 pages,"I. I. Trifonova, S. Z. Stefanov",quantitative biology,val
Energetic model of tumor growth,"A macroscopic model of the tumor Gompertzian growth is proposed. This approach is based on the energetic balance among the different cell activities, described by methods of statistical mechanics and related to the growth inhibitor factors. The model is successfully applied to the multicellular tumor spheroid data.","5 pages, 2 figures, contribution to ""Complexity, Metastability and
  Nonextensivity"", Erice, July 2004","Paolo Castorina, Dario Zappalá",quantitative biology,train
Telomere loss limits the rate of human epithelial tumor formation,"Most human carcinomas exhibit telomere abnormalities early in the carcinogenesis process suggesting that crisis caused by telomere shortening may be a necessary event leading to human carcinomas. Epidemiological records of the age at which each patient in a population develops carcinoma are known as age-incidence data; these provide a quantitative measure of human tumor initiation and dynamics. If crisis brought on by telomere shortening is necessary for most human carcinomas, it may also be the rate limiting step. To test this, we compared a mathematical model in which telomere loss is the rate limiting step during carcinogenesis with age-incidence data compiled by the Surveillance, Epidemiology and End Results (SEER) program. We found that this model adequately explains the age-incidence data. The model also implies that two distinct paths exist for carcinoma to develop in prostate, breast, and ovary tissues. We conclude that a single step, crisis brought on by telomere shortening, limits the rate of formation of human carcinomas.","15 pages, includes 7 figures","Hermann B. Frieboes, James P. Brody",quantitative biology,train
Optimal systems of subalgebras for a nonlinear Black-Scholes equation,"The main object of our study is a four dimensional Lie algebra which describes the symmetry properties of a nonlinear Black-Scholes model. This model implements a feedback effect which is typical for an illiquid market. The structure of the Lie algebra depends on one parameter, i.e. we have to do with a one-parametric family of algebras. We provide a classification of these algebras using Patera--Winternitz method. Optimal systems of one-, two- and three- dimensional subalgebras are described for the family of symmetry algebras of the nonlinear Black-Scholes equation. The optimal systems give us the possibility to describe a complete set of invariant solutions to the equation.",,Maxim Bobrov,quantitative finance,val
Bayesian inference with an adaptive proposal density for GARCH models,"We perform the Bayesian inference of a GARCH model by the Metropolis-Hastings algorithm with an adaptive proposal density. The adaptive proposal density is assumed to be the Student's t-distribution and the distribution parameters are evaluated by using the data sampled during the simulation. We apply the method for the QGARCH model which is one of asymmetric GARCH models and make empirical studies for for Nikkei 225, DAX and Hang indexes. We find that autocorrelation times from our method are very small, thus the method is very efficient for generating uncorrelated Monte Carlo data. The results from the QGARCH model show that all the three indexes show the leverage effect, i.e. the volatility is high after negative observations.",,Tetsuya Takaishi,quantitative finance,train
Markov Chain Monte Carlo on Asymmetric GARCH Model Using the Adaptive Construction Scheme,We perform Markov chain Monte Carlo simulations for a Bayesian inference of the GJR-GARCH model which is one of asymmetric GARCH models. The adaptive construction scheme is used for the construction of the proposal density in the Metropolis-Hastings algorithm and the parameters of the proposal density are determined adaptively by using the data sampled by the Markov chain Monte Carlo simulation. We study the performance of the scheme with the artificial GJR-GARCH data. We find that the adaptive construction scheme samples GJR-GARCH parameters effectively and conclude that the Metropolis-Hastings algorithm with the adaptive construction scheme is an efficient method to the Bayesian inference of the GJR-GARCH model.,"10 pages, 5 figures",Tetsuya Takaishi,quantitative finance,train
Defaultable bonds with an infinite number of Levy factors,A market with defaultable bonds where the bond dynamics is in a Heath-Jarrow-Morton setting and the forward rates are driven by an infinite number of Levy factors is considered. The setting includes rating migrations driven by a Markov chain. All basic types of recovery are investigated. We formulate necessary and sufficient conditions (generalized HJM conditions) under which the market is arbitrage free. Connections with consistency conditions are discussed.,24 pages,"Jacek Jakubowski, Mariusz Nieweglowski",quantitative finance,train
On the Performance of Delta Hedging Strategies in Exponential Lévy Models,"We consider the performance of non-optimal hedging strategies in exponential L\'evy models. Given that both the payoff of the contingent claim and the hedging strategy admit suitable integral representations, we use the Laplace transform approach of Hubalek et al. (2006) to derive semi-explicit formulas for the resulting mean squared hedging error in terms of the cumulant generating function of the underlying L\'evy process. In two numerical examples, we apply these results to compare the efficiency of the Black-Scholes hedge and the model delta to the mean-variance optimal hedge in a normal inverse Gaussian and a diffusion-extended CGMY L\'evy model.","25 pages, 5 figures. Second numerical example added","Stephan Denkl, Martina Goy, Jan Kallsen, Johannes Muhle-Karbe, Arnd Pauwels",quantitative finance,train
Appraisal of a contour integral method for the Black-Scholes and Heston equations,"A contour integral method recently proposed by Weideman [IMA J. Numer. Anal., to appear] for integrating semi-discrete advection-diffusion PDEs, is extended for application to some of the important equations of mathematical finance. Using estimates for the numerical range of the spatial operator, optimal contour parameters are derived theoretically and tested numerically. Test examples presented are the Black-Scholes PDE in one space dimension and the Heston PDE in two dimensions. In the latter case efficiency is compared to ADI splitting schemes for solving this problem. In the examples it is found that the contour integral method is superior for the range of medium to high accuracy requirements. Further improvements to the current implementation of the contour integral method are suggested.",Paper has been published,"K. J. in 't Hout, J. A. C. Weideman",quantitative finance,train
Simulation de trajectoires de processus continus,"Continuous time stochastic processes are useful models especially for financial and insurance purposes. The numerical simulation of such models is dependant of the time discrete discretization, of the parametric estimation and of the choice of a random number generator. The aim of this paper is to provide the tools for the practical implementation of diffusion processes simulation, particularly for insurance contexts.",,"Frédéric Planchet, Pierre-Emanuel Thérond",quantitative finance,test
Sequential optimizing investing strategy with neural networks,In this paper we propose an investing strategy based on neural network models combined with ideas from game-theoretic probability of Shafer and Vovk. Our proposed strategy uses parameter values of a neural network with the best performance until the previous round (trading day) for deciding the investment in the current round. We compare performance of our proposed strategy with various strategies including a strategy based on supervised neural network models and show that our procedure is competitive with other strategies.,,"Ryo Adachi, Akimichi Takemura",quantitative finance,train
Basket Options Valuation for a Local Volatility Jump-Diffusion Model with the Asymptotic Expansion Method,In this paper we discuss the basket options valuation for a jump-diffusion model. The underlying asset prices follow some correlated local volatility diffusion processes with systematic jumps. We derive a forward partial integral differential equation (PIDE) for general stochastic processes and use the asymptotic expansion method to approximate the conditional expectation of the stochastic variance associated with the basket value process. The numerical tests show that the suggested method is fast and accurate in comparison with the Monte Carlo and other methods in most cases.,"16 pages, 4 tables","Guoping Xu, Harry Zheng",quantitative finance,train
Computational LPPL Fit to Financial Bubbles,"The log-periodic power law (LPPL) is a model of asset prices during endogenous bubbles. If the on-going development of a bubble is suspected, asset prices can be fit numerically to the LPPL law. The best solutions can then indicate whether a bubble is in progress and, if so, the bubble critical time (i.e., when the bubble is expected to burst). Consequently, the LPPL model is useful only if the data can be fit to the model with algorithms that are accurate and computationally efficient. In this paper, we address primarily the computational efficiency and secondarily the precision of the LPPL non-linear least-square fit. Specifically, we present a parallel Levenberg-Marquardt algorithm (LMA) for LPPL least-square fit that sped up computation of more than a factor of four over a sequential LMA on historical and synthetic price series. Additionally, we isolate a linear sub-structure of the LPPL least-square fit that can be paired with an exact computation of the Jacobian, give new settings for the Levenberg-Marquardt damping factor, and describe a heuristic method to choose initial solutions.",,Vincenzo Liberatore,quantitative finance,test
A Dynamical Model of the Industrial Economy of the Humber Region,"The Humber region in the UK is a large and diverse industrial area centred around oil refining, chemical industries and energy production. However there is currently a desire to see the region transition towards a more bio-based economy. New bio-related industries are being situated in the region as a consequence of policy and economic incentives. Many of these industries are connected through their supply chains, either directly, or by sharing common suppliers or customers and the growth or decline of one industry can hence have impacts on many others. Therefore an important question to consider is what effect this movement towards bio-based industry will actually have on the regional economy as a whole. In this paper we develop a general abstract dynamical model for the metabolic interactions of firms or industries. This dynamical model has been applied to the Humber region in order to gain a deeper understanding of how the region may develop. The model suggests that the transition to a bio-based economy will occur with oil refining losing its dominance to bioethanol production and biological chemical production, whilst anaerobic digestion grows as a major source of electricity, in turn driving up the value of regional waste aggregators and arable farming in the overall economy.",,"Christopher J. K. Knight, Alexandra S. Penn, Rebecca B. Hoyle",quantitative finance,train
Stability and Identification with Optimal Macroprudential Policy Rules,"This paper investigates the identification, the determinacy and the stability of ad hoc, ""quasi-optimal"" and optimal policy rules augmented with financial stability indicators (such as asset prices deviations from their fundamental values) and minimizing the volatility of the policy interest rates, when the central bank precommits to financial stability. Firstly, ad hoc and quasi-optimal rules parameters of financial stability indicators cannot be identified. For those rules, non zero policy rule parameters of financial stability indicators are observationally equivalent to rule parameters set to zero in another rule, so that they are unable to inform monetary policy. Secondly, under controllability conditions, optimal policy rules parameters of financial stability indicators can all be identified, along with a bounded solution stabilizing an unstable economy as in Woodford (2003), with determinacy of the initial conditions of non- predetermined variables.",18 pages,"Jean-Bernard Chatelain, Kirsten Ralf",quantitative finance,train
The Italian Crisis and Producer Households Debt: a Source of Stability? A Reproducible Research,"The European Credit Research Institute Research Report 2013 identifies Households debt ""rapid increase and abrupt retrenchment"" among the causes of macroeconomic instability in the European Union after 2008. In our research: i) we accessed the Bank of Italy Online Statistical Database on Customers and Risk for Producer Households and Non-Financial Corporations with R Sweave open access statistical software, which makes our analysis freely reproducible by other researchers; ii) we subset the European System of Accounts sector Households into the Bank of Italy sub-sectors Households and Producer Households, which are market producing entities limited to informal partnerships, de facto companies and sole proprietorships with up to five employees and iii) we tested the hypothesis of ""rapid increase and abrupt retrenchment"" of debt for this subset in Italy for the period 1996-2013. We found that PH debt (bad debt) has been more stable with a lower Variation Coefficient of 10.3% (14.2%) versus 13.2% (20.1%) in NFC. We also found that the time series of the ratio of debt granted to NFC (numerator) versus PH (denominator) is best described (Multiple Squared 0.95) by the concavity of the 5th degree coefficient (slope -1.22; 95% CI -1.52 - -0.91) of a 5th order polynomial linear regression and by the convexity of the 2nd degree coefficient (slope 4.26; 95% CI 2.53 - 5.99) for bad debt (Multiple R Squared 0.47), with this concavity of debt and convexity of bad debt beginning with the Italian crisis in the second trimester of 2008. We reject the hypothesis (p < 0.01) of ""rapid increase and abrupt retrenchment"" of debt for the subset Producer Households during the Italian Crisis. We generate the hypothesis that this subset could represent a prospective source of stability relative to Non-Financial Corporation.","Accepted at the Risk, Banking and Finance Society, University of
  Florence, New York University Stern Salomon Center, and Warsaw School of
  Economics International Credit Risk Management Conference 2014, June 23,24 in
  Warsaw, Poland","Stefano Olgiati, Gilberto Bronzini, Alessandro Danovi",quantitative finance,train
Can Analysts Predict Rallies Better Than Crashes?,"We use the copula approach to study the structure of dependence between sell-side analysts' consensus recommendations and subsequent security returns, with a focus on asymmetric tail dependence. We match monthly vintages of I/B/E/S recommendations for the period January to December 2011 with excess security returns during six months following recommendation issue. Using a symmetrized Joe-Clayton Copula (SJC) model we find evidence to suggest that analysts can identify stocks that will substantially outperform, but not underperform relative to the market, and that their predictive ability is conditional on recommendation changes.","15 pages, 1 figure",Ivan Medovikov,quantitative finance,train
Strategy-proofness and single-peackedness in bounded distributive lattices,"Two distinct specifications of single peakedness as currently met in the relevant literature are singled out and discussed. Then, it is shown that, under both of those specifications, a voting rule as defined on a bounded distributive lattice is strategy-proof on the set of all profiles of single peaked total preorders if and only if it can be represented as an iterated median of projections and constants, or equivalently as the behaviour of a certain median tree-automaton. The equivalence of individual and coalitional strategy-proofness that is known to hold for single peaked domains in bounded linear orders fails in such a general setting. A related impossibility result on anonymous coalitionally strategy-proof voting rules is also obtained.",,"Ernesto Savaglio, Stefano Vannucci",quantitative finance,val
Superstars in politics: the role of the media in the rise and success of Junichiro Koizumi,"This paper explores the role of mass media in people perceptions of charismatic leaders, focusing on the case of Junichiro Koizumi, Prime Minister of Japan from 2001 to 2006. Using survey data collected immediately after his 2005 landslide electoral victory, this study empirically assesses the influence of television and newspapers on support for Koizumi and for the most distinctive policy action he announced during his campaign, the privatization of the postal service.","Keywords mass media, television, newspapers, elections, Koizumi,
  Japan, superstar effect","Eiji Yamamura, Fabio Sabatini",quantitative finance,test
Microscopic Models for Welfare Measures Addressing a Reduction of Economic Inequality,"We formulate a flexible micro-to-macro kinetic model which is able to explain the emergence of income profiles out of a whole of individual economic interactions. The model is expressed by a system of several nonlinear differential equations which involve parameters defined by probabilities. Society is described as an ensemble of individuals divided into income classes; the individuals exchange money through binary and ternary interactions, leaving the total wealth unchanged. The ternary interactions represent taxation and redistribution effects. Dynamics is investigated through computational simulations, the focus being on the effects that different fiscal policies and differently weighted welfare policies have on the long-run income distributions. The model provides a tool which may contribute to the identification of the most effective actions towards a reduction of economic inequality. We find for instance that, under certain hypotheses, the Gini index is more affected by a policy of reduction of the welfare and subsidies for the rich classes than by an increase of the upper tax rate. Such a policy also has the effect of slightly increasing the total tax revenue.","15 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1403.0015","Maria Letizia Bertotti, Giovanni Modanese",quantitative finance,test
A finite set of equilibria for the indeterminacy of linear rational expectations models,"This paper demonstrates the existence of a finite set of equilibria in the case of the indeterminacy of linear rational expectations models. The number of equilibria corresponds to the number of ways to select n eigenvectors among a larger set of eigenvectors related to stable eigenvalues. A finite set of equilibria is a substitute to continuous (uncountable) sets of sunspots equilibria, when the number of independent eigenvectors for each stable eigenvalue is equal to one.",,"Jean-Bernard Chatelain, Kirsten Ralf",quantitative finance,train
Semiparametric Estimation of First-Price Auction Models,"We propose a semiparametric method to estimate the density of private values in first-price auctions. Specifically, we model private values through a set of conditional moment restrictions and use a two-step procedure. In the first step we recover a sample of pseudo private values using Local Polynomial Estimator. In the second step we use a GMM procedure to estimate the parameter(s) of interest. We show that the proposed semiparametric estimator is consistent, has an asymptotic normal distribution, and attains the parametric (""root-n"") rate of convergence.","66 pages, 2 figures","Gaurab Aryal, Maria Florencia Gabrielli, Quang Vuong",quantitative finance,val
Structural social capital and health in Italy,"This paper presents the first empirical assessment of the causal relationship between social capital and health in Italy. The analysis draws on the 2000 wave of the Multipurpose Survey on Household conducted by the Italian Institute of Statistics on a representative sample of the population (n = 46,868). Our measure of social capital is the frequency of meetings with friends. Based on IV and bivariate probit estimates, we find that individuals who meet friends every day or at least two times a week are approximately 11% to 16% more likely to report good health.",46 pages,"Damiano Fiorillo, Fabio Sabatini",quantitative finance,val
Taxation and Valuation,"The greatest harm from highway robbers lies not in seized wallets but in inhibited travel. Similarly, incentives for tax-reducing strategies put much sand in the wheels of the economy. Demands to replace our monumental tax code with a simple, graceful one that does not distort economic incentives heat up periodically in political debate, but such dreams never materialize. A FUNDAMENTAL obstacle, not yet well understood in the economic literature, is the impossibility of objectively evaluating the tax base -- assets, income, etc. One can see this even in toy examples, say, trying to assess the value of a position in chess: great masters' assessments will all differ. Here computer theory can add an insight not provided by classical economics tools. A way around is to avoid evaluations by expressing the tax in natural units, not in cash. For publicly traded corporations, these could be corporate shares. I discuss a simple (postcard-sized in ALL details) corporate tax system that avoids ANY distortion of incentives. (Tax tools MEANT to influence corporate policies should be set as explicit separate taxes or credits, open to public scrutiny, not hidden between lines of an incomprehensible tax code.) Roughly, the~system is to periodically take a t*i fraction of shares to auction, where t is the tax rate, i is the interest rate. It replaces all income taxes on publicly traded corporations, their subsidiaries, and shareholders. The interest rate is defined via specially designed bonds, so that the whole system can be shown PRECISELY equivalent to a flat tax on INVESTMENT RETURN. Note that taxing the return DIRECTLY is impossible: it would invite manipulation of stock market~prices. The main feature is that nothing corporations and investors do can change their tax (t*i fraction of shares), so they would do business exactly the SAME WAY they would WITHOUT TAXES.","3 pages, minor changes",Leonid A. Levin,quantitative finance,val
Fluctuations of company yearly profits versus scaled revenue: Fat tail distribution of Levy type,"We analyze annual revenues and earnings data for the 500 largest-revenue U.S. companies during the period 1954-2007. We find that mean year profits are proportional to mean year revenues, exception made for few anomalous years, from which we postulate a linear relation between company expected mean profit and revenue. Mean annual revenues are used to scale both company profits and revenues. Annual profit fluctuations are obtained as difference between actual annual profit and its expected mean value, scaled by a power of the revenue to get a stationary behavior as a function of revenue. We find that profit fluctuations are broadly distributed having approximate power-law tails with a Levy-type exponent $\alpha \simeq 1.7$, from which we derive the associated break-even probability distribution. The predictions are compared with empirical data.","6 pages, 6 figures","H. E. Roman, R. A. Siliprandi, C. Dose, C. Riccardi, M. Porto",quantitative finance,train
Mathematical analysis of Soros's theory of reflexivity,"The mathematical model proposed by George Soros for his theory of reflexivity is analyzed under the framework of discrete dynamical systems. We show the importance of the notion of fixed points for explaining the behavior of a reflexive system governed by its cognitive and manipulative functions. The interrelationship between these two functions induces fixed points with different characteristics, which in turn generate various system behaviors including the so-called ""boom then bust"" phenomenon in Soros's theory.","22 pages, 6 figures",C. P. Kwong,quantitative finance,test
The Reality Game,"We introduce an evolutionary game with feedback between perception and reality, which we call the reality game. It is a game of chance in which the probabilities for different objective outcomes (e.g., heads or tails in a coin toss) depend on the amount wagered on those outcomes. By varying the `reality map', which relates the amount wagered to the probability of the outcome, it is possible to move continuously from a purely objective game in which probabilities have no dependence on wagers to a purely subjective game in which probabilities equal the amount wagered. We study self-reinforcing games, in which betting more on an outcome increases its odds, and self-defeating games, in which the opposite is true. This is investigated in and out of equilibrium, with and without rational players, and both numerically and analytically. We introduce a method of measuring the inefficiency of the game, similar to measuring the magnitude of the arbitrage opportunities in a financial market. We prove that convergence to equilibrium is is a power law with an extremely slow rate of convergence: The more subjective the game, the slower the convergence.","21 pages, 5 figures","Dmitriy Cherkashin, J. Doyne Farmer, Seth Lloyd",quantitative finance,train
"A Conceptual Model for Bidirectional Service, Information and Product Quality in an IS Outsourcing Collaboration Environment","This paper advances theory on the process of collaboration between entities and its implications on the quality of services, information, and/or products (SIPs) that the collaborating entities provide to each other. It investigates the scenario of outsourced IS projects (such as custom software development) where the extent of collaboration between a client and vendor is high. Using the social exchange theory, the proposed conceptual model tries to establish the ""bidirectional"" nature of SIP quality in a collaborative environment, where the SIPs exchanged are possibly ""dependent"" on each other, and if any entity wishes to receive high SIP quality then it should make efforts to provide high SIP quality in return too. Furthermore, it advocates increasing efforts to link financial stakes (tangible or intangible monetary benefits or risks) to the quality of SIP being continuously exchanged throughout the project lifecycle.",,Subrata Chakrabarty,quantitative finance,train
Time and symmetry in models of economic markets,"These notes discuss several topics in neoclassical economics and alternatives, with an aim of reviewing fundamental issues in modeling economic markets. I start with a brief, non-rigorous summary of the basic Arrow-Debreu model of general equilibrium, as well as its extensions to include time and contingency. I then argue that symmetries due to similarly endowed individuals and similar products are generically broken by the constraints of scarcity, leading to the existence of multiple equilibria. This is followed by an evaluation of the strengths and weaknesses of the model generally. Several of the weaknesses are concerned with the treatments of time and contingency. To address these we discuss a class of agent based models. Another set of issues has to do with the fundamental meaning of prices and the related question of what the observables of a non-equilibrium, dynamic model of an economic market should be. We argue that these issues are addressed by formulating economics in the language of a gauge theory, as proposed originally by Malaney and Weinstein. We review some of their work and provide a sketch of how gauge invariance can be incorporated into the formulation of agent based models.","41 pages, one figure",Lee Smolin,quantitative finance,test
Mapping markets to the statistical mechanics: the derivatives act against the self-regulation of stock market,"Mapping the economy to the some statistical physics models we get strong indications that, in contrary to the pure stock market, the stock market with derivatives could not self-regulate.",3 pages,David B. Saakian,quantitative finance,train
The Transfer Pricing Problem with Non-Linearities,"A number of approaches to solving the well-known transfer pricing problem are known. However, few models satisfactorily resolve the core problem of allowing both the source and receiving divisions to earn a profit on transfers during a period in such a way that sub-optimal output levels are avoided. In 1969, Samuel proposed to use a transfer price schedule instead of just a single transfer price. An essential improvement of Samuels' model was given by Tomkins (1990) in his pragmatic-analytical transfer pricing approach, which is a combination of a single cost-plus transfer price and the pragmatic process of negotiation. This fundamental approach was developed under the assumption that the net average revenue curve for the final product is linear. In this paper, Tomkins' pragmatic-analytical model is further developed for non-linear net average revenue curves. In particular, typical quadratic functions are considered and corresponding transfer price schedules are determined. A similar technique can be used for the transfer pricing problem with any net average revenue curve.",15 pages,S. Zverovich,quantitative finance,train
Does economics need a scientific revolution?,Economics does not need a scientific revolution. Economics needs accurate measurements according to high standards of natural sciences and meticulous work on revealing empirical relationships between measured variables.,"6 pages, 3 figures",Ivan O. Kitov,quantitative finance,train
The Problem of Modeling of Economic Dynamics,"The correctness of Harrods model in the differential form is studied. The inadequacy of exponential growth of economy is shown; an alternative result is obtained. By example of Phillips model, an approach to correction of macroeconomic models (in terms of initial prerequisites) is generalized. A methodology based on balance relations for modelling of economic dynamics, including obtaining forecast estimates, is developed. The problems thus considered are reduced to the solution of Volterra and Fredholm integral equations of the second kind.",,"S. I. Chernyshov, A. V. Voronin, S. A. Razumovsky",quantitative finance,val
Option Pricing Accuracy for Estimated Heston Models,"We consider assets for which price $X_t$ and squared volatility $Y_t$ are jointly driven by Heston joint stochastic differential equations (SDEs). When the parameters of these SDEs are estimated from $N$ sub-sampled data $(X_{nT}, Y_{nT})$, estimation errors do impact the classical option pricing PDEs. We estimate these option pricing errors by combining numerical evaluation of estimation errors for Heston SDEs parameters with the computation of option price partial derivatives with respect to these SDEs parameters. This is achieved by solving six parabolic PDEs with adequate boundary conditions. To implement this approach, we also develop an estimator $\hat \lambda$ for the market price of volatility risk, and we study the sensitivity of option pricing to estimation errors affecting $\hat \lambda$. We illustrate this approach by fitting Heston SDEs to 252 daily joint observations of the S\&P 500 index and of its approximate volatility VIX, and by numerical applications to European options written on the S\&P 500 index.",,"Robert Azencott, Yutheeka Gadhyan, Roland Glowinski",quantitative finance,train
Modelling the skew and smile of SPX and DAX index options using the Shifted Log-Normal and SABR stochastic models,"We discuss modelling of SPX and DAX index option prices using the Shifted Log-Normal (SLN) model, (also known as Displaced Diffusion), and the SABR model. We found out that for SPX options, an example of strongly skewed option prices, SLN can produce a quite accurate fit. Moreover, for both types of index options, the SLN model is giving a good fit of near-at-the-forward strikes. Such a near-at-the-money fit allows us to calculate precisely the skew parameter without involving directly the 3rd moment of the related probability distribution. Eventually, we can follow with a procedure in which the skew is calculated using the SLN model and further smile effects are added as a next iteration/perturbation. Furthermore, we point out that the SLN trajectories are exact solutions of the SABR model for rho = +/-1.","5 pages, 10 figures","Jan Kuklinski, Doinita Negru, Pawel Pliszka",quantitative finance,test
Reconstruction of density functions by sk-splines,"Reconstruction of density functions and their characteristic functions by radial basis functions with scattered data points is a popular topic in the theory of pricing of basket options. Such functions are usually entire or admit an analytic extension into an appropriate tube and ""bell-shaped"" with rapidly decaying tails. Unfortunately, the domain of such functions is not compact which creates various technical difficulties. We solve interpolation problem on an infinite rectangular grid for a wide range of kernel functions and calculate explicitly their Fourier transform to obtain representations for the respective density functions.",,"A. Kushpel, J. Levesley",quantitative finance,train
Interest rate models and Whittaker functions,"I present the technique which can analyse some interest rate models: Constantinides-Ingersoll, CIR-model, geometric CIR and Geometric Brownian Motion. All these models have the unified structure of Whittaker function. The main focus of this text is closed-form solutions of the zero-coupon bond value in these models. In text I emphasize the specific details of mathematical methods of their determination such as Laplace transform and hypergeometric functions.","19 pages, 2 figures",Dmitry Muravey,quantitative finance,train
Intensity Process for a Pure Jump Lévy Structural Model with Incomplete Information,"In this paper we discuss a credit risk model with a pure jump L\'evy process for the asset value and an unobservable random barrier. The default time is the first time when the asset value falls below the barrier. Using the indistinguishability of the intensity process and the likelihood process, we prove the existence of the intensity process of the default time and find its explicit representation in terms of the distance between the asset value and its running minimal value. We apply the result to find the instantaneous credit spread process and illustrate it with a numerical example.","15 pages, 2 figures","Xin Dong, Harry Zheng",quantitative finance,train
Valuation and Hedging of Contracts with Funding Costs and Collateralization,"The research presented in this work is motivated by recent papers by Brigo et al. (2011), Burgard and Kjaer (2009), Cr\'epey (2012), Fujii and Takahashi (2010), Piterbarg (2010) and Pallavicini et al. (2012). Our goal is to provide a sound theoretical underpinning for some results presented in these papers by developing a unified framework for the non-linear approach to hedging and pricing of OTC financial contracts. We introduce a systematic approach to valuation and hedging in nonlinear markets, that is, in markets where cash flows of the financial contracts may depend on the hedging strategies. Our systematic approach allows to identify primary sources of and quantify various adjustment to valuation and hedging, primarily the funding and liquidity adjustment and credit risk adjustment. We propose a way to define no-arbitrage in such nonlinear markets, and we provide conditions that imply absence of arbitrage in some specific market trading models. Accordingly, we formulate a concept of no-arbitrage price, and we provide relevant (non-linear) BSDE that produces the no-arbitrage price in case when the contract's cash flows can be replicated.",,"Tomasz R. Bielecki, Marek Rutkowski",quantitative finance,val
Explicit investment rules with time-to-build and uncertainty,"We establish explicit socially optimal rules for an irreversible investment deci- sion with time-to-build and uncertainty. Assuming a price sensitive demand function with a random intercept, we provide comparative statics and economic interpreta- tions for three models of demand (arithmetic Brownian, geometric Brownian, and the Cox-Ingersoll-Ross). Committed capacity, that is, the installed capacity plus the in- vestment in the pipeline, must never drop below the best predictor of future demand, minus two biases. The discounting bias takes into account the fact that investment is paid upfront for future use; the precautionary bias multiplies a type of risk aversion index by the local volatility. Relying on the analytical forms, we discuss in detail the economic effects.",,"René Aid, Salvatore Federico, Huyên Pham, Bertrand Villeneuve",quantitative finance,val
"Path Diffusion, Part I",This paper investigates the position (state) distribution of the single step binomial (multi-nomial) process on a discrete state / time grid under the assumption that the velocity process rather than the state process is Markovian. In this model the particle follows a simple multi-step process in velocity space which also preserves the proper state equation of motion. Many numerical numerical examples of this process are provided. For a smaller grid the probability construction converges into a correlated set of probabilities of hyperbolic functions for each velocity at each state point. It is shown that the two dimensional process can be transformed into a Telegraph equation and via transformation into a Klein-Gordon equation if the transition rates are constant. In the last Section there is an example of multi-dimensional hyperbolic partial differential equation whose numerical average satisfies Newton's equation. There is also a momentum measure provided both for the two-dimensional case as for the multi-dimensional rate matrix.,"28 pages, 10 Figures","Johan GB Beumee, Chris Cormack, Peyman Khorsand, Manish Patel",quantitative finance,val
Option Pricing in an Imperfect World,"In a model with no given probability measure, we consider asset pricing in the presence of frictions and other imperfections and characterize the property of coherent pricing, a notion related to (but much weaker than) the no arbitrage property. We show that prices are coherent if and only if the set of pricing measures is non empty, i.e. if pricing by expectation is possible. We then obtain a decomposition of coherent prices highlighting the role of bubbles. eventually we show that under very weak conditions the coherent pricing of options allows for a very clear representation from which it is possible, as in the original work of Breeden and Litzenberger, to extract the implied probability. Eventually we test this conclusion empirically via a new non parametric approach.","The paper has been withdrawn because in the newer version it was
  split into two different papers, each of which have been uploaded into Arxiv",Gianluca Cassese,quantitative finance,train
Robust pricing and hedging under trading restrictions and the emergence of local martingale models,"We consider the pricing of derivatives in a setting with trading restrictions, but without any probabilistic assumptions on the underlying model, in discrete and continuous time. In particular, we assume that European put or call options are traded at certain maturities, and the forward price implied by these option prices may be strictly decreasing in time. In discrete time, when call options are traded, the short-selling restrictions ensure no arbitrage, and we show that classical duality holds between the smallest super-replication price and the supremum over expectations of the payoff over all supermartingale measures. More surprisingly in the case where the only vanilla options are put options, we show that there is a duality gap. Embedding the discrete time model into a continuous time setup, we make a connection with (strict) local-martingale models, and derive framework and results often seen in the literature on financial bubbles. This connection suggests a certain natural interpretation of many existing results in the literature on financial bubbles.",,"Alexander M. G. Cox, Zhaoxu Hou, Jan Obloj",quantitative finance,train
Evaluating the performance of adapting trading strategies with different memory lengths,We propose a prediction model based on the minority game in which traders continuously evaluate a complete set of trading strategies with different memory lengths using the strategies' past performance. Based on the chosen trading strategy they determine their prediction of the movement for the following time period of a single asset. We find empirically using stocks from the S&P500 that our prediction model yields a high success rate of over 51.5% and produces higher returns than a buy-and-hold strategy. Even when taking into account trading costs we find that using the predictions will generate superior investment portfolios.,12 pages with 9 figures,Andreas Krause,quantitative finance,val
Application of the Kelly Criterion to Ornstein-Uhlenbeck Processes,"In this paper, we study the Kelly criterion in the continuous time framework building on the work of E.O. Thorp and others. The existence of an optimal strategy is proven in a general setting and the corresponding optimal wealth process is found. A simple formula is provided for calculating the optimal portfolio for a set of price processes satisfying some simple conditions. Properties of the optimal investment strategy for assets governed by multiple Ornstein-Uhlenbeck processes are studied. The paper ends with a short discussion of the implications of these ideas for financial markets.","presented at Complex'2009 (Shanghai, Feb. 23-25)","Yingdong Lv, Bernhard K. Meister",quantitative finance,train
La prime de risque dans un cadre international : le risque de change est-il apprécié ?,"In this article, we investigate whether exchange rate risk is priced. We use a multivariate GARCH-in-Mean specification and test alternative conditional international CAPM versions. Our results support strongly the international asset-pricing model that includes exchange rate risk for both developed and emerging stock markets. However, there are important time and cross-country variations in the relative size and dynamics of different risk premia.",,Mohamed El Hedi Arouri,quantitative finance,train
Jump-Diffusion Risk-Sensitive Asset Management,"This paper considers a portfolio optimization problem in which asset prices are represented by SDEs driven by Brownian motion and a Poisson random measure, with drifts that are functions of an auxiliary diffusion 'factor' process. The criterion, following earlier work by Bielecki, Pliska, Nagai and others, is risk-sensitive optimization (equivalent to maximizing the expected growth rate subject to a constraint on variance.) By using a change of measure technique introduced by Kuroda and Nagai we show that the problem reduces to solving a certain stochastic control problem in the factor process, which has no jumps. The main result of the paper is that the Hamilton-Jacobi-Bellman equation for this problem has a classical solution. The proof uses Bellman's ""policy improvement"" method together with results on linear parabolic PDEs due to Ladyzhenskaya et al.",35 pages. Uses SIAM style file siamltex.cls,"Mark H. A. Davis, Sebastien Lleo",quantitative finance,train
Continuous-Time Markowitz's Model with Transaction Costs,"A continuous-time Markowitz's mean-variance portfolio selection problem is studied in a market with one stock, one bond, and proportional transaction costs. This is a singular stochastic control problem,inherently in a finite time horizon. With a series of transformations, the problem is turned into a so-called double obstacle problem, a well studied problem in physics and partial differential equation literature, featuring two time-varying free boundaries. The two boundaries, which define the buy, sell, and no-trade regions, are proved to be smooth in time. This in turn characterizes the optimal strategy, via a Skorokhod problem, as one that tries to keep a certain adjusted bond-stock position within the no-trade region. Several features of the optimal strategy are revealed that are remarkably different from its no-transaction-cost counterpart. It is shown that there exists a critical length in time, which is dependent on the stock excess return as well as the transaction fees but independent of the investment target and the stock volatility, so that an expected terminal return may not be achievable if the planning horizon is shorter than that critical length (while in the absence of transaction costs any expected return can be reached in an arbitrary period of time). It is further demonstrated that anyone following the optimal strategy should not buy the stock beyond the point when the time to maturity is shorter than the aforementioned critical length. Moreover, the investor would be less likely to buy the stock and more likely to sell the stock when the maturity date is getting closer. These features, while consistent with the widely accepted investment wisdom, suggest that the planning horizon is an integral part of the investment opportunities.","30 pages, 1 figure","Min Dai, Zuo Quan Xu, Xun Yu Zhou",quantitative finance,val
The premium of dynamic trading,"It is well established that in a market with inclusion of a risk-free asset the single-period mean-variance efficient frontier is a straight line tangent to the risky region, a fact that is the very foundation of the classical CAPM. In this paper, it is shown that in a continuous-time market where the risky prices are described by Ito's processes and the investment opportunity set is deterministic (albeit time-varying), any efficient portfolio must involve allocation to the risk-free asset at any time. As a result, the dynamic mean-variance efficient frontier, though still a straight line, is strictly above the entire risky region. This in turn suggests a positive premium, in terms of the Sharpe ratio of the efficient frontier, arising from the dynamic trading. Another implication is that the inclusion of a risk-free asset boosts the Sharpe ratio of the efficient frontier, which again contrasts sharply with the single-period case.","24 pages, 6 figures","Chun Hung Chiu, Xun Yu Zhou",quantitative finance,train
Global risk minimization in financial markets,"Recurring international financial crises have adverse socioeconomic effects and demand novel regulatory instruments or strategies for risk management and market stabilization. However, the complex web of market interactions often impedes rational decisions that would absolutely minimize the risk. Here we show that, for any given expected return, investors can overcome this complexity and globally minimize their financial risk in portfolio selection models, which is mathematically equivalent to computing the ground state of spin glass models in physics, provided the margin requirement remains below a critical, empirically measurable value. For markets with centrally regulated margin requirements, this result suggests a potentially stabilizing intervention strategy.",8 pages; 1 figure,Andreas Martin Lisewski,quantitative finance,test
Optimal investment with inside information and parameter uncertainty,This paper has been withdrawn by the authors pending corrections.,This paper has been withdrawn,"Albina Danilova, Michael Monoyios, Andrew Ng",quantitative finance,train
Mutual Fund Theorem for continuous time markets with random coefficients,"We study the optimal investment problem for a continuous time incomplete market model such that the risk-free rate, the appreciation rates and the volatility of the stocks are all random; they are assumed to be independent from the driving Brownian motion, and they are supposed to be currently observable. It is shown that some weakened version of Mutual Fund Theorem holds for this market for general class of utilities; more precisely, it is shown that the supremum of expected utilities can be achieved on a sequence of strategies with a certain distribution of risky assets that does not depend on risk preferences described by different utilities.",17 pages,Nikolai Dokuchaev,quantitative finance,val
Existence of Shadow Prices in Finite Probability Spaces,"A shadow price is a process lying within the bid/ask prices of a market with proportional transaction costs, such that maximizing expected utility from consumption in the frictionless market with this price process leads to the same maximal utility as in the original market with transaction costs. For finite probability spaces, this note provides an elementary proof for the existence of such a shadow price.",11 pages,"Jan Kallsen, Johannes Muhle-Karbe",quantitative finance,val
Measuring expectations in options markets: An application to the SP500 index,"Extracting market expectations has always been an important issue when making national policies and investment decisions in financial markets. In option markets, the most popular way has been to extract implied volatilities to assess the future variability of the underlying with the use of the Black and Scholes formula. In this manuscript, we propose a novel way to extract the whole time varying distribution of the market implied asset price from option prices. We use a Bayesian nonparametric method that makes use of the Sethuraman representation for Dirichlet processes to take into account the evolution of distributions in time. As an illustration, we present the analysis of options on the SP500 index.",,"Abel Rodriguez, Enrique ter Horst",quantitative finance,val
Robust pricing and hedging of double no-touch options,"Double no-touch options, contracts which pay out a fixed amount provided an underlying asset remains within a given interval, are commonly traded, particularly in FX markets. In this work, we establish model-free bounds on the price of these options based on the prices of more liquidly traded options (call and digital call options). Key steps are the construction of super- and sub-hedging strategies to establish the bounds, and the use of Skorokhod embedding techniques to show the bounds are the best possible. In addition to establishing rigorous bounds, we consider carefully what is meant by arbitrage in settings where there is no {\it a priori} known probability measure. We discuss two natural extensions of the notion of arbitrage, weak arbitrage and weak free lunch with vanishing risk, which are needed to establish equivalence between the lack of arbitrage and the existence of a market model.","32 pages, 5 figures","Alexander M. G. Cox, Jan Obloj",quantitative finance,train
Volatility forecasts and the at-the-money implied volatility: a multi-components ARCH approach and its relation with market models,"For a given time horizon DT, this article explores the relationship between the realized volatility (the volatility that will occur between t and t+DT), the implied volatility (corresponding to at-the-money option with expiry at t+DT), and several forecasts for the volatility build from multi-scales linear ARCH processes. The forecasts are derived from the process equations, and the parameters set a priori. An empirical analysis across multiple time horizons DT shows that a forecast provided by an I-GARCH(1) process (1 time scale) does not capture correctly the dynamic of the realized volatility. An I-GARCH(2) process (2 time scales, similar to GARCH(1,1)) is better, while a long memory LM-ARCH process (multiple time scales) replicates correctly the dynamic of the realized volatility and delivers consistently good forecast for the implied volatility. The relationship between market models for the forward variance and the volatility forecasts provided by ARCH processes is investigated. The structure of the forecast equations is identical, but with different coefficients. Yet the process equations for the variance are very different (postulated for a market model, induced by the process equations for an ARCH model), and not of any usual diffusive type when derived from ARCH.","21 pages, 6 figures",Gilles Zumbach,quantitative finance,val
BSLP: Markovian Bivariate Spread-Loss Model for Portfolio Credit Derivatives,"BSLP is a two-dimensional dynamic model of interacting portfolio-level loss and spread (more exactly, loss intensity) processes. The model is similar to the top-down HJM-like frameworks developed by Schonbucher (2005) and Sidenius-Peterbarg-Andersen (SPA) (2005), however is constructed as a Markovian, short-rate intensity model. This property of the model enables fast lattice methods for pricing various portfolio credit derivatives such as tranche options, forward-starting tranches, leveraged super-senior tranches etc. A non-parametric model specification is used to achieve nearly perfect calibration to liquid tranche quotes across strikes and maturities. A non-dynamic version of the model obtained in the zero volatility limit of stochastic intensity is useful on its own as an arbitrage-free interpolation model to price non-standard index tranches off the standard ones.","42 pages, 9 figures","Matthias Arnsdorf, Igor Halperin",quantitative finance,train
Exchangeability type properties of asset prices,"In this paper we analyse financial implications of exchangeability and similar properties of finite dimensional random vectors. We show how these properties are reflected in prices of some basket options in view of the well-known put-call symmetry property and the duality principle in option pricing. A particular attention is devoted to the case of asset prices driven by Levy processes. Based on this, concrete semi-static hedging techniques for multi-asset barrier options, such as certain weighted barrier spread options, weighted barrier swap options or weighted barrier quanto-swap options are suggested.","The final version of the paper ""Semi-static hedging under
  exchangeability type conditions"". To appear in Advances in Applied
  Probability","Ilya Molchanov, Michael Schmutz",quantitative finance,train
Quantized Interest Rate at the Money for American Options,"In this work, we expand the idea of Samuelson[3] and Shepp[2,5,6] for stock optimization using the Bachelier model [4] as our models for the stock price at the money (X[stock price]= K[strike price]) for the American call and put options [1]. At the money (X= K) for American options, the expected payoff of both the call and put options is zero. Shepp investigated several stochastic optimization problems using martingale and stopping time theories [2,5,6]. One of the problems he investigated was how to optimize the stock price using both the Black-Scholes (multiplicative) and the Bachelier (additive) models [7,6] for the American option above the strike price K (exercise price) to a stopping point. In order to explore the non-relativistic quantum effect on the expected payoff for both the call and put options at the money, we assumed the stock price to undergo a stochastic process governed by the Bachelier (additive) model [4]. Further, using Ito calculus and martingale theory, we obtained a differential equation for the expected payoff for both the call and put options in terms of delta and gamma. We also obtained the solution to the non-relativistic Schroedinger equation as the expected payoff for both the call and put options. Then, we expressed the stochastic process that is the expected payoff for both the call and put options at the money in terms of the solution to the Schroedinger equation. We concluded the stochastic process that is the expected payoff at the money for both options to be an oscillatory function with quantized interest rates.","10 pages, 1 figure. Presented at the American Physical Society
  meeting",L. M. Dieng,quantitative finance,train
A Simplified Approach to modeling the credit-risk of CMO,"The credit crisis of 2007 and 2008 has thrown much focus on the models used to price mortgage backed securities. Many institutions have relied heavily on the credit ratings provided by credit agency. The relationships between management of credit agencies and debt issuers may have resulted in conflict of interest when pricing these securities which has lead to incorrect risk assumptions and value expectations from institutional buyers. Despite the existence of sophisticated models, institutional buyers have relied on these ratings when considering the risks involved with these products. Institutional investors interested in non-agency MBS are particularly vulnerable due to both the credit risks as well as prepayment risks. This paper describes a simple simulation model that model non-agency MBS and CMO. The simulation model builds on existing models for agency MBS. It incorporates credit risks of mortgage buyers using existing models used in capital requirements as specified by the Basel II Accord.",This article is withdrawn,K. Rajaratnam,quantitative finance,val
Exact Pricing Asymptotics of Investment-Grade Tranches of Synthetic CDO's Part I: A Large Homogeneous Pool,"We use the theory of large deviations to study the pricing of investment-grade tranches of synthetic CDO's. In this paper, we consider a simplified model which will allow us to introduce some of the concepts and calculations.",,Richard B. Sowers,quantitative finance,train
Exact Pricing Asymptotics for Investment-Grade Tranches of Synthetic CDO's. Part II: A Large Heterogeneous Pool,"We use the theory of large deviations to study the pricing of investment-grade tranches of synthetic CDO's. In this paper, we consider a heterogeneous pool of names. Our main tool is a large-deviations analysis which allows us to precisely study the behavior of a large amount of idiosyncratic randomness. Our calculations allow a fairly general treatment of correlation.",,Richard B. Sowers,quantitative finance,val
Maximum Entropy Distributions Inferred from Option Portfolios on an Asset,"We obtain the maximum entropy distribution for an asset from call and digital option prices. A rigorous mathematical proof of its existence and exponential form is given, which can also be applied to legitimise a formal derivation by Buchen and Kelly. We give a simple and robust algorithm for our method and compare our results to theirs. We present numerical results which show that our approach implies very realistic volatility surfaces even when calibrating only to at-the-money options. Finally, we apply our approach to options on the S&P 500 index.","23 pages, 5 figures, to appear in Finance and Stochastics","C. Neri, L. Schneider",quantitative finance,train
"Partial Equilibria with Convex Capital Requirements: Existence, Uniqueness and Stability","In an incomplete semimartingale model of a financial market, we consider several risk-averse financial agents who negotiate the price of a bundle of contingent claims. Assuming that the agents' risk preferences are modelled by convex capital requirements, we define and analyze their demand functions and propose a notion of a partial equilibrium price. In addition to sufficient conditions for the existence and uniqueness, we also show that the equilibrium prices are stable with respect to misspecifications of agents' risk preferences.",,"Michail Anthropelos, Gordan Zitkovic",quantitative finance,train
Monitoring dates of maximal risk,"Monitoring means to observe a system for any changes which may occur over time, using a monitor or measuring device of some sort. In this paper we formulate a problem of monitoring dates of maximal risk of a financial position. Thus, the systems we are going to observe arise from situations in finance. The measuring device we are going to use is a time-consistent measure of risk. In the first part of the paper we discuss the numerical representation of conditional convex risk measures which are defined in a space Lp(F,R) and take values in L1(G,R). This will allow us to consider time-consistent convex risk measures in L1(R). In the second part of the paper we use a time-consistent convex risk measure in order to define an abstract problem of monitoring stopping times of maximal risk. The penalty function involved in the robust representation changes qualitatively the time when maximal risk is for the first time identified. A phenomenon which we discuss from the point of view of robust statistics.",Working Paper,Erick Trevino Aguilar,quantitative finance,val
The Structural Modelling of Operational Risk via Bayesian inference: Combining Loss Data with Expert Opinions,"To meet the Basel II regulatory requirements for the Advanced Measurement Approaches, the bank's internal model must include the use of internal data, relevant external data, scenario analysis and factors reflecting the business environment and internal control systems. Quantification of operational risk cannot be based only on historical data but should involve scenario analysis. Historical internal operational risk loss data have limited ability to predict future behaviour moreover, banks do not have enough internal data to estimate low frequency high impact events adequately. Historical external data are difficult to use due to different volumes and other factors. In addition, internal and external data have a survival bias, since typically one does not have data of all collapsed companies. The idea of scenario analysis is to estimate frequency and severity of risk events via expert opinions taking into account bank environment factors with reference to events that have occurred (or may have occurred) in other banks. Scenario analysis is forward looking and can reflect changes in the banking environment. It is important to not only quantify the operational risk capital but also provide incentives to business units to improve their risk management policies, which can be accomplished through scenario analysis. By itself, scenario analysis is very subjective but combined with loss data it is a powerful tool to estimate operational risk losses. Bayesian inference is a statistical technique well suited for combining expert opinions and historical data. In this paper, we present examples of the Bayesian inference methods for operational risk quantification.",,"P. V. Shevchenko, M. V. Wüthrich",quantitative finance,val
Estimation of Operational Risk Capital Charge under Parameter Uncertainty,"Many banks adopt the Loss Distribution Approach to quantify the operational risk capital charge under Basel II requirements. It is common practice to estimate the capital charge using the 0.999 quantile of the annual loss distribution, calculated using point estimators of the frequency and severity distribution parameters. The uncertainty of the parameter estimates is typically ignored. One of the unpleasant consequences for the banks accounting for parameter uncertainty is an increase in the capital requirement. This paper demonstrates how the parameter uncertainty can be taken into account using a Bayesian framework that also allows for incorporation of expert opinions and external data into the estimation procedure.",,Pavel V. Shevchenko,quantitative finance,train
"A ""Toy"" Model for Operational Risk Quantification using Credibility Theory","To meet the Basel II regulatory requirements for the Advanced Measurement Approaches in operational risk, the bank's internal model should make use of the internal data, relevant external data, scenario analysis and factors reflecting the business environment and internal control systems. One of the unresolved challenges in operational risk is combining of these data sources appropriately. In this paper we focus on quantification of the low frequency high impact losses exceeding some high threshold. We suggest a full credibility theory approach to estimate frequency and severity distributions of these losses by taking into account bank internal data, expert opinions and industry data.",,"Hans Bühlmann, Pavel V. Shevchenko, Mario V. Wüthrich",quantitative finance,train
Implementing Loss Distribution Approach for Operational Risk,"To quantify the operational risk capital charge under the current regulatory framework for banking supervision, referred to as Basel II, many banks adopt the Loss Distribution Approach. There are many modeling issues that should be resolved to use the approach in practice. In this paper we review the quantitative methods suggested in literature for implementation of the approach. In particular, the use of the Bayesian inference method that allows to take expert judgement and parameter uncertainty into account, modeling dependence and inclusion of insurance are discussed.",,Pavel V. Shevchenko,quantitative finance,train
Collective firm bankruptcies and phase transition in rating dynamics,"We present a simple model of firm rating evolution. We consider two sources of defaults: individual dynamics of economic development and Potts-like interactions between firms. We show that such a defined model leads to phase transition, which results in collective defaults. The existence of the collective phase depends on the mean interaction strength. For small interaction strength parameters, there are many independent bankruptcies of individual companies. For large parameters, there are giant collective defaults of firm clusters. In the case when the individual firm dynamics favors dumping of rating changes, there is an optimal strength of the firm's interactions from the systemic risk point of view.",,"Paweł Sieczka, Janusz A. Hołyst",quantitative finance,train
Conditional Value-at-Risk Constraint and Loss Aversion Utility Functions,"We provide an economic interpretation of the practice consisting in incorporating risk measures as constraints in a classic expected return maximization problem. For what we call the infimum of expectations class of risk measures, we show that if the decision maker (DM) maximizes the expectation of a random return under constraint that the risk measure is bounded above, he then behaves as a ``generalized expected utility maximizer'' in the following sense. The DM exhibits ambiguity with respect to a family of utility functions defined on a larger set of decisions than the original one; he adopts pessimism and performs first a minimization of expected utility over this family, then performs a maximization over a new decisions set. This economic behaviour is called ``Maxmin under risk'' and studied by Maccheroni (2002). This economic interpretation allows us to exhibit a loss aversion factor when the risk measure is the Conditional Value-at-Risk.",,"Laetitia Andrieu, Michel De Lara, Babacar Seck",quantitative finance,train
A Bayesian Networks Approach to Operational Risk,"A system for Operational Risk management based on the computational paradigm of Bayesian Networks is presented. The algorithm allows the construction of a Bayesian Network targeted for each bank using only internal loss data, and takes into account in a simple and realistic way the correlations among different processes of the bank. The internal losses are averaged over a variable time horizon, so that the correlations at different times are removed, while the correlations at the same time are kept: the averaged losses are thus suitable to perform the learning of the network topology and parameters. The algorithm has been validated on synthetic time series. It should be stressed that the practical implementation of the proposed algorithm has a small impact on the organizational structure of a bank and requires an investment in human resources limited to the computational area.",,"V. Aquaro, M. Bardoscia, R. Bellotti, A. Consiglio, F. De Carlo, G. Ferri",quantitative finance,train
"Preferences Yielding the ""Precautionary Effect""","Consider an agent taking two successive decisions to maximize his expected utility under uncertainty. After his first decision, a signal is revealed that provides information about the state of nature. The observation of the signal allows the decision-maker to revise his prior and the second decision is taken accordingly. Assuming that the first decision is a scalar representing consumption, the \emph{precautionary effect} holds when initial consumption is less in the prospect of future information than without (no signal). \citeauthor{Epstein1980:decision} in \citep*{Epstein1980:decision} has provided the most operative tool to exhibit the precautionary effect. Epstein's Theorem holds true when the difference of two convex functions is either convex or concave, which is not a straightforward property, and which is difficult to connect to the primitives of the economic model. Our main contribution consists in giving a geometric characterization of when the difference of two convex functions is convex, then in relating this to the primitive utility model. With this tool, we are able to study and unite a large body of the literature on the precautionary effect.",,Michel De Lara,quantitative finance,val
A long-range memory stochastic model of the return in financial markets,"We present a nonlinear stochastic differential equation (SDE) which mimics the probability density function (PDF) of the return and the power spectrum of the absolute return in financial markets. Absolute return as a measure of market volatility is considered in the proposed model as a long-range memory stochastic variable. The SDE is obtained from the analogy with earlier proposed model of trading activity in the financial markets and generalized within the nonextensive statistical mechanics framework. The proposed stochastic model generates time series of the return with two power law statistics, i.e., the PDF and the power spectral density, reproducing the empirical data for the one minute trading return in the NYSE.","9 pages, 3 figures","V. Gontis, J. Ruseckas, A. Kononovicius",quantitative finance,test
"Correction to ""Leverage and volatility feedback effects in high-frequency data"" [J. Financial Econometrics 4 (2006) 353--384]","Bollerslev et al. (2006) study the cross-covariances for squared returns under the Heston (1993) stochastic volatility model. In order to obtain these cross-covariances the authors use an incorrect expression for the distribution of the squared returns. Here we will obtain the correct distribution of the squared returns and check that, under this new distribution, the result in Appendix A.2 in Bollerslev et al. (2006) still holds.",3 pages,Amparo Baillo,quantitative finance,train
Mechanical Model of Personal Income Distribution,"A microeconomic model is developed, which accurately predicts the shape of personal income distribution (PID) in the United States and the evolution of the shape over time. The underlying concept is borrowed from geo-mechanics and thus can be considered as mechanics of income distribution. The model allows the resolution of empirical and definitional problems associated with personal income measurements. It also serves as a firm fundament for definitions of income inequality as secondary derivatives from personal income distribution. It is found that in relative terms the PID in the US has not been changing since 1947. Effectively, the Gini coefficient has been almost constant during the last 60 years, as reported by the Census Bureau.",,Ivan O. Kitov,quantitative finance,train
What is the best firm size to invest?,"Significant differences in the evolution of firm size distribution for various industries in the United States have been revealed and documented. For theoretical considerations, this finding puts major constraints on the modelling of firm growth. For practical purposes, the observed differences create a solid basis for selective investment strategies.",,Ivan O. Kitov,quantitative finance,train
Statistical analysis of the overnight and daytime return,"We investigate the two components of the total daily return (close-to-close), the overnight return (close-to-open) and the daytime return (open-to-close), as well as the corresponding volatilities of the 2215 NYSE stocks from 1988 to 2007. The tail distribution of the volatility, the long-term memory in the sequence, and the cross-correlation between different returns are analyzed. Our results suggest that: (i) The two component returns and volatilities have similar features as that of the total return and volatility. The tail distribution follows a power law for all volatilities, and long-term correlations exist in the volatility sequences but not in the return sequences. (ii) The daytime return contributes more to the total return. Both the tail distribution and the long-term memory of the daytime volatility are more similar to that of the total volatility, compared to the overnight records. In addition, the cross-correlation between the daytime return and the total return is also stronger. (iii) The two component returns tend to be anti-correlated. Moreover, we find that the cross-correlations between the three different returns (total, overnight, and daytime) are quite stable over the entire 20-year period.","22 pages, 8 figures, 2 tables","Fengzhong Wang, Shwu-Jane Shieh, Shlomo Havlin, H. Eugene Stanley",quantitative finance,train
Statistical thermodynamics of economic systems,"We formulate thermodynamics of economic systems in terms of an arbitrary probability distribution for a conserved economic quantity. As in statistical physics, thermodynamic macroeconomic variables emerge as the mean value of microeconomic variables and their determination is reduced to the computation of the partition function, starting from an arbitrary function. Explicit hypothetical examples are given which include linear and nonlinear economic systems, as well as multiplicative systems such as those dominated by a Pareto law distribution. We propose to use the formalism of phase transitions to study severe changes of macroeconomic variables.","Discussions added, typos corrected","H. Quevedo, M. N. Quevedo",quantitative finance,train
Long-term correlations and multifractal analysis of trading volumes for Chinese stocks,We investigate the temporal correlations and multifractal nature of trading volume of 22 liquid stocks traded on the Shenzhen Stock Exchange in 2003. We find that the trading volume exhibit size-dependent non-universal long memory and multifractal nature. No crossover in the power-law dependence of the detrended fluctuation functions is observed. Our results show that the intraday pattern in the trading volume has negligible impact on the long memory and multifractality.,"12 pages, 6 figures, 1 table","Guo-Hua Mu, Wei Chen, János Kertész, Wei-Xing Zhou",quantitative finance,train
Scaling and memory in the return intervals of realized volatility,"We perform return interval analysis of 1-min {\em{realized volatility}} defined by the sum of absolute high-frequency intraday returns for the Shanghai Stock Exchange Composite Index (SSEC) and 22 constituent stocks of SSEC. The scaling behavior and memory effect of the return intervals between successive realized volatilities above a certain threshold $q$ are carefully investigated. In comparison with the volatility defined by the closest tick prices to the minute marks, the return interval distribution for the realized volatility shows a better scaling behavior since 20 stocks (out of 22 stocks) and the SSEC pass the Kolmogorov-Smirnov (KS) test and exhibit scaling behaviors, among which the scaling function for 8 stocks could be approximated well by a stretched exponential distribution revealed by the KS goodness-of-fit test under the significance level of 5%. The improved scaling behavior is further confirmed by the relation between the fitted exponent $\gamma$ and the threshold $q$. In addition, the similarity of the return interval distributions for different stocks is also observed for the realized volatility. The investigation of the conditional probability distribution and the detrended fluctuation analysis (DFA) show that both short-term and long-term memory exists in the return intervals of realized volatility.","12 pages, 6 figures, 2 tables","Fei Ren, Gao-Feng Gu, Wei-Xing Zhou",quantitative finance,val
"Colloquium: Statistical mechanics of money, wealth, and income","This Colloquium reviews statistical models for money, wealth, and income distributions developed in the econophysics literature since the late 1990s. By analogy with the Boltzmann-Gibbs distribution of energy in physics, it is shown that the probability distribution of money is exponential for certain classes of models with interacting economic agents. Alternative scenarios are also reviewed. Data analysis of the empirical distributions of wealth and income reveals a two-class distribution. The majority of the population belongs to the lower class, characterized by the exponential (""thermal"") distribution, whereas a small fraction of the population in the upper class is characterized by the power-law (""superthermal"") distribution. The lower part is very stable, stationary in time, whereas the upper part is highly dynamical and out of equilibrium.","24 pages, 13 figures; v.2 - minor stylistic changes and updates of
  references corresponding to the published version","Victor M. Yakovenko, J. Barkley Rosser",quantitative finance,train
The effect of a market factor on information flow between stocks using minimal spanning tree,"We empirically investigated the effects of market factors on the information flow created from N(N-1)/2 linkage relationships among stocks. We also examined the possibility of employing the minimal spanning tree (MST) method, which is capable of reducing the number of links to N-1. We determined that market factors carry important information value regarding information flow among stocks. Moreover, the information flow among stocks evidenced time-varying properties according to the changes in market status. In particular, we noted that the information flow increased dramatically during periods of market crises. Finally, we confirmed, via the MST method, that the information flow among stocks could be assessed effectively with the reduced linkage relationships among all links between stocks from the perspective of the overall market.",,"Cheoljun Eom, Okyu Kwon, Woo-Sung Jung, Seunghwan Kim",quantitative finance,val
The Minimal Model of Financial Complexity,"A representative investor generates realistic and complex security price paths by following this trading strategy: if, a few ticks ago, the market asset had two consecutive upticks or two consecutive downticks, then sell, and otherwise buy. This simple, unique, and robust model is the smallest possible deterministic model of financial complexity, and its generalization leads to complex variety. Compared to a random walk, the minimal model generates time series with fatter tails and more frequent crashes, thus more closely matching the real world. It does all this without any parameter fitting.","changed from LaTeX to Word; accepted for publication in Quantitative
  Finance",Philip Maymin,quantitative finance,val
Emergence of Power Law in a Market with Mixed Models,"We investigate the problem of wealth distribution from the viewpoint of asset exchange. Robust nature of Pareto's law across economies, ideologies and nations suggests that this could be an outcome of trading strategies. However, the simple asset exchange models fail to reproduce this feature. A yardsale(YS) model in which amount put on the bet is a fraction of minimum of the two players leads to condensation of wealth in hands of some agent while theft and fraud(TF) model in which the amount to be exchanged is a fraction of loser's wealth leads to an exponential distribution of wealth. We show that if we allow few agents to follow a different model than others, {\it i.e.} there are some agents following TF model while rest follow YS model, it leads to distribution with power law tails. Similar effect is observed when one carries out transactions for a fraction of one's wealth using TF model and for the rest YS model is used. We also observe a power law tail in wealth distribution if we allow the agents to follow either of the models with some probability.",18 pages and 9 figures,"M. Ali Saif, Prashant M. Gade",quantitative finance,train
Effects of introduction of new resources and fragmentation of existing resources on limiting wealth distribution in asset exchange models,"Pareto law, which states that wealth distribution in societies have a power-law tail, has been a subject of intensive investigations in statistical physics community. Several models have been employed to explain this behavior. However, most of the agent based models assume the conservation of number of agents and wealth. Both these assumptions are unrealistic. In this paper, we study the limiting wealth distribution when one or both of these assumptions are not valid. Given the universality of the law, we have tried to study the wealth distribution from the asset exchange models point of view. We consider models in which a) new agents enter the market at constant rate b) richer agents fragment with higher probability introducing newer agents in the system c) both fragmentation and entry of new agents is taking place. While models a) and c) do not conserve total wealth or number of agents, model b) conserves total wealth. All these models lead to a power-law tail in the wealth distribution pointing to the possibility that more generalized asset exchange models could help us to explain emergence of power-law tail in wealth distribution.",15 pages and 6 figures,"M. Ali Saif, Prashant M. Gade",quantitative finance,train
A Unified Framework for Dynamic Pari-Mutuel Information Market Design,"Recently, several new pari-mutuel mechanisms have been introduced to organize markets for contingent claims. Hanson introduced a market maker derived from the logarithmic scoring rule, and later Chen and Pennock developed a cost function formulation for the market maker. On the other hand, the SCPM model of Peters et al. is based on ideas from a call auction setting using a convex optimization model. In this work, we develop a unified framework that bridges these seemingly unrelated models for centrally organizing contingent claim markets. The framework, developed as a generalization of the SCPM, will support many desirable properties such as proper scoring, truthful bidding (in a myopic sense), efficient computation, and guarantees on worst case loss. In fact, our unified framework will allow us to express various proper scoring rules, existing or new, from classical utility functions in a convex optimization problem representing the market organizer. Additionally, we utilize concepts from duality to show that the market model is equivalent to a risk minimization problem where a convex risk measure is employed. This will allow us to more clearly understand the differences in the risk attitudes adopted by various mechanisms, and particularly deepen our intuition about popular mechanisms like Hanson's market-maker. In aggregate, we believe this work advances our understanding of the objectives that the market organizer is optimizing in popular pari-mutuel mechanisms by recasting them into one unified framework.",,"Shipra Agrawal, Erick Delage, Mark Peters, Zizhuo Wang, Yinyu Ye",quantitative finance,train
Optimal Trade Execution in Illiquid Markets,"We study optimal trade execution strategies in financial markets with discrete order flow. The agent has a finite liquidation horizon and must minimize price impact given a random number of incoming trade counterparties. Assuming that the order flow $N$ is given by a Poisson process, we give a full analysis of the properties and computation of the optimal dynamic execution strategy. Extensions, whereby (a) $N$ is a fully-observed regime-switching Poisson process; and (b) $N$ is a Markov-modulated compound Poisson process driven by a hidden Markov chain, are also considered. We derive and compare the properties of the three cases and illustrate our results with computational examples.",,"Erhan Bayraktar, Mike Ludkovski",quantitative finance,train
"Scale Invariance, Bounded Rationality and Non-Equilibrium Economics","We study a class of heterogeneous agent-based models which are based on a basic set of principles, and the most fundamental operations of an economic system: trade and product transformations. A basic guiding principle is scale invariance, which means that the dynamics of the economy should not depend on the units used to measure the different products. We develop the idea of a ""near-equilibrium"" expansion which allow us to study the dynamics of fluctuations around economic equilibrium. This is similar to the familiar ""perturbation theory"" studied in many areas of physics. We study some simple models of both centralized and decentralized markets. We show the relaxation to equilibrium when appropriate. More interestingly, we study a simple model of a decentralized market that shows a spontaneous transition into a monetary phase. We use mean field theory analysis to provide a statistical interpretation of the monetary phase. Furthermore, we show that such phase can be dynamically unstable. Finally, we study some simple centralized financial markets, one of which shows a speculative bubble and a crash.","40 pages, 17 figs",Samuel E. Vazquez,quantitative finance,train
"Liquidity Crisis, Granularity of the Order Book and Price Fluctuations","We introduce a microscopic model for the dynamics of the order book to study how the lack of liquidity influences price fluctuations. We use the average density of the stored orders (granularity $g$) as a proxy for liquidity. This leads to a Price Impact Surface which depends on both volume $\omega$ and $g$. The dependence on the volume (averaged over the granularity) of the Price Impact Surface is found to be a concave power law function $<\phi(\omega,g)>_g\sim\omega^\delta$ with $\delta\approx 0.59$. Instead the dependence on the granularity is $\phi(\omega,g|\omega)\sim g^\alpha$ with $\alpha\approx-1$, showing a divergence of price fluctuations in the limit $g\to 0$. Moreover, even in intermediate situations of finite liquidity, this effect can be very large and it is a natural candidate for understanding the origin of large price fluctuations.","18 pages, 7 figures","M. Cristelli, V. Alfi, L. Pietronero, A. Zaccaria",quantitative finance,train
Perturbation theory in a pure exchange non-equilibrium economy,"We develop a formalism to study linearized perturbations around the equilibria of a pure exchange economy. With the use of mean field theory techniques, we derive equations for the flow of products in an economy driven by heterogeneous preferences and probabilistic interaction between agents. We are able to show that if the economic agents have static preferences, which are also homogeneous in any of the steady states, the final wealth distribution is independent of the dynamics of the non-equilibrium theory. In particular, it is completely determined in terms of the initial conditions, and it is independent of the probability, and the network of interaction between agents. We show that the main effect of the network is to determine the relaxation time via the usual eigenvalue gap as in random walks on graphs.","7 pages, 2 figures","Samuel E. Vazquez, Simone Severini",quantitative finance,val
Stock markets and quantum dynamics: a second quantized description,"In this paper we continue our descriptions of stock markets in terms of some non abelian operators which are used to describe the portfolio of the various traders and other {\em observable} quantities. After a first prototype model with only two traders, we discuss a more realistic model of market with an arbitrary number of traders. For both models we find approximated solutions for the time evolution of the portfolio of each trader. In particular, for the more realistic model, we use the {\em stochastic limit} approach and a {\em fixed point like} approximation.",,F. Bagarello,quantitative finance,train
Simplified stock markets described by number operators,"In this paper we continue our systematic analysis of the operatorial approach previously proposed in an economical context and we discuss a {\em mixed} toy model of a simplified stock market, i.e. a model in which the price of the shares is given as an input. We deduce the time evolution of the portfolio of the various traders of the market, as well as of other {\em observable} quantities. As in a previous paper, we solve the equations of motion by means of a {\em fixed point like} approximation.","Rep. on Math. Phys., in press",F. Bagarello,quantitative finance,train
"Dynamical Equilibrium, trajectories study in an economical system. The case of the labor market","The paper deals with the study of labor market dynamics, and aims to characterize its equilibriums and possible trajectories. The theoretical background is the theory of the segmented labor market. The main idea is that this theory is well adapted to interpret the observed trajectories, due to the heterogeneity of the work situations.",accepted to the WSOM 2007 Conference (Bielefield),"Patrick Letrémy, Marie Cottrell, Patrice Gaubert, Joseph Rynkiewicz",statistics,train
Missing Data: A Comparison of Neural Network and Expectation Maximisation Techniques,"The estimation of missing input vector elements in real time processing applications requires a system that possesses the knowledge of certain characteristics such as correlations between variables, which are inherent in the input space. Computational intelligence techniques and maximum likelihood techniques do possess such characteristics and as a result are important for imputation of missing data. This paper compares two approaches to the problem of missing data estimation. The first technique is based on the current state of the art approach to this problem, that being the use of Maximum Likelihood (ML) and Expectation Maximisation (EM. The second approach is the use of a system based on auto-associative neural networks and the Genetic Algorithm as discussed by Adbella and Marwala3. The estimation ability of both of these techniques is compared, based on three datasets and conclusions are made.","24 pages, 7 figures, 4 tables","Fulufhelo V. Nelwamondo, Shakir Mohamed, Tshilidzi Marwala",statistics,train
An Integrated Human-Computer System for Controlling Interstate Disputes,"In this paper we develop a scientific approach to control inter-country conflict. This system makes use of a neural network and a feedback control approach. It was found that by controlling the four controllable inputs: Democracy, Dependency, Allies and Capability simultaneously, all the predicted dispute outcomes could be avoided. Furthermore, it was observed that controlling a single input Dependency or Capability also avoids all the predicted conflicts. When the influence of each input variable on conflict is assessed, Dependency, Capability, and Democracy emerge as key variables that influence conflict.","29 pages, 6 figures, 2 tables","Tshilidzi Marwala, Monica Lagazio, Thando Tettey",statistics,train
Mixed models for longitudinal left-censored repeated measures,"Longitudinal studies could be complicated by left-censored repeated measures. For example, in Human Immunodeficiency Virus infection, there is a detection limit of the assay used to quantify the plasma viral load. Simple imputation of the limit of the detection or of half of this limit for left-censored measures biases estimations and their standard errors. In this paper, we review two likelihood-based methods proposed to handle left-censoring of the outcome in linear mixed model. We show how to fit these models using SAS Proc NLMIXED and we compare this tool with other programs. Indications and limitations of the programs are discussed and an example in the field of HIV infection is shown.",,"Rodolphe Thiébaut, Hélène Jacqmin-Gadda",statistics,test
Finite Element Model Updating Using Bayesian Approach,"This paper compares the Maximum-likelihood method and Bayesian method for finite element model updating. The Maximum-likelihood method was implemented using genetic algorithm while the Bayesian method was implemented using the Markov Chain Monte Carlo. These methods were tested on a simple beam and an unsymmetrical H-shaped structure. The results show that the Bayesian method gave updated finite element models that predicted more accurate modal properties than the updated finite element models obtained through the use of the Maximum-likelihood method. Furthermore, both these methods were found to require the same levels of computational loads.","7 pages, IMAC2004","Tshilidzi Marwala, Lungile Mdlazi, Sibusiso Sibisi",statistics,val
Evaluating Throwing Ability in Baseball,We present a quantitative analysis of throwing ability for major league outfielders and catchers. We use detailed game event data to tabulate success and failure events in outfielder and catcher throwing opportunities. We attribute a run contribution to each success or failure which are tabulated for each player in each season. We use four seasons of data to estimate the overall throwing ability of each player using a Bayesian hierarchical model. This model allows us to shrink individual player estimates towards an overall population mean depending on the number of opportunities for each player. We use the posterior distribution of player abilities from this model to identify players with significant positive and negative throwing contributions.,"Accepted for publication in the Journal of Quantitative Analysis in
  Sports","Matthew Carruth, Shane T. Jensen",statistics,val
Modeling Hourly Ozone Concentration Fields,"This paper presents a dynamic linear model for modeling hourly ozone concentrations over the eastern United States. That model, which is developed within an Bayesian hierarchical framework, inherits the important feature of such models that its coefficients, treated as states of the process, can change with time. Thus the model includes a time--varying site invariant mean field as well as time varying coefficients for 24 and 12 diurnal cycle components. This cost of this model's great flexibility comes at the cost of computational complexity, forcing us to use an MCMC approach and to restrict application of our model domain to a small number of monitoring sites. We critically assess this model and discover some of its weaknesses in this type of application.","25 pages, 10 figures","Yiping Dou, Nhu D Le, James V Zidek",statistics,train
"Controlling for individual heterogeneity in longitudinal models, with applications to student achievement","Longitudinal data tracking repeated measurements on individuals are highly valued for research because they offer controls for unmeasured individual heterogeneity that might otherwise bias results. Random effects or mixed models approaches, which treat individual heterogeneity as part of the model error term and use generalized least squares to estimate model parameters, are often criticized because correlation between unobserved individual effects and other model variables can lead to biased and inconsistent parameter estimates. Starting with an examination of the relationship between random effects and fixed effects estimators in the standard unobserved effects model, this article demonstrates through analysis and simulation that the mixed model approach has a ``bias compression'' property under a general model for individual heterogeneity that can mitigate bias due to uncontrolled differences among individuals. The general model is motivated by the complexities of longitudinal student achievement measures, but the results have broad applicability to longitudinal modeling.","Published at http://dx.doi.org/10.1214/07-EJS057 in the Electronic
  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)","J. R. Lockwood, Daniel F. McCaffrey",statistics,train
M-estimation of Boolean models for particle flow experiments,"Probability models are proposed for passage time data collected in experiments with a device designed to measure particle flow during aerial application of fertilizer. Maximum likelihood estimation of flow intensity is reviewed for the simple linear Boolean model, which arises with the assumption that each particle requires the same known passage time. M-estimation is developed for a generalization of the model in which passage times behave as a random sample from a distribution with a known mean. The generalized model improves fit in these experiments. An estimator of total particle flow is constructed by conditioning on lengths of multi-particle clumps.",,"Jason A. Osborne, Tony E. Grift",statistics,train
Does heterosexual transmission drive the HIV/AIDS epidemic in Sub-Saharan Africa (or elsewhere)?,"A two-sex Basic Reproduction Number (BRN) is used to investigate the conditions under which the Human Immunodeficiency Virus (HIV) may spread through heterosexual contacts in Sub-Saharan Africa. (The BRN is the expected number of new infections generated by one infected individual; the disease spreads if the BRN is larger than 1). A simple analytical expression for the BRN is derived on the basis of recent data on survival rates, transmission probabilities, and levels of sexual activity. Baseline results show that in the population at large (characterized by equal numbers of men and women) the BRN is larger than 1 if every year each person has 82 sexual contacts with different partners. the BRN is also larger than 1 for commercial sex workers (CSWs) and their clients (two populations of different sizes) if each CSW has about 256 clients per year and each client visits one CSW every two weeks. A sensitivity analysis explores the effect on the BRN of a doubling (or a halving) of the transmission probabilities. Implications and extensions are discussed.",,"Marc Artzrouni, Vivient Kamla",statistics,val
Construction of Bayesian Deformable Models via Stochastic Approximation Algorithm: A Convergence Study,"The problem of the definition and the estimation of generative models based on deformable templates from raw data is of particular importance for modelling non aligned data affected by various types of geometrical variability. This is especially true in shape modelling in the computer vision community or in probabilistic atlas building for Computational Anatomy (CA). A first coherent statistical framework modelling the geometrical variability as hidden variables has been given by Allassonni\`ere, Amit and Trouv\'e (JRSS 2006). Setting the problem in a Bayesian context they proved the consistency of the MAP estimator and provided a simple iterative deterministic algorithm with an EM flavour leading to some reasonable approximations of the MAP estimator under low noise conditions. In this paper we present a stochastic algorithm for approximating the MAP estimator in the spirit of the SAEM algorithm. We prove its convergence to a critical point of the observed likelihood with an illustration on images of handwritten digits.",,"Stéphanie Allassonnière, Estelle Kuhn, Alain Trouvé",statistics,val
The random Tukey depth,"The computation of the Tukey depth, also called halfspace depth, is very demanding, even in low dimensional spaces, because it requires the consideration of all possible one-dimensional projections. In this paper we propose a random depth which approximates the Tukey depth. It only takes into account a finite number of one-dimensional projections which are chosen at random. Thus, this random depth requires a very small computation time even in high dimensional spaces. Moreover, it is easily extended to cover the functional framework. We present some simulations indicating how many projections should be considered depending on the sample size and on the dimension of the sample space. We also compare this depth with some others proposed in the literature. It is noteworthy that the random depth, based on a very low number of projections, obtains results very similar to those obtained with other depths.",,"J. A. Cuesta-Albertos, A. Nieto-Reyes",statistics,test
Deconvolution by simulation,"Given samples (x_1,...,x_m) and (z_1,...,z_n) which we believe are independent realizations of random variables X and Z respectively, where we further believe that Z=X+Y with Y independent of X, the problem is to estimate the distribution of Y. We present a new method for doing this, involving simulation. Experiments suggest that the method provides useful estimates.","Published at http://dx.doi.org/10.1214/074921707000000021 in the IMS
  Lecture Notes Monograph Series
  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of
  Mathematical Statistics (http://www.imstat.org)",Colin Mallows,statistics,val
Parallel marginalization Monte Carlo with applications to conditional path sampling,"Monte Carlo sampling methods often suffer from long correlation times. Consequently, these methods must be run for many steps to generate an independent sample. In this paper a method is proposed to overcome this difficulty. The method utilizes information from rapidly equilibrating coarse Markov chains that sample marginal distributions of the full system. This is accomplished through exchanges between the full chain and the auxiliary coarse chains. Results of numerical tests on the bridge sampling and filtering/smoothing problems for a stochastic differential equation are presented.",,Jonathan Weare,statistics,train
On The Density Estimation by Super-Parametric Method,"The super-parametric density estimators and its related algorism were suggested by Y. -S. Tsai et al [7]. The number of parameters is unlimited in the super- parametric estimators and it is a general theory in sense of unifying or connecting nonparametric and parametric estimators. Before applying to numerical examples, we can not give any comment of the estimators. In this paper, we will focus on the implementation, the computer programming, of the algorism and strategies of choosing window functions. B-splines, Bezier splines and covering windows are studied as well. According to the criterion of the convergence conditions for Parzen window, the number of the window functions shall be, roughly, proportional to the number of samples and so is the number of the variables. Since the algorism is designed for solving the optimization of likelihood function, there will be a set of nonlinear equations with a large number of variables. The results show that algorism suggested by Y. -S. Tsai is very powerful and effective in the sense of mathematics, that is, the iteration procedures converge and the rates of convergence are very fast. Also, the numerical results of different window functions show that the approach of super-parametric density estimators has ushered a new era of statistics.","In this paper, new aspproaches od density estimation are studied. The
  B-spline estimatos and the Berzier spline are stdudied carfully. The
  consistency of the Bezier spline estimator is studied as well. There are 17
  pages including 6 figures","Yeong-Shyeong Tsai, Ying-Lin Hsu, Mung-Chung Shung",statistics,train
Adaptive Importance Sampling in General Mixture Classes,"In this paper, we propose an adaptive algorithm that iteratively updates both the weights and component parameters of a mixture importance sampling density so as to optimise the importance sampling performances, as measured by an entropy criterion. The method is shown to be applicable to a wide class of importance sampling densities, which includes in particular mixtures of multivariate Student t distributions. The performances of the proposed scheme are studied on both artificial and real examples, highlighting in particular the benefit of a novel Rao-Blackwellisation device which can be easily incorporated in the updating scheme.",Removed misleading comment in Section 2,"Olivier Cappé, Randal Douc, Arnaud Guillin, Jean-Michel Marin, Christian P. Robert",statistics,train
Particle Filters for Multiscale Diffusions,We consider multiscale stochastic systems that are partially observed at discrete points of the slow time scale. We introduce a particle filter that takes advantage of the multiscale structure of the system to efficiently approximate the optimal filter.,"to appear in ESAIM Proceedings (Workshop on Sequential Monte Carlo
  Methods: filtering and other applications, Oxford, 2006)",Anastasia Papavasiliou,statistics,train
An Elegant Method for Generating Multivariate Poisson Random Variable,Generating multivariate Poisson data is essential in many applications. Current simulation methods suffer from limitations ranging from computational complexity to restrictions on the structure of the correlation matrix. We propose a computationally efficient and conceptually appealing method for generating multivariate Poisson data. The method is based on simulating multivariate Normal data and converting them to achieve a specific correlation matrix and Poisson rate vector. This allows for generating data that have positive or negative correlations as well as different rates.,"11 pages, 11 figures","Inbal Yahav, Galit Shmueli",statistics,train
Population-Based Reversible Jump Markov Chain Monte Carlo,"In this paper we present an extension of population-based Markov chain Monte Carlo (MCMC) to the trans-dimensional case. One of the main challenges in MCMC-based inference is that of simulating from high and trans-dimensional target measures. In such cases, MCMC methods may not adequately traverse the support of the target; the simulation results will be unreliable. We develop population methods to deal with such problems, and give a result proving the uniform ergodicity of these population algorithms, under mild assumptions. This result is used to demonstrate the superiority, in terms of convergence rate, of a population transition kernel over a reversible jump sampler for a Bayesian variable selection problem. We also give an example of a population algorithm for a Bayesian multivariate mixture model with an unknown number of components. This is applied to gene expression data of 1000 data points in six dimensions and it is demonstrated that our algorithm out performs some competing Markov chain samplers.",,"Ajay Jasra, David A. Stephens, Chris C. Holmes",statistics,train
A statistical analysis of probabilistic counting algorithms,"This paper considers the problem of cardinality estimation in data stream applications. We present a statistical analysis of probabilistic counting algorithms, focusing on two techniques that use pseudo-random variates to form low-dimensional data sketches. We apply conventional statistical methods to compare probabilistic algorithms based on storing either selected order statistics, or random projections. We derive estimators of the cardinality in both cases, and show that the maximal-term estimator is recursively computable and has exponentially decreasing error bounds. Furthermore, we show that the estimators have comparable asymptotic efficiency, and explain this result by demonstrating an unexpected connection between the two approaches.","19 pages, 0 figures","Peter Clifford, Ioana A. Cosma",statistics,train
Inflated Beta Distributions,"This paper considers the issue of modeling fractional data observed in the interval [0,1), (0,1] or [0,1]. Mixed continuous-discrete distributions are proposed. The beta distribution is used to describe the continuous component of the model since its density can have quite diferent shapes depending on the values of the two parameters that index the distribution. Properties of the proposed distributions are examined. Also, maximum likelihood and method of moments estimation is discussed. Finally, practical applications that employ real data are presented.","15 pages, 4 figures. Submitted to Statistical Papers","Raydonal Ospina, Silvia L. P. Ferrari",statistics,train
Codage arithmetique pour la description d'une distribution,"Using predictive adaptive arithmetic coding and the Minimum Description Length principle, we derive an efficient tool for model selection problems : the RIC information criterion. We then present an extension of these coding techniques to non-parametrical estimation of a distribution and illustrate it on the gray scales histogram of an image. Key-words : Information criteria, MDL, model selection, non-parametrical estimation, histograms.","7 pages, 6 figures, in French, TAIMA'07 conference presentation
  http://taima.enst-bretagne.fr/","Guilhem Coq, Olivier Alata, Marc Arnaudon, Christian Olivier",statistics,train
Variable Selection Incorporating Prior Constraint Information into Lasso,"We propose the variable selection procedure incorporating prior constraint information into lasso. The proposed procedure combines the sample and prior information, and selects significant variables for responses in a narrower region where the true parameters lie. It increases the efficiency to choose the true model correctly. The proposed procedure can be executed by many constrained quadratic programming methods and the initial estimator can be found by least square or Monte Carlo method. The proposed procedure also enjoys good theoretical properties. Moreover, the proposed procedure is not only used for linear models but also can be used for generalized linear models({\sl GLM}), Cox models, quantile regression models and many others with the help of Wang and Leng (2007)'s LSA, which changes these models as the approximation of linear models. The idea of combining sample and prior constraint information can be also used for other modified lasso procedures. Some examples are used for illustration of the idea of incorporating prior constraint information in variable selection procedures.",15 pages,"Shurong Zheng, Guodong Song, Ning-Zhong Shi",statistics,train
Bayesian Covariance Matrix Estimation using a Mixture of Decomposable Graphical Models,"A Bayesian approach is used to estimate the covariance matrix of Gaussian data. Ideas from Gaussian graphical models and model selection are used to construct a prior for the covariance matrix that is a mixture over all decomposable graphs. For this prior the probability of each graph size is specified by the user and graphs of equal size are assigned equal probability. Most previous approaches assume that all graphs are equally probable. We show empirically that the prior that assigns equal probability over graph sizes outperforms the prior that assigns equal probability over all graphs, both in identifying the correct decomposable graph and in more efficiently estimating the covariance matrix.",28 pages and 11 figures,"Helen Armstrong, Christopher K. Carter, Kevin F. Wong, Robert Kohn",statistics,test
Sensitivity of principal Hessian direction analysis,"We provide sensitivity comparisons for two competing versions of the dimension reduction method principal Hessian directions (pHd). These comparisons consider the effects of small perturbations on the estimation of the dimension reduction subspace via the influence function. We show that the two versions of pHd can behave completely differently in the presence of certain observational types. Our results also provide evidence that outliers in the traditional sense may or may not be highly influential in practice. Since influential observations may lurk within otherwise typical data, we consider the influence function in the empirical setting for the efficient detection of influential observations in practice.","Published at http://dx.doi.org/10.1214/07-EJS064 in the Electronic
  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)","Luke A. Prendergast, Jodie A. Smith",statistics,train
Statistical testing procedure for the interaction effects of several controllable factors in two-valued input-output systems,"Suppose several two-valued input-output systems are designed by setting the levels of several controllable factors. For this situation, Taguchi method has proposed to assign the controllable factors to the orthogonal array and use ANOVA model for the standardized SN ratio, which is a natural measure for evaluating the performance of each input-output system. Though this procedure is simple and useful in application indeed, the result can be unreliable when the estimated standard errors of the standardized SN ratios are unbalanced. In this paper, we treat the data arising from the full factorial or fractional factorial designs of several controllable factors as the frequencies of high-dimensional contingency tables, and propose a general testing procedure for the main effects or the interaction effects of the controllable factors.",14pages,"Satoshi Aoki, Masami Miyakawa",statistics,train
Undercomplete Blind Subspace Deconvolution via Linear Prediction,"We present a novel solution technique for the blind subspace deconvolution (BSSD) problem, where temporal convolution of multidimensional hidden independent components is observed and the task is to uncover the hidden components using the observation only. We carry out this task for the undercomplete case (uBSSD): we reduce the original uBSSD task via linear prediction to independent subspace analysis (ISA), which we can solve. As it has been shown recently, applying temporal concatenation can also reduce uBSSD to ISA, but the associated ISA problem can easily become `high dimensional' [1]. The new reduction method circumvents this dimensionality problem. We perform detailed studies on the efficiency of the proposed technique by means of numerical simulations. We have found several advantages: our method can achieve high quality estimations for smaller number of samples and it can cope with deeper temporal convolutions.",12 pages,"Zoltan Szabo, Barnabas Poczos, Andras Lorincz",statistics,train
SiZer for time series: A new approach to the analysis of trends,"Smoothing methods and SiZer are a useful statistical tool for discovering statistically significant structure in data. Based on scale space ideas originally developed in the computer vision literature, SiZer (SIgnificant ZERo crossing of the derivatives) is a graphical device to assess which observed features are `really there' and which are just spurious sampling artifacts. In this paper, we develop SiZer like ideas in time series analysis to address the important issue of significance of trends. This is not a straightforward extension, since one data set does not contain the information needed to distinguish `trend' from `dependence'. A new visualization is proposed, which shows the statistician the range of trade-offs that are available. Simulation and real data results illustrate the effectiveness of the method.","Published at http://dx.doi.org/10.1214/07-EJS006 in the Electronic
  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)","Vitaliana Rondonotti, J. S. Marron, Cheolwoo Park",statistics,train
On semiparametric regression with O'Sullivan penalised splines,"This is an expos\'e on the use of O'Sullivan penalised splines in contemporary semiparametric regression, including mixed model and Bayesian formulations. O'Sullivan penalised splines are similar to P-splines, but have an advantage of being a direct generalisation of smoothing splines. Exact expressions for the O'Sullivan penalty matrix are obtained. Comparisons between the two reveals that O'Sullivan penalised splines more closely mimic the natural boundary behaviour of smoothing splines. Implementation in modern computing environments such as Matlab, R and BUGS is discussed.",19 pages with 9 figures,"M. P. Wand, J. T. Ormerod",statistics,train
A new graphical tool of outliers detection in regression models based on recursive estimation,"We present in this paper a new tool for outliers detection in the context of multiple regression models. This graphical tool is based on recursive estimation of the parameters. Simulations were carried out to illustrate the performance of this graphical procedure. As a conclusion, this tool is applied to real data containing outliers according to the classical available tools.",,Christian Paroissin,statistics,train
Lasso type classifiers with a reject option,"We consider the problem of binary classification where one can, for a particular cost, choose not to classify an observation. We present a simple proof for the oracle inequality for the excess risk of structural risk minimizers using a lasso type penalty.","Published at http://dx.doi.org/10.1214/07-EJS058 in the Electronic
  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)",Marten Wegkamp,statistics,train
Metric Embedding for Nearest Neighbor Classification,"The distance metric plays an important role in nearest neighbor (NN) classification. Usually the Euclidean distance metric is assumed or a Mahalanobis distance metric is optimized to improve the NN performance. In this paper, we study the problem of embedding arbitrary metric spaces into a Euclidean space with the goal to improve the accuracy of the NN classifier. We propose a solution by appealing to the framework of regularization in a reproducing kernel Hilbert space and prove a representer-like theorem for NN classification. The embedding function is then determined by solving a semidefinite program which has an interesting connection to the soft-margin linear binary support vector machine classifier. Although the main focus of this paper is to present a general, theoretical framework for metric embedding in a NN setting, we demonstrate the performance of the proposed method on some benchmark datasets and show that it performs better than the Mahalanobis metric learning algorithm in terms of leave-one-out and generalization errors.","9 pages, 1 table","Bharath K. Sriperumbudur, Gert R. G. Lanckriet",statistics,train
Degenerating families of dendrograms,"Dendrograms used in data analysis are ultrametric spaces, hence objects of nonarchimedean geometry. It is known that there exist $p$-adic representation of dendrograms. Completed by a point at infinity, they can be viewed as subtrees of the Bruhat-Tits tree associated to the $p$-adic projective line. The implications are that certain moduli spaces known in algebraic geometry are $p$-adic parameter spaces of (families of) dendrograms, and stochastic classification can also be handled within this framework. At the end, we calculate the topology of the hidden part of a dendrogram.","13 pages, 8 figures",Patrick Erik Bradley,statistics,val
Families of dendrograms,"A conceptual framework for cluster analysis from the viewpoint of p-adic geometry is introduced by describing the space of all dendrograms for n datapoints and relating it to the moduli space of p-adic Riemannian spheres with punctures using a method recently applied by Murtagh (2004b). This method embeds a dendrogram as a subtree into the Bruhat-Tits tree associated to the p-adic numbers, and goes back to Cornelissen et al. (2001) in p-adic geometry. After explaining the definitions, the concept of classifiers is discussed in the context of moduli spaces, and upper bounds for the number of hidden vertices in dendrograms are given.","7 pages, 3 figures. To appear in: Proceedings of the 31st Annual
  Conference of the German Classification Society on Data Analysis, Machine
  Learning, and Applications, Freiburg im Breisgau, 7-9 March 2007. Springer
  series Studies in Classification, Data Analysis, and Knowledge Organization",Patrick Erik Bradley,statistics,val
Online Learning in Discrete Hidden Markov Models,We present and analyse three online algorithms for learning in discrete Hidden Markov Models (HMMs) and compare them with the Baldi-Chauvin Algorithm. Using the Kullback-Leibler divergence as a measure of generalisation error we draw learning curves in simplified situations. The performance for learning drifting concepts of one of the presented algorithms is analysed and compared with the Baldi-Chauvin algorithm in the same situations. A brief discussion about learning and symmetry breaking based on our results is also presented.,"8 pages, 6 figures","Roberto C. Alamino, Nestor Caticha",statistics,train
Supervised Machine Learning with a Novel Kernel Density Estimator,"In recent years, kernel density estimation has been exploited by computer scientists to model machine learning problems. The kernel density estimation based approaches are of interest due to the low time complexity of either O(n) or O(n*log(n)) for constructing a classifier, where n is the number of sampling instances. Concerning design of kernel density estimators, one essential issue is how fast the pointwise mean square error (MSE) and/or the integrated mean square error (IMSE) diminish as the number of sampling instances increases. In this article, it is shown that with the proposed kernel function it is feasible to make the pointwise MSE of the density estimator converge at O(n^-2/3) regardless of the dimension of the vector space, provided that the probability density function at the point of interest meets certain conditions.","The new version includes an additional theorem, Theorem 3","Yen-Jen Oyang, Darby Tien-Hao Chang, Yu-Yen Ou, Hao-Geng Hung, Chih-Peng Wu, Chien-Yu Chen",statistics,train
Bayesian Classification and Regression with High Dimensional Features,"This thesis responds to the challenges of using a large number, such as thousands, of features in regression and classification problems. There are two situations where such high dimensional features arise. One is when high dimensional measurements are available, for example, gene expression data produced by microarray techniques. For computational or other reasons, people may select only a small subset of features when modelling such data, by looking at how relevant the features are to predicting the response, based on some measure such as correlation with the response in the training data. Although it is used very commonly, this procedure will make the response appear more predictable than it actually is. In Chapter 2, we propose a Bayesian method to avoid this selection bias, with application to naive Bayes models and mixture models. High dimensional features also arise when we consider high-order interactions. The number of parameters will increase exponentially with the order considered. In Chapter 3, we propose a method for compressing a group of parameters into a single one, by exploiting the fact that many predictor variables derived from high-order interactions have the same values for all the training cases. The number of compressed parameters may have converged before considering the highest possible order. We apply this compression method to logistic sequence prediction models and logistic classification models. We use both simulated data and real data to test our methods in both chapters.","PhD Thesis Submitted to University of Toronto, 129 Pages",Longhai Li,statistics,test
Simulated Annealing: Rigorous finite-time guarantees for optimization on continuous domains,Simulated annealing is a popular method for approaching the solution of a global optimization problem. Existing results on its performance apply to discrete combinatorial optimization where the optimization variables can assume only a finite set of possible values. We introduce a new general formulation of simulated annealing which allows one to guarantee finite-time performance in the optimization of functions of continuous variables. The results hold universally for any optimization problem on a bounded domain and establish a connection between simulated annealing and up-to-date theory of convergence of Markov chain Monte Carlo methods on continuous domains. This work is inspired by the concept of finite-time learning with known accuracy and confidence developed in statistical learning theory.,"10 pages, 2 figures. Preprint. The final version will appear in:
  Advances in Neural Information Processing Systems 20, Proceedings of NIPS
  2007, MIT Press","A. Lecchini-Visintini, J. Lygeros, J. Maciejowski",statistics,val
The nested Chinese restaurant process and Bayesian nonparametric inference of topic hierarchies,"We present the nested Chinese restaurant process (nCRP), a stochastic process which assigns probability distributions to infinitely-deep, infinitely-branching trees. We show how this stochastic process can be used as a prior distribution in a Bayesian nonparametric model of document collections. Specifically, we present an application to information retrieval in which documents are modeled as paths down a random tree, and the preferential attachment dynamics of the nCRP leads to clustering of documents according to sharing of topics at multiple levels of abstraction. Given a corpus of documents, a posterior inference algorithm finds an approximation to a posterior distribution over trees, topics and allocations of words to levels of the tree. We demonstrate this algorithm on collections of scientific abstracts from several journals. This model exemplifies a recent trend in statistical machine learning--the use of Bayesian nonparametric methods to infer distributions on flexible data structures.",,"David M. Blei, Thomas L. Griffiths, Michael I. Jordan",statistics,val
Probabilistic coherence and proper scoring rules,We provide self-contained proof of a theorem relating probabilistic coherence of forecasts to their non-domination by rival forecasts with respect to any proper scoring rule. The theorem appears to be new but is closely related to results achieved by other investigators.,"LaTeX2, 15 pages","Joel Predd, Robert Seiringer, Elliott H. Lieb, Daniel Osherson, Vincent Poor, Sanjeev Kulkarni",statistics,val
Cognitive Constructivism and the Epistemic Significance of Sharp Statistical Hypotheses in Natural Sciences,"This book presents our case in defense of a constructivist epistemological framework and the use of compatible statistical theory and inference tools. The basic metaphor of decision theory is the maximization of a gambler's expected fortune, according to his own subjective utility, prior beliefs an learned experiences. This metaphor has proven to be very useful, leading the development of Bayesian statistics since its XX-th century revival, rooted on the work of de Finetti, Savage and others. The basic metaphor presented in this text, as a foundation for cognitive constructivism, is that of an eigen-solution, and the verification of its objective epistemic status. The FBST - Full Bayesian Significance Test - is the cornerstone of a set of statistical tolls conceived to assess the epistemic value of such eigen-solutions, according to their four essential attributes, namely, sharpness, stability, separability and composability. We believe that this alternative perspective, complementary to the one ofered by decision theory, can provide powerful insights and make pertinent contributions in the context of scientific research.",453 pages,J. M. Stern,statistics,train
"Sweave Documentation for ""Implementing Markov chain Monte Carlo: Estimating with confidence""","This file is the Sweave documentation for the examples provided in Flegal, J. M. and Jones, G. L. (2010), ""Implementing Markov chain Monte Carlo: Estimating with confidence"", in Handbook of Markov Chain Monte Carlo, edited by Brooks, S., Gelman, A., Jones, G., and Meng, X. published by Chapman & Hall/CRC Press.",,"James M. Flegal, Galin L. Jones",statistics,val
Hotelling's test for highly correlated data,"This paper is motivated by the analysis of gene expression sets, especially by finding differentially expressed gene sets between two phenotypes. Gene $\log_2$ expression levels are highly correlated and, very likely, have approximately normal distribution. Therefore, it seems reasonable to use two-sample Hotelling's test for such data. We discover some unexpected properties of the test making it different from the majority of tests previously used for such data. It appears that the Hotelling's test does not always reach maximal power when all marginal distributions are differentially expressed. For highly correlated data its maximal power is attained when about a half of marginal distributions are essentially different. For the case when the correlation coefficient is greater than 0.5 this test is more powerful if only one marginal distribution is shifted, omparing to the case when all marginal distributions are equally shifted. Moreover, when the correlation coefficient increases the power of Hotelling's test increases as well.","8 pages, 3 figures, 1 table",Peter Bubeliny,statistics,train
"The two sample problem: Exact distributions, numerical solutions, simulations","The work presented in this article suggests a solution to the two sample problem. Keywords: Two sample problem, Welch-Aspin solution, Fisher-Behrens problem, nuisance parameter, similarity, the Linnik phenomenon.",,D. E. Chambers,statistics,train
Development and Initial Validation of a Scale to Measure Instructors' Attitudes toward Concept-Based Teaching of Introductory Statistics in the Health and Behavioral Sciences,"Despite more than a decade of reform efforts, students continue to experience difficulty understanding and applying statistical concepts. The predominant focus of reform has been on content, pedagogy, technology and assessment, with little attention to instructor characteristics. However, there is strong theoretical and empirical evidence that instructors' attitudes impact the quality of teaching and learning. The objective of this study was to develop and initially validate a scale to measure instructors' attitudes toward reform-oriented (or concept-based) teaching of introductory statistics in the health and behavioral sciences, at the tertiary level. This scale will be referred to as FATS (Faculty Attitudes Toward Statistics). Data were obtained from 227 instructors (USA and international), and analyzed using factor analysis, multidimensional scaling and hierarchical cluster analysis. The overall scale consists of five sub-scales with a total of 25 items, and an overall alpha of 0.89. Construct validity was established. Specifically, the overall scale, and subscales (except perceived difficulty) plausibly differentiated between low-reform and high-reform practice instructors. Statistically significant differences in attitude were observed with respect to age, but not gender, employment status, membership status in professional organizations, ethnicity, highest academic qualification, and degree concentration. This scale can be considered a reliable and valid measure of instructors' attitudes toward reform-oriented (concept-based or constructivist) teaching of introductory statistics in the health and behavioral sciences at the tertiary level. These five dimensions influence instructors' attitudes. Additional studies are required to confirm these structural and psychometric properties.",ISI (International Statistical Institute) Conference Publication,"Rossi A. Hassad, Anthony P. M. Coxon",statistics,val
$L_p$-nested symmetric distributions,"Tractable generalizations of the Gaussian distribution play an important role for the analysis of high-dimensional data. One very general super-class of Normal distributions is the class of $\nu$-spherical distributions whose random variables can be represented as the product $\x = r\cdot \u$ of a uniformly distribution random variable $\u$ on the $1$-level set of a positively homogeneous function $\nu$ and arbitrary positive radial random variable $r$. Prominent subclasses of $\nu$-spherical distributions are spherically symmetric distributions ($\nu(\x)=\|\x\|_2$) which have been further generalized to the class of $L_p$-spherically symmetric distributions ($\nu(\x)=\|\x\|_p$). Both of these classes contain the Gaussian as a special case. In general, however, $\nu$-spherical distributions are computationally intractable since, for instance, the normalization constant or fast sampling algorithms are unknown for an arbitrary $\nu$. In this paper we introduce a new subclass of $\nu$-spherical distributions by choosing $\nu$ to be a nested cascade of $L_p$-norms. This class is still computationally tractable, but includes all the aforementioned subclasses as a special case. We derive a general expression for $L_p$-nested symmetric distributions as well as the uniform distribution on the $L_p$-nested unit sphere, including an explicit expression for the normalization constant. We state several general properties of $L_p$-nested symmetric distributions, investigate its marginals, maximum likelihood fitting and discuss its tight links to well known machine learning methods such as Independent Component Analysis (ICA), Independent Subspace Analysis (ISA) and mixed norm regularizers. Finally, we derive a fast and exact sampling algorithm for arbitrary $L_p$-nested symmetric distributions, and introduce the Nested Radial Factorization algorithm (NRF), which is a form of non-linear ICA.",,"Fabian Sinz, Matthias Bethge",statistics,train
Extreme shock models: an alternative perspective,"Extreme shock models have been introduced in Gut and H\""usler (1999) to study systems that at random times are subject to shock of random magnitude. These systems break down when some shock overcomes a given resistance level. In this paper we propose an alternative approach to extreme shock models using reinforced urn processes. As a consequence of this we are able to look at the same problem under a Bayesian nonparametric perspective, providing the predictive distribution of systems' defaults.",,"Pasquale Cirillo, Jürg Hüsler",statistics,test
Tests of Non-Equivalence among Absolutely Nonsingular Tensors through Geometric Invariants,"4x4x3 absolutely nonsingular tensors are characterized by their determinant polynomial. Non-quivalence among absolutely nonsingular tensors with respect to a class of linear transformations, which do not chage the tensor rank,is studied. It is shown theoretically that affine geometric invariants of the constant surface of a determinant polynomial is useful to discriminate non-equivalence among absolutely nonsingular tensors. Also numerical caluculations are presented and these invariants are shown to be useful indeed. For the caluculation of invarinats by 20-spherical design is also commented. We showed that an algebraic problem in tensor data analysis can be attacked by an affine geometric method.","24 pages, 3 figures, 5 tables","Toshio Sakata, Kazumitsu Maehra, Takeshi Sasaki, Toshio Sumi, Mitsuhiro Miyazaki, Yoshitaka Watanabe",statistics,val
A Conversation with James Hannan,"Jim Hannan is a professor who has lived an interesting life and one whose fundamental research in repeated games was not fully appreciated until late in his career. During his service as a meteorologist in the Army in World War II, Jim played poker and made weather forecasts. It is curious that his later research included strategies for repeated play that apply to selecting the best forecaster. James Hannan was born in Holyoke, Massachusetts on September 14, 1922. He attended St. Jerome's High School and in January 1943 received the Ph.B. from St. Michael's College in Colchester, Vermont. Jim enlisted in the US Army Air Force to train and serve as a meteorologist. This took him to army airbases in China by the close of the war. Following discharge from the army, Jim studied mathematics at Harvard and graduated with the M.S. in June 1947. To prepare for doctoral work in statistics at the University of North Carolina that fall, Jim went to the University of Michigan in the summer of 1947. The routine admissions' physical revealed a spot on the lung and the possibility of tuberculosis. This caused Jim to stay at Ann Arbor through the fall of 1947 and then at a Veterans Administration Hospital in Framingham, Massachusetts to have his condition followed more closely. He was discharged from the hospital in the spring and started his study at Chapel Hill in the fall of 1948. There he began research in compound decision theory under Herbert Robbins. Feeling the need for teaching experience, Jim left Chapel Hill after two years and short of thesis to take a three year appointment as an instructor at Catholic University in Washington, DC. When told that renewal was not coming, Jim felt pressure to finish his degree.","Published in at http://dx.doi.org/10.1214/09-STS283 the Statistical
  Science (http://www.imstat.org/sts/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)","Dennis Gilliland, R. V. Ramamoorthi",statistics,train
A Conversation with Martin Bradbury Wilk,"Martin Bradbury Wilk was born on December 18, 1922, in Montr\'{e}al, Qu\'{e}bec, Canada. He completed a B.Eng. degree in Chemical Engineering in 1945 at McGill University and worked as a Research Engineer on the Atomic Energy Project for the National Research Council of Canada from 1945 to 1950. He then went to Iowa State College, where he completed a M.Sc. and a Ph.D. degree in Statistics in 1953 and 1955, respectively. After a one-year post-doc with John Tukey, he became Assistant Director of the Statistical Techniques Research Group at Princeton University in 1956--1957, and then served as Professor and Director of Research in Statistics at Rutgers University from 1959 to 1963. In parallel, he also had a 14-year career at Bell Laboratories, Murray Hill, New Jersey. From 1956 to 1969, he was in turn Member of Technical Staff, Head of the Statistical Models and Methods Research Department, and Statistical Director in Management Sciences Research. He wrote a number of influential papers in statistical methodology during that period, notably testing procedures for normality (the Shapiro--Wilk statistic) and probability plotting techniques for multivariate data. In 1970, Martin moved into higher management levels of the American Telephone and Telegraph (AT&T) Company. He occupied various positions culminating as Assistant Vice-President and Director of Corporate Planning. In 1980, he returned to Canada and became the first professional statistician to serve as Chief Statistician. His accomplishments at Statistics Canada were numerous and contributed to a resurgence of the institution's international standing. He played a crucial role in the reinstatement of the Cabinet-cancelled 1986 Census.","Published in at http://dx.doi.org/10.1214/08-STS272 the Statistical
  Science (http://www.imstat.org/sts/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)","Christian Genest, Gordon Brackstone",statistics,train
On the Conditioning of the Spherical Harmonic Matrix for Spatial Audio Applications,"In this paper, we attempt to study the conditioning of the Spherical Harmonic Matrix (SHM), which is widely used in the discrete, limited order orthogonal representation of sound fields. SHM's has been widely used in the audio applications like spatial sound reproduction using loudspeakers, orthogonal representation of Head Related Transfer Functions (HRTFs) etc. The conditioning behaviour of the SHM depends on the sampling positions chosen in the 3D space. Identification of the optimal sampling points in the continuous 3D space that results in a well-conditioned SHM for any number of sampling points is a highly challenging task. In this work, an attempt has been made to solve a discrete version of the above problem using optimization based techniques. The discrete problem is, to identify the optimal sampling points from a discrete set of densely sampled positions of the 3D space, that minimizes the condition number of SHM. This method has been subsequently utilized for identifying the geometry of loudspeakers in the spatial sound reproduction, and in the selection of spatial sampling configurations for HRTF measurement. The application specific requirements have been formulated as additional constraints of the optimization problem. Recently developed mixed-integer optimization solvers have been used in solving the formulated problem. The performance of the obtained sampling position in each application is compared with the existing configurations. Objective measures like condition number, D-measure, and spectral distortion are used to study the performance of the sampling configurations resulting from the proposed and the existing methods. It is observed that the proposed solution is able to find the sampling points that results in a better conditioned SHM and also maintains all the application specific requirements.","12 pages; This paper is a preprint of a paper submitted to IET Signal
  Processing Journal. If accepted, the copy of record will be available at the
  IET Digital Library","C Sandeep Reddy, Rajesh M Hegde",electrical engineering and systems science,val
Singing voice correction using canonical time warping,"Expressive singing voice correction is an appealing but challenging problem. A robust time-warping algorithm which synchronizes two singing recordings can provide a promising solution. We thereby propose to address the problem by canonical time warping (CTW) which aligns amateur singing recordings to professional ones. A new pitch contour is generated given the alignment information, and a pitch-corrected singing is synthesized back through the vocoder. The objective evaluation shows that CTW is robust against pitch-shifting and time-stretching effects, and the subjective test demonstrates that CTW prevails the other methods including DTW and the commercial auto-tuning software. Finally, we demonstrate the applicability of the proposed method in a practical, real-world scenario.",,"Yin-Jyun Luo, Ming-Tso Chen, Tai-Shih Chi, Li Su",electrical engineering and systems science,val
Raga Identification using Repetitive Note Patterns from prescriptive notations of Carnatic Music,"Carnatic music, a form of Indian Art Music, has relied on an oral tradition for transferring knowledge across several generations. Over the last two hundred years, the use of prescriptive notations has been adopted for learning, sight-playing and sight-singing. Prescriptive notations offer generic guidelines for a raga rendition and do not include information about the ornamentations or the gamakas, which are considered to be critical for characterizing a raga. In this paper, we show that prescriptive notations contain raga attributes and can reliably identify a raga of Carnatic music from its octave-folded prescriptive notations. We restrict the notations to 7 notes and suppress the finer note position information. A dictionary based approach captures the statistics of repetitive note patterns within a raga notation. The proposed stochastic models of repetitive note patterns (or SMRNP in short) obtained from raga notations of known compositions, outperforms the state of the art melody based raga identification technique on an equivalent melodic data corresponding to the same compositions. This in turn shows that for Carnatic music, the note transitions and movements have a greater role in defining the raga structure than the exact note positions.",,"Ranjani H. G., T. V. Sreenivas",electrical engineering and systems science,train
Enhancement of Noisy Speech Exploiting an Exponential Model Based Threshold and a Custom Thresholding Function in Perceptual Wavelet Packet Domain,"For enhancement of noisy speech, a method of threshold determination based on modeling of Teager energy (TE) operated perceptual wavelet packet (PWP) coefficients of the noisy speech by exponential distribution is presented. A custom thresholding function based on the combination of mu-law and semisoft thresholding functions is designed and exploited to apply the statistically derived threshold upon the PWP coefficients. The effectiveness of the proposed method is evaluated for car and multi-talker babble noise corrupted speech signals through performing extensive simulations using the NOIZEUS database. The proposed method outperforms some of the state-of-the-art speech enhancement methods both at high and low levels of SNRs in terms of the standard objective measures and the subjective evaluations including formal listening tests.","Submitted to Circuits, Systems and Signal Processing, 17 pages, 20
  figures, 8 tables. arXiv admin note: text overlap with arXiv:1802.03472","Md Tauhidul Islam, Celia Shahnaz, Wei-Ping Zhu, M. Omair Ahmad",electrical engineering and systems science,train
Precise Detection of Speech Endpoints Dynamically: A Wavelet Convolution based approach,"Precise detection of speech endpoints is an important factor which affects the performance of the systems where speech utterances need to be extracted from the speech signal such as Automatic Speech Recognition (ASR) system. Existing endpoint detection (EPD) methods mostly uses Short-Term Energy (STE), Zero-Crossing Rate (ZCR) based approaches and their variants. But STE and ZCR based EPD algorithms often fail in the presence of Non-speech Sound Artifacts (NSAs) produced by the speakers. Algorithms based on pattern recognition and classification techniques are also proposed but require labeled data for training. A new algorithm termed as Wavelet Convolution based Speech Endpoint Detection (WCSEPD) is proposed in this article to extract speech endpoints. WCSEPD decomposes the speech signal into high-frequency and low-frequency components using wavelet convolution and computes entropy based thresholds for the two frequency components. The low-frequency thresholds are used to extract voiced speech segments, whereas the high-frequency thresholds are used to extract the unvoiced speech segments by filtering out the NSAs. WCSEPD does not require any labeled data for training and can automatically extract speech segments. Experiment results show that the proposed algorithm precisely extracts speech endpoints in the presence of NSAs.",25 Pages,"Tanmoy Roy, Tshilidzi Marwala, Snehashish Chakraverty",electrical engineering and systems science,test
Simulating dysarthric speech for training data augmentation in clinical speech applications,"Training machine learning algorithms for speech applications requires large, labeled training data sets. This is problematic for clinical applications where obtaining such data is prohibitively expensive because of privacy concerns or lack of access. As a result, clinical speech applications are typically developed using small data sets with only tens of speakers. In this paper, we propose a method for simulating training data for clinical applications by transforming healthy speech to dysarthric speech using adversarial training. We evaluate the efficacy of our approach using both objective and subjective criteria. We present the transformed samples to five experienced speech-language pathologists (SLPs) and ask them to identify the samples as healthy or dysarthric. The results reveal that the SLPs identify the transformed speech as dysarthric 65% of the time. In a pilot classification experiment, we show that by using the simulated speech samples to balance an existing dataset, the classification accuracy improves by about 10% after data augmentation.",Will appear in Proc. of ICASSP 2018,"Yishan Jiao, Ming Tu, Visar Berisha, Julie Liss",electrical engineering and systems science,val
Angular Softmax Loss for End-to-end Speaker Verification,"End-to-end speaker verification systems have received increasing interests. The traditional i-vector approach trains a generative model (basically a factor-analysis model) to extract i-vectors as speaker embeddings. In contrast, the end-to-end approach directly trains a discriminative model (often a neural network) to learn discriminative speaker embeddings; a crucial component is the training criterion. In this paper, we use angular softmax (A-softmax), which is originally proposed for face verification, as the loss function for feature learning in end-to-end speaker verification. By introducing margins between classes into softmax loss, A-softmax can learn more discriminative features than softmax loss and triplet loss, and at the same time, is easy and stable for usage. We make two contributions in this work. 1) We introduce A-softmax loss into end-to-end speaker verification and achieve significant EER reductions. 2) We find that the combination of using A-softmax in training the front-end and using PLDA in the back-end scoring further boosts the performance of end-to-end systems under short utterance condition (short in both enrollment and test). Experiments are conducted on part of $Fisher$ dataset and demonstrate the improvements of using A-softmax.",,"Yutian Li, Feng Gao, Zhijian Ou, Jiasong Sun",electrical engineering and systems science,train
RTF-Based Binaural MVDR Beamformer Exploiting an External Microphone in a Diffuse Noise Field,"Besides suppressing all undesired sound sources, an important objective of a binaural noise reduction algorithm for hearing devices is the preservation of the binaural cues, aiming at preserving the spatial perception of the acoustic scene. A well-known binaural noise reduction algorithm is the binaural minimum variance distortionless response beamformer, which can be steered using the relative transfer function (RTF) vector of the desired source, relating the acoustic transfer functions between the desired source and all microphones to a reference microphone. In this paper, we propose a computationally efficient method to estimate the RTF vector in a diffuse noise field, requiring an additional microphone that is spatially separated from the head-mounted microphones. Assuming that the spatial coherence between the noise components in the head-mounted microphone signals and the additional microphone signal is zero, we show that an unbiased estimate of the RTF vector can be obtained. Based on real-world recordings, experimental results for several reverberation times show that the proposed RTF estimator outperforms the widely used RTF estimator based on covariance whitening and a simple biased RTF estimator in terms of noise reduction and binaural cue preservation performance.",Accepted at ITG Conference on Speech Communication 2018,"N. Gößling, S. Doclo",electrical engineering and systems science,val
Independent Low-Rank Matrix Analysis Based on Time-Variant Sub-Gaussian Source Model,"Independent low-rank matrix analysis (ILRMA) is a fast and stable method for blind audio source separation. Conventional ILRMAs assume time-variant (super-)Gaussian source models, which can only represent signals that follow a super-Gaussian distribution. In this paper, we focus on ILRMA based on a generalized Gaussian distribution (GGD-ILRMA) and propose a new type of GGD-ILRMA that adopts a time-variant sub-Gaussian distribution for the source model. By using a new update scheme called generalized iterative projection for homogeneous source models, we obtain a convergence-guaranteed update rule for demixing spatial parameters. In the experimental evaluation, we show the versatility of the proposed method, i.e., the proposed time-variant sub-Gaussian source model can be applied to various types of source signal.","8 pages, 5 figures, To appear in the Proceedings of APSIPA ASC 2018","Shinichi Mogami, Norihiro Takamune, Daichi Kitamura, Hiroshi Saruwatari, Yu Takahashi, Kazunobu Kondo, Hiroaki Nakajima, Nobutaka Ono",electrical engineering and systems science,train
Advancing Multi-Accented LSTM-CTC Speech Recognition using a Domain Specific Student-Teacher Learning Paradigm,"Non-native speech causes automatic speech recognition systems to degrade in performance. Past strategies to address this challenge have considered model adaptation, accent classification with a model selection, alternate pronunciation lexicon, etc. In this study, we consider a recurrent neural network (RNN) with connectionist temporal classification (CTC) cost function trained on multi-accent English data including US (Native), Indian and Hispanic accents. We exploit dark knowledge from a model trained with the multi-accent data to train student models under the guidance of both a teacher model and CTC cost of target transcription. We show that transferring knowledge from a single RNN-CTC trained model toward a student model, yields better performance than the stand-alone teacher model. Since the outputs of different trained CTC models are not necessarily aligned, it is not possible to simply use an ensemble of CTC teacher models. To address this problem, we train accent specific models under the guidance of a single multi-accent teacher, which results in having multiple aligned and trained CTC models. Furthermore, we train a student model under the supervision of the accent-specific teachers, resulting in an even further complementary model, which achieves +20.1% relative Character Error Rate (CER) reduction compared to the baseline trained without any teacher. Having this effective multi-accent model, we can achieve further improvement for each accent by adapting the model to each accent. Using the accent specific model's outputs to regularize the adapting process (i.e., a knowledge distillation version of Kullback-Leibler (KL) divergence) results in even superior performance compared to the conventional approach using general teacher models.",Accepted at SLT 2018,"Shahram Ghorbani, Ahmet E. Bulut, John H. L. Hansen",electrical engineering and systems science,val
Assessing Visual Quality of Omnidirectional Videos,"In contrast with traditional video, omnidirectional video enables spherical viewing direction with support for head-mounted displays, providing an interactive and immersive experience. Unfortunately, to the best of our knowledge, there are few visual quality assessment (VQA) methods, either subjective or objective, for omnidirectional video coding. This paper proposes both subjective and objective methods for assessing quality loss in encoding omnidirectional video. Specifically, we first present a new database, which includes the viewing direction data from several subjects watching omnidirectional video sequences. Then, from our database, we find a high consistency in viewing directions across different subjects. The viewing directions are normally distributed in the center of the front regions, but they sometimes fall into other regions, related to video content. Given this finding, we present a subjective VQA method for measuring difference mean opinion score (DMOS) of the whole and regional omnidirectional video, in terms of overall DMOS (O-DMOS) and vectorized DMOS (V-DMOS), respectively. Moreover, we propose two objective VQA methods for encoded omnidirectional video, in light of human perception characteristics of omnidirectional video. One method weighs the distortion of pixels with regard to their distances to the center of front regions, which considers human preference in a panorama. The other method predicts viewing directions according to video content, and then the predicted viewing directions are leveraged to allocate weights to the distortion of each pixel in our objective VQA method. Finally, our experimental results verify that both the subjective and objective methods proposed in this paper advance state-of-the-art VQA for omnidirectional video.","[PLEASE CITE the TCSVT version instead of arxiv version!] Published
  in: IEEE Transactions on Circuits and Systems for Video Technology ( Early
  Access )","Mai Xu, Chen Li, Zulin Wang, Zhenzhong Chen, Zhenyu Guan",electrical engineering and systems science,train
Image Acquisition System Using On Sensor Compressed Sampling Technique,"Advances in CMOS technology have made high resolution image sensors possible. These image sensor pose significant challenges in terms of the amount of raw data generated, energy efficiency and frame rate. This paper presents a new design methodology for an imaging system and a simplified novel image sensor pixel design to be used in such system so that Compressed Sensing (CS) technique can be implemented easily at the sensor level. This results in significant energy savings as it not only cuts the raw data rate but also reduces transistor count per pixel, decreases pixel size, increases fill factor, simplifies ADC, JPEG encoder and JPEG decoder design and decreases wiring as well as address decoder size by half. Thus CS has the potential to increase the resolution of image sensors for a given technology and die size while significantly decreasing the power consumption and design complexity. We show that it has potential to reduce power consumption by about 23%-65%.",,"Pravir Singh Gupta, Gwan Seong Choi",electrical engineering and systems science,train
Having your cake and eating it too: Scripted workflows for image manipulation,"The reproducibility issue in science has come under increased scrutiny. One consistent suggestion lies in the use of scripted methods or workflows for data analysis. Image analysis is one area in science in which little can be done in scripted methods. The SWIIM Project (Scripted Workflows to Improve Image Manipulation) is designed to generate workflows from popular image manipulation tools. In the project, 2 approaches are being taken to construct workflows in the image analysis area. First, the open-source tool GIMP is being enhanced to produce an active log (which can be run on a stand-alone basis to perform the same manipulation). Second, the R system Shiny tool is being used to construct a graphical user interface (GUI) which works with EBImage code to modify images, and to produce an active log which can perform the same operations. This process has been successful to date, but is not complete. The basic method for each component is discussed, and example code is shown.",Written for Work17 Conference,"Paul A. Thompson, Norm Matloff, Alex Fu, Ariel Shin",electrical engineering and systems science,train
Neuromorphic adaptive edge-preserving denoising filter,"In this paper, we present on-sensor neuromorphic vision hardware implementation of denoising spatial filter. The mean or median spatial filters with fixed window shape are known for its denoising ability, however, have the drawback of blurring the object edges. The effect of blurring increases with an increase in window size. To preserve the edge information, we propose an adaptive spatial filter that uses neuron's ability to detect similar pixels and calculates the mean. The analog input differences of neighborhood pixels are converted to the chain of pulses with voltage controlled oscillator and applied as neuron input. When the input pulses charge the neuron to equal or greater level than its threshold, the neuron will fire, and pixels are identified as similar. The sequence of the neuron's responses for pixels is stored in the serial-in-parallel-out shift register. The outputs of shift registers are used as input to the selector switches of an averaging circuit making this an adaptive mean operation resulting in an edge preserving mean filter. System level simulation of the hardware is conducted using 150 images from Caltech database with added Gaussian noise to test the robustness of edge-preserving and denoising ability of the proposed filter. Threshold values of the hardware neuron were adjusted so that the proposed edge-preserving spatial filter achieves optimal performance in terms of PSNR and MSE, and these results outperforms that of the conventional mean and median filters.",IEEE International Conference on Rebooting Computing 2017,"Aidana Irmanova, Olga Krestinskaya, Alex Pappachen James",electrical engineering and systems science,val
Statistically Segregated k-Space Sampling for Accelerating Multiple-Acquisition MRI,"A central limitation of multiple-acquisition magnetic resonance imaging (MRI) is the degradation in scan efficiency as the number of distinct datasets grows. Sparse recovery techniques can alleviate this limitation via randomly undersampled acquisitions. A frequent sampling strategy is to prescribe for each acquisition a different random pattern drawn from a common sampling density. However, naive random patterns often contain gaps or clusters across the acquisition dimension that in turn can degrade reconstruction quality or reduce scan efficiency. To address this problem, a statistically-segregated sampling method is proposed for multiple-acquisition MRI. This method generates multiple patterns sequentially, while adaptively modifying the sampling density to minimize k-space overlap across patterns. As a result, it improves incoherence across acquisitions while still maintaining similar sampling density across the radial dimension of k-space. Comprehensive simulations and in vivo results are presented for phase-cycled balanced steady-state free precession and multi-echo T$_2$-weighted imaging. Segregated sampling achieves significantly improved quality in both Fourier and compressed-sensing reconstructions of multiple-acquisition datasets.","10 pages, 9 figures. Submitted to IEEE Transactions on Medical
  Imaging","L Kerem Senel, Toygan Kilic, Alper Gungor, Emre Kopanoglu, H Emre Guven, Emine U Saritas, Aykut Koc, Tolga Cukur",electrical engineering and systems science,train
Light Field Retargeting for Multi-Panel Displays,"Light fields preserve angular information which can be retargeted to multi-panel depth displays. Due to limited aperture size and constrained spatial-angular sampling of many light field capture systems, the displayed light fields provide only a narrow viewing zone in which parallax views can be supported. In addition, multi-panel displays typically have a reduced number of panels being able to coarsely sample depth content resulting in a layered appearance of light fields. We propose a light field retargeting technique for multi-panel displays that enhances the perceived parallax and achieves seamless transition over different depths and viewing angles. This is accomplished by slicing the captured light fields according to their depth content, boosting the parallax, and blending the results across the panels. Displayed views are synthesized and aligned dynamically according to the position of the viewer. The proposed technique is outlined, simulated and verified experimentally on a three-panel aerial display.",16 Pages,"Basel Salahieh, Seth Hunter, Yi Wu, Oscar Nestares",electrical engineering and systems science,train
A Semi-Automated Technique for Internal Jugular Vein Segmentation in Ultrasound Images Using Active Contours,"The assessment of the blood volume is crucial for the management of many acute and chronic diseases. Recent studies have shown that circulating blood volume correlates with the cross-sectional area (CSA) of the internal jugular vein (IJV) estimated from ultrasound imagery. In this paper, a semi-automatic segmentation algorithm is proposed using a combination of region growing and active contour techniques to provide a fast and accurate segmentation of IJV ultrasound videos. The algorithm is applied to track and segment the IJV across a range of image qualities, shapes, and temporal variation. The experimental results show that the algorithm performs well compared to expert manual segmentation and outperforms several published algorithms incorporating speckle tracking.","4 pages, 6 figures","Ebrahim Karami, Mohamed Shehata, Peter McGuire, Andrew Smith",electrical engineering and systems science,train
A Fast and Efficient Near-Lossless Image Compression using Zipper Transformation,"Near-lossless image compression-decompression scheme is proposed in this paper using Zipper Transformation (ZT) and inverse zipper transformation (iZT). The proposed ZT exploits the conjugate symmetry property of Discrete Fourier Transformation (DFT). The proposed transformation is implemented using two different configurations: the interlacing and concatenating ZT. In order to quantify the efficacy of the proposed transformation, we benchmark with Discrete Cosine Transformation (DCT) and Fast Walsh Hadamard Transformation (FWHT) in terms of lossless compression capability and computational cost. Numerical simulations show that ZT-based compression algorithm is near-lossless, compresses better, and offers faster implementation than both DCT and FWHT. Also, interlacing and concatenating ZT are shown to yield similar results in most of the test cases considered.",,Babajide O. Ayinde,electrical engineering and systems science,train
On-the-fly Adaptive $k$-Space Sampling for Linear MRI Reconstruction Using Moment-Based Spectral Analysis,"In high-dimensional magnetic resonance imaging applications, time-consuming, sequential acquisition of data samples in the spatial frequency domain ($k$-space) can often be accelerated by accounting for dependencies along imaging dimensions other than space in linear reconstruction, at the cost of noise amplification that depends on the sampling pattern. Examples are support-constrained, parallel, and dynamic MRI, and $k$-space sampling strategies are primarily driven by image-domain metrics that are expensive to compute for arbitrary sampling patterns. It remains challenging to provide systematic and computationally efficient automatic designs of arbitrary multidimensional Cartesian sampling patterns that mitigate noise amplification, given the subspace to which the object is confined. To address this problem, this work introduces a theoretical framework that describes local geometric properties of the sampling pattern and relates these properties to a measure of the spread in the eigenvalues of the information matrix described by its first two spectral moments. This new criterion is then used for very efficient optimization of complex multidimensional sampling patterns that does not require reconstructing images or explicitly mapping noise amplification. Experiments with in vivo data show strong agreement between this criterion and traditional, comprehensive image-domain- and $k$-space-based metrics, indicating the potential of the approach for computationally efficient (on-the-fly), automatic, and adaptive design of sampling patterns.","12 pages, 8 figures, Submitted to IEEE Transactions on Medical
  Imaging","Evan Levine, Brian Hargreaves",electrical engineering and systems science,train
Silver Standard Masks for Data Augmentation Applied to Deep-Learning-Based Skull-Stripping,"The bottleneck of convolutional neural networks (CNN) for medical imaging is the number of annotated data required for training. Manual segmentation is considered to be the ""gold-standard"". However, medical imaging datasets with expert manual segmentation are scarce as this step is time-consuming and expensive. We propose in this work the use of what we refer to as silver standard masks for data augmentation in deep-learning-based skull-stripping also known as brain extraction. We generated the silver standard masks using the consensus algorithm Simultaneous Truth and Performance Level Estimation (STAPLE). We evaluated CNN models generated by the silver and gold standard masks. Then, we validated the silver standard masks for CNNs training in one dataset, and showed its generalization to two other datasets. Our results indicated that models generated with silver standard masks are comparable to models generated with gold standard masks and have better generalizability. Moreover, our results also indicate that silver standard masks could be used to augment the input dataset at training stage, reducing the need for manual segmentation at this step.",,"Oeslle Lucena, Roberto Souza, Letícia Rittner, Richard Frayne, Roberto Lotufo",electrical engineering and systems science,train
Cognitive Random Stepped Frequency Radar with Sparse Recovery,"Random stepped frequency (RSF) radar, which transmits random-frequency pulses, can suppress the range ambiguity, improve convert detection, and possess excellent electronic counter-countermeasures (ECCM) ability [1]. In this paper, we apply a sparse recovery method to estimate the range and Doppler of targets. We also propose a cognitive mechanism for RSF radar to further enhance the performance of the sparse recovery method. The carrier frequencies of transmitted pulses are adaptively designed in response to the observed circumstance. We investigate the criterion to design carrier frequencies, and efficient methods are then devised. Simulation results demonstrate that the adaptive frequency-design mechanism significantly improves the performance of target reconstruction in comparison with the non-adaptive mechanism.","29 pages, 13 figures","Tianyao Huang, Yimin Liu, Huadong Meng, Xiqin Wang",electrical engineering and systems science,train
Cramer-Rao Lower Bounds of Joint Delay-Doppler Estimation for an Extended Target,"The problem on the Cramer-Rao Lower Bounds (CRLBs) for the joint time delay and Doppler stretch estimation of an extended target is considered in this paper. The integral representations of the CRLBs for both the time delay and the Doppler stretch are derived. To facilitate computation and analysis, series representations and approximations of the CRLBs are introduced. According to these series representations, the impact of several waveform parameters on the estimation accuracy is investigated, which reveals that the CRLB of the Doppler stretch is inversely proportional to the effective time-bandwidth product of the waveform. This conclusion generalizes a previous result in the narrowband case. The popular wideband ambiguity function (WBAF) based delay-Doppler estimator is evaluated and compared with the CRLBs through numerical experiments. Our results indicate that the WBAF estimator, originally derived from a single scatterer model, is not suitable for the parameter estimation of an extended target.",,"Tong Zhao, Tianyao Huang",electrical engineering and systems science,test
Bounds on Discrete Fourier Transform of Random Mask,"This paper proposes some bounds on the maximum of magnitude of a random mask in Fourier domain. The random mask is used in random sampling scheme. Having a bound on the maximum value of a random mask in Fourier domain is very useful for some iterative recovery methods that use thresholding operator. In this paper, we propose some different bounds and compare them with the empirical examples.",,"Nematollah Zarmehi, Farokh Marvasti",electrical engineering and systems science,test
Adaptive Nonlinear RF Cancellation for Improved Isolation in Simultaneous Transmit-Receive Systems,"This paper proposes an active radio frequency (RF) cancellation solution to suppress the transmitter (TX) passband leakage signal in radio transceivers supporting simultaneous transmission and reception. The proposed technique is based on creating an opposite-phase baseband equivalent replica of the TX leakage signal in the transceiver digital front-end through adaptive nonlinear filtering of the known transmit data, to facilitate highly accurate cancellation under a nonlinear TX power amplifier (PA). The active RF cancellation is then accomplished by employing an auxiliary transmitter chain, to generate the actual RF cancellation signal, and combining it with the received signal at the receiver (RX) low noise amplifier (LNA) input. A closed-loop parameter learning approach, based on the decorrelation principle, is also developed to efficiently estimate the coefficients of the nonlinear cancellation filter in the presence of a nonlinear TX PA with memory, finite passive isolation, and a nonlinear RX LNA. The performance of the proposed cancellation technique is evaluated through comprehensive RF measurements adopting commercial LTE-Advanced transceiver hardware components. The results show that the proposed technique can provide an additional suppression of up to 54 dB for the TX passband leakage signal at the RX LNA input, even at considerably high transmit power levels and with wide transmission bandwidths. Such novel cancellation solution can therefore substantially improve the TX-RX isolation, hence reducing the requirements on passive isolation and RF component linearity, as well as increasing the efficiency and flexibility of the RF spectrum use in the emerging 5G radio networks.",accepted to IEEE,"Adnan Kiayani, Muhammad Zeeshan Waheed, Lauri Anttila, Mahmoud Abdelaziz, Dani Korpi, Ville Syrjälä, Marko Kosunen, Kari Stadius, Jussi Ryynänen, Mikko Valkama",electrical engineering and systems science,train
Optimal Linear Precoding for Indoor Visible Light Communication System,"Visible light communication (VLC) is an emerging technique that uses light-emitting diodes (LED) to combine communication and illumination. It is considered as a promising scheme for indoor wireless communication that can be deployed at reduced costs while offering high data rate performance. In this paper, we focus on the design of the downlink of a multi-user VLC system. Inherent to multi-user systems is the interference caused by the broadcast nature of the medium. Linear precoding based schemes are among the most popular solutions that have recently been proposed to mitigate inter-user interference. This paper focuses on the design of the optimal linear precoding scheme that solves the max-min signal-to-interference-plus-noise ratio (SINR) problem. The performance of the proposed precoding scheme is studied under different working conditions and compared with the classical zero-forcing precoding. Simulations have been provided to illustrate the high gain of the proposed scheme.","5 pages, 4 figures, accepted for publication in ICC proceedings 2017","Houssem Sifaou, Ki-Hong Park, Abla Kammoun, Mohamed-Slim Alouini",electrical engineering and systems science,val
Optimal Training for Residual Self-Interference for Full Duplex One-way Relays,"Channel estimation and optimal training sequence design for full-duplex one-way relays are investigated. We propose a training scheme to estimate the residual self-interference (RSI) channel and the channels between nodes simultaneously. A maximum likelihood estimator is implemented with Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm. In the presence of RSI, the overall source-to-destination channel becomes an inter-symbol-interference (ISI) channel. With the help of estimates of the RSI channel, the destination is able to cancel the ISI through equalization. We derive and analyze the Cramer-Rao bound (CRB) in closed-form by using the asymptotic properties of Toeplitz matrices. The optimal training sequence is obtained by minimizing the CRB. Extensions for the fundamental one-way relay model to the frequency-selective fading channels and the multiple relays case are also considered. For the former, we propose a training scheme to estimate the overall channel, and for the latter the CRB and the optimal number of relays are derived when the distance between the source and the destination is fixed. Simulations using LTE parameters corroborate our theoretical results.",,"Xiaofeng Li, Cihan Tepedelenlioğlu, Habib Şenol",electrical engineering and systems science,train
Modeling and Analysis of Power Line Communications for Application in Smart Grid,"Smart grid is an energy infrastructure that increases energy efficiency by using communication infrastructure, smart meters, smart appliances, automated control and networking, and more. This paper focuses on the Power Line Communication (PLC) aspect and technologies used in the smart grid. There are various challenges and advancements in the smart grid; this research discusses how PLC can improve smart grid performance. In order to provide applicable results, practical PLC system parameters and other required data was obtained from Florida Power and Light (FPL). Modeling of the PLC system with different types of digital modulations was conducted using MATLAB/Simulink software and Python. The benefits and design tradeoffs of Amplitude Shift Keying (ASK), Frequency Shift Keying (FSK), and Phase Shift Keying (PSK) are discussed. The modulation schemes are compared on the basis of their applicability to a practical PLC network by comparing the results of the simulations","6 pages, 13 figures, LACCEI 2017, Boca Raton, FL","Moegamat Peck, Genesis Alvarez, Benjamin Coleman, Hadis Moradi, Mark Forest, Valentine Aalo",electrical engineering and systems science,train
Interconnection Strategies for Self-Calibration of Large Scale Antenna Arrays,"In time-division duplexing (TDD) systems, massive multiple-input multiple-output (MIMO) relies on the channel reciprocity to obtain the downlink (DL) channel state information (CSI) with the uplink (UL) CSI. In practice, the mismatches in the radio frequency (RF) analog circuits among different antennas at the base station (BS) break the end-to-end UL and DL channel reciprocity. Antenna calibration is necessary to avoid the severe performance degradation with massive MIMO. Many calibration schemes are available to compensate the RF gain mismatches and restore the channel reciprocity in TDD massive MIMO systems. In this paper, we focus on the internal self-calibration scheme where different BS antennas are interconnected via hardware transmission lines. First, we study the resulting calibration performance for an arbitrary interconnection strategy. Next, we obtain closed-form Cramer-Rao lower bound (CRLB) expressions for each interconnection strategy at the BS with only (M-1) transmission lines and M denotes the total number of BS antennas. Basing on the derived results, we further prove that the star interconnection strategy is optimal for internal self-calibration due to its lowest CRLB. In addition, we also put forward efficient recursive algorithms to derive the corresponding maximum-likelihood (ML) estimates of all the calibration coefficients. Numerical simulation results are also included to corroborate our theoretical analyses and results.",,"Hanyu Zhu, Fuqian Yang, Zhaowei Zhu, Xiliang Luo",electrical engineering and systems science,train
Bolt Detection Signal Analysis Method Based on ICEEMD,"The construction quality of the bolt is directly related to the safety of the project, and as such, it must be tested. In this paper, the improved complete ensemble empirical mode decomposition (ICEEMD) method is introduced to the bolt detection signal analysis. The ICEEMD is used in order to decompose the anchor detection signal according to the approximate entropy of each intrinsic mode function (IMF). The noise of the IMFs is eliminated by the wavelet soft threshold de-noising technique. Based on the approximate entropy, and the wavelet de-noising principle, the ICEEMD-De anchor signal analysis method is proposed. From the analysis of the vibration analog signal, as well as the bolt detection signal, the result shows that the ICEEMD-De method is capable of correctly separating the different IMFs under noisy conditions, and also that the IMF can effectively identify the reflection signal of the end of the bolt.",,"Chunhui Guo, Zhan Zhang, Xin Xie, Zhengyu Yang",electrical engineering and systems science,test
Spectral and Energy Efficiency of Superimposed Pilots in Uplink Massive MIMO,"Next generation wireless networks aim at providing substantial improvements in spectral efficiency (SE) and energy efficiency (EE). Massive MIMO has been proved to be a viable technology to achieve these goals by spatially multiplexing several users using many base station (BS) antennas. A potential limitation of Massive MIMO in multicell systems is pilot contamination, which arises in the channel estimation process from the interference caused by reusing pilots in neighboring cells. A standard method to reduce pilot contamination, known as regular pilot (RP), is to adjust the length of pilot sequences while transmitting data and pilot symbols disjointly. An alternative method, called superimposed pilot (SP), sends a superposition of pilot and data symbols. This allows to use longer pilots which, in turn, reduces pilot contamination. We consider the uplink of a multicell Massive MIMO network using maximum ratio combining detection and compare RP and SP in terms of SE and EE. To this end, we derive rigorous closed-form achievable rates with SP under a practical random BS deployment. We prove that the reduction of pilot contamination with SP is outweighed by the additional coherent and non-coherent interference. Numerical results show that when both methods are optimized, RP achieves comparable SE and EE to SP in practical scenarios.","32 pages, 12 figures, 3 tables. Submitted in March 2017 to IEEE
  Transactions on Wireless Communications","Daniel Verenzuela, Emil Björnson, Luca Sanguinetti",electrical engineering and systems science,val
Cluster Synchronization of Coupled Systems with Nonidentical Linear Dynamics,"This paper considers the cluster synchronization problem of generic linear dynamical systems whose system models are distinct in different clusters. These nonidentical linear models render control design and coupling conditions highly correlated if static couplings are used for all individual systems. In this paper, a dynamic coupling structure, which incorporates a global weighting factor and a vanishing auxiliary control variable, is proposed for each agent and is shown to be a feasible solution. Lower bounds on the global and local weighting factors are derived under the condition that every interaction subgraph associated with each cluster admits a directed spanning tree. The spanning tree requirement is further shown to be a necessary condition when the clusters connect acyclically with each other. Simulations for two applications, cluster heading alignment of nonidentical ships and cluster phase synchronization of nonidentical harmonic oscillators, illustrate essential parts of the derived theoretical results.","accepted version by International Journal of Robust and Nonlinear
  Control","Zhongchang Liu, Wing Shing Wong, Hui Cheng",electrical engineering and systems science,val
Global stabilization of multiple integrators by a bounded feedback with constraints on its successive derivatives,"In this paper, we address the global stabilization of chains of integrators by means of a bounded static feedback law whose p first time derivatives are bounded. Our construction is based on the technique of nested saturations introduced by Teel. We show that the control amplitude and the maximum value of its p first derivatives can be imposed below any prescribed values. Our results are illustrated by the stabilization of the third order integrator on the feedback and its first two derivatives.",,"Jonathan Laporte, Antoine Chaillet, Yacine Chitour",electrical engineering and systems science,train
Stochastic Battery Model for Aggregation of Thermostatically Controlled Loads,"The potential of demand side as a frequency reserve proposes interesting opportunity in handling imbalances due to intermittent renewable energy sources. This paper proposes a novel approach for computing the parameters of a stochastic battery model representing the aggregation of Thermostatically Controlled Loads (TCLs). A hysteresis based non-disruptive control is used using priority stack algorithm to track the reference regulation signal. The parameters of admissible ramp-rate and the charge limits of the battery are dynamically calculated using the information from TCLs that is the status (on/off), availability and relative temperature distance till the switching boundary. The approach builds on and improves on the existing research work by providing a straight-forward mechanism for calculation of stochastic parameters of equivalent battery model. The effectiveness of proposed approach is demonstrated by a test case having a large number of residential TCLs tracking a scaled down real frequency regulation signal.",IEEE ICIT 2016 conference,"Sohail Khan, Mohsin Shahzad, Usman Habib, Wolfgang Gawlik, Peter Palensky",computer science,train
PI(D) tuning for Flight Control Systems via Incremental Nonlinear Dynamic Inversion,"Previous results reported in the robotics literature show the relationship between time-delay control (TDC) and proportional-integral-derivative control (PID). In this paper, we show that incremental nonlinear dynamic inversion (INDI) - more familiar in the aerospace community - are in fact equivalent to TDC. This leads to a meaningful and systematic method for PI(D)-control tuning of robust nonlinear flight control systems via INDI. We considered a reformulation of the plant dynamics inversion which removes effector blending models from the resulting control law, resulting in robust model-free control laws like PI(D)-control.","Accepted to IFAC 2017 World Congress, Toulouse, France","Paul Acquatella B., Wim van Ekeren, Qi Ping Chu",computer science,train
Robust Power System Dynamic State Estimator with Non-Gaussian Measurement Noise: Part II--Implementation and Results,"This paper is the second of a two-part series that discusses the implementation issues and test results of a robust Unscented Kalman Filter (UKF) for power system dynamic state estimation with non-Gaussian synchrophasor measurement noise. The tuning of the parameters of our Generalized Maximum-Likelihood-type robust UKF (GM-UKF) is presented and discussed in a systematic way. Using simulations carried out on the IEEE 39-bus system, its performance is evaluated under different scenarios, including i) the occurrence of two different types of noises following thick-tailed distributions, namely the Laplace or Cauchy probability distributions for real and reactive power measurements; ii) the occurrence of observation and innovation outliers; iii) the occurrence of PMU measurement losses due to communication failures; iv) cyber attacks; and v) strong system nonlinearities. It is also compared to the UKF and the Generalized Maximum-Likelihood-type robust iterated EKF (GM-IEKF). Simulation results reveal that the GM-UKF outperforms the GM-IEKF and the UKF in all scenarios considered. In particular, when the system is operating under stressed conditions, inducing system nonlinearities, the GM-IEKF and the UKF diverge while our GM-UKF does converge. In addition, when the power measurement noises obey a Cauchy distribution, our GM-UKF converges to a state estimate vector that exhibits a much higher statistical efficiency than that of the GM-IEKF; by contrast, the UKF fails to converge. Finally, potential applications and future work of the proposed GM-UKF are discussed in concluding remarks section.",Submitted to IEEE Transactions on Power Systems,"Junbo Zhao, Lamine Mili",computer science,test
Online Simultaneous State and Parameter Estimation,"In this paper, a concurrent learning based adaptive observer is developed for a class of second-order nonlinear time-invariant systems with uncertain dynamics. The developed technique results in uniformly ultimately bounded state and parameter estimation errors. As opposed to persistent excitation which is required for parameter convergence in traditional adaptive control methods, the developed technique only requires excitation over a finite time interval to achieve parameter convergence. Simulation results in both noise-free and noisy environments are presented to validate the design.",arXiv admin note: text overlap with arXiv:1609.05879,"Ryan Self, Moad Abudia, S. M. Nahid Mahmud, Rushikesh Kamalapurkar",electrical engineering and systems science,train
A Graphical Characterization of Structurally Controllable Linear Systems with Dependent Parameters,"One version of the concept of structural controllability defined for single-input systems by Lin and subsequently generalized to multi-input systems by others, states that a parameterized matrix pair $(A, B)$ whose nonzero entries are distinct parameters, is structurally controllable if values can be assigned to the parameters which cause the resulting matrix pair to be controllable. In this paper the concept of structural controllability is broadened to allow for the possibility that a parameter may appear in more than one location in the pair $(A, B)$. Subject to a certain condition on the parameterization called the ""binary assumption"", an explicit graph-theoretic characterization of such matrix pairs is derived.",,"Fengjiao Liu, A. Stephen Morse",computer science,train
"Variation Evolving for Optimal Control Computation, a Compact Way","A compact version of the variation evolving method (VEM) is developed in the primal variable space for optimal control computation. Following the idea that originates from the Lyapunov continuous-time dynamics stability theory in the control field, the optimal solution is analogized to the stable equilibrium point of a dynamic system and obtained asymptotically through the variation motion. With the introduction of a virtual dimension, namely the variation time, the evolution partial differential equation (EPDE), which seeks the optimal solution with a theoretical guarantee, is developed for the optimal control problem (OCP) with free terminal states, and the equivalent optimality conditions with no employment of costates are established in the primal space. These conditions show that the optimal feedback control law is generally not analytically available because the optimal control is related to the future states. Since the derived EPDE is suitable to be computed with the semi-discrete method in the field of PDE numerical calculation, the optimal solution may be obtained by solving the resulting finite-dimensional initial-value problem (IVP).","22 pages, 8 figures. arXiv admin note: text overlap with
  arXiv:1703.10263","Sheng Zhang, Jiang-Tao Huang, Kai-Feng He, Fei Liao",electrical engineering and systems science,train
Small Satellite Constellation Separation using Linear Programming based Differential Drag Commands,"We study the optimal control of an arbitrarily large constellation of small satellites operating in low Earth orbit. Simulating the lack of on-board propulsion, we limit our actuation to the use of differential drag maneuvers to make in-plane changes to the satellite orbits. We propose an efficient method to separate a cluster of satellites into a desired constellation shape while respecting actuation constraints and maximizing the operational lifetime of the constellation. By posing the problem as a linear program, we solve for the optimal drag commands for each of the satellites on a daily basis with a shrinking-horizon model predictive control approach. We then apply this control strategy in a nonlinear orbital dynamics simulation with a simple, varying atmospheric density model. We demonstrate the ability to control a cluster of 100+ satellites starting at the same initial conditions in a circular low Earth orbit to form an equally spaced constellation (with a relative angular separation error tolerance of one-tenth a degree). The constellation separation task can be executed in 71 days, a time frame that is competitive for the state-of-the-practice. This method allows us to trade the time required to converge to the desired constellation with a sacrifice in the overall constellation lifetime, measured as the maximum altitude loss experienced by one of the satellites in the group after the separation maneuvers.","8 pages, 9 figures","Emmanuel Sin, Murat Arcak, Andrew Packard",computer science,test
An Elementary Introduction to Kalman Filtering,"Kalman filtering is a classic state estimation technique used in application areas such as signal processing and autonomous control of vehicles. It is now being used to solve problems in computer systems such as controlling the voltage and frequency of processors. Although there are many presentations of Kalman filtering in the literature, they usually deal with particular systems like autonomous robots or linear systems with Gaussian noise, which makes it difficult to understand the general principles behind Kalman filtering. In this paper, we first present the abstract ideas behind Kalman filtering at a level accessible to anyone with a basic knowledge of probability theory and calculus, and then show how these concepts can be applied to the particular problem of state estimation in linear systems. This separation of concepts from applications should make it easier to understand Kalman filtering and to apply it to other problems in computer systems.",Small tweaks,"Yan Pei, Swarnendu Biswas, Donald S. Fussell, Keshav Pingali",electrical engineering and systems science,train
Fixed Effect Estimation of Large T Panel Data Models,"This article reviews recent advances in fixed effect estimation of panel data models for long panels, where the number of time periods is relatively large. We focus on semiparametric models with unobserved individual and time effects, where the distribution of the outcome variable conditional on covariates and unobserved effects is specified parametrically, while the distribution of the unobserved effects is left unrestricted. Compared to existing reviews on long panels (Arellano and Hahn 2007; a section in Arellano and Bonhomme 2011) we discuss models with both individual and time effects, split-panel Jackknife bias corrections, unbalanced panels, distribution and quantile effects, and other extensions. Understanding and correcting the incidental parameter bias caused by the estimation of many fixed effects is our main focus, and the unifying theme is that the order of this bias is given by the simple formula p/n for all models discussed, with p the number of estimated parameters and n the total sample size.","40 pages, 1 table","Iván Fernández-Val, Martin Weidner",economics,val
Bounds On Treatment Effects On Transitions,"This paper considers the identification of treatment effects on conditional transition probabilities. We show that even under random assignment only the instantaneous average treatment effect is point identified. Since treated and control units drop out at different rates, randomization only ensures the comparability of treatment and controls at the time of randomization, so that long-run average treatment effects are not point identified. Instead we derive informative bounds on these average treatment effects. Our bounds do not impose (semi)parametric restrictions, for example, proportional hazards. We also explore various assumptions such as monotone treatment response, common shocks and positively correlated outcomes that tighten the bounds.","40 pages, 5 tables","Johan Vikström, Geert Ridder, Martin Weidner",economics,val
Inference on Estimators defined by Mathematical Programming,"We propose an inference procedure for estimators defined by mathematical programming problems, focusing on the important special cases of linear programming (LP) and quadratic programming (QP). In these settings, the coefficients in both the objective function and the constraints of the mathematical programming problem may be estimated from data and hence involve sampling error. Our inference approach exploits the characterization of the solutions to these programming problems by complementarity conditions; by doing so, we can transform the problem of doing inference on the solution of a constrained optimization problem (a non-standard inference problem) into one involving inference based on a set of inequalities with pre-estimated coefficients, which is much better understood. We evaluate the performance of our procedure in several Monte Carlo simulations and an empirical application to the classic portfolio selection problem in finance.",,"Yu-Wei Hsieh, Xiaoxia Shi, Matthew Shum",economics,test
Sharp bounds and testability of a Roy model of STEM major choices,"We analyze the empirical content of the Roy model, stripped down to its essential features, namely sector specific unobserved heterogeneity and self-selection on the basis of potential outcomes. We characterize sharp bounds on the joint distribution of potential outcomes and testable implications of the Roy self-selection model under an instrumental constraint on the joint distribution of potential outcomes we call stochastically monotone instrumental variable (SMIV). We show that testing the Roy model selection is equivalent to testing stochastic monotonicity of observed outcomes relative to the instrument. We apply our sharp bounds to the derivation of a measure of departure from Roy self-selection to identify values of observable characteristics that induce the most costly misallocation of talent and sector and are therefore prime targets for intervention. Special emphasis is put on the case of binary outcomes, which has received little attention in the literature to date. For richer sets of outcomes, we emphasize the distinction between pointwise sharp bounds and functional sharp bounds, and its importance, when constructing sharp bounds on functional features, such as inequality measures. We analyze a Roy model of college major choice in Canada and Germany within this framework, and we take a new look at the under-representation of women in~STEM.",,"Ismael Mourifie, Marc Henry, Romuald Meango",economics,train
Zero-rating of Content and its Effect on the Quality of Service in the Internet,"The ongoing net neutrality debate has generated a lot of heated discussions on whether or not monetary interactions should be regulated between content and access providers. Among the several topics discussed, `differential pricing' has recently received attention due to `zero-rating' platforms proposed by some service providers. In the differential pricing scheme, Internet Service Providers (ISPs) can exempt data access charges for on content from certain CPs (zero-rated) while no exemption is on content from other CPs. This allows the possibility for Content Providers (CPs) to make `sponsorship' agreements to zero-rate their content and attract more user traffic. In this paper, we study the effect of differential pricing on various players in the Internet. We first consider a model with a monopolistic ISP and multiple CPs where users select CPs based on the quality of service (QoS) and data access charges. We show that in a differential pricing regime 1) a CP offering low QoS can make have higher surplus than a CP offering better QoS through sponsorships. 2) Overall QoS (mean delay) for end users can degrade under differential pricing schemes. In the oligopolistic market with multiple ISPs, users tend to select the ISP with lowest ISP resulting in same type of conclusions as in the monopolistic market. We then study how differential pricing effects the revenue of ISPs.",,"Manjesh K. Hanawal, Fehmina Malik, Yezekael Hayel",economics,train
Quasi-random Monte Carlo application in CGE systematic sensitivity analysis,"The uncertainty and robustness of Computable General Equilibrium models can be assessed by conducting a Systematic Sensitivity Analysis. Different methods have been used in the literature for SSA of CGE models such as Gaussian Quadrature and Monte Carlo methods. This paper explores the use of Quasi-random Monte Carlo methods based on the Halton and Sobol' sequences as means to improve the efficiency over regular Monte Carlo SSA, thus reducing the computational requirements of the SSA. The findings suggest that by using low-discrepancy sequences, the number of simulations required by the regular MC SSA methods can be notably reduced, hence lowering the computational time required for SSA of CGE models.","7 pages, 6 figures, Submitted",Theodoros Chatzivasileiadis,economics,val
Estimation of Peer Effects in Endogenous Social Networks: Control Function Approach,"We propose a method of estimating the linear-in-means model of peer effects in which the peer group, defined by a social network, is endogenous in the outcome equation for peer effects. Endogeneity is due to unobservable individual characteristics that influence both link formation in the network and the outcome of interest. We propose two estimators of the peer effect equation that control for the endogeneity of the social connections using a control function approach. We leave the functional form of the control function unspecified and treat it as unknown. To estimate the model, we use a sieve semiparametric approach, and we establish asymptotics of the semiparametric estimator.",,"Ida Johnsson, Hyungsik Roger Moon",economics,val
Forecasting with Dynamic Panel Data Models,This paper considers the problem of forecasting a collection of short time series using cross sectional information in panel data. We construct point predictors using Tweedie's formula for the posterior mean of heterogeneous coefficients under a correlated random effects distribution. This formula utilizes cross-sectional information to transform the unit-specific (quasi) maximum likelihood estimator into an approximation of the posterior mean under a prior distribution that equals the population distribution of the random coefficients. We show that the risk of a predictor based on a non-parametric estimate of the Tweedie correction is asymptotically equivalent to the risk of a predictor that treats the correlated-random-effects distribution as known (ratio-optimality). Our empirical Bayes predictor performs well compared to various competitors in a Monte Carlo study. In an empirical application we use the predictor to forecast revenues for a large panel of bank holding companies and compare forecasts that condition on actual and severely adverse macroeconomic conditions.,,"Laura Liu, Hyungsik Roger Moon, Frank Schorfheide",economics,test
Inference for VARs Identified with Sign Restrictions,"There is a fast growing literature that set-identifies structural vector autoregressions (SVARs) by imposing sign restrictions on the responses of a subset of the endogenous variables to a particular structural shock (sign-restricted SVARs). Most methods that have been used to construct pointwise coverage bands for impulse responses of sign-restricted SVARs are justified only from a Bayesian perspective. This paper demonstrates how to formulate the inference problem for sign-restricted SVARs within a moment-inequality framework. In particular, it develops methods of constructing confidence bands for impulse response functions of sign-restricted SVARs that are valid from a frequentist perspective. The paper also provides a comparison of frequentist and Bayesian coverage bands in the context of an empirical application - the former can be substantially wider than the latter.",,"Eleonora Granziera, Hyungsik Roger Moon, Frank Schorfheide",economics,val
Heterogeneous Employment Effects of Job Search Programmes: A Machine Learning Approach,"We systematically investigate the effect heterogeneity of job search programmes for unemployed workers. To investigate possibly heterogeneous employment effects, we combine non-experimental causal empirical models with Lasso-type estimators. The empirical analyses are based on rich administrative data from Swiss social security records. We find considerable heterogeneities only during the first six months after the start of training. Consistent with previous results of the literature, unemployed persons with fewer employment opportunities profit more from participating in these programmes. Furthermore, we also document heterogeneous employment effects by residence status. Finally, we show the potential of easy-to-implement programme participation rules for improving average employment effects of these active labour market programmes.",,"Michael Knaus, Michael Lechner, Anthony Strittmatter",economics,train
Identification and Estimation of Multidimensional Screening,"We study the identification and estimation of a multidimensional screening model, where a monopolist sells a multi-attribute product to consumers with private information about their multidimensional preferences. Under optimal screening, the seller designs product and payment rules that exclude ""low-type"" consumers, bunches the ""medium types"" at ""medium-quality"" products, and perfectly screens the ""high types."" Under the assumption that the cost function is quadratic and additively separable in products, we determine sufficient conditions to identify the joint distribution of preferences and the marginal costs from data on optimal individual choices and payments. Then, we propose estimators for these objects, establish their asymptotic properties, and assess their small-sample performance using Monte Carlo experiments.",,"Gaurab Aryal, Federico Zincenko",economics,train
The Mittag-Leffler Fitting of the Phillips Curve,"In this paper, a mathematical model based on the one-parameter Mittag-Leffler function is proposed to be used for the first time to describe the relation between unemployment rate and inflation rate, also known as the Phillips curve. The Phillips curve is in the literature often represented by an exponential-like shape. On the other hand, Phillips in his fundamental paper used a power function in the model definition. Considering that the ordinary as well as generalised Mittag-Leffler function behaves between a purely exponential function and a power function it is natural to implement it in the definition of the model used to describe the relation between the data representing the Phillips curve. For the modelling purposes the data of two different European economies, France and Switzerland, were used and an ""out-of-sample"" forecast was done to compare the performance of the Mittag-Leffler model to the performance of the power-type and exponential-type model. The results demonstrate that the ability of the Mittag-Leffler function to fit data that manifest signs of stretched exponentials, oscillations or even damped oscillations can be of use when describing economic relations and phenomenons, such as the Phillips curve.","20 pages, 4 figures, 3 tables, 7 numbered equations",Tomas Skovranek,economics,train
Economic Development and Inequality: a complex system analysis,"By borrowing methods from complex system analysis, in this paper we analyze the features of the complex relationship that links the development and the industrialization of a country to economic inequality. In order to do this, we identify industrialization as a combination of a monetary index, the GDP per capita, and a recently introduced measure of the complexity of an economy, the Fitness. At first we explore these relations on a global scale over the time period 1990--2008 focusing on two different dimensions of inequality: the capital share of income and a Theil measure of wage inequality. In both cases, the movement of inequality follows a pattern similar to the one theorized by Kuznets in the fifties. We then narrow down the object of study ad we concentrate on wage inequality within the United States. By employing data on wages and employment on the approximately 3100 US counties for the time interval 1990--2014, we generalize the Fitness-Complexity algorithm for counties and NAICS sectors, and we investigate wage inequality between industrial sectors within counties. At this scale, in the early nineties we recover a behavior similar to the global one. While, in more recent years, we uncover a trend reversal: wage inequality monotonically increases as industrialization levels grow. Hence at a county level, at net of the social and institutional factors that differ among countries, we not only observe an upturn in inequality but also a change in the structure of the relation between wage inequality and development.",,"Angelica Sbardella, Emanuele Pugliese, Luciano Pietronero",economics,val
Banks as Tanks: A Continuous-Time Model of Financial Clearing,"We present a simple continuous-time model of clearing in financial networks. Financial firms are represented as ""tanks"" filled with fluid (money), flowing in and out. Once ""pipes"" connecting ""tanks"" are open, the system reaches the clearing payment vector in finite time. This approach provides a simple recursive solution to a classical static model of financial clearing in bankruptcy, and suggests a practical payment mechanism. With sufficient resources, a system of mutual obligations can be restructured into an equivalent system that has a cascade structure: there is a group of banks that paid off their debts, another group that owes money only to banks in the first group, and so on. Technically, we use the machinery of Markov chains to analyze evolution of a deterministic dynamical system.",,"Isaac M. Sonin, Konstantin Sonin",economics,train
"Economic Complexity: ""Buttarla in caciara"" vs a constructive approach","This note is a contribution to the debate about the optimal algorithm for Economic Complexity that recently appeared on ArXiv [1, 2] . The authors of [2] eventually agree that the ECI+ algorithm [1] consists just in a renaming of the Fitness algorithm we introduced in 2012, as we explicitly showed in [3]. However, they omit any comment on the fact that their extensive numerical tests claimed to demonstrate that the same algorithm works well if they name it ECI+, but not if its name is Fitness. They should realize that this eliminates any credibility to their numerical methods and therefore also to their new analysis, in which they consider many algorithms [2]. Since by their own admission the best algorithm is the Fitness one, their new claim became that the search for the best algorithm is pointless and all algorithms are alike. This is exactly the opposite of what they claimed a few days ago and it does not deserve much comments. After these clarifications we also present a constructive analysis of the status of Economic Complexity, its algorithms, its successes and its perspectives. For us the discussion closes here, we will not reply to further comments.",,"Luciano Pietronero, Matthieu Cristelli, Andrea Gabrielli, Dario Mazzilli, Emanuele Pugliese, Andrea Tacchella, Andrea Zaccaria",economics,train
Interpreting Economic Complexity,"Two network measures known as the Economic Complexity Index (ECI) and Product Complexity Index (PCI) have provided important insights into patterns of economic development. We show that the ECI and PCI are equivalent to a spectral clustering algorithm that partitions a similarity graph into two parts. The measures are also related to various dimensionality reduction methods and can be interpreted as vectors that determine distances between nodes based on their similarity. Our results shed a new light on the ECI's empirical success in explaining cross-country differences in GDP/capita and economic growth, which is often linked to the diversity of country export baskets. In fact, countries with high (low) ECI tend to specialize in high (low) PCI products. We also find that the ECI and PCI uncover economically informative specialization patterns across US states and UK regions.",Revision of previous version,"Penny Mealy, J. Doyne Farmer, Alexander Teytelboym",quantitative finance,val
Forecasting the sustainable status of the labor market in agriculture,"In this article, a game-theoretic model is constructed that is related to the problem of optimal assignments. Examples are considered. A compromise point is found, the Nash equilibriums and the decision of the Nash arbitration scheme are constructed.",,"O. A. Malafeyev, V. E. Onishenko, I. V. Zaytseva",economics,train
Justifying the Adoption and Relevance of Inflation Targeting Framework: A Time-Varying Evidence from Ghana,"This paper scrutinizes the rationale for the adoption of inflation targeting (IT) by Bank of Ghana in 2002. In this case, we determine the stability or otherwise of the relationship between money supply and inflation in Ghana over the period 1970M1-2016M3 using battery of econometric methods. The empirical results show an unstable link between inflation and monetary growth in Ghana, while the final state coefficient of inflation elasticity to money growth is positive but statistically insignificant. We find that inflation elasticity to monetary growth has continued to decline since the 1970s, showing a waning impact of money growth on inflation in Ghana. Notably, there is also evidence of negative inflation elasticity to monetary growth between 2001 and 2004, lending support to the adoption of IT framework in Ghana in 2002. We emphasized that the unprecedented 31-months of single-digit inflation (June 2010-December 2012), despite the observed inflationary shocks in 2010 and 2012, reinforces the immense contribution of the IT framework in anchoring inflation expectations, with better inflation outcomes and inflation variability in Ghana. The paper therefore recommends the continuous pursuance and strengthening of the IT framework in Ghana, as it embodies a more eclectic approach to policy formulation and implementation.",,"Nana Kwame Akosah, Francis W. Loloh, Maurice Omane-Adjepong",economics,train
How do public research labs use funding for research? A case study,"This paper discusses how public research organizations consume funding for research, applying a new approach based on economic metabolism of research labs, in a broad analogy with biology. This approach is applied to a case study in Europe represented by one of the biggest European public research organizations, the National Research council of Italy. Results suggest that funding for research (state subsidy and public contracts) of this public research organization is mainly consumed for the cost of personnel. In addition, the analysis shows a disproportionate growth of the cost of personnel in public research labs in comparison with total revenue from government. In the presence of shrinking public research lab budgets, this organizational behavior generates inefficiencies and stress. R&D management and public policy implications are suggested for improving economic performance of public research organizations in turbulent markets.",33 pages; 4 tables; 7 figures (4 in text + 3 in appendix),Mario Coccia,economics,train
A Physical Review on Currency,"A theoretical self-sustainable economic model is established based on the fundamental factors of production, consumption, reservation and reinvestment, where currency is set as a unconditional credit symbol serving as transaction equivalent and stock means. Principle properties of currency are explored in this ideal economic system. Physical analysis reveals some facts that were not addressed by traditional monetary theory, and several basic principles of ideal currency are concluded: 1. The saving-replacement is a more primary function of currency than the transaction equivalents; 2. The ideal efficiency of currency corresponds to the least practical value; 3. The contradiction between constant face value of currency and depreciable goods leads to intrinsic inflation.","14 pages, 6 figures",Ran Huang,economics,train
Payoff Information and Learning in Signaling Games,"We add the assumption that players know their opponents' payoff functions and rationality to a model of non-equilibrium learning in signaling games. Agents are born into player roles and play against random opponents every period. Inexperienced agents are uncertain about the prevailing distribution of opponents' play, but believe that opponents never choose conditionally dominated strategies. Agents engage in active learning and update beliefs based on personal observations. Payoff information can refine or expand learning predictions, since patient young senders' experimentation incentives depend on which receiver responses they deem plausible. We show that with payoff knowledge, the limiting set of long-run learning outcomes is bounded above by rationality-compatible equilibria (RCE), and bounded below by uniform RCE. RCE refine the Intuitive Criterion (Cho and Kreps, 1987) and include all divine equilibria (Banks and Sobel, 1987). Uniform RCE sometimes but not always exists, and implies universally divine equilibrium.","This material was previously part of a larger paper titled
  ""Type-Compatible Equilibria in Signalling Games,"" which split into two
  smaller papers: ""Learning and Type Compatibility in Signaling Games"" and
  ""Payoff Information and Learning in Signaling Games.""","Drew Fudenberg, Kevin He",economics,train
Player-Compatible Learning and Player-Compatible Equilibrium,"Player-Compatible Equilibrium (PCE) imposes cross-player restrictions on the magnitudes of the players' ""trembles"" onto different strategies. These restrictions capture the idea that trembles correspond to deliberate experiments by agents who are unsure of the prevailing distribution of play. PCE selects intuitive equilibria in a number of examples where trembling-hand perfect equilibrium (Selten, 1975) and proper equilibrium (Myerson, 1978) have no bite. We show that rational learning and weighted fictitious play imply our compatibility restrictions in a steady-state setting.",,"Drew Fudenberg, Kevin He",economics,val
Investigating Wheat Price with a Multi-Agent Model,"In this paper, we build a computational model for the analysis of international wheat spot price formation, its dynamics and the dynamics of internationally exchanged quantities. The model has been calibrated using FAOSTAT data to evaluate its in-sample predictive power. The model is able to generate wheat prices in twelve international markets and wheat used quantities in twenty-four world regions. The time span considered goes from 1992 to 2013. In our study, a particular attention was paid to the impact of Russian Federation's 2010 grain export ban on wheat price and internationally traded quantities. Among other results, we find that wheat average weighted world price in 2013 would have been 3.55\% lower than the observed one if the Russian Federation would not have imposed the export ban in 2010.","24 pages, 14 figures, Submitted to the Journal of Artificial
  Societies and Social Simulation (JASSS)","Gianfranco Giulioni, Edmondo Di Giuseppe, Massimiliano Pasqui, Piero Toscano, Francesco Miglietta",economics,train
Exceeding Expectations: Stochastic Dominance as a General Decision Theory,"The principle that rational agents should maximize expected utility or choiceworthiness is intuitively plausible in many ordinary cases of decision-making under uncertainty. But it is less plausible in cases of extreme, low-probability risk (like Pascal's Mugging), and intolerably paradoxical in cases like the St. Petersburg and Pasadena games. In this paper I show that, under certain conditions, stochastic dominance reasoning can capture most of the plausible implications of expectational reasoning while avoiding most of its pitfalls. Specifically, given sufficient background uncertainty about the choiceworthiness of one's options, many expectation-maximizing gambles that do not stochastically dominate their alternatives ""in a vacuum"" become stochastically dominant in virtue of that background uncertainty. But, even under these conditions, stochastic dominance will not require agents to accept options whose expectational superiority depends on sufficiently small probabilities of extreme payoffs. The sort of background uncertainty on which these results depend looks unavoidable for any agent who measures the choiceworthiness of her options in part by the total amount of value in the resulting world. At least for such agents, then, stochastic dominance offers a plausible general principle of choice under uncertainty that can explain more of the apparent rational constraints on such choices than has previously been recognized.",,Christian Tarsney,economics,test
Banking Stability System: Does it Matter if the Rate of Return is Fixed or Stochastic?,"The purpose is to compare the perfect Stochastic Return (SR) model like Islamic banks to the Fixed Return (FR) model as in conventional banks by measuring up their impacts at the macroeconomic level. We prove that if the optimal choice of investor share in SR model {\alpha}* realizes the indifference of the financial institution toward SR and FR models, there exists {\alpha} less than {\alpha}* such that the banks strictly prefers the SR model. Also, there exists {\alpha}, {\gamma} and {\lambda} verifying the conditions of {\alpha}-sharing such that each party in economy can be better under the SR model and the economic welfare could be improved in a Pareto-efficient way.",,Hassan Ghassan,economics,train
Preference Identification,"An experimenter seeks to learn a subject's preference relation. The experimenter produces pairs of alternatives. For each pair, the subject is asked to choose. We argue that, in general, large but finite data do not give close approximations of the subject's preference, even when the limiting (countably infinite) data are enough to infer the preference perfectly. We provide sufficient conditions on the set of alternatives, preferences, and sequences of pairs so that the observation of finitely many choices allows the experimenter to learn the subject's preference with arbitrary precision. While preferences can be identified under our sufficient conditions, we show that it is harder to identify utility functions. We illustrate our results with several examples, including consumer choice, expected utility, and preferences in the Anscombe-Aumann model.",,"Christopher P. Chambers, Federico Echenique, Nicolas S. Lambert",economics,train
Strictly strategy-proof auctions,"A strictly strategy-proof mechanism is one that asks agents to use strictly dominant strategies. In the canonical one-dimensional mechanism design setting with private values, we show that strict strategy-proofness is equivalent to strict monotonicity plus the envelope formula, echoing a well-known characterisation of (weak) strategy-proofness. A consequence is that strategy-proofness can be made strict by an arbitrarily small modification, so that strictness is 'essentially for free'.",,"Matteo Escudé, Ludvig Sinander",economics,train
Dynamic Random Subjective Expected Utility,"Dynamic Random Subjective Expected Utility (DR-SEU) allows to model choice data observed from an agent or a population of agents whose beliefs about objective payoff-relevant states and tastes can both evolve stochastically. Our observable, the augmented Stochastic Choice Function (aSCF) allows, in contrast to previous work in decision theory, for a direct test of whether the agent's beliefs reflect the true data-generating process conditional on their private information as well as identification of the possibly incorrect beliefs. We give an axiomatic characterization of when an agent satisfies the model, both in a static as well as in a dynamic setting. We look at the case when the agent has correct beliefs about the evolution of objective states as well as at the case when her beliefs are incorrect but unforeseen contingencies are impossible. We also distinguish two subvariants of the dynamic model which coincide in the static setting: Evolving SEU, where a sophisticated agent's utility evolves according to a Bellman equation and Gradual Learning, where the agent is learning about her taste. We prove easy and natural comparative statics results on the degree of belief incorrectness as well as on the speed of learning about taste. Auxiliary results contained in the online appendix extend previous decision theory work in the menu choice and stochastic choice literature from a technical as well as a conceptual perspective.","online appendix available on
  https://sites.google.com/site/jetlirduraj1/",Jetlir Duraj,economics,train
"A characterization of ""Phelpsian"" statistical discrimination","We establish that statistical discrimination is possible if and only if it is impossible to uniquely identify the signal structure observed by an employer from a realized empirical distribution of skills. The impossibility of statistical discrimination is shown to be equivalent to the existence of a fair, skill-dependent, remuneration for workers. Finally, we connect the statistical discrimination literature to Bayesian persuasion, establishing that if discrimination is absent, then the optimal signaling problem results in a linear payoff function (as well as a kind of converse).",,"Christopher P. Chambers, Federico Echenique",economics,val
Existence of Equilibrium Prices: A Pedagogical Proof,"Under the same assumptions made by Mas-Colell et al. (1995), I develop a short, simple, and complete proof of existence of equilibrium prices based on excess demand functions. The result is obtained by applying the Brouwer fixed point theorem to a trimmed simplex which does not contain prices equal to zero. The mathematical techniques are based on some results obtained in Neuefeind (1980) and Geanakoplos (2003).",,Simone Tonin,economics,train
